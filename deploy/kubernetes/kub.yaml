apiVersion: apps/v1
kind: Deployment
metadata:
  name: litellm-deployment
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      app: litellm
  template:
    metadata:
      labels:
        app: litellm
    spec:
      volumes:
        - name: config-volume
          emptyDir: {}
      initContainers:
        - name: init-config
          image: busybox
          command:
            - sh
            - -c
            - |
              mkdir -p /config && cat <<EOF > /config/proxy_config.yaml
              litellm_settings:
                cache: true 
                cache_params:
                  type: redis
                  namespace: "litellm.caching.caching"
              EOF
          volumeMounts:
            - name: config-volume
              mountPath: /config
    spec:
      containers:
        - name: litellm-container
          image: ghcr.io/berriai/litellm:main-latest # recommended to lock it to a version in prod (like ghcr.io/berriai/litellm:main-v1.67.0-stable)
          imagePullPolicy: Always
          env: # Recommended to use secrets and mount them here
            - name: AZURE_API_KEY
              value: "d6f****"
            - name: AZURE_API_BASE
              value: "https://openai"
            - name: LITELLM_MASTER_KEY
              value: "sk-1234"
            - name: DATABASE_URL
              value: "postgresql://ishaan*********"
          # envFrom:
          #   - secretRef:
          #       name: litellm-secrets
          args:
            - "--config"
            - "/app/proxy_config.yaml"  # Update the path to mount the config file
          volumeMounts:                 # Define volume mount for proxy_config.yaml
            - name: config-volume       # Here, init container creates the config file, and can store the configs 
              mountPath: /app
              readOnly: true
          resources:
            requests:
              cpu: "100m"
              memory: "128Mi"
            limits:
              cpu: "500m"
              memory: "512Mi"
          livenessProbe:
            httpGet:
              path: /health/liveliness
              port: 4000
            initialDelaySeconds: 120
            periodSeconds: 15
            successThreshold: 1
            failureThreshold: 3
            timeoutSeconds: 10
          readinessProbe:
            httpGet:
              path: /health/readiness
              port: 4000
            initialDelaySeconds: 120
            periodSeconds: 15
            successThreshold: 1
            failureThreshold: 3
            timeoutSeconds: 10
