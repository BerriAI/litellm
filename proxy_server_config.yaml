model_list:
  - model_name: gpt-4 # user-facing model alias
    litellm_params: # all params accepted by litellm.completion() - https://docs.litellm.ai/docs/completion/input
      model: azure/dp-gpt4
      api_base: xxx
      api_version: 2023-08-01-preview
      api_key: xxx # does os.getenv("AZURE_API_KEY_EU")
      rpm: 6      # Rate limit for this deployment: in requests per minute (rpm)


litellm_settings: # module level litellm settings - https://github.com/BerriAI/litellm/blob/main/litellm/__init__.py
  drop_params: True
  set_verbose: True

#general_settings:
#  master_key: sk-1234 # [OPTIONAL] Only use this if you to require all calls to contain this key (Authorization: Bearer sk-1234)


# model_list:
#   - model_name: gpt-4
#     litellm_params:
#       model: azure/chatgpt-v-2
#       api_base: https://openai-gpt-4-test-v-1.openai.azure.com/
#       api_version: "2023-05-15"
#       api_key: os.environ/AZURE_API_KEY # The `os.environ/` prefix tells litellm to read this from the env. See https://docs.litellm.ai/docs/simple_proxy#load-api-keys-from-vault
#   - model_name: gpt-4
#     litellm_params:
#       model: azure/gpt-turbo
#       api_key: os.environ/AZURE_FRANCE_API_KEY
#       api_base: https://openai-france-1234.openai.azure.com/
#       rpm: 100
#   - model_name: gpt-4
#     litellm_params:
#       model: azure/gpt-35-turbo
#       api_key: os.environ/AZURE_EUROPE_API_KEY
#       api_base: https://my-endpoint-europe-berri-992.openai.azure.com
#       rpm: 10

# litellm_settings:
#   drop_params: True
#   set_verbose: True

# general_settings: 
#   master_key: sk-1234 # [OPTIONAL] Only use this if you to require all calls to contain this key (Authorization: Bearer sk-1234)
#   # database_url: "postgresql://<user>:<password>@<host>:<port>/<dbname>" # [OPTIONAL] use for token-based auth to proxy

# environment_variables:
#   # settings for using redis caching
#   # REDIS_HOST: redis-16337.c322.us-east-1-2.ec2.cloud.redislabs.com
#   # REDIS_PORT: "16337"
#   # REDIS_PASSWORD: 
