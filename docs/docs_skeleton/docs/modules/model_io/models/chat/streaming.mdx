# Streaming

Some Chat models provide a streaming response. This means that instead of waiting for the entire response to be returned, you can start processing it as soon as it's available. This is useful if you want to display the response to the user as it's being generated, or if you want to process the response as it's being generated.

import StreamingChatModel from "@snippets/modules/model_io/models/chat/how_to/streaming.mdx"

<StreamingChatModel/>
