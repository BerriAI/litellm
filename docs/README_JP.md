<h1 align="center">
        ğŸš… LiteLLM
    </h1>
    <p align="center">
        <p align="center">OpenAIã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ã€ã™ã¹ã¦ã®LLM APIã‚’å‘¼ã³å‡ºã™ [Bedrockã€Huggingfaceã€VertexAIã€TogetherAIã€Azureã€OpenAIãªã©]
        <br>
    </p>




<h4 align="center"><a href="https://docs.litellm.ai/docs/simple_proxy" target="_blank">OpenAIãƒ—ãƒ­ã‚­ã‚·ã‚µãƒ¼ãƒãƒ¼ï¼ˆOpenAI Proxy Serverï¼‰</a> | <a href="https://docs.litellm.ai/docs/enterprise"target="_blank">ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºå±¤ï¼ˆEnterprise Tierï¼‰</a></h4>

LiteLLMãŒç®¡ç†ã™ã‚‹ã‚‚ã®:
- ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®`completion`ã€`embedding`ã€`image_generation`ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¸ã®å…¥åŠ›ã®å¤‰æ›
- [ä¸€è²«ã—ãŸå‡ºåŠ›](https://docs.litellm.ai/docs/completion/output)ã€‚ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯å¸¸ã«`['choices'][0]['message']['content']`ã§åˆ©ç”¨å¯èƒ½
- è¤‡æ•°ã®ãƒ‡ãƒ—ãƒ­ã‚¤ï¼ˆAzure/OpenAIãªã©ï¼‰ã«ã‚ãŸã‚‹ãƒªãƒˆãƒ©ã‚¤/ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ­ã‚¸ãƒƒã‚¯ - [ãƒ«ãƒ¼ã‚¿ãƒ¼ï¼ˆRouterï¼‰](https://docs.litellm.ai/docs/routing)
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã€APIã‚­ãƒ¼ã€ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®äºˆç®—ã¨æ–™é‡‘åˆ¶é™ã®è¨­å®š [OpenAIãƒ—ãƒ­ã‚­ã‚·ã‚µãƒ¼ãƒãƒ¼ï¼ˆOpenAI Proxy Serverï¼‰](https://docs.litellm.ai/docs/simple_proxy)

**å®‰å®šãƒªãƒªãƒ¼ã‚¹**: v`1.30.2` ğŸ‘ˆ ãƒ—ãƒ­ã‚­ã‚·ã®æ¨å¥¨å®‰å®šãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€‚

[**OpenAIãƒ—ãƒ­ã‚­ã‚·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã‚¸ãƒ£ãƒ³ãƒ—ï¼ˆJump to OpenAI Proxy Docsï¼‰**](https://github.com/BerriAI/litellm?tab=readme-ov-file#openai-proxy---docs) <br>
[**ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«ã‚¸ãƒ£ãƒ³ãƒ—ï¼ˆJump to Supported LLM Providersï¼‰**](https://github.com/BerriAI/litellm?tab=readme-ov-file#supported-provider-docs)

ã‚ˆã‚Šå¤šãã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’ã‚µãƒãƒ¼ãƒˆã€‚ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚„LLMãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯ã€[æ©Ÿèƒ½ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆfeature requestï¼‰](https://github.com/BerriAI/litellm/issues/new?assignees=&labels=enhancement&projects=&template=feature_request.yml&title=%5BFeature%5D%3A+)ã‚’ä¸Šã’ã¦ãã ã•ã„ã€‚

# ä½¿ç”¨æ–¹æ³•ï¼ˆUsageï¼‰ ([**ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆDocsï¼‰**](https://docs.litellm.ai/docs/))
> [!é‡è¦ï¼ˆIMPORTANTï¼‰]
> LiteLLM v1.0.0ã§ã¯ã€`openai>=1.0.0`ãŒå¿…è¦ã«ãªã‚Šã¾ã—ãŸã€‚ç§»è¡Œã‚¬ã‚¤ãƒ‰ï¼ˆmigration guideï¼‰ã¯[ã“ã¡ã‚‰](https://docs.litellm.ai/docs/migration)


<a target="_blank" href="https://colab.research.google.com/github/BerriAI/litellm/blob/main/cookbook/liteLLM_Getting_Started.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabã§é–‹ãï¼ˆOpen In Colabï¼‰"/>
</a>


```shell
pip install litellm
```

```python
from litellm import completion
import os

## ç’°å¢ƒå¤‰æ•°ã®è¨­å®š 
os.environ["OPENAI_API_KEY"] = "your-openai-key" 
os.environ["COHERE_API_KEY"] = "your-cohere-key" 

messages = [{ "content": "ã“ã‚“ã«ã¡ã¯ã€å…ƒæ°—ã§ã™ã‹ï¼Ÿ","role": "user"}]

# OpenAIã®å‘¼ã³å‡ºã—
response = completion(model="gpt-3.5-turbo", messages=messages)

# Cohereã®å‘¼ã³å‡ºã—
response = completion(model="command-nightly", messages=messages)
print(response)
```

`model=<provider_name>/<model_name>`ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒã‚µãƒãƒ¼ãƒˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚ã“ã“ã«ã¯ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å›ºæœ‰ã®è©³ç´°ãŒå«ã¾ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€è©³ç´°ã«ã¤ã„ã¦ã¯[ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆprovider docsï¼‰](https://docs.litellm.ai/docs/providers)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

## éåŒæœŸï¼ˆAsyncï¼‰ ([ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆDocsï¼‰](https://docs.litellm.ai/docs/completion/stream#async-completion))

```python
from litellm import acompletion
import asyncio

async def test_get_response():
    user_message = "ã“ã‚“ã«ã¡ã¯ã€å…ƒæ°—ã§ã™ã‹ï¼Ÿ"
    messages = [{"content": user_message, "role": "user"}]
    response = await acompletion(model="gpt-3.5-turbo", messages=messages)
    return response

response = asyncio.run(test_get_response())
print(response)
```

## ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼ˆStreamingï¼‰ ([ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆDocsï¼‰](https://docs.litellm.ai/docs/completion/stream))
liteLLMã¯ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚`stream=True`ã‚’æ¸¡ã™ã¨ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ãƒ¼ãŒè¿”ã•ã‚Œã¾ã™ã€‚  
ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã¯ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ï¼ˆBedrockã€Huggingfaceã€TogetherAIã€Azureã€OpenAIãªã©ï¼‰ã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚
```python
from litellm import completion
response = completion(model="gpt-3.5-turbo", messages=messages, stream=True)
for part in response:
    print(part.choices[0].delta.content or "")

# claude 2
response = completion('claude-2', messages, stream=True)
for part in response:
    print(part.choices[0].delta.content or "")
```

## ãƒ­ã‚®ãƒ³ã‚°ç›£è¦–ï¼ˆLogging Observabilityï¼‰ ([ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆDocsï¼‰](https://docs.litellm.ai/docs/observability/callbacks))
LiteLLMã¯ã€Langfuseã€DynamoDBã€S3ãƒã‚±ãƒƒãƒˆã€LLMonitorã€Heliconeã€Promptlayerã€Traceloopã€Athinaã€Slackã«ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡ã™ã‚‹ãŸã‚ã®å®šç¾©æ¸ˆã¿ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å…¬é–‹ã—ã¦ã„ã¾ã™ã€‚
```python
from litellm import completion

## ãƒ­ã‚®ãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã®ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š
os.environ["LANGFUSE_PUBLIC_KEY"] = ""
os.environ["LANGFUSE_SECRET_KEY"] = ""
os.environ["LLMONITOR_APP_ID"] = "your-llmonitor-app-id"
os.environ["ATHINA_API_KEY"] = "your-athina-api-key"

os.environ["OPENAI_API_KEY"]

# ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã®è¨­å®š
litellm.success_callback = ["langfuse", "llmonitor", "athina"] # å…¥åŠ›/å‡ºåŠ›ã‚’Langfuseã€LLMonitorã€Supabaseã€Athinaãªã©ã«ãƒ­ã‚°

# OpenAIã®å‘¼ã³å‡ºã—
response = completion(model="gpt-3.5-turbo", messages=[{"role": "user", "content": "ã“ã‚“ã«ã¡ã¯ ğŸ‘‹ - ç§ã¯OpenAIã§ã™"}])
```

# OpenAIãƒ—ãƒ­ã‚­ã‚·ï¼ˆOpenAI Proxyï¼‰ - ([ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆDocsï¼‰](https://docs.litellm.ai/docs/simple_proxy))

è¤‡æ•°ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã¾ãŸãŒã‚‹äºˆç®—ã¨æ–™é‡‘åˆ¶é™ã‚’è¨­å®š

ãƒ—ãƒ­ã‚­ã‚·ãŒæä¾›ã™ã‚‹ã‚‚ã®: 
1. [èªè¨¼ç”¨ãƒ•ãƒƒã‚¯ï¼ˆHooks for authï¼‰](https://docs.litellm.ai/docs/proxy/virtual_keys#custom-auth)
2. [ãƒ­ã‚®ãƒ³ã‚°ç”¨ãƒ•ãƒƒã‚¯ï¼ˆHooks for loggingï¼‰](https://docs.litellm.ai/docs/proxy/logging#step-1---create-your-custom-litellm-callback-class)
3. [ã‚³ã‚¹ãƒˆè¿½è·¡ï¼ˆCost trackingï¼‰](https://docs.litellm.ai/docs/proxy/virtual_keys#tracking-spend)
4. [ãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼ˆRate Limitingï¼‰](https://docs.litellm.ai/docs/proxy/users#set-rate-limits)

## ğŸ“– ãƒ—ãƒ­ã‚­ã‚·ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆProxy Endpointsï¼‰ - [Swaggerãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆSwagger Docsï¼‰](https://litellm-api.up.railway.app/)

## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆãƒ—ãƒ­ã‚­ã‚·ï¼ˆQuick Start Proxyï¼‰ - CLI 

```shell
pip install 'litellm[proxy]'
```

### ã‚¹ãƒ†ãƒƒãƒ—1: litellmãƒ—ãƒ­ã‚­ã‚·ã‚’èµ·å‹•
```shell
$ litellm --model huggingface/bigcode/starcoder

#æƒ…å ±ï¼ˆINFOï¼‰: ãƒ—ãƒ­ã‚­ã‚·ãŒhttp://0.0.0.0:4000ã§å®Ÿè¡Œä¸­
```

### ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ—ãƒ­ã‚­ã‚·ã«ChatCompletionsãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
```python
import openai # openai v1.0.0ä»¥é™
client = openai.OpenAI(api_key="anything",base_url="http://0.0.0.0:4000") # ãƒ—ãƒ­ã‚­ã‚·ã‚’base_urlã«è¨­å®š
# litellmãƒ—ãƒ­ã‚­ã‚·ã§è¨­å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«é€ä¿¡ã•ã‚ŒãŸãƒªã‚¯ã‚¨ã‚¹ãƒˆã€`litellm --model`
response = client.chat.completions.create(model="gpt-3.5-turbo", messages = [
    {
        "role": "user",
        "content": "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ã™ã€‚çŸ­ã„è©©ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚"
    }
])

print(response)
```

## ãƒ—ãƒ­ã‚­ã‚·ã‚­ãƒ¼ç®¡ç†ï¼ˆProxy Key Managementï¼‰ ([ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆDocsï¼‰](https://docs.litellm.ai/docs/proxy/virtual_keys))
ãƒ—ãƒ­ã‚­ã‚·ã‚µãƒ¼ãƒãƒ¼ã®`/ui`ã«ã‚ã‚‹UI 
![ui_3](https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033)

è¤‡æ•°ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã¾ãŸãŒã‚‹äºˆç®—ã¨æ–™é‡‘åˆ¶é™ã‚’è¨­å®š
`POST /key/generate`

### ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆRequestï¼‰
```shell
curl 'http://0.0.0.0:4000/key/generate' \
--header 'Authorization: Bearer sk-1234' \
--header 'Content-Type: application/json' \
--data-raw '{"models": ["gpt-3.5-turbo", "gpt-4", "claude-2"], "duration": "20m","metadata": {"user": "ishaan@berri.ai", "team": "core-infra"}}'
```

### æœŸå¾…ã•ã‚Œã‚‹ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆExpected Responseï¼‰
```shell
{
    "key": "sk-kdEXbIqZRwEeEiHwdg7sFA", # Bearer token
    "expires": "2023-11-19T01:38:25.838000+00:00" # datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
}
```

## ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆSupported Providersï¼‰ ([ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆDocsï¼‰](https://docs.litellm.ai/docs/providers))
| ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼      | [Completion](https://docs.litellm.ai/docs/#basic-usage) | [Streaming](https://docs.litellm.ai/docs/completion/stream#streaming-responses)  | [Async Completion](https://docs.litellm.ai/docs/completion/stream#async-completion)  | [Async Streaming](https://docs.litellm.ai/docs/completion/stream#async-streaming)  | [Async Embedding](https://docs.litellm.ai/docs/embedding/supported_embedding)  | [Async Image Generation](https://docs.litellm.ai/docs/image_generation)  | 
| ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- |
| [openai](https://docs.litellm.ai/docs/providers/openai)  | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
| [azure](https://docs.litellm.ai/docs/providers/azure)  | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
| [aws - sagemaker](https://docs.litellm.ai/docs/providers/aws_sagemaker)  | âœ… | âœ… | âœ… | âœ… | âœ… |
| [aws - bedrock](https://docs.litellm.ai/docs/providers/bedrock)  | âœ… | âœ… | âœ… | âœ… |âœ… |
| [google - vertex_ai [Gemini]](https://docs.litellm.ai/docs/providers/vertex)  | âœ… | âœ… | âœ… | âœ… |
| [google - palm](https://docs.litellm.ai/docs/providers/palm)  | âœ… | âœ… | âœ… | âœ… |
| [google AI Studio - gemini](https://docs.litellm.ai/docs/providers/gemini)  | âœ… |  | âœ… |  | |
| [mistral ai api](https://docs.litellm.ai/docs/providers/mistral)  | âœ… | âœ… | âœ… | âœ… | âœ… |
| [cloudflare AI Workers](https://docs.litellm.ai/docs/providers/cloudflare_workers)  | âœ… | âœ… | âœ… | âœ… |
| [cohere](https://docs.litellm.ai/docs/providers/cohere)  | âœ… | âœ… | âœ… | âœ… | âœ… |
| [anthropic](https://docs.litellm.ai/docs/providers/anthropic)  | âœ… | âœ… | âœ… | âœ… |
| [huggingface](https://docs.litellm.ai/docs/providers/huggingface)  | âœ… | âœ… | âœ… | âœ… | âœ… |
| [replicate](https://docs.litellm.ai/docs/providers/replicate)  | âœ… | âœ… | âœ… | âœ… |
| [together_ai](https://docs.litellm.ai/docs/providers/togetherai)  | âœ… | âœ… | âœ… | âœ… |
| [openrouter](https://docs.litellm.ai/docs/providers/openrouter)  | âœ… | âœ… | âœ… | âœ… |
| [ai21](https://docs.litellm.ai/docs/providers/ai21)  | âœ… | âœ… | âœ… | âœ… |
| [baseten](https://docs.litellm.ai/docs/providers/baseten)  | âœ… | âœ… | âœ… | âœ… |
| [vllm](https://docs.litellm.ai/docs/providers/vllm)  | âœ… | âœ… | âœ… | âœ… |
| [nlp_cloud](https://docs.litellm.ai/docs/providers/nlp_cloud)  | âœ… | âœ… | âœ… | âœ… |
| [aleph alpha](https://docs.litellm.ai/docs/providers/aleph_alpha)  | âœ… | âœ… | âœ… | âœ… |
| [petals](https://docs.litellm.ai/docs/providers/petals)  | âœ… | âœ… | âœ… | âœ… |
| [ollama](https://docs.litellm.ai/docs/providers/ollama)  | âœ… | âœ… | âœ… | âœ… |
| [deepinfra](https://docs.litellm.ai/docs/providers/deepinfra)  | âœ… | âœ… | âœ… | âœ… |
| [perplexity-ai](https://docs.litellm.ai/docs/providers/perplexity)  | âœ… | âœ… | âœ… | âœ… |
| [Groq AI](https://docs.litellm.ai/docs/providers/groq)  | âœ… | âœ… | âœ… | âœ… |
| [anyscale](https://docs.litellm.ai/docs/providers/anyscale)  | âœ… | âœ… | âœ… | âœ… |
| [voyage ai](https://docs.litellm.ai/docs/providers/voyage)  |  |  |  |  | âœ… |
| [xinference [Xorbits Inference]](https://docs.litellm.ai/docs/providers/xinference)  |  |  |  |  | âœ… |


[**ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã‚€ï¼ˆRead the Docsï¼‰**](https://docs.litellm.ai/docs/)

## è²¢çŒ®ï¼ˆContributingï¼‰
è²¢çŒ®ã™ã‚‹ã«ã¯: ãƒªãƒã‚¸ãƒˆãƒªã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ã‚¯ãƒ­ãƒ¼ãƒ³ â†’ å¤‰æ›´ã‚’åŠ ãˆã‚‹ â†’ å¤‰æ›´ã‚’å«ã‚€PRã‚’é€ä¿¡ã€‚

ãƒªãƒã‚¸ãƒˆãƒªã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã§å¤‰æ›´ã™ã‚‹æ–¹æ³•ã¯æ¬¡ã®ã¨ãŠã‚Šã§ã™:
ã‚¹ãƒ†ãƒƒãƒ—1: ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³
```
git clone https://github.com/BerriAI/litellm.git
```

ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ç§»å‹•ã—ã€ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«:
```
cd litellm
poetry install
```

ã‚¹ãƒ†ãƒƒãƒ—3: å¤‰æ›´ã‚’ãƒ†ã‚¹ãƒˆ:
```
cd litellm/tests # pwd: Documents/litellm/litellm/tests
poetry run flake8
poetry run pytest .
```

ã‚¹ãƒ†ãƒƒãƒ—4: å¤‰æ›´ã‚’å«ã‚€PRã‚’é€ä¿¡! ğŸš€
- ãƒ•ã‚©ãƒ¼ã‚¯ã—ãŸãƒªãƒã‚¸ãƒˆãƒªã‚’GitHubã«ãƒ—ãƒƒã‚·ãƒ¥
- ãã“ã‹ã‚‰PRã‚’é€ä¿¡

# ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºï¼ˆEnterpriseï¼‰
ã‚ˆã‚Šé«˜ã„ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç†ã€ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‚µãƒãƒ¼ãƒˆã‚’å¿…è¦ã¨ã™ã‚‹ä¼æ¥­å‘ã‘

[å‰µæ¥­è€…ã¨è©±ã™ï¼ˆTalk to foundersï¼‰](https://calendly.com/d/4mp-gd3-k5k/litellm-1-1-onboarding-chat)

ã“ã‚Œã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã¾ã™:
- âœ… **[LiteLLMå•†ç”¨ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ï¼ˆLiteLLM Commercial Licenseï¼‰](https://docs.litellm.ai/docs/proxy/enterprise)ã®æ©Ÿèƒ½:**
- âœ… **æ©Ÿèƒ½ã®å„ªå…ˆé †ä½ä»˜ã‘ï¼ˆFeature Prioritizationï¼‰**
- âœ… **ã‚«ã‚¹ã‚¿ãƒ çµ±åˆï¼ˆCustom Integrationsï¼‰**
- âœ… **ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‚µãƒãƒ¼ãƒˆ - å°‚ç”¨ã®Discord + Slackï¼ˆProfessional Support - Dedicated discord + slackï¼‰**
- âœ… **ã‚«ã‚¹ã‚¿ãƒ SLAï¼ˆCustom SLAsï¼‰**
- âœ… **ã‚·ãƒ³ã‚°ãƒ«ã‚µã‚¤ãƒ³ã‚ªãƒ³ã«ã‚ˆã‚‹å®‰å…¨ãªã‚¢ã‚¯ã‚»ã‚¹ï¼ˆSecure access with Single Sign-Onï¼‰**

# ã‚µãƒãƒ¼ãƒˆ / å‰µæ¥­è€…ã¨è©±ã™
- [ãƒ‡ãƒ¢ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« ğŸ‘‹ï¼ˆSchedule Demoï¼‰](https://calendly.com/d/4mp-gd3-k5k/berriai-1-1-onboarding-litellm-hosted-version)
- [ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£Discord ğŸ’­ï¼ˆCommunity Discordï¼‰](https://discord.gg/wuPM9dRgDw)
- é›»è©±ç•ªå· ğŸ“ +1 (770) 8783-106 / â€­+1 (412) 618-6238â€¬
- ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ âœ‰ï¸ ishaan@berri.ai / krrish@berri.ai

# ãªãœç§ãŸã¡ã¯ã“ã‚Œã‚’æ§‹ç¯‰ã—ãŸã®ã‹
- **ã‚·ãƒ³ãƒ—ãƒ«ã•ã®å¿…è¦æ€§ï¼ˆNeed for simplicityï¼‰**: Azureã€OpenAIã€Cohereã®é–“ã§å‘¼ã³å‡ºã—ã‚’ç®¡ç†ãƒ»å¤‰æ›ã™ã‚‹éš›ã€ã‚³ãƒ¼ãƒ‰ãŒéå¸¸ã«è¤‡é›‘ã«ãªã£ã¦ãã¦ã„ãŸã€‚

# è²¢çŒ®è€…ï¼ˆContributorsï¼‰

<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore-start -->
<!-- markdownlint-disable -->

<!-- markdownlint-restore -->
<!-- prettier-ignore-end -->

<!-- ALL-CONTRIBUTORS-LIST:END -->

<a href="https://github.com/BerriAI/litellm/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=BerriAI/litellm" />
</a>