/**
 * Creating a sidebar enables you to:
 - create an ordered group of docs
 - render a sidebar for each doc of that group
 - provide next/previous navigation

 The sidebars can be generated from the filesystem, or explicitly defined here.

 Create as many sidebars as you want.
 */

// @ts-check

/** @type {import('@docusaurus/plugin-content-docs').SidebarsConfig} */
const sidebars = {
  // // By default, Docusaurus generates a sidebar from the docs folder structure
  integrationsSidebar: [
    { type: "doc", id: "integrations/index" },
    {
      type: "category",
      label: "Observability",
      items: [
        {
          type: "autogenerated",
          dirName: "observability"
        }
      ],
    },
    {
      type: "category",
      label: "[Beta] Guardrails",
      items: [
        "proxy/guardrails/quick_start",
        ...[
          "proxy/guardrails/aim_security",
          "proxy/guardrails/aporia_api",
          "proxy/guardrails/azure_content_guardrail",
          "proxy/guardrails/bedrock",
          "proxy/guardrails/lasso_security",
          "proxy/guardrails/guardrails_ai",
          "proxy/guardrails/lakera_ai",
          "proxy/guardrails/model_armor",
          "proxy/guardrails/noma_security",
          "proxy/guardrails/openai_moderation",
          "proxy/guardrails/pangea",
          "proxy/guardrails/pillar_security",
          "proxy/guardrails/pii_masking_v2",
          "proxy/guardrails/panw_prisma_airs",
          "proxy/guardrails/secret_detection",
          "proxy/guardrails/custom_guardrail",
          "proxy/guardrails/prompt_injection",
          "proxy/guardrails/tool_permission",
          "proxy/guardrails/javelin",
        ].sort(),
      ],
    },
    {
      type: "category",
      label: "Alerting & Monitoring",
      items: [
        "proxy/alerting",
        "proxy/pagerduty",
        "proxy/prometheus"
      ]
    },
    {
      type: "category",
      label: "[Beta] Prompt Management",
      items: [
        "proxy/custom_prompt_management",
        "proxy/native_litellm_prompt",
        "proxy/prompt_management"
      ]
    },
    {
      type: "category",
      label: "AI Tools (OpenWebUI, Claude Code, etc.)",
      items: [
        "tutorials/claude_responses_api",
        "tutorials/cost_tracking_coding",
        "tutorials/github_copilot_integration",
        "tutorials/litellm_gemini_cli",
        "tutorials/litellm_qwen_code_cli",
        "tutorials/openai_codex",
        "tutorials/openweb_ui"
      ]
    },

  ],
  // But you can create a sidebar manually
  tutorialSidebar: [
    { type: "doc", id: "index" }, // NEW

    {
      type: "category",
      label: "LiteLLM Proxy Server",
      link: {
        type: "generated-index",
        title: "LiteLLM Proxy Server (LLM Gateway)",
        description: `OpenAI Proxy Server (LLM Gateway) to call 100+ LLMs in a unified interface & track spend, set budgets per virtual key/user`,
        slug: "/simple_proxy",
      },
      items: [
        "proxy/docker_quick_start",
        {
          "type": "category",
          "label": "Config.yaml",
          "items": ["proxy/configs", "proxy/config_management", "proxy/config_settings"]
        },
        {
          type: "category",
          label: "Setup & Deployment",
          items: [
            "proxy/quick_start",
            "proxy/cli",
            "proxy/debugging",
            "proxy/deploy",
            "proxy/health",
            "proxy/master_key_rotations",
            "proxy/model_management",
            "proxy/prod",
            "proxy/release_cycle",
          ],
        },
        "proxy/demo",
        {
          type: "category",
          label: "Admin UI",
          items: [
            "proxy/admin_ui_sso",
            "proxy/custom_root_ui",
            "proxy/custom_sso",
            "proxy/model_hub",
            "proxy/public_teams",
            "proxy/self_serve",
            "proxy/ui",
            "proxy/ui/bulk_edit_users",
            "proxy/ui_credentials",
            "tutorials/scim_litellm",
            {
              type: "category",
              label: "UI Logs",
              items: [
                "proxy/ui_logs",
                "proxy/ui_logs_sessions"
              ]
            }
          ],
        },
        {
          type: "category",
          label: "Architecture",
          items: [
            "proxy/architecture",
            "proxy/control_plane_and_data_plane",
            "proxy/db_deadlocks",
            "proxy/db_info",
            "proxy/image_handling",
            "proxy/jwt_auth_arch",
            "proxy/spend_logs_deletion",
            "proxy/user_management_heirarchy",
            "router_architecture"
          ],
        },
        {
          type: "link",
          label: "All Endpoints (Swagger)",
          href: "https://litellm-api.up.railway.app/",
        },
  "proxy/enterprise",
  "proxy/management_cli",
        {
          type: "category",
          label: "Authentication",
          items: [
            "proxy/virtual_keys",
            "proxy/token_auth",
            "proxy/service_accounts",
            "proxy/access_control",
            "proxy/cli_sso",
            "proxy/custom_auth",
            "proxy/ip_address",
            "proxy/email",
            "proxy/multiple_admins",
          ],
        },
        {
          type: "category",
          label: "Budgets + Rate Limits",
          items: [
            "proxy/customers",
            "proxy/dynamic_rate_limit",
            "proxy/rate_limit_tiers",
            "proxy/team_budgets",
            "proxy/temporary_budget_increase",
            "proxy/users"
          ],
        },
        "proxy/caching",
        {
          type: "category",
          label: "Create Custom Plugins",
          description: "Modify requests, responses, and more",
          items: [
            "proxy/call_hooks",
            "proxy/rules",
          ]
        },
        {
          type: "link",
          label: "Load Balancing, Routing, Fallbacks",
          href: "https://docs.litellm.ai/docs/routing-load-balancing",
        },
        {
          type: "category",
          label: "Logging, Alerting, Metrics",
          items: [
            "proxy/dynamic_logging",
            "proxy/logging",
            "proxy/logging_spec",
            "proxy/team_logging"
          ],
        },
        {
          type: "category",
          label: "Making LLM Requests",
          items: [
            "proxy/user_keys",
            "proxy/clientside_auth",
            "proxy/request_headers",
            "proxy/response_headers",
            "proxy/forward_client_headers",
            "proxy/model_discovery",
          ],
        },
        {
          type: "category",
          label: "Model Access",
          items: [
            "proxy/model_access",
            "proxy/team_model_add"
          ]
        },
        {
          type: "category",
          label: "Secret Managers",
          items: [
            "secret",
            "oidc"
          ]
        },
        {
          type: "category",
          label: "Spend Tracking",
          items: [
            "proxy/billing",
            "proxy/cost_tracking",
            "proxy/custom_pricing"
          ],
        },
      ]
    },
    {
      type: "category",
      label: "Supported Endpoints",
      link: {
        type: "generated-index",
        title: "Supported Endpoints",
        description:
          "Learn how to deploy + call models from different providers on LiteLLM",
        slug: "/supported_endpoints",
      },
      items: [
        "assistants",
        {
          type: "category",
          label: "/audio",
          items: [
            "audio_transcription",
            "text_to_speech",
          ]
        },
        {
          type: "category",
          label: "/batches",
          items: [
            "batches",
            "proxy/managed_batches",
          ]
        },
        {
          type: "category",
          label: "/chat/completions",
          link: {
            type: "generated-index",
            title: "Chat Completions",
            description: "Details on the completion() function",
            slug: "/completion",
          },
          items: [
            "completion/input",
            "completion/output",
            "completion/usage",
            "completion/http_handler_config",
          ],
        },
        "text_completion",
        "embedding/supported_embedding",
        {
          type: "category",
          label: "/files",
          items: [
            "files_endpoints",
            "proxy/litellm_managed_files",
          ],
        },
        {
          type: "category",
          label: "/fine_tuning",
          items: [
            "fine_tuning",
            "proxy/managed_finetuning",
          ]
        },
          "generateContent",
          "apply_guardrail",
        {
          type: "category",
          label: "/images",
          items: [
            "image_edits",
            "image_generation",
            "image_variations",
          ]
        },
        "mcp",
        "moderation",
        {
          type: "category",
          label: "Pass-through Endpoints (Anthropic SDK, etc.)",
          items: [
            "pass_through/intro",
            "pass_through/anthropic_completion",
            "pass_through/assembly_ai",
            "pass_through/bedrock",
            "pass_through/azure_passthrough",
            "pass_through/cohere",
            "pass_through/google_ai_studio",
            "pass_through/langfuse",
            "pass_through/mistral",
            "pass_through/openai_passthrough",
            "pass_through/vertex_ai",
            "pass_through/vllm",
            "proxy/pass_through"
          ]
        },
        "realtime",
        "rerank",
        "response_api",
        "anthropic_unified",
        {
          type: "category",
          label: "/vector_stores",
          items: [
            "vector_stores/search",
          ]
        },
      ],
    },
    {
      type: "category",
      label: "Supported Models & Providers",
      link: {
        type: "generated-index",
        title: "Providers",
        description:
          "Learn how to deploy + call models from different providers on LiteLLM",
        slug: "/providers",
      },
      items: [
        {
          type: "category",
          label: "OpenAI",
          items: [
            "providers/openai",
            "providers/openai/responses_api",
            "providers/openai/text_to_speech",
          ]
        },
        "providers/text_completion_openai",
        "providers/openai_compatible",
        {
          type: "category",
          label: "Azure OpenAI",
          items: [
            "providers/azure/azure",
            "providers/azure/azure_responses",
            "providers/azure/azure_embedding",
          ]
        },
        {
          type: "category",
          label: "Azure AI",
          items: [
            "providers/azure_ai",
            "providers/azure_ai_img",
          ]
        },
        {
          type: "category",
          label: "Vertex AI",
          items: [
            "providers/vertex",
            "providers/vertex_partner",
            "providers/vertex_image",
            "providers/vertex_batch",
          ]
        },
        {
          type: "category",
          label: "Google AI Studio",
          items: [
            "providers/gemini",
            "providers/google_ai_studio/files",
            "providers/google_ai_studio/image_gen",
            "providers/google_ai_studio/realtime",
          ]
        },
        "providers/anthropic",
        "providers/aws_sagemaker",
        {
          type: "category",
          label: "Bedrock",
          items: [
            "providers/bedrock",
            "providers/bedrock_embedding",
            "providers/bedrock_agents",
            "providers/bedrock_batches",
            "providers/bedrock_vector_store",
          ]
        },
        "providers/litellm_proxy",
        "providers/meta_llama",
        "providers/mistral",
        "providers/codestral",
        "providers/cohere",
        "providers/anyscale",
        {
          type: "category",
          label: "HuggingFace",
          items: [
            "providers/huggingface",
            "providers/huggingface_rerank",
          ]
        },
        "providers/hyperbolic",
        "providers/databricks",
        "providers/deepgram",
        "providers/watsonx",
        "providers/predibase",
        {
          type: "category",
          label: "Nvidia NIM",
          items: [
            "providers/nvidia_nim",
            "providers/nvidia_nim_rerank",
          ]
        },
        { type: "doc", id: "providers/nscale", label: "Nscale (EU Sovereign)" },
        "providers/xai",
        "providers/moonshot",
        "providers/lm_studio",
        "providers/cerebras",
        "providers/volcano",
        "providers/triton-inference-server",
        "providers/ollama",
        "providers/perplexity",
        "providers/friendliai",
        "providers/galadriel",
        "providers/topaz",
        "providers/groq",
        "providers/deepseek",
        "providers/elevenlabs",
        "providers/fireworks_ai",
        "providers/clarifai",
        "providers/compactifai",
        "providers/lemonade",
        "providers/vllm",
        "providers/llamafile",
        "providers/infinity",
        "providers/xinference",
        "providers/aiml",
        "providers/cloudflare_workers",
        "providers/deepinfra",
        "providers/github",
        "providers/github_copilot",
        "providers/ai21",
        "providers/nlp_cloud",
        "providers/recraft",
        "providers/replicate",
        "providers/togetherai",
        "providers/v0",
        "providers/vercel_ai_gateway",
        "providers/morph",
        "providers/lambda_ai",
        "providers/novita",
        "providers/voyage",
        "providers/jina_ai",
        "providers/aleph_alpha",
        "providers/baseten",
        "providers/openrouter",
        "providers/sambanova",
        "providers/custom_llm_server",
        "providers/petals",
        "providers/snowflake",
        "providers/gradient_ai",
        "providers/featherless_ai",
        "providers/nebius",
        "providers/dashscope",
        "providers/bytez",
        "providers/heroku",
        "providers/oci",
        "providers/datarobot",
        "providers/ovhcloud",  
      ],
    },
    {
      type: "category",
      label: "Guides",
      items: [
        {
          type: "category",
          label: "Tools",
          items: [
            "completion/computer_use",
            "completion/web_search",
            "completion/web_fetch",
            "completion/function_call",
          ]
        },
        "completion/audio",
        "completion/document_understanding",
        "completion/drop_params",
        "completion/image_generation_chat",
        "completion/json_mode",
        "completion/knowledgebase",
        "completion/message_trimming",
        "completion/model_alias",
        "completion/mock_requests",
        "completion/predict_outputs",
        "completion/prefix",
        "completion/prompt_caching",
        "completion/prompt_formatting",
        "completion/reliable_completions",
        "completion/stream",
        "completion/provider_specific_params",
        "completion/vision",
        "exception_mapping",
        "completion/batching",
        "guides/finetuned_models",
        "guides/security_settings",
        "proxy/veo_video_generation",
        "reasoning_content"
      ]
    },

    {
      type: "category",
      label: "Routing, Loadbalancing & Fallbacks",
      link: {
        type: "generated-index",
        title: "Routing, Loadbalancing & Fallbacks",
        description: "Learn how to load balance, route, and set fallbacks for your LLM requests",
        slug: "/routing-load-balancing",
      },
      items: [
        "routing",
        "scheduler",
        "proxy/auto_routing",
        "proxy/load_balancing",
        "proxy/provider_budget_routing",
        "proxy/reliability",
        "proxy/tag_routing",
        "proxy/timeout",
        "wildcard_routing"
      ],
    },
    {
      type: "category",
      label: "LiteLLM Python SDK",
      items: [
        "set_keys",
        "budget_manager",
        "caching/all_caches",
        "completion/token_usage",
        "sdk_custom_pricing",
        "embedding/async_embedding",
        "embedding/moderation",
        "migration",
        "sdk_custom_pricing",
        {
          type: "category",
          label: "LangChain, LlamaIndex, Instructor Integration",
          items: ["langchain/langchain", "tutorials/instructor"],
        }
      ],
    },

    {
      type: "category",
      label: "Load Testing",
      items: [
        "benchmarks",
        "load_test_advanced",
        "load_test_sdk",
        "load_test_rpm",
      ]
    },
    {
      type: "category",
      label: "Tutorials",
      items: [
        "tutorials/openweb_ui",
        "tutorials/openai_codex",
        "tutorials/litellm_gemini_cli",
        "tutorials/litellm_qwen_code_cli",
        "tutorials/anthropic_file_usage",
        "tutorials/default_team_self_serve",
        "tutorials/msft_sso",
        "tutorials/prompt_caching",
        "tutorials/tag_management",
        'tutorials/litellm_proxy_aporia',
        "tutorials/elasticsearch_logging",
        "tutorials/gemini_realtime_with_audio",
        "tutorials/claude_responses_api",
        {
          type: "category",
          label: "LiteLLM Python SDK Tutorials",
          items: [
            'tutorials/google_adk',
            'tutorials/azure_openai',
            'tutorials/instructor',
            "tutorials/gradio_integration",
            "tutorials/huggingface_codellama",
            "tutorials/huggingface_tutorial",
            "tutorials/TogetherAI_liteLLM",
            "tutorials/finetuned_chat_gpt",
            "tutorials/text_completion",
            "tutorials/first_playground",
            "tutorials/model_fallbacks",
          ],
        },
      ]
    },
    {
      type: "category",
      label: "Contributing",
      items: [
        "extras/contributing_code",
        {
          type: "category",
          label: "Adding Providers",
          items: [
            "adding_provider/directory_structure",
            "adding_provider/new_rerank_provider"],
        },
        "extras/contributing",
        "contributing",
      ]
    },
    {
      type: "category",
      label: "Extras",
      items: [
        "data_security",
        "data_retention",
        "migration_policy",
        {
          type: "category",
          label: "❤️ 🚅 Projects built on LiteLLM",
          link: {
            type: "generated-index",
            title: "Projects built on LiteLLM",
            description:
              "Learn how to deploy + call models from different providers on LiteLLM",
            slug: "/project",
          },
          items: [
            "projects/smolagents",
            "projects/Docq.AI",
            "projects/PDL",
            "projects/OpenInterpreter",
            "projects/Elroy",
            "projects/dbally",
            "projects/FastREPL",
            "projects/PROMPTMETHEUS",
            "projects/Codium PR Agent",
            "projects/Prompt2Model",
            "projects/SalesGPT",
            "projects/Quivr",
            "projects/Langstream",
            "projects/Otter",
            "projects/GPT Migrate",
            "projects/YiVal",
            "projects/LiteLLM Proxy",
            "projects/llm_cord",
            "projects/pgai",
            "projects/GPTLocalhost",
            "projects/HolmesGPT",
            "projects/Railtracks",
          ],
        },
        "extras/code_quality",
        "rules",
        "proxy/team_based_routing",
        "proxy/customer_routing",
        "proxy_server",
      ],
    },
    {
      type: "doc",
      id: "provider_registration/index",
      label: "Integrate as a Model Provider",
    },
    "troubleshoot",
  ],
};

module.exports = sidebars;
