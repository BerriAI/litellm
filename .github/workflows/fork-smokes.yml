name: Fork Smokes

on:
  push:
    branches: [ fork/stable ]
  pull_request:
    branches: [ fork/stable ]

jobs:
  smokes:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      - name: Install
        run: |
          python -m pip install -U pip
          pip install -e .
          pip install pytest
      - name: Mini-agent & HTTP tools
        run: |
          PYTHONPATH=$(pwd) pytest -q tests/smoke/test_mini_agent.py tests/smoke/test_mini_agent_repair_loop.py tests/smoke/test_mini_agent_research_on_unsure.py tests/smoke/test_mini_agent_response_shapes.py tests/smoke/test_http_tools_invoker.py tests/smoke/test_http_tools_invoker_headers.py tests/smoke/test_http_error_tail.py tests/smoke/test_agent_proxy_headers_and_errors.py tests/smoke/test_prune_history_preserve_pair.py
      - name: Router streaming parity
        run: |
          PYTHONPATH=$(pwd) pytest -q tests/smoke/test_router_streaming_parity.py::test_router_streaming_parity
      - name: Router streaming metrics (extracted)
        run: |
          PYTHONPATH=$(pwd) pytest -q tests/smoke/test_router_streaming_metrics_extracted.py::test_router_streaming_metrics_extracted
      - name: Router streaming fallback parity
        run: |
          PYTHONPATH=$(pwd) pytest -q tests/smoke/test_router_streaming_fallback_parity.py::test_router_streaming_midstream_fallback_parity


  live-check:
    if: ${{ secrets.OPENAI_API_KEY != '' || secrets.GEMINI_API_KEY != '' }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      - name: Install
        run: |
          python -m pip install -U pip
          pip install -e .
      - name: Live check via Router
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          LITELLM_DEFAULT_MODEL: ${{ secrets.LITELLM_DEFAULT_MODEL }}
        run: |
          python - << 'PYIN'
          import os, asyncio
          from litellm.router import Router
          model = os.environ.get('LITELLM_DEFAULT_MODEL')
          if not model:
            model = 'openai/gpt-4o-mini' if os.environ.get('OPENAI_API_KEY') else 'gemini/gemini-1.5-flash'
          key_var = 'OPENAI_API_KEY' if model.startswith('openai/') else 'GEMINI_API_KEY'
          api_key = os.environ.get(key_var)
          if not api_key:
            raise SystemExit('missing API key for model')
          r = Router(model_list=[{"model_name":"live","litellm_params":{"model": model, "api_key": api_key}}])
          out = asyncio.get_event_loop().run_until_complete(r.acompletion(model='live', messages=[{"role":"user","content":"ping"}], stream=False))
          text = getattr(getattr(out,'choices',[{}])[0],'message',{}).get('content') if hasattr(out,'choices') else (out.get('choices',[{}])[0].get('message',{}).get('content'))
          assert text is not None and text != ''
          print('ok: live content len=', len(text))
          PYIN
