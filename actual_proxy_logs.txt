Using json logs. Setting log_config to None.

   ‚ñà‚ñà‚ïó     ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó     ‚ñà‚ñà‚ïó     ‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ñà‚ïó
   ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ïë
   ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïî‚ñà‚ñà‚ñà‚ñà‚ïî‚ñà‚ñà‚ïë
   ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë
   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë ‚ïö‚ïê‚ïù ‚ñà‚ñà‚ïë
   ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù   ‚ïö‚ïê‚ïù   ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù


[1;37m#------------------------------------------------------------#[0m
[1;37m#                                                            #[0m
[1;37m#            'The thing I wish you improved is...'            #[0m
[1;37m#        https://github.com/BerriAI/litellm/issues/new        #[0m
[1;37m#                                                            #[0m
[1;37m#------------------------------------------------------------#[0m

 Thank you for using LiteLLM! - Krrish & Ishaan



[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m


[94m Initialized Success Callbacks - [] [0m
[94m Initialized Failure Callbacks - [] [0m
[32mLiteLLM: Proxy initialized with Config, Set models:[0m
[32m    gpt-3.5-turbo[0m
[32m    azure-gpt-35[0m
[32m    vertex-gemini[0m
[32m    azure-embedding[0m
{"message": "litellm.proxy.proxy_server._handle_llm_api_exception(): Exception occured - litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: sk-fake-**************fail. You can find your API key at https://platform.openai.com/account/api-keys.. Received Model Group=gpt-3.5-turbo\nAvailable Model Group Fallbacks=None", "level": "ERROR", "timestamp": "2026-01-19T22:51:46.250125", "stacktrace": "Traceback (most recent call last):\n  File \"/home/user/litellm/litellm/llms/openai/openai.py\", line 840, in acompletion\n    headers, response = await self.make_openai_chat_completion_request(\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/litellm_core_utils/logging_utils.py\", line 190, in async_wrapper\n    result = await func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/openai/openai.py\", line 460, in make_openai_chat_completion_request\n    raise e\n  File \"/home/user/litellm/litellm/llms/openai/openai.py\", line 437, in make_openai_chat_completion_request\n    await openai_aclient.chat.completions.with_raw_response.create(\n  File \"/usr/local/lib/python3.11/dist-packages/openai/_legacy_response.py\", line 381, in wrapped\n    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions/completions.py\", line 2678, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 1797, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 1597, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-fake-**************fail. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}, 'status': 401}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/user/litellm/litellm/main.py\", line 610, in acompletion\n    response = await init_response\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/openai/openai.py\", line 887, in acompletion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-fake-**************fail. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}, 'status': 401}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/user/litellm/litellm/proxy/proxy_server.py\", line 5250, in chat_completion\n    result = await base_llm_response_processor.base_process_llm_request(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/proxy/common_request_processing.py\", line 680, in base_process_llm_request\n    responses = await llm_responses\n                ^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/router.py\", line 1374, in acompletion\n    raise e\n  File \"/home/user/litellm/litellm/router.py\", line 1350, in acompletion\n    response = await self.async_function_with_fallbacks(**kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/router.py\", line 4571, in async_function_with_fallbacks\n    return await self.async_function_with_fallbacks_common_utils(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/router.py\", line 4529, in async_function_with_fallbacks_common_utils\n    raise original_exception\n  File \"/home/user/litellm/litellm/router.py\", line 4563, in async_function_with_fallbacks\n    response = await self.async_function_with_retries(*args, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/router.py\", line 4685, in async_function_with_retries\n    self.should_retry_this_error(\n  File \"/home/user/litellm/litellm/router.py\", line 4887, in should_retry_this_error\n    raise error  # then raise error\n    ^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/router.py\", line 4659, in async_function_with_retries\n    response = await self.make_call(original_function, *args, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/router.py\", line 4787, in make_call\n    response = await response\n               ^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/router.py\", line 1660, in _acompletion\n    raise e\n  File \"/home/user/litellm/litellm/router.py\", line 1606, in _acompletion\n    response = await _response\n               ^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/utils.py\", line 1970, in wrapper_async\n    raise e\n  File \"/home/user/litellm/litellm/utils.py\", line 1790, in wrapper_async\n    result = await original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/main.py\", line 629, in acompletion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2356, in exception_type\n    raise e\n  File \"/home/user/litellm/litellm/litellm_core_utils/exception_mapping_utils.py\", line 502, in exception_type\n    raise AuthenticationError(\nlitellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: sk-fake-**************fail. You can find your API key at https://platform.openai.com/account/api-keys.. Received Model Group=gpt-3.5-turbo\nAvailable Model Group Fallbacks=None"}
{"message": "Failed to load vertex credentials. Check to see if credentials containing partial/invalid information. Error: No module named 'google'", "level": "ERROR", "timestamp": "2026-01-19T22:51:49.318104", "stacktrace": "Traceback (most recent call last):\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 546, in get_access_token\n    _credentials, credential_project_id = self.load_auth(\n                                          ^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 121, in load_auth\n    creds, creds_project_id = self._credentials_from_default_auth(\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 172, in _credentials_from_default_auth\n    import google.auth as google_auth\nModuleNotFoundError: No module named 'google'"}
{"message": "Failed to load vertex credentials. Check to see if credentials containing partial/invalid information. Error: No module named 'google'", "level": "ERROR", "timestamp": "2026-01-19T22:51:50.414869", "stacktrace": "Traceback (most recent call last):\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 546, in get_access_token\n    _credentials, credential_project_id = self.load_auth(\n                                          ^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 121, in load_auth\n    creds, creds_project_id = self._credentials_from_default_auth(\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 172, in _credentials_from_default_auth\n    import google.auth as google_auth\nModuleNotFoundError: No module named 'google'"}
{"message": "Failed to load vertex credentials. Check to see if credentials containing partial/invalid information. Error: No module named 'google'", "level": "ERROR", "timestamp": "2026-01-19T22:51:51.976356", "stacktrace": "Traceback (most recent call last):\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 546, in get_access_token\n    _credentials, credential_project_id = self.load_auth(\n                                          ^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 121, in load_auth\n    creds, creds_project_id = self._credentials_from_default_auth(\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 172, in _credentials_from_default_auth\n    import google.auth as google_auth\nModuleNotFoundError: No module named 'google'"}
{"message": "litellm.proxy.proxy_server._handle_llm_api_exception(): Exception occured - litellm.APIConnectionError: No module named 'google'\nTraceback (most recent call last):\n  File \"/home/user/litellm/litellm/main.py\", line 610, in acompletion\n    response = await init_response\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py\", line 2430, in async_completion\n    _auth_header, vertex_project = await self._ensure_access_token_async(\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 642, in _ensure_access_token_async\n    raise e\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 637, in _ensure_access_token_async\n    return await asyncify(self.get_access_token)(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/litellm_core_utils/asyncify.py\", line 57, in wrapper\n    return await anyio.to_thread.run_sync(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 63, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2502, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 986, in run\n    result = context.run(func, *args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 553, in get_access_token\n    raise e\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 546, in get_access_token\n    _credentials, credential_project_id = self.load_auth(\n                                          ^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 121, in load_auth\n    creds, creds_project_id = self._credentials_from_default_auth(\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 172, in _credentials_from_default_auth\n    import google.auth as google_auth\nModuleNotFoundError: No module named 'google'\n. Received Model Group=vertex-gemini\nAvailable Model Group Fallbacks=None LiteLLM Retried: 2 times, LiteLLM Max Retries: 2", "level": "ERROR", "timestamp": "2026-01-19T22:51:54.192782", "stacktrace": "Traceback (most recent call last):\n  File \"/home/user/litellm/litellm/main.py\", line 610, in acompletion\n    response = await init_response\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py\", line 2430, in async_completion\n    _auth_header, vertex_project = await self._ensure_access_token_async(\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 642, in _ensure_access_token_async\n    raise e\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 637, in _ensure_access_token_async\n    return await asyncify(self.get_access_token)(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/litellm_core_utils/asyncify.py\", line 57, in wrapper\n    return await anyio.to_thread.run_sync(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 63, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2502, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 986, in run\n    result = context.run(func, *args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 553, in get_access_token\n    raise e\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 546, in get_access_token\n    _credentials, credential_project_id = self.load_auth(\n                                          ^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 121, in load_auth\n    creds, creds_project_id = self._credentials_from_default_auth(\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 172, in _credentials_from_default_auth\n    import google.auth as google_auth\nModuleNotFoundError: No module named 'google'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/user/litellm/litellm/proxy/proxy_server.py\", line 5250, in chat_completion\n    result = await base_llm_response_processor.base_process_llm_request(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/proxy/common_request_processing.py\", line 680, in base_process_llm_request\n    responses = await llm_responses\n                ^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/router.py\", line 1374, in acompletion\n    raise e\n  File \"/home/user/litellm/litellm/router.py\", line 1350, in acompletion\n    response = await self.async_function_with_fallbacks(**kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/router.py\", line 4571, in async_function_with_fallbacks\n    return await self.async_function_with_fallbacks_common_utils(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/router.py\", line 4529, in async_function_with_fallbacks_common_utils\n    raise original_exception\n  File \"/home/user/litellm/litellm/router.py\", line 4563, in async_function_with_fallbacks\n    response = await self.async_function_with_retries(*args, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/router.py\", line 4776, in async_function_with_retries\n    raise original_exception\n  File \"/home/user/litellm/litellm/router.py\", line 4659, in async_function_with_retries\n    response = await self.make_call(original_function, *args, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/router.py\", line 4787, in make_call\n    response = await response\n               ^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/router.py\", line 1660, in _acompletion\n    raise e\n  File \"/home/user/litellm/litellm/router.py\", line 1606, in _acompletion\n    response = await _response\n               ^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/utils.py\", line 1970, in wrapper_async\n    raise e\n  File \"/home/user/litellm/litellm/utils.py\", line 1790, in wrapper_async\n    result = await original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/main.py\", line 629, in acompletion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2356, in exception_type\n    raise e\n  File \"/home/user/litellm/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2332, in exception_type\n    raise APIConnectionError(\nlitellm.exceptions.APIConnectionError: litellm.APIConnectionError: No module named 'google'\nTraceback (most recent call last):\n  File \"/home/user/litellm/litellm/main.py\", line 610, in acompletion\n    response = await init_response\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py\", line 2430, in async_completion\n    _auth_header, vertex_project = await self._ensure_access_token_async(\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 642, in _ensure_access_token_async\n    raise e\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 637, in _ensure_access_token_async\n    return await asyncify(self.get_access_token)(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/litellm_core_utils/asyncify.py\", line 57, in wrapper\n    return await anyio.to_thread.run_sync(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 63, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2502, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 986, in run\n    result = context.run(func, *args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 553, in get_access_token\n    raise e\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 546, in get_access_token\n    _credentials, credential_project_id = self.load_auth(\n                                          ^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 121, in load_auth\n    creds, creds_project_id = self._credentials_from_default_auth(\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/user/litellm/litellm/llms/vertex_ai/vertex_llm_base.py\", line 172, in _credentials_from_default_auth\n    import google.auth as google_auth\nModuleNotFoundError: No module named 'google'\n. Received Model Group=vertex-gemini\nAvailable Model Group Fallbacks=None LiteLLM Retried: 2 times, LiteLLM Max Retries: 2"}
