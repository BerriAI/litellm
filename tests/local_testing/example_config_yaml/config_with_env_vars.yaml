model_list:
  ################################################################################
  # Azure
  - model_name: gpt-4o-mini
    litellm_params:
      model: azure/gpt-4o-mini
      api_base: https://amazin-prod.openai.azure.com
      api_key: "os.environ/AZURE_GPT_4O"
      deployment_id: gpt-4o-mini
  - model_name: gpt-4o
    litellm_params:
      model: azure/gpt-4o
      api_base: https://very-cool-prod.openai.azure.com
      api_key: "os.environ/AZURE_GPT_4O"
      deployment_id: gpt-4o

  ################################################################################
  # Fireworks
  - model_name: fireworks-llama-v3p1-405b-instruct
    litellm_params:
      model: fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct
      api_key: "os.environ/FIREWORKS"
  - model_name: fireworks-llama-v3p1-70b-instruct
    litellm_params:
      model: fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct
      api_key: "os.environ/FIREWORKS"
  
general_settings:
  alerting_threshold: 300 # sends alerts if requests hang for 5min+ and responses take 5min+
litellm_settings: # module level litellm settings - https://github.com/BerriAI/litellm/blob/main/litellm/__init__.py
  success_callback: ["prometheus"]
  service_callback: ["prometheus_system"]
  drop_params: False # Raise an exception if the openai param being passed in isn't supported.
  cache: false
  default_internal_user_params:
    user_role: os.environ/DEFAULT_USER_ROLE

  success_callback: ["s3"]
  s3_callback_params:
    s3_bucket_name: logs-bucket-litellm   # AWS Bucket Name for S3
    s3_region_name: us-west-2              # AWS Region Name for S3
    s3_aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID  # us os.environ/<variable name> to pass environment variables. This is AWS Access Key ID for S3
    s3_aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY  # AWS Secret Access Key for S3
    s3_path: my-test-path # [OPTIONAL] set path in bucket you want to write logs to
    s3_endpoint_url: https://s3.amazonaws.com  # [OPTIONAL] S3 endpoint URL, if you want to use Backblaze/cloudflare s3 buckets

router_settings:
  routing_strategy: simple-shuffle # "simple-shuffle" shown to result in highest throughput. https://docs.litellm.ai/docs/proxy/configs#load-balancing
