services:
  # Default LiteLLM without patches
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    profiles: ["default", "unpatched"]
    ports:
      - "4000:4000"
    volumes:
      - ./litellm-config.yaml:/app/config.yaml
    command:
      - "--config=/app/config.yaml"
      - "--detailed_debug"
    environment:
      DATABASE_URL: "postgresql://llmproxy:dbpassword9090@db:5432/litellm"
      STORE_MODEL_IN_DB: "True"
      LITELLM_MASTER_KEY: "sk-1234"
      LITELLM_SALT_KEY: "mock-salt-key-12345"
      LITELLM_LOG: "DEBUG"
      real_azure_api_key: "${real_azure_api_key:-}"
    depends_on:
      db:
        condition: service_healthy
      mock-server:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 http://localhost:4000/health/liveliness || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # LiteLLM with patches enabled
  litellm-patched:
    image: ghcr.io/berriai/litellm:main-latest
    profiles: ["patched"]
    ports:
      - "4000:4000"
    volumes:
      - ./litellm-config.yaml:/app/config.yaml
      # patch1
      - ./patches/managed_files.py:/usr/lib/python3.13/site-packages/litellm_enterprise/proxy/hooks/managed_files.py
      - ./patches/managed_files.py:/app/enterprise/litellm_enterprise/proxy/hooks/managed_files.py
      # patch2
      - ./patches/_types.py:/usr/lib/python3.13/site-packages/litellm/proxy/_types.py
      - ./patches/_types.py:/app/litellm/proxy/_types.py
      # patch3
      - ./patches/batches_endpoints.py:/usr/lib/python3.13/site-packages/litellm/proxy/batches_endpoints/endpoints.py
      - ./patches/batches_endpoints.py:/app/litellm/proxy/batches_endpoints/endpoints.py
      # patch4
      - ./patches/files_endpoints.py:/usr/lib/python3.13/site-packages/litellm/proxy/openai_files_endpoints/files_endpoints.py
      - ./patches/files_endpoints.py:/app/litellm/proxy/openai_files_endpoints/files_endpoints.py
    command:
      - "--config=/app/config.yaml"
      - "--detailed_debug"
    environment:
      DATABASE_URL: "postgresql://llmproxy:dbpassword9090@db:5432/litellm"
      STORE_MODEL_IN_DB: "True"
      LITELLM_MASTER_KEY: "sk-1234"
      LITELLM_SALT_KEY: "mock-salt-key-12345"
      LITELLM_LOG: "DEBUG"
      real_azure_api_key: "${real_azure_api_key:-}"
    depends_on:
      db:
        condition: service_healthy
      mock-server:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 http://localhost:4000/health/liveliness || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  db:
    image: postgres:16
    restart: always
    container_name: litellm_local_db
    environment:
      POSTGRES_DB: litellm
      POSTGRES_USER: llmproxy
      POSTGRES_PASSWORD: dbpassword9090
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d litellm -U llmproxy"]
      interval: 1s
      timeout: 5s
      retries: 10

  mock-server:
    build:
      context: ./mock-server
      dockerfile: Dockerfile
    ports:
      - "8090:8090"
    environment:
      TIME_TO_SLEEP: "0"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8090/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 5s

volumes:
  postgres_data:
    name: litellm_local_postgres_data
