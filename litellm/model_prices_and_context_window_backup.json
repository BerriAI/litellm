{
    "sample_spec": {
        "code_interpreter_cost_per_session": 0.0,
        "computer_use_input_cost_per_1k_tokens": 0.0,
        "computer_use_output_cost_per_1k_tokens": 0.0,
        "deprecation_date": "date when the model becomes deprecated in the format YYYY-MM-DD",
        "display_name": "human readable model name e.g. 'Llama 3.2 3B Instruct', 'GPT-4o', 'Grok 2', etc.",
        "file_search_cost_per_1k_calls": 0.0,
        "file_search_cost_per_gb_per_day": 0.0,
        "input_cost_per_audio_token": 0.0,
        "input_cost_per_token": 0.0,
        "litellm_provider": "one of https://docs.litellm.ai/docs/providers",
        "max_input_tokens": "max input tokens, if the provider specifies it. if not default to max_tokens",
        "max_output_tokens": "max output tokens, if the provider specifies it. if not default to max_tokens",
        "max_tokens": "LEGACY parameter. set to max_output_tokens if provider specifies it. IF not set to max_input_tokens, if provider specifies it.",
        "mode": "one of: chat, embedding, completion, image_generation, audio_transcription, audio_speech, image_generation, moderation, rerank, search",
        "model_vendor": "used to group models by vendor e.g. openai, google, etc.",
        "model_version": "used to group models by version e.g. v1, v2, etc.",
        "output_cost_per_reasoning_token": 0.0,
        "output_cost_per_token": 0.0,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.0,
            "search_context_size_low": 0.0,
            "search_context_size_medium": 0.0
        },
        "supported_regions": [
            "global",
            "us-west-2",
            "eu-west-1",
            "ap-southeast-1",
            "ap-northeast-1"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_vision": true,
        "supports_web_search": true,
        "vector_store_cost_per_gb_per_day": 0.0
    },
    "1024-x-1024/50-steps/bedrock/amazon.nova-canvas-v1:0": {
        "display_name": "Nova Canvas",
        "litellm_provider": "bedrock",
        "max_input_tokens": 2600,
        "mode": "image_generation",
        "model_vendor": "amazon",
        "model_version": "v1:0",
        "output_cost_per_image": 0.06
    },
    "1024-x-1024/50-steps/stability.stable-diffusion-xl-v1": {
        "display_name": "Stable Diffusion XL",
        "litellm_provider": "bedrock",
        "max_input_tokens": 77,
        "max_tokens": 77,
        "mode": "image_generation",
        "model_vendor": "stability",
        "model_version": "v1",
        "output_cost_per_image": 0.04
    },
    "1024-x-1024/dall-e-2": {
        "display_name": "DALL-E 2",
        "model_vendor": "openai",
        "input_cost_per_pixel": 1.9e-08,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0
    },
    "1024-x-1024/max-steps/stability.stable-diffusion-xl-v1": {
        "display_name": "Stable Diffusion XL",
        "litellm_provider": "bedrock",
        "max_input_tokens": 77,
        "max_tokens": 77,
        "mode": "image_generation",
        "model_vendor": "stability",
        "model_version": "v1",
        "output_cost_per_image": 0.08
    },
    "256-x-256/dall-e-2": {
        "display_name": "DALL-E 2",
        "model_vendor": "openai",
        "input_cost_per_pixel": 2.4414e-07,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0
    },
    "512-x-512/50-steps/stability.stable-diffusion-xl-v0": {
        "display_name": "Stable Diffusion XL",
        "litellm_provider": "bedrock",
        "max_input_tokens": 77,
        "max_tokens": 77,
        "mode": "image_generation",
        "model_vendor": "stability",
        "model_version": "v0",
        "output_cost_per_image": 0.018
    },
    "512-x-512/dall-e-2": {
        "display_name": "DALL-E 2",
        "model_vendor": "openai",
        "input_cost_per_pixel": 6.86e-08,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0
    },
    "512-x-512/max-steps/stability.stable-diffusion-xl-v0": {
        "display_name": "Stable Diffusion XL",
        "litellm_provider": "bedrock",
        "max_input_tokens": 77,
        "max_tokens": 77,
        "mode": "image_generation",
        "model_vendor": "stability",
        "model_version": "v0",
        "output_cost_per_image": 0.036
    },
    "ai21.j2-mid-v1": {
        "display_name": "Jurassic-2 Mid",
        "input_cost_per_token": 1.25e-05,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8191,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "ai21",
        "model_version": "v1",
        "output_cost_per_token": 1.25e-05
    },
    "ai21.j2-ultra-v1": {
        "display_name": "Jurassic-2 Ultra",
        "input_cost_per_token": 1.88e-05,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8191,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "ai21",
        "model_version": "v1",
        "output_cost_per_token": 1.88e-05
    },
    "ai21.jamba-1-5-large-v1:0": {
        "display_name": "Jamba 1.5 Large",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "model_vendor": "ai21",
        "model_version": "1.5-large-v1:0",
        "output_cost_per_token": 8e-06
    },
    "ai21.jamba-1-5-mini-v1:0": {
        "display_name": "Jamba 1.5 Mini",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "model_vendor": "ai21",
        "model_version": "1.5-mini-v1:0",
        "output_cost_per_token": 4e-07
    },
    "ai21.jamba-instruct-v1:0": {
        "display_name": "Jamba Instruct",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 70000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "ai21",
        "model_version": "instruct-v1:0",
        "output_cost_per_token": 7e-07,
        "supports_system_messages": true
    },
    "aiml/dall-e-2": {
        "display_name": "DALL-E 2",
        "model_vendor": "openai",
        "litellm_provider": "aiml",
        "metadata": {
            "notes": "DALL-E 2 via AI/ML API - Reliable text-to-image generation"
        },
        "mode": "image_generation",
        "output_cost_per_image": 0.021,
        "source": "https://docs.aimlapi.com/",
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "aiml/dall-e-3": {
        "display_name": "DALL-E 3",
        "model_vendor": "openai",
        "litellm_provider": "aiml",
        "metadata": {
            "notes": "DALL-E 3 via AI/ML API - High-quality text-to-image generation"
        },
        "mode": "image_generation",
        "output_cost_per_image": 0.042,
        "source": "https://docs.aimlapi.com/",
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "aiml/flux-pro": {
        "display_name": "FLUX Pro",
        "litellm_provider": "aiml",
        "metadata": {
            "notes": "Flux Dev - Development version optimized for experimentation"
        },
        "mode": "image_generation",
        "model_vendor": "black-forest-labs",
        "output_cost_per_image": 0.053,
        "source": "https://docs.aimlapi.com/",
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "aiml/flux-pro/v1.1": {
        "display_name": "FLUX Pro",
        "litellm_provider": "aiml",
        "mode": "image_generation",
        "model_vendor": "black-forest-labs",
        "model_version": "v1.1",
        "output_cost_per_image": 0.042,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "aiml/flux-pro/v1.1-ultra": {
        "display_name": "FLUX Pro Ultra",
        "litellm_provider": "aiml",
        "mode": "image_generation",
        "model_vendor": "black-forest-labs",
        "model_version": "v1.1-ultra",
        "output_cost_per_image": 0.063,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "aiml/flux-realism": {
        "display_name": "FLUX Realism",
        "litellm_provider": "aiml",
        "metadata": {
            "notes": "Flux Pro - Professional-grade image generation model"
        },
        "mode": "image_generation",
        "model_vendor": "black-forest-labs",
        "output_cost_per_image": 0.037,
        "source": "https://docs.aimlapi.com/",
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "aiml/flux/dev": {
        "display_name": "FLUX Dev",
        "litellm_provider": "aiml",
        "metadata": {
            "notes": "Flux Dev - Development version optimized for experimentation"
        },
        "mode": "image_generation",
        "model_vendor": "black-forest-labs",
        "output_cost_per_image": 0.026,
        "source": "https://docs.aimlapi.com/",
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "aiml/flux/kontext-max/text-to-image": {
        "display_name": "FLUX Kontext Max",
        "litellm_provider": "aiml",
        "metadata": {
            "notes": "Flux Pro v1.1 - Enhanced version with improved capabilities and 6x faster inference speed"
        },
        "mode": "image_generation",
        "model_vendor": "black-forest-labs",
        "output_cost_per_image": 0.084,
        "source": "https://docs.aimlapi.com/",
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "aiml/flux/kontext-pro/text-to-image": {
        "display_name": "FLUX Kontext Pro",
        "litellm_provider": "aiml",
        "metadata": {
            "notes": "Flux Pro v1.1 - Enhanced version with improved capabilities and 6x faster inference speed"
        },
        "mode": "image_generation",
        "model_vendor": "black-forest-labs",
        "output_cost_per_image": 0.042,
        "source": "https://docs.aimlapi.com/",
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "aiml/flux/schnell": {
        "display_name": "FLUX Schnell",
        "litellm_provider": "aiml",
        "metadata": {
            "notes": "Flux Schnell - Fast generation model optimized for speed"
        },
        "mode": "image_generation",
        "model_vendor": "black-forest-labs",
        "output_cost_per_image": 0.003,
        "source": "https://docs.aimlapi.com/",
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "amazon.nova-canvas-v1:0": {
        "display_name": "Nova Canvas",
        "litellm_provider": "bedrock",
        "max_input_tokens": 2600,
        "mode": "image_generation",
        "model_vendor": "amazon",
        "model_version": "v1:0",
        "output_cost_per_image": 0.06
    },
    "us.writer.palmyra-x4-v1:0": {
        "display_name": "Writer.palmyra X4 V1:0",
        "model_vendor": "google",
        "model_version": "0",
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supports_function_calling": true,
        "supports_pdf_input": true
    },
    "us.writer.palmyra-x5-v1:0": {
        "display_name": "Writer.palmyra X5 V1:0",
        "model_vendor": "google",
        "model_version": "0",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "supports_function_calling": true,
        "supports_pdf_input": true
    },
    "writer.palmyra-x4-v1:0": {
        "display_name": "Palmyra X4 V1:0",
        "model_vendor": "google",
        "model_version": "0",
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supports_function_calling": true,
        "supports_pdf_input": true
    },
    "writer.palmyra-x5-v1:0": {
        "display_name": "Palmyra X5 V1:0",
        "model_vendor": "google",
        "model_version": "0",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "supports_function_calling": true,
        "supports_pdf_input": true
    },
    "amazon.nova-lite-v1:0": {
        "display_name": "Nova Lite",
        "input_cost_per_token": 6e-08,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 300000,
        "max_output_tokens": 10000,
        "max_tokens": 10000,
        "mode": "chat",
        "model_vendor": "amazon",
        "model_version": "v1:0",
        "output_cost_per_token": 2.4e-07,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "amazon.nova-2-lite-v1:0": {
        "display_name": "Nova 2 Lite",
        "model_vendor": "amazon",
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 2.5e-06,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_video_input": true,
        "supports_vision": true
    },
    "apac.amazon.nova-2-lite-v1:0": {
        "display_name": "Nova 2 Lite",
        "model_vendor": "amazon",
        "cache_read_input_token_cost": 8.25e-08,
        "input_cost_per_token": 3.3e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 2.75e-06,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_video_input": true,
        "supports_vision": true
    },
    "eu.amazon.nova-2-lite-v1:0": {
        "display_name": "Nova 2 Lite",
        "model_vendor": "amazon",
        "cache_read_input_token_cost": 8.25e-08,
        "input_cost_per_token": 3.3e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 2.75e-06,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_video_input": true,
        "supports_vision": true
    },
    "us.amazon.nova-2-lite-v1:0": {
        "display_name": "Nova 2 Lite",
        "model_vendor": "amazon",
        "cache_read_input_token_cost": 8.25e-08,
        "input_cost_per_token": 3.3e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 2.75e-06,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_video_input": true,
        "supports_vision": true
    },
    "amazon.nova-micro-v1:0": {
        "display_name": "Nova Micro",
        "input_cost_per_token": 3.5e-08,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 10000,
        "max_tokens": 10000,
        "mode": "chat",
        "model_vendor": "amazon",
        "model_version": "v1:0",
        "output_cost_per_token": 1.4e-07,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true
    },
    "amazon.nova-pro-v1:0": {
        "display_name": "Nova Pro",
        "input_cost_per_token": 8e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 300000,
        "max_output_tokens": 10000,
        "max_tokens": 10000,
        "mode": "chat",
        "model_vendor": "amazon",
        "model_version": "v1:0",
        "output_cost_per_token": 3.2e-06,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "amazon.rerank-v1:0": {
        "display_name": "Amazon Rerank",
        "input_cost_per_query": 0.001,
        "input_cost_per_token": 0.0,
        "litellm_provider": "bedrock",
        "max_document_chunks_per_query": 100,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000,
        "max_query_tokens": 32000,
        "max_tokens": 32000,
        "max_tokens_per_document_chunk": 512,
        "mode": "rerank",
        "model_vendor": "amazon",
        "model_version": "v1:0",
        "output_cost_per_token": 0.0
    },
    "amazon.titan-embed-image-v1": {
        "display_name": "Titan Embed Image",
        "input_cost_per_image": 6e-05,
        "input_cost_per_token": 8e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128,
        "max_tokens": 128,
        "metadata": {
            "notes": "'supports_image_input' is a deprecated field. Use 'supports_embedding_image_input' instead."
        },
        "mode": "embedding",
        "model_vendor": "amazon",
        "model_version": "v1",
        "output_cost_per_token": 0.0,
        "output_vector_size": 1024,
        "source": "https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/providers?model=amazon.titan-image-generator-v1",
        "supports_embedding_image_input": true,
        "supports_image_input": true
    },
    "amazon.titan-embed-text-v1": {
        "display_name": "Titan Embed Text",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_tokens": 8192,
        "mode": "embedding",
        "model_vendor": "amazon",
        "model_version": "v1",
        "output_cost_per_token": 0.0,
        "output_vector_size": 1536
    },
    "amazon.titan-embed-text-v2:0": {
        "display_name": "Titan Embed Text",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_tokens": 8192,
        "mode": "embedding",
        "model_vendor": "amazon",
        "model_version": "v2:0",
        "output_cost_per_token": 0.0,
        "output_vector_size": 1024
    },
    "amazon.titan-image-generator-v1": {
        "display_name": "Titan Image Generator",
        "input_cost_per_image": 0.0,
        "litellm_provider": "bedrock",
        "mode": "image_generation",
        "model_vendor": "amazon",
        "model_version": "v1",
        "output_cost_per_image": 0.008,
        "output_cost_per_image_above_512_and_512_pixels": 0.01,
        "output_cost_per_image_above_512_and_512_pixels_and_premium_image": 0.012,
        "output_cost_per_image_premium_image": 0.01
    },
    "amazon.titan-image-generator-v2": {
        "display_name": "Titan Image Generator",
        "input_cost_per_image": 0.0,
        "litellm_provider": "bedrock",
        "mode": "image_generation",
        "model_vendor": "amazon",
        "model_version": "v2",
        "output_cost_per_image": 0.008,
        "output_cost_per_image_above_1024_and_1024_pixels": 0.01,
        "output_cost_per_image_above_1024_and_1024_pixels_and_premium_image": 0.012,
        "output_cost_per_image_premium_image": 0.01
    },
    "amazon.titan-image-generator-v2:0": {
        "display_name": "Titan Image Generator V2:0",
        "model_vendor": "amazon",
        "model_version": "0",
        "input_cost_per_image": 0.0,
        "output_cost_per_image": 0.008,
        "output_cost_per_image_premium_image": 0.01,
        "output_cost_per_image_above_1024_and_1024_pixels": 0.01,
        "output_cost_per_image_above_1024_and_1024_pixels_and_premium_image": 0.012,
        "litellm_provider": "bedrock",
        "mode": "image_generation"
    },
    "twelvelabs.marengo-embed-2-7-v1:0": {
        "display_name": "Marengo Embed",
        "input_cost_per_token": 7e-05,
        "litellm_provider": "bedrock",
        "max_input_tokens": 77,
        "max_tokens": 77,
        "mode": "embedding",
        "model_vendor": "twelve-labs",
        "model_version": "2.7-v1:0",
        "output_cost_per_token": 0.0,
        "output_vector_size": 1024,
        "supports_embedding_image_input": true,
        "supports_image_input": true
    },
    "us.twelvelabs.marengo-embed-2-7-v1:0": {
        "display_name": "Marengo Embed",
        "input_cost_per_audio_per_second": 0.00014,
        "input_cost_per_image": 0.0001,
        "input_cost_per_token": 7e-05,
        "input_cost_per_video_per_second": 0.0007,
        "litellm_provider": "bedrock",
        "max_input_tokens": 77,
        "max_tokens": 77,
        "mode": "embedding",
        "model_vendor": "twelve-labs",
        "model_version": "2.7-v1:0",
        "output_cost_per_token": 0.0,
        "output_vector_size": 1024,
        "supports_embedding_image_input": true,
        "supports_image_input": true
    },
    "eu.twelvelabs.marengo-embed-2-7-v1:0": {
        "display_name": "Marengo Embed",
        "input_cost_per_audio_per_second": 0.00014,
        "input_cost_per_image": 0.0001,
        "input_cost_per_token": 7e-05,
        "input_cost_per_video_per_second": 0.0007,
        "litellm_provider": "bedrock",
        "max_input_tokens": 77,
        "max_tokens": 77,
        "mode": "embedding",
        "model_vendor": "twelve-labs",
        "model_version": "2.7-v1:0",
        "output_cost_per_token": 0.0,
        "output_vector_size": 1024,
        "supports_embedding_image_input": true,
        "supports_image_input": true
    },
    "twelvelabs.pegasus-1-2-v1:0": {
        "display_name": "Pegasus",
        "input_cost_per_video_per_second": 0.00049,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "model_vendor": "twelve-labs",
        "model_version": "1.2-v1:0",
        "output_cost_per_token": 7.5e-06,
        "supports_video_input": true
    },
    "us.twelvelabs.pegasus-1-2-v1:0": {
        "display_name": "Pegasus",
        "input_cost_per_video_per_second": 0.00049,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "model_vendor": "twelve-labs",
        "model_version": "1.2-v1:0",
        "output_cost_per_token": 7.5e-06,
        "supports_video_input": true
    },
    "eu.twelvelabs.pegasus-1-2-v1:0": {
        "display_name": "Pegasus",
        "input_cost_per_video_per_second": 0.00049,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "model_vendor": "twelve-labs",
        "model_version": "1.2-v1:0",
        "output_cost_per_token": 7.5e-06,
        "supports_video_input": true
    },
    "amazon.titan-text-express-v1": {
        "display_name": "Titan Text Express",
        "input_cost_per_token": 1.3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 42000,
        "max_output_tokens": 8000,
        "max_tokens": 8000,
        "mode": "chat",
        "model_vendor": "amazon",
        "model_version": "v1",
        "output_cost_per_token": 1.7e-06
    },
    "amazon.titan-text-lite-v1": {
        "display_name": "Titan Text Lite",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 42000,
        "max_output_tokens": 4000,
        "max_tokens": 4000,
        "mode": "chat",
        "model_vendor": "amazon",
        "model_version": "v1",
        "output_cost_per_token": 4e-07
    },
    "amazon.titan-text-premier-v1:0": {
        "display_name": "Titan Text Premier",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 42000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "model_vendor": "amazon",
        "model_version": "v1:0",
        "output_cost_per_token": 1.5e-06
    },
    "anthropic.claude-3-5-haiku-20241022-v1:0": {
        "cache_creation_input_token_cost": 1e-06,
        "cache_read_input_token_cost": 8e-08,
        "display_name": "Claude 3.5 Haiku",
        "input_cost_per_token": 8e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20241022-v1:0",
        "output_cost_per_token": 4e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "anthropic.claude-haiku-4-5-20251001-v1:0": {
        "cache_creation_input_token_cost": 1.25e-06,
        "cache_read_input_token_cost": 1e-07,
        "display_name": "Claude 4.5 Haiku",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20251001-v1:0",
        "output_cost_per_token": 5e-06,
        "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 346
    },
    "anthropic.claude-haiku-4-5@20251001": {
        "cache_creation_input_token_cost": 1.25e-06,
        "cache_read_input_token_cost": 1e-07,
        "display_name": "Claude 4.5 Haiku",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20251001",
        "output_cost_per_token": 5e-06,
        "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 346
    },
    "anthropic.claude-3-5-sonnet-20240620-v1:0": {
        "display_name": "Claude 3.5 Sonnet",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20240620-v1:0",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "anthropic.claude-3-5-sonnet-20241022-v2:0": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "display_name": "Claude 3.5 Sonnet",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20241022-v2:0",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "anthropic.claude-3-7-sonnet-20240620-v1:0": {
        "cache_creation_input_token_cost": 4.5e-06,
        "cache_read_input_token_cost": 3.6e-07,
        "display_name": "Claude 3.7 Sonnet",
        "input_cost_per_token": 3.6e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20240620-v1:0",
        "output_cost_per_token": 1.8e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "anthropic.claude-3-7-sonnet-20250219-v1:0": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "display_name": "Claude 3.7 Sonnet",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20250219-v1:0",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "anthropic.claude-3-haiku-20240307-v1:0": {
        "display_name": "Claude 3 Haiku",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20240307-v1:0",
        "output_cost_per_token": 1.25e-06,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "anthropic.claude-3-opus-20240229-v1:0": {
        "display_name": "Claude 3 Opus",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20240229-v1:0",
        "output_cost_per_token": 7.5e-05,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "anthropic.claude-3-sonnet-20240229-v1:0": {
        "display_name": "Claude 3 Sonnet",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20240229-v1:0",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "anthropic.claude-instant-v1": {
        "display_name": "Claude Instant",
        "input_cost_per_token": 8e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "v1",
        "output_cost_per_token": 2.4e-06,
        "supports_tool_choice": true
    },
    "anthropic.claude-opus-4-1-20250805-v1:0": {
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "display_name": "Claude 4.1 Opus",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20250805-v1:0",
        "output_cost_per_token": 7.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "anthropic.claude-opus-4-20250514-v1:0": {
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "display_name": "Claude 4 Opus",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20250514-v1:0",
        "output_cost_per_token": 7.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "anthropic.claude-opus-4-5-20251101-v1:0": {
        "cache_creation_input_token_cost": 6.25e-06,
        "cache_read_input_token_cost": 5e-07,
        "display_name": "Claude 4.5 Opus",
        "input_cost_per_token": 5e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20251101-v1:0",
        "output_cost_per_token": 2.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "anthropic.claude-sonnet-4-20250514-v1:0": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost": 3e-07,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "display_name": "Claude 4 Sonnet",
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20250514-v1:0",
        "output_cost_per_token": 1.5e-05,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "anthropic.claude-sonnet-4-5-20250929-v1:0": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost": 3e-07,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "display_name": "Claude 4.5 Sonnet",
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20250929-v1:0",
        "output_cost_per_token": 1.5e-05,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "anthropic.claude-v1": {
        "display_name": "Claude",
        "input_cost_per_token": 8e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "v1",
        "output_cost_per_token": 2.4e-05
    },
    "anthropic.claude-v2:1": {
        "display_name": "Claude 2.1",
        "input_cost_per_token": 8e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "v2:1",
        "output_cost_per_token": 2.4e-05,
        "supports_tool_choice": true
    },
    "anyscale/HuggingFaceH4/zephyr-7b-beta": {
        "display_name": "Zephyr 7B Beta",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "anyscale",
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "huggingface",
        "output_cost_per_token": 1.5e-07
    },
    "anyscale/codellama/CodeLlama-34b-Instruct-hf": {
        "display_name": "CodeLlama 34B Instruct",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "anyscale",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "meta",
        "output_cost_per_token": 1e-06
    },
    "anyscale/codellama/CodeLlama-70b-Instruct-hf": {
        "display_name": "CodeLlama 70B Instruct",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "anyscale",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "meta",
        "output_cost_per_token": 1e-06,
        "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/codellama-CodeLlama-70b-Instruct-hf"
    },
    "anyscale/google/gemma-7b-it": {
        "display_name": "Gemma 7B IT",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "anyscale",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "google",
        "output_cost_per_token": 1.5e-07,
        "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/google-gemma-7b-it"
    },
    "anyscale/meta-llama/Llama-2-13b-chat-hf": {
        "display_name": "Llama 2 13B Chat",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "anyscale",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "meta",
        "output_cost_per_token": 2.5e-07
    },
    "anyscale/meta-llama/Llama-2-70b-chat-hf": {
        "display_name": "Llama 2 70B Chat",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "anyscale",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "meta",
        "output_cost_per_token": 1e-06
    },
    "anyscale/meta-llama/Llama-2-7b-chat-hf": {
        "display_name": "Llama 2 7B Chat",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "anyscale",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "meta",
        "output_cost_per_token": 1.5e-07
    },
    "anyscale/meta-llama/Meta-Llama-3-70B-Instruct": {
        "display_name": "Llama 3 70B Instruct",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "anyscale",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "meta",
        "output_cost_per_token": 1e-06,
        "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-70B-Instruct"
    },
    "anyscale/meta-llama/Meta-Llama-3-8B-Instruct": {
        "display_name": "Llama 3 8B Instruct",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "anyscale",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "meta",
        "output_cost_per_token": 1.5e-07,
        "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-8B-Instruct"
    },
    "anyscale/mistralai/Mistral-7B-Instruct-v0.1": {
        "display_name": "Mistral 7B Instruct",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "anyscale",
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "mistral",
        "model_version": "v0.1",
        "output_cost_per_token": 1.5e-07,
        "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mistral-7B-Instruct-v0.1",
        "supports_function_calling": true
    },
    "anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1": {
        "display_name": "Mixtral 8x22B Instruct",
        "input_cost_per_token": 9e-07,
        "litellm_provider": "anyscale",
        "max_input_tokens": 65536,
        "max_output_tokens": 65536,
        "max_tokens": 65536,
        "mode": "chat",
        "model_vendor": "mistral",
        "model_version": "v0.1",
        "output_cost_per_token": 9e-07,
        "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x22B-Instruct-v0.1",
        "supports_function_calling": true
    },
    "anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1": {
        "display_name": "Mixtral 8x7B Instruct",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "anyscale",
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "mistral",
        "model_version": "v0.1",
        "output_cost_per_token": 1.5e-07,
        "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x7B-Instruct-v0.1",
        "supports_function_calling": true
    },
    "apac.amazon.nova-lite-v1:0": {
        "display_name": "Nova Lite",
        "input_cost_per_token": 6.3e-08,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 300000,
        "max_output_tokens": 10000,
        "max_tokens": 10000,
        "mode": "chat",
        "model_vendor": "amazon",
        "model_version": "v1:0",
        "output_cost_per_token": 2.52e-07,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "apac.amazon.nova-micro-v1:0": {
        "display_name": "Nova Micro",
        "input_cost_per_token": 3.7e-08,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 10000,
        "max_tokens": 10000,
        "mode": "chat",
        "model_vendor": "amazon",
        "model_version": "v1:0",
        "output_cost_per_token": 1.48e-07,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true
    },
    "apac.amazon.nova-pro-v1:0": {
        "display_name": "Nova Pro",
        "input_cost_per_token": 8.4e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 300000,
        "max_output_tokens": 10000,
        "max_tokens": 10000,
        "mode": "chat",
        "model_vendor": "amazon",
        "model_version": "v1:0",
        "output_cost_per_token": 3.36e-06,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "apac.anthropic.claude-3-5-sonnet-20240620-v1:0": {
        "display_name": "Claude 3.5 Sonnet",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20240620-v1:0",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "apac.anthropic.claude-3-5-sonnet-20241022-v2:0": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "display_name": "Claude 3.5 Sonnet",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20241022-v2:0",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "apac.anthropic.claude-3-haiku-20240307-v1:0": {
        "display_name": "Claude 3 Haiku",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20240307-v1:0",
        "output_cost_per_token": 1.25e-06,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "apac.anthropic.claude-haiku-4-5-20251001-v1:0": {
        "cache_creation_input_token_cost": 1.375e-06,
        "cache_read_input_token_cost": 1.1e-07,
        "display_name": "Claude 4.5 Haiku",
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20251001-v1:0",
        "output_cost_per_token": 5.5e-06,
        "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 346
    },
    "apac.anthropic.claude-3-sonnet-20240229-v1:0": {
        "display_name": "Claude 3 Sonnet",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20240229-v1:0",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "apac.anthropic.claude-sonnet-4-20250514-v1:0": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost": 3e-07,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "display_name": "Claude 4 Sonnet",
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20250514-v1:0",
        "output_cost_per_token": 1.5e-05,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "assemblyai/best": {
        "display_name": "AssemblyAI Best",
        "input_cost_per_second": 3.333e-05,
        "litellm_provider": "assemblyai",
        "mode": "audio_transcription",
        "model_vendor": "assemblyai",
        "output_cost_per_second": 0.0
    },
    "assemblyai/nano": {
        "display_name": "AssemblyAI Nano",
        "input_cost_per_second": 0.00010278,
        "litellm_provider": "assemblyai",
        "mode": "audio_transcription",
        "model_vendor": "assemblyai",
        "output_cost_per_second": 0.0
    },
    "au.anthropic.claude-sonnet-4-5-20250929-v1:0": {
        "cache_creation_input_token_cost": 4.125e-06,
        "cache_creation_input_token_cost_above_200k_tokens": 8.25e-06,
        "cache_read_input_token_cost": 3.3e-07,
        "cache_read_input_token_cost_above_200k_tokens": 6.6e-07,
        "display_name": "Claude 4.5 Sonnet",
        "input_cost_per_token": 3.3e-06,
        "input_cost_per_token_above_200k_tokens": 6.6e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20250929-v1:0",
        "output_cost_per_token": 1.65e-05,
        "output_cost_per_token_above_200k_tokens": 2.475e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 346
    },
    "azure/ada": {
        "display_name": "Ada",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 8191,
        "max_tokens": 8191,
        "mode": "embedding",
        "model_vendor": "openai",
        "output_cost_per_token": 0.0
    },
    "azure/codex-mini": {
        "cache_read_input_token_cost": 3.75e-07,
        "display_name": "Codex Mini",
        "input_cost_per_token": 1.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "model_vendor": "openai",
        "output_cost_per_token": 6e-06,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/command-r-plus": {
        "display_name": "Command R+",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "cohere",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true
    },
    "azure_ai/claude-haiku-4-5": {
        "display_name": "Claude 4.5 Haiku",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 5e-06,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure_ai/claude-opus-4-1": {
        "display_name": "Claude 4.1 Opus",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 7.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure_ai/claude-sonnet-4-5": {
        "display_name": "Claude 4.5 Sonnet",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/computer-use-preview": {
        "display_name": "Computer Use Preview",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 8192,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 1.2e-05,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": false,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/container": {
        "code_interpreter_cost_per_session": 0.03,
        "display_name": "Container",
        "litellm_provider": "azure",
        "mode": "chat",
        "model_vendor": "openai"
    },
    "azure/eu/gpt-4o-2024-08-06": {
        "cache_read_input_token_cost": 1.375e-06,
        "deprecation_date": "2026-02-27",
        "display_name": "GPT-4o",
        "input_cost_per_token": 2.75e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-08-06",
        "output_cost_per_token": 1.1e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/eu/gpt-4o-2024-11-20": {
        "cache_creation_input_token_cost": 1.38e-06,
        "deprecation_date": "2026-03-01",
        "display_name": "GPT-4o",
        "input_cost_per_token": 2.75e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-11-20",
        "output_cost_per_token": 1.1e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/eu/gpt-4o-mini-2024-07-18": {
        "cache_read_input_token_cost": 8.3e-08,
        "display_name": "GPT-4o Mini",
        "input_cost_per_token": 1.65e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-07-18",
        "output_cost_per_token": 6.6e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/eu/gpt-4o-mini-realtime-preview-2024-12-17": {
        "cache_creation_input_audio_token_cost": 3.3e-07,
        "cache_read_input_token_cost": 3.3e-07,
        "display_name": "GPT-4o Mini Realtime",
        "input_cost_per_audio_token": 1.1e-05,
        "input_cost_per_token": 6.6e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "realtime-2024-12-17",
        "output_cost_per_audio_token": 2.2e-05,
        "output_cost_per_token": 2.64e-06,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/eu/gpt-4o-realtime-preview-2024-10-01": {
        "cache_creation_input_audio_token_cost": 2.2e-05,
        "cache_read_input_token_cost": 2.75e-06,
        "display_name": "GPT-4o Realtime",
        "input_cost_per_audio_token": 0.00011,
        "input_cost_per_token": 5.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "realtime-2024-10-01",
        "output_cost_per_audio_token": 0.00022,
        "output_cost_per_token": 2.2e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/eu/gpt-4o-realtime-preview-2024-12-17": {
        "cache_read_input_audio_token_cost": 2.5e-06,
        "cache_read_input_token_cost": 2.75e-06,
        "display_name": "GPT-4o Realtime",
        "input_cost_per_audio_token": 4.4e-05,
        "input_cost_per_token": 5.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "realtime-2024-12-17",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 2.2e-05,
        "supported_modalities": [
            "text",
            "audio"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/eu/gpt-5-2025-08-07": {
        "cache_read_input_token_cost": 1.375e-07,
        "display_name": "GPT-5",
        "input_cost_per_token": 1.375e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-08-07",
        "output_cost_per_token": 1.1e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/eu/gpt-5-mini-2025-08-07": {
        "cache_read_input_token_cost": 2.75e-08,
        "display_name": "GPT-5 Mini",
        "input_cost_per_token": 2.75e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-08-07",
        "output_cost_per_token": 2.2e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/eu/gpt-5.1": {
        "cache_read_input_token_cost": 1.4e-07,
        "display_name": "GPT-5.1",
        "input_cost_per_token": 1.38e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 1.1e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/eu/gpt-5.1-chat": {
        "cache_read_input_token_cost": 1.4e-07,
        "display_name": "GPT-5.1 Chat",
        "input_cost_per_token": 1.38e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 1.1e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/eu/gpt-5.1-codex": {
        "cache_read_input_token_cost": 1.4e-07,
        "display_name": "GPT-5.1 Codex",
        "input_cost_per_token": 1.38e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "model_vendor": "openai",
        "output_cost_per_token": 1.1e-05,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/eu/gpt-5.1-codex-mini": {
        "cache_read_input_token_cost": 2.8e-08,
        "display_name": "GPT-5.1 Codex Mini",
        "input_cost_per_token": 2.75e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "model_vendor": "openai",
        "output_cost_per_token": 2.2e-06,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/eu/gpt-5-nano-2025-08-07": {
        "cache_read_input_token_cost": 5.5e-09,
        "display_name": "GPT-5 Nano",
        "input_cost_per_token": 5.5e-08,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-08-07",
        "output_cost_per_token": 4.4e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/eu/o1-2024-12-17": {
        "cache_read_input_token_cost": 8.25e-06,
        "display_name": "o1",
        "input_cost_per_token": 1.65e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-12-17",
        "output_cost_per_token": 6.6e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/eu/o1-mini-2024-09-12": {
        "cache_read_input_token_cost": 6.05e-07,
        "display_name": "o1 Mini",
        "input_cost_per_token": 1.21e-06,
        "input_cost_per_token_batches": 6.05e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "max_tokens": 65536,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-09-12",
        "output_cost_per_token": 4.84e-06,
        "output_cost_per_token_batches": 2.42e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_vision": false
    },
    "azure/eu/o1-preview-2024-09-12": {
        "cache_read_input_token_cost": 8.25e-06,
        "display_name": "o1 Preview",
        "input_cost_per_token": 1.65e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "preview-2024-09-12",
        "output_cost_per_token": 6.6e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_vision": false
    },
    "azure/eu/o3-mini-2025-01-31": {
        "cache_read_input_token_cost": 6.05e-07,
        "display_name": "o3 Mini",
        "input_cost_per_token": 1.21e-06,
        "input_cost_per_token_batches": 6.05e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-01-31",
        "output_cost_per_token": 4.84e-06,
        "output_cost_per_token_batches": 2.42e-06,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "azure/global-standard/gpt-4o-2024-08-06": {
        "cache_read_input_token_cost": 1.25e-06,
        "deprecation_date": "2026-02-27",
        "display_name": "GPT-4o",
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-08-06",
        "output_cost_per_token": 1e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/global-standard/gpt-4o-2024-11-20": {
        "cache_read_input_token_cost": 1.25e-06,
        "deprecation_date": "2026-03-01",
        "display_name": "GPT-4o",
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-11-20",
        "output_cost_per_token": 1e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/global-standard/gpt-4o-mini": {
        "display_name": "GPT-4o Mini",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 6e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/global/gpt-4o-2024-08-06": {
        "cache_read_input_token_cost": 1.25e-06,
        "deprecation_date": "2026-02-27",
        "display_name": "GPT-4o",
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-08-06",
        "output_cost_per_token": 1e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/global/gpt-4o-2024-11-20": {
        "cache_read_input_token_cost": 1.25e-06,
        "deprecation_date": "2026-03-01",
        "display_name": "GPT-4o",
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-11-20",
        "output_cost_per_token": 1e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/global/gpt-5.1": {
        "cache_read_input_token_cost": 1.25e-07,
        "display_name": "GPT-5.1",
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/global/gpt-5.1-chat": {
        "cache_read_input_token_cost": 1.25e-07,
        "display_name": "GPT-5.1 Chat",
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/global/gpt-5.1-codex": {
        "cache_read_input_token_cost": 1.25e-07,
        "display_name": "GPT-5.1 Codex",
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "model_vendor": "openai",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/global/gpt-5.1-codex-mini": {
        "cache_read_input_token_cost": 2.5e-08,
        "display_name": "GPT-5.1 Codex Mini",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "model_vendor": "openai",
        "output_cost_per_token": 2e-06,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-3.5-turbo": {
        "display_name": "GPT-3.5 Turbo",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 4097,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 1.5e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-3.5-turbo-0125": {
        "deprecation_date": "2025-03-31",
        "display_name": "GPT-3.5 Turbo",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 16384,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "0125",
        "output_cost_per_token": 1.5e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-3.5-turbo-instruct-0914": {
        "display_name": "GPT-3.5 Turbo Instruct",
        "input_cost_per_token": 1.5e-06,
        "litellm_provider": "azure_text",
        "max_input_tokens": 4097,
        "max_tokens": 4097,
        "mode": "completion",
        "model_vendor": "openai",
        "model_version": "instruct-0914",
        "output_cost_per_token": 2e-06
    },
    "azure/gpt-35-turbo": {
        "display_name": "GPT-3.5 Turbo",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 4097,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 1.5e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-35-turbo-0125": {
        "deprecation_date": "2025-05-31",
        "display_name": "GPT-3.5 Turbo",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 16384,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "0125",
        "output_cost_per_token": 1.5e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-35-turbo-0301": {
        "deprecation_date": "2025-02-13",
        "display_name": "GPT-3.5 Turbo",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 4097,
        "max_output_tokens": 4096,
        "max_tokens": 4097,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "0301",
        "output_cost_per_token": 2e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-35-turbo-0613": {
        "deprecation_date": "2025-02-13",
        "display_name": "GPT-3.5 Turbo",
        "input_cost_per_token": 1.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 4097,
        "max_output_tokens": 4096,
        "max_tokens": 4097,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "0613",
        "output_cost_per_token": 2e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-35-turbo-1106": {
        "deprecation_date": "2025-03-31",
        "display_name": "GPT-3.5 Turbo",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 16384,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "1106",
        "output_cost_per_token": 2e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-35-turbo-16k": {
        "display_name": "GPT-3.5 Turbo 16K",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 4e-06,
        "supports_tool_choice": true
    },
    "azure/gpt-35-turbo-16k-0613": {
        "display_name": "GPT-3.5 Turbo 16K",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "16k-0613",
        "output_cost_per_token": 4e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-35-turbo-instruct": {
        "display_name": "GPT-3.5 Turbo Instruct",
        "input_cost_per_token": 1.5e-06,
        "litellm_provider": "azure_text",
        "max_input_tokens": 4097,
        "max_tokens": 4097,
        "mode": "completion",
        "model_vendor": "openai",
        "output_cost_per_token": 2e-06
    },
    "azure/gpt-35-turbo-instruct-0914": {
        "display_name": "GPT-3.5 Turbo Instruct",
        "input_cost_per_token": 1.5e-06,
        "litellm_provider": "azure_text",
        "max_input_tokens": 4097,
        "max_tokens": 4097,
        "mode": "completion",
        "model_vendor": "openai",
        "model_version": "instruct-0914",
        "output_cost_per_token": 2e-06
    },
    "azure/gpt-4": {
        "display_name": "GPT-4",
        "input_cost_per_token": 3e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 6e-05,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4-0125-preview": {
        "display_name": "GPT-4 Turbo Preview",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "0125-preview",
        "output_cost_per_token": 3e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4-0613": {
        "display_name": "GPT-4",
        "input_cost_per_token": 3e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "0613",
        "output_cost_per_token": 6e-05,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4-1106-preview": {
        "display_name": "GPT-4 Turbo Preview",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "1106-preview",
        "output_cost_per_token": 3e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4-32k": {
        "display_name": "GPT-4 32K",
        "input_cost_per_token": 6e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 0.00012,
        "supports_tool_choice": true
    },
    "azure/gpt-4-32k-0613": {
        "display_name": "GPT-4 32K",
        "input_cost_per_token": 6e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "32k-0613",
        "output_cost_per_token": 0.00012,
        "supports_tool_choice": true
    },
    "azure/gpt-4-turbo": {
        "display_name": "GPT-4 Turbo",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 3e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4-turbo-2024-04-09": {
        "display_name": "GPT-4 Turbo",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-04-09",
        "output_cost_per_token": 3e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-4-turbo-vision-preview": {
        "display_name": "GPT-4 Turbo Vision",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "vision-preview",
        "output_cost_per_token": 3e-05,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-4.1": {
        "cache_read_input_token_cost": 5e-07,
        "display_name": "GPT-4.1",
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_batches": 1e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 8e-06,
        "output_cost_per_token_batches": 4e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": false
    },
    "azure/gpt-4.1-2025-04-14": {
        "cache_read_input_token_cost": 5e-07,
        "deprecation_date": "2026-11-04",
        "display_name": "GPT-4.1",
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_batches": 1e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-04-14",
        "output_cost_per_token": 8e-06,
        "output_cost_per_token_batches": 4e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": false
    },
    "azure/gpt-4.1-mini": {
        "cache_read_input_token_cost": 1e-07,
        "display_name": "GPT-4.1 Mini",
        "input_cost_per_token": 4e-07,
        "input_cost_per_token_batches": 2e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 1.6e-06,
        "output_cost_per_token_batches": 8e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": false
    },
    "azure/gpt-4.1-mini-2025-04-14": {
        "cache_read_input_token_cost": 1e-07,
        "deprecation_date": "2026-11-04",
        "display_name": "GPT-4.1 Mini",
        "input_cost_per_token": 4e-07,
        "input_cost_per_token_batches": 2e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "mini-2025-04-14",
        "output_cost_per_token": 1.6e-06,
        "output_cost_per_token_batches": 8e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": false
    },
    "azure/gpt-4.1-nano": {
        "cache_read_input_token_cost": 2.5e-08,
        "display_name": "GPT-4.1 Nano",
        "input_cost_per_token": 1e-07,
        "input_cost_per_token_batches": 5e-08,
        "litellm_provider": "azure",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 4e-07,
        "output_cost_per_token_batches": 2e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-4.1-nano-2025-04-14": {
        "cache_read_input_token_cost": 2.5e-08,
        "deprecation_date": "2026-11-04",
        "display_name": "GPT-4.1 Nano",
        "input_cost_per_token": 1e-07,
        "input_cost_per_token_batches": 5e-08,
        "litellm_provider": "azure",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "nano-2025-04-14",
        "output_cost_per_token": 4e-07,
        "output_cost_per_token_batches": 2e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-4.5-preview": {
        "cache_read_input_token_cost": 3.75e-05,
        "display_name": "GPT-4.5 Preview",
        "input_cost_per_token": 7.5e-05,
        "input_cost_per_token_batches": 3.75e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 0.00015,
        "output_cost_per_token_batches": 7.5e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-4o": {
        "cache_read_input_token_cost": 1.25e-06,
        "display_name": "GPT-4o",
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 1e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-4o-2024-05-13": {
        "display_name": "GPT-4o",
        "input_cost_per_token": 5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-05-13",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-4o-2024-08-06": {
        "cache_read_input_token_cost": 1.25e-06,
        "deprecation_date": "2026-02-27",
        "display_name": "GPT-4o",
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-08-06",
        "output_cost_per_token": 1e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-4o-2024-11-20": {
        "cache_read_input_token_cost": 1.25e-06,
        "deprecation_date": "2026-03-01",
        "display_name": "GPT-4o",
        "input_cost_per_token": 2.75e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-11-20",
        "output_cost_per_token": 1.1e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-audio-2025-08-28": {
        "display_name": "GPT Audio",
        "input_cost_per_audio_token": 4e-05,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-08-28",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/chat/completions"
        ],
        "supported_modalities": [
            "text",
            "audio"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": false,
        "supports_reasoning": false,
        "supports_response_schema": false,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "azure/gpt-audio-mini-2025-10-06": {
        "display_name": "GPT Audio Mini",
        "input_cost_per_audio_token": 1e-05,
        "input_cost_per_token": 6e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "mini-2025-10-06",
        "output_cost_per_audio_token": 2e-05,
        "output_cost_per_token": 2.4e-06,
        "supported_endpoints": [
            "/v1/chat/completions"
        ],
        "supported_modalities": [
            "text",
            "audio"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": false,
        "supports_reasoning": false,
        "supports_response_schema": false,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "azure/gpt-4o-audio-preview-2024-12-17": {
        "display_name": "GPT-4o Audio Preview",
        "input_cost_per_audio_token": 4e-05,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "audio-preview-2024-12-17",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/chat/completions"
        ],
        "supported_modalities": [
            "text",
            "audio"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": false,
        "supports_reasoning": false,
        "supports_response_schema": false,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "azure/gpt-4o-mini": {
        "cache_read_input_token_cost": 7.5e-08,
        "display_name": "GPT-4o Mini",
        "input_cost_per_token": 1.65e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 6.6e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-4o-mini-2024-07-18": {
        "cache_read_input_token_cost": 7.5e-08,
        "display_name": "GPT-4o Mini",
        "input_cost_per_token": 1.65e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-07-18",
        "output_cost_per_token": 6.6e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-4o-mini-audio-preview-2024-12-17": {
        "display_name": "GPT-4o Mini Audio Preview",
        "input_cost_per_audio_token": 4e-05,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "audio-preview-2024-12-17",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/chat/completions"
        ],
        "supported_modalities": [
            "text",
            "audio"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": false,
        "supports_reasoning": false,
        "supports_response_schema": false,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "azure/gpt-4o-mini-realtime-preview-2024-12-17": {
        "cache_creation_input_audio_token_cost": 3e-07,
        "cache_read_input_token_cost": 3e-07,
        "display_name": "GPT-4o Mini Realtime Preview",
        "input_cost_per_audio_token": 1e-05,
        "input_cost_per_token": 6e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "realtime-preview-2024-12-17",
        "output_cost_per_audio_token": 2e-05,
        "output_cost_per_token": 2.4e-06,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/gpt-realtime-2025-08-28": {
        "cache_creation_input_audio_token_cost": 4e-06,
        "cache_read_input_token_cost": 4e-06,
        "display_name": "GPT Realtime",
        "input_cost_per_audio_token": 3.2e-05,
        "input_cost_per_image": 5e-06,
        "input_cost_per_token": 4e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 32000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-08-28",
        "output_cost_per_audio_token": 6.4e-05,
        "output_cost_per_token": 1.6e-05,
        "supported_endpoints": [
            "/v1/realtime"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/gpt-realtime-mini-2025-10-06": {
        "cache_creation_input_audio_token_cost": 3e-07,
        "cache_read_input_token_cost": 6e-08,
        "display_name": "GPT Realtime Mini",
        "input_cost_per_audio_token": 1e-05,
        "input_cost_per_image": 8e-07,
        "input_cost_per_token": 6e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 32000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "mini-2025-10-06",
        "output_cost_per_audio_token": 2e-05,
        "output_cost_per_token": 2.4e-06,
        "supported_endpoints": [
            "/v1/realtime"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4o-mini-transcribe": {
        "display_name": "GPT-4o Mini Transcribe",
        "input_cost_per_audio_token": 3e-06,
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 16000,
        "max_output_tokens": 2000,
        "mode": "audio_transcription",
        "model_vendor": "openai",
        "output_cost_per_token": 5e-06,
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "azure/gpt-4o-mini-tts": {
        "display_name": "GPT-4o Mini TTS",
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "azure",
        "mode": "audio_speech",
        "model_vendor": "openai",
        "output_cost_per_audio_token": 1.2e-05,
        "output_cost_per_second": 0.00025,
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/audio/speech"
        ],
        "supported_modalities": [
            "text",
            "audio"
        ],
        "supported_output_modalities": [
            "audio"
        ]
    },
    "azure/gpt-4o-realtime-preview-2024-10-01": {
        "cache_creation_input_audio_token_cost": 2e-05,
        "cache_read_input_token_cost": 2.5e-06,
        "display_name": "GPT-4o Realtime Preview",
        "input_cost_per_audio_token": 0.0001,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "realtime-preview-2024-10-01",
        "output_cost_per_audio_token": 0.0002,
        "output_cost_per_token": 2e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4o-realtime-preview-2024-12-17": {
        "cache_read_input_token_cost": 2.5e-06,
        "display_name": "GPT-4o Realtime Preview",
        "input_cost_per_audio_token": 4e-05,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "realtime-preview-2024-12-17",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 2e-05,
        "supported_modalities": [
            "text",
            "audio"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4o-transcribe": {
        "display_name": "GPT-4o Transcribe",
        "input_cost_per_audio_token": 6e-06,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 16000,
        "max_output_tokens": 2000,
        "mode": "audio_transcription",
        "model_vendor": "openai",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "azure/gpt-4o-transcribe-diarize": {
        "display_name": "GPT-4o Transcribe Diarize",
        "input_cost_per_audio_token": 6e-06,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 16000,
        "max_output_tokens": 2000,
        "mode": "audio_transcription",
        "model_vendor": "openai",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "azure/gpt-5.1-2025-11-13": {
        "cache_read_input_token_cost": 1.25e-07,
        "cache_read_input_token_cost_priority": 2.5e-07,
        "display_name": "GPT-5.1",
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_priority": 2.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-11-13",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_priority": 2e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-5.1-chat-2025-11-13": {
        "cache_read_input_token_cost": 1.25e-07,
        "cache_read_input_token_cost_priority": 2.5e-07,
        "display_name": "GPT-5.1 Chat",
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_priority": 2.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "chat-2025-11-13",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_priority": 2e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": false,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "azure/gpt-5.1-codex-2025-11-13": {
        "cache_read_input_token_cost": 1.25e-07,
        "cache_read_input_token_cost_priority": 2.5e-07,
        "display_name": "GPT-5.1 Codex",
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_priority": 2.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "model_vendor": "openai",
        "model_version": "codex-2025-11-13",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_priority": 2e-05,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-5.1-codex-mini-2025-11-13": {
        "cache_read_input_token_cost": 2.5e-08,
        "cache_read_input_token_cost_priority": 4.5e-08,
        "display_name": "GPT-5.1 Codex Mini",
        "input_cost_per_token": 2.5e-07,
        "input_cost_per_token_priority": 4.5e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "model_vendor": "openai",
        "model_version": "codex-mini-2025-11-13",
        "output_cost_per_token": 2e-06,
        "output_cost_per_token_priority": 3.6e-06,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-5": {
        "cache_read_input_token_cost": 1.25e-07,
        "display_name": "GPT-5",
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-5-2025-08-07": {
        "cache_read_input_token_cost": 1.25e-07,
        "display_name": "GPT-5",
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-08-07",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-5-chat": {
        "cache_read_input_token_cost": 1.25e-07,
        "display_name": "GPT-5 Chat",
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 1e-05,
        "source": "https://azure.microsoft.com/en-us/blog/gpt-5-in-azure-ai-foundry-the-future-of-ai-apps-and-agents-starts-here/",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "azure/gpt-5-chat-latest": {
        "cache_read_input_token_cost": 1.25e-07,
        "display_name": "GPT-5 Chat",
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "azure/gpt-5-codex": {
        "cache_read_input_token_cost": 1.25e-07,
        "display_name": "GPT-5 Codex",
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "model_vendor": "openai",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-5-mini": {
        "cache_read_input_token_cost": 2.5e-08,
        "display_name": "GPT-5 Mini",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 2e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-5-mini-2025-08-07": {
        "cache_read_input_token_cost": 2.5e-08,
        "display_name": "GPT-5 Mini",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-08-07",
        "output_cost_per_token": 2e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-5-nano": {
        "cache_read_input_token_cost": 5e-09,
        "display_name": "GPT-5 Nano",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 4e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-5-nano-2025-08-07": {
        "cache_read_input_token_cost": 5e-09,
        "display_name": "GPT-5 Nano",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-08-07",
        "output_cost_per_token": 4e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-5-pro": {
        "display_name": "GPT-5 Pro",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 400000,
        "mode": "responses",
        "model_vendor": "openai",
        "output_cost_per_token": 0.00012,
        "source": "https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/concepts/models-sold-directly-by-azure?pivots=azure-openai&tabs=global-standard-aoai%2Cstandard-chat-completions%2Cglobal-standard#gpt-5",
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-5.1": {
        "cache_read_input_token_cost": 1.25e-07,
        "display_name": "GPT-5.1",
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-5.1-chat": {
        "cache_read_input_token_cost": 1.25e-07,
        "display_name": "GPT-5.1 Chat",
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-5.1-codex": {
        "cache_read_input_token_cost": 1.25e-07,
        "display_name": "GPT-5.1 Codex",
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "model_vendor": "openai",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-5.1-codex-max": {
        "display_name": "GPT 5.1 Codex Max",
        "model_vendor": "openai",
        "model_version": "5.1",
        "cache_read_input_token_cost": 1.25e-07,
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 400000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-5.1-codex-mini": {
        "cache_read_input_token_cost": 2.5e-08,
        "display_name": "GPT-5.1 Codex Mini",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "model_vendor": "openai",
        "output_cost_per_token": 2e-06,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-5.2": {
        "display_name": "GPT 5.2",
        "model_vendor": "openai",
        "model_version": "5.2",
        "cache_read_input_token_cost": 1.75e-07,
        "input_cost_per_token": 1.75e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 400000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.4e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-5.2-2025-12-11": {
        "display_name": "GPT 5.2 2025 12 11",
        "model_vendor": "openai",
        "model_version": "2025-12-11",
        "cache_read_input_token_cost": 1.75e-07,
        "cache_read_input_token_cost_priority": 3.5e-07,
        "input_cost_per_token": 1.75e-06,
        "input_cost_per_token_priority": 3.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 400000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.4e-05,
        "output_cost_per_token_priority": 2.8e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "azure/gpt-5.2-chat-2025-12-11": {
        "display_name": "GPT 5.2 Chat 2025 12 11",
        "model_vendor": "openai",
        "model_version": "2025-12-11",
        "cache_read_input_token_cost": 1.75e-07,
        "cache_read_input_token_cost_priority": 3.5e-07,
        "input_cost_per_token": 1.75e-06,
        "input_cost_per_token_priority": 3.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1.4e-05,
        "output_cost_per_token_priority": 2.8e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/gpt-5.2-pro": {
        "display_name": "GPT 5.2 Pro",
        "model_vendor": "openai",
        "model_version": "5.2",
        "input_cost_per_token": 2.1e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 400000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "output_cost_per_token": 0.000168,
        "supported_endpoints": [
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "azure/gpt-5.2-pro-2025-12-11": {
        "display_name": "GPT 5.2 Pro 2025 12 11",
        "model_vendor": "openai",
        "model_version": "2025-12-11",
        "input_cost_per_token": 2.1e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 400000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "output_cost_per_token": 0.000168,
        "supported_endpoints": [
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "azure/gpt-image-1": {
        "display_name": "GPT Image 1",
        "model_vendor": "openai",
        "input_cost_per_pixel": 4.0054321e-08,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure/hd/1024-x-1024/dall-e-3": {
        "display_name": "DALL-E 3 HD",
        "model_vendor": "openai",
        "input_cost_per_pixel": 7.629e-08,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_token": 0.0
    },
    "azure/hd/1024-x-1792/dall-e-3": {
        "display_name": "DALL-E 3 HD",
        "model_vendor": "openai",
        "input_cost_per_pixel": 6.539e-08,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_token": 0.0
    },
    "azure/hd/1792-x-1024/dall-e-3": {
        "display_name": "DALL-E 3 HD",
        "model_vendor": "openai",
        "input_cost_per_pixel": 6.539e-08,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_token": 0.0
    },
    "azure/high/1024-x-1024/gpt-image-1": {
        "display_name": "GPT Image 1 High",
        "model_vendor": "openai",
        "input_cost_per_pixel": 1.59263611e-07,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure/high/1024-x-1536/gpt-image-1": {
        "display_name": "GPT Image 1 High",
        "model_vendor": "openai",
        "input_cost_per_pixel": 1.58945719e-07,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure/high/1536-x-1024/gpt-image-1": {
        "display_name": "GPT Image 1 High",
        "model_vendor": "openai",
        "input_cost_per_pixel": 1.58945719e-07,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure/low/1024-x-1024/gpt-image-1": {
        "display_name": "GPT Image 1 Low",
        "model_vendor": "openai",
        "input_cost_per_pixel": 1.0490417e-08,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure/low/1024-x-1536/gpt-image-1": {
        "display_name": "GPT Image 1 Low",
        "model_vendor": "openai",
        "input_cost_per_pixel": 1.0172526e-08,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure/low/1536-x-1024/gpt-image-1": {
        "display_name": "GPT Image 1 Low",
        "model_vendor": "openai",
        "input_cost_per_pixel": 1.0172526e-08,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure/medium/1024-x-1024/gpt-image-1": {
        "display_name": "GPT Image 1 Medium",
        "model_vendor": "openai",
        "input_cost_per_pixel": 4.0054321e-08,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure/medium/1024-x-1536/gpt-image-1": {
        "display_name": "GPT Image 1 Medium",
        "model_vendor": "openai",
        "input_cost_per_pixel": 4.0054321e-08,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure/medium/1536-x-1024/gpt-image-1": {
        "display_name": "GPT Image 1 Medium",
        "model_vendor": "openai",
        "input_cost_per_pixel": 4.0054321e-08,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure/gpt-image-1-mini": {
        "display_name": "GPT Image 1 Mini",
        "model_vendor": "openai",
        "input_cost_per_pixel": 8.0566406e-09,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure/low/1024-x-1024/gpt-image-1-mini": {
        "display_name": "GPT Image 1 Mini Low",
        "model_vendor": "openai",
        "input_cost_per_pixel": 2.0751953125e-09,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure/low/1024-x-1536/gpt-image-1-mini": {
        "display_name": "GPT Image 1 Mini Low",
        "model_vendor": "openai",
        "input_cost_per_pixel": 2.0751953125e-09,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure/low/1536-x-1024/gpt-image-1-mini": {
        "display_name": "GPT Image 1 Mini Low",
        "model_vendor": "openai",
        "input_cost_per_pixel": 2.0345052083e-09,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure/medium/1024-x-1024/gpt-image-1-mini": {
        "display_name": "GPT Image 1 Mini Medium",
        "model_vendor": "openai",
        "input_cost_per_pixel": 8.056640625e-09,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure/medium/1024-x-1536/gpt-image-1-mini": {
        "display_name": "GPT Image 1 Mini Medium",
        "model_vendor": "openai",
        "input_cost_per_pixel": 8.056640625e-09,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure/medium/1536-x-1024/gpt-image-1-mini": {
        "display_name": "GPT Image 1 Mini Medium",
        "model_vendor": "openai",
        "input_cost_per_pixel": 7.9752604167e-09,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure/high/1024-x-1024/gpt-image-1-mini": {
        "display_name": "GPT Image 1 Mini High",
        "model_vendor": "openai",
        "input_cost_per_pixel": 3.173828125e-08,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure/high/1024-x-1536/gpt-image-1-mini": {
        "display_name": "GPT Image 1 Mini High",
        "model_vendor": "openai",
        "input_cost_per_pixel": 3.173828125e-08,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure/high/1536-x-1024/gpt-image-1-mini": {
        "display_name": "GPT Image 1 Mini High",
        "model_vendor": "openai",
        "input_cost_per_pixel": 3.1575520833e-08,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure/mistral-large-2402": {
        "display_name": "Mistral Large",
        "input_cost_per_token": 8e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "model_vendor": "mistral",
        "model_version": "2402",
        "output_cost_per_token": 2.4e-05,
        "supports_function_calling": true
    },
    "azure/mistral-large-latest": {
        "display_name": "Mistral Large",
        "input_cost_per_token": 8e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "model_vendor": "mistral",
        "output_cost_per_token": 2.4e-05,
        "supports_function_calling": true
    },
    "azure/o1": {
        "cache_read_input_token_cost": 7.5e-06,
        "display_name": "o1",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 6e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/o1-2024-12-17": {
        "cache_read_input_token_cost": 7.5e-06,
        "display_name": "o1",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-12-17",
        "output_cost_per_token": 6e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/o1-mini": {
        "cache_read_input_token_cost": 6.05e-07,
        "display_name": "o1 Mini",
        "input_cost_per_token": 1.21e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "max_tokens": 65536,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 4.84e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_vision": false
    },
    "azure/o1-mini-2024-09-12": {
        "cache_read_input_token_cost": 5.5e-07,
        "display_name": "o1 Mini",
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "max_tokens": 65536,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-09-12",
        "output_cost_per_token": 4.4e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_vision": false
    },
    "azure/o1-preview": {
        "cache_read_input_token_cost": 7.5e-06,
        "display_name": "o1 Preview",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 6e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_vision": false
    },
    "azure/o1-preview-2024-09-12": {
        "cache_read_input_token_cost": 7.5e-06,
        "display_name": "o1 Preview",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-09-12",
        "output_cost_per_token": 6e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_vision": false
    },
    "azure/o3": {
        "cache_read_input_token_cost": 5e-07,
        "display_name": "o3",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 8e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/o3-2025-04-16": {
        "deprecation_date": "2026-04-16",
        "cache_read_input_token_cost": 5e-07,
        "display_name": "o3",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-04-16",
        "output_cost_per_token": 8e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/o3-deep-research": {
        "cache_read_input_token_cost": 2.5e-06,
        "display_name": "o3 Deep Research",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "model_vendor": "openai",
        "output_cost_per_token": 4e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "azure/o3-mini": {
        "cache_read_input_token_cost": 5.5e-07,
        "display_name": "o3 Mini",
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 4.4e-06,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "azure/o3-mini-2025-01-31": {
        "cache_read_input_token_cost": 5.5e-07,
        "display_name": "o3 Mini",
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-01-31",
        "output_cost_per_token": 4.4e-06,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "azure/o3-pro": {
        "display_name": "o3 Pro",
        "input_cost_per_token": 2e-05,
        "input_cost_per_token_batches": 1e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "model_vendor": "openai",
        "output_cost_per_token": 8e-05,
        "output_cost_per_token_batches": 4e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_prompt_caching": false,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/o3-pro-2025-06-10": {
        "display_name": "o3 Pro",
        "input_cost_per_token": 2e-05,
        "input_cost_per_token_batches": 1e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "model_vendor": "openai",
        "model_version": "2025-06-10",
        "output_cost_per_token": 8e-05,
        "output_cost_per_token_batches": 4e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_prompt_caching": false,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/o4-mini": {
        "cache_read_input_token_cost": 2.75e-07,
        "display_name": "o4 Mini",
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 4.4e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/o4-mini-2025-04-16": {
        "cache_read_input_token_cost": 2.75e-07,
        "display_name": "o4 Mini",
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-04-16",
        "output_cost_per_token": 4.4e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/standard/1024-x-1024/dall-e-2": {
        "display_name": "DALL-E 2",
        "model_vendor": "openai",
        "input_cost_per_pixel": 0.0,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_token": 0.0
    },
    "azure/standard/1024-x-1024/dall-e-3": {
        "display_name": "DALL-E 3",
        "model_vendor": "openai",
        "input_cost_per_pixel": 3.81469e-08,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_token": 0.0
    },
    "azure/standard/1024-x-1792/dall-e-3": {
        "display_name": "DALL-E 3",
        "model_vendor": "openai",
        "input_cost_per_pixel": 4.359e-08,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_token": 0.0
    },
    "azure/standard/1792-x-1024/dall-e-3": {
        "display_name": "DALL-E 3",
        "model_vendor": "openai",
        "input_cost_per_pixel": 4.359e-08,
        "litellm_provider": "azure",
        "mode": "image_generation",
        "output_cost_per_token": 0.0
    },
    "azure/text-embedding-3-large": {
        "display_name": "Text Embedding 3 Large",
        "model_vendor": "openai",
        "input_cost_per_token": 1.3e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 8191,
        "max_tokens": 8191,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "azure/text-embedding-3-small": {
        "display_name": "Text Embedding 3 Small",
        "model_vendor": "openai",
        "deprecation_date": "2026-04-30",
        "input_cost_per_token": 2e-08,
        "litellm_provider": "azure",
        "max_input_tokens": 8191,
        "max_tokens": 8191,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "azure/text-embedding-ada-002": {
        "display_name": "Text Embedding Ada 002",
        "model_vendor": "openai",
        "model_version": "002",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 8191,
        "max_tokens": 8191,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "azure/speech/azure-tts": {
        "display_name": "Azure TTS",
        "input_cost_per_character": 1.5e-05,
        "litellm_provider": "azure",
        "mode": "audio_speech",
        "model_vendor": "microsoft",
        "source": "https://azure.microsoft.com/en-us/pricing/calculator/"
    },
    "azure/speech/azure-tts-hd": {
        "display_name": "Azure TTS HD",
        "input_cost_per_character": 3e-05,
        "litellm_provider": "azure",
        "mode": "audio_speech",
        "model_vendor": "microsoft",
        "source": "https://azure.microsoft.com/en-us/pricing/calculator/"
    },
    "azure/tts-1": {
        "display_name": "TTS 1",
        "input_cost_per_character": 1.5e-05,
        "litellm_provider": "azure",
        "mode": "audio_speech",
        "model_vendor": "openai"
    },
    "azure/tts-1-hd": {
        "display_name": "TTS 1 HD",
        "input_cost_per_character": 3e-05,
        "litellm_provider": "azure",
        "mode": "audio_speech",
        "model_vendor": "openai"
    },
    "azure/us/gpt-4.1-2025-04-14": {
        "deprecation_date": "2026-11-04",
        "cache_read_input_token_cost": 5.5e-07,
        "display_name": "GPT-4.1",
        "input_cost_per_token": 2.2e-06,
        "input_cost_per_token_batches": 1.1e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-04-14",
        "output_cost_per_token": 8.8e-06,
        "output_cost_per_token_batches": 4.4e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": false
    },
    "azure/us/gpt-4.1-mini-2025-04-14": {
        "deprecation_date": "2026-11-04",
        "cache_read_input_token_cost": 1.1e-07,
        "display_name": "GPT-4.1 Mini",
        "input_cost_per_token": 4.4e-07,
        "input_cost_per_token_batches": 2.2e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-04-14",
        "output_cost_per_token": 1.76e-06,
        "output_cost_per_token_batches": 8.8e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": false
    },
    "azure/us/gpt-4.1-nano-2025-04-14": {
        "deprecation_date": "2026-11-04",
        "cache_read_input_token_cost": 2.5e-08,
        "display_name": "GPT-4.1 Nano",
        "input_cost_per_token": 1.1e-07,
        "input_cost_per_token_batches": 6e-08,
        "litellm_provider": "azure",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-04-14",
        "output_cost_per_token": 4.4e-07,
        "output_cost_per_token_batches": 2.2e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/us/gpt-4o-2024-08-06": {
        "deprecation_date": "2026-02-27",
        "cache_read_input_token_cost": 1.375e-06,
        "display_name": "GPT-4o",
        "input_cost_per_token": 2.75e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-08-06",
        "output_cost_per_token": 1.1e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/us/gpt-4o-2024-11-20": {
        "deprecation_date": "2026-03-01",
        "cache_creation_input_token_cost": 1.38e-06,
        "display_name": "GPT-4o",
        "input_cost_per_token": 2.75e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-11-20",
        "output_cost_per_token": 1.1e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/us/gpt-4o-mini-2024-07-18": {
        "cache_read_input_token_cost": 8.3e-08,
        "display_name": "GPT-4o Mini",
        "input_cost_per_token": 1.65e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-07-18",
        "output_cost_per_token": 6.6e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/us/gpt-4o-mini-realtime-preview-2024-12-17": {
        "cache_creation_input_audio_token_cost": 3.3e-07,
        "cache_read_input_token_cost": 3.3e-07,
        "display_name": "GPT-4o Mini Realtime Preview",
        "input_cost_per_audio_token": 1.1e-05,
        "input_cost_per_token": 6.6e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-12-17",
        "output_cost_per_audio_token": 2.2e-05,
        "output_cost_per_token": 2.64e-06,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/us/gpt-4o-realtime-preview-2024-10-01": {
        "cache_creation_input_audio_token_cost": 2.2e-05,
        "cache_read_input_token_cost": 2.75e-06,
        "display_name": "GPT-4o Realtime Preview",
        "input_cost_per_audio_token": 0.00011,
        "input_cost_per_token": 5.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-10-01",
        "output_cost_per_audio_token": 0.00022,
        "output_cost_per_token": 2.2e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/us/gpt-4o-realtime-preview-2024-12-17": {
        "cache_read_input_audio_token_cost": 2.5e-06,
        "cache_read_input_token_cost": 2.75e-06,
        "display_name": "GPT-4o Realtime Preview",
        "input_cost_per_audio_token": 4.4e-05,
        "input_cost_per_token": 5.5e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-12-17",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 2.2e-05,
        "supported_modalities": [
            "text",
            "audio"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/us/gpt-5-2025-08-07": {
        "cache_read_input_token_cost": 1.375e-07,
        "display_name": "GPT-5",
        "input_cost_per_token": 1.375e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-08-07",
        "output_cost_per_token": 1.1e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/us/gpt-5-mini-2025-08-07": {
        "cache_read_input_token_cost": 2.75e-08,
        "display_name": "GPT-5 Mini",
        "input_cost_per_token": 2.75e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-08-07",
        "output_cost_per_token": 2.2e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/us/gpt-5-nano-2025-08-07": {
        "cache_read_input_token_cost": 5.5e-09,
        "display_name": "GPT-5 Nano",
        "input_cost_per_token": 5.5e-08,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-08-07",
        "output_cost_per_token": 4.4e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/us/gpt-5.1": {
        "cache_read_input_token_cost": 1.4e-07,
        "display_name": "GPT-5.1",
        "input_cost_per_token": 1.38e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 1.1e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/us/gpt-5.1-chat": {
        "cache_read_input_token_cost": 1.4e-07,
        "display_name": "GPT-5.1 Chat",
        "input_cost_per_token": 1.38e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 1.1e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/us/gpt-5.1-codex": {
        "cache_read_input_token_cost": 1.4e-07,
        "display_name": "GPT-5.1 Codex",
        "input_cost_per_token": 1.38e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "model_vendor": "openai",
        "output_cost_per_token": 1.1e-05,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/us/gpt-5.1-codex-mini": {
        "cache_read_input_token_cost": 2.8e-08,
        "display_name": "GPT-5.1 Codex Mini",
        "input_cost_per_token": 2.75e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "model_vendor": "openai",
        "output_cost_per_token": 2.2e-06,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/us/o1-2024-12-17": {
        "cache_read_input_token_cost": 8.25e-06,
        "display_name": "o1",
        "input_cost_per_token": 1.65e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-12-17",
        "output_cost_per_token": 6.6e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/us/o1-mini-2024-09-12": {
        "cache_read_input_token_cost": 6.05e-07,
        "display_name": "o1 Mini",
        "input_cost_per_token": 1.21e-06,
        "input_cost_per_token_batches": 6.05e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "max_tokens": 65536,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-09-12",
        "output_cost_per_token": 4.84e-06,
        "output_cost_per_token_batches": 2.42e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_vision": false
    },
    "azure/us/o1-preview-2024-09-12": {
        "cache_read_input_token_cost": 8.25e-06,
        "display_name": "o1 Preview",
        "input_cost_per_token": 1.65e-05,
        "litellm_provider": "azure",
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2024-09-12",
        "output_cost_per_token": 6.6e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_vision": false
    },
    "azure/us/o3-2025-04-16": {
        "deprecation_date": "2026-04-16",
        "cache_read_input_token_cost": 5.5e-07,
        "display_name": "o3",
        "input_cost_per_token": 2.2e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-04-16",
        "output_cost_per_token": 8.8e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/us/o3-mini-2025-01-31": {
        "cache_read_input_token_cost": 6.05e-07,
        "display_name": "o3 Mini",
        "input_cost_per_token": 1.21e-06,
        "input_cost_per_token_batches": 6.05e-07,
        "litellm_provider": "azure",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-01-31",
        "output_cost_per_token": 4.84e-06,
        "output_cost_per_token_batches": 2.42e-06,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "azure/us/o4-mini-2025-04-16": {
        "cache_read_input_token_cost": 3.1e-07,
        "display_name": "o4 Mini",
        "input_cost_per_token": 1.21e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "model_vendor": "openai",
        "model_version": "2025-04-16",
        "output_cost_per_token": 4.84e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure/whisper-1": {
        "display_name": "Whisper",
        "input_cost_per_second": 0.0001,
        "litellm_provider": "azure",
        "mode": "audio_transcription",
        "model_vendor": "openai",
        "output_cost_per_second": 0.0001
    },
    "azure_ai/Cohere-embed-v3-english": {
        "display_name": "Cohere Embed v3 English",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 512,
        "max_tokens": 512,
        "mode": "embedding",
        "model_vendor": "cohere",
        "output_cost_per_token": 0.0,
        "output_vector_size": 1024,
        "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice",
        "supports_embedding_image_input": true
    },
    "azure_ai/Cohere-embed-v3-multilingual": {
        "display_name": "Cohere Embed v3 Multilingual",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 512,
        "max_tokens": 512,
        "mode": "embedding",
        "model_vendor": "cohere",
        "output_cost_per_token": 0.0,
        "output_vector_size": 1024,
        "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice",
        "supports_embedding_image_input": true
    },
    "azure_ai/FLUX-1.1-pro": {
        "display_name": "FLUX 1.1 Pro",
        "litellm_provider": "azure_ai",
        "mode": "image_generation",
        "model_vendor": "black-forest-labs",
        "output_cost_per_image": 0.04,
        "source": "https://techcommunity.microsoft.com/blog/azure-ai-foundry-blog/black-forest-labs-flux-1-kontext-pro-and-flux1-1-pro-now-available-in-azure-ai-f/4434659",
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure_ai/FLUX.1-Kontext-pro": {
        "display_name": "FLUX 1 Kontext Pro",
        "litellm_provider": "azure_ai",
        "mode": "image_generation",
        "model_vendor": "black-forest-labs",
        "output_cost_per_image": 0.04,
        "source": "https://azuremarketplace.microsoft.com/pt-br/marketplace/apps/cohere.cohere-embed-4-offer?tab=PlansAndPrice",
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "azure_ai/Llama-3.2-11B-Vision-Instruct": {
        "display_name": "Llama 3.2 11B Vision",
        "input_cost_per_token": 3.7e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "mode": "chat",
        "model_vendor": "meta",
        "output_cost_per_token": 3.7e-07,
        "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-11b-vision-instruct-offer?tab=Overview",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure_ai/Llama-3.2-90B-Vision-Instruct": {
        "display_name": "Llama 3.2 90B Vision",
        "input_cost_per_token": 2.04e-06,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "mode": "chat",
        "model_vendor": "meta",
        "output_cost_per_token": 2.04e-06,
        "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-90b-vision-instruct-offer?tab=Overview",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure_ai/Llama-3.3-70B-Instruct": {
        "display_name": "Llama 3.3 70B",
        "input_cost_per_token": 7.1e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "mode": "chat",
        "model_vendor": "meta",
        "output_cost_per_token": 7.1e-07,
        "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.llama-3-3-70b-instruct-offer?tab=Overview",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "azure_ai/Llama-4-Maverick-17B-128E-Instruct-FP8": {
        "display_name": "Llama 4 Maverick 17B",
        "input_cost_per_token": 1.41e-06,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 1000000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "meta",
        "output_cost_per_token": 3.5e-07,
        "source": "https://azure.microsoft.com/en-us/blog/introducing-the-llama-4-herd-in-azure-ai-foundry-and-azure-databricks/",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure_ai/Llama-4-Scout-17B-16E-Instruct": {
        "display_name": "Llama 4 Scout 17B",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 10000000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "meta",
        "output_cost_per_token": 7.8e-07,
        "source": "https://azure.microsoft.com/en-us/blog/introducing-the-llama-4-herd-in-azure-ai-foundry-and-azure-databricks/",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure_ai/Meta-Llama-3-70B-Instruct": {
        "display_name": "Llama 3 70B",
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 8192,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "mode": "chat",
        "model_vendor": "meta",
        "output_cost_per_token": 3.7e-07,
        "supports_tool_choice": true
    },
    "azure_ai/Meta-Llama-3.1-405B-Instruct": {
        "display_name": "Llama 3.1 405B",
        "input_cost_per_token": 5.33e-06,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "mode": "chat",
        "model_vendor": "meta",
        "output_cost_per_token": 1.6e-05,
        "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-405b-instruct-offer?tab=PlansAndPrice",
        "supports_tool_choice": true
    },
    "azure_ai/Meta-Llama-3.1-70B-Instruct": {
        "display_name": "Llama 3.1 70B",
        "input_cost_per_token": 2.68e-06,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "mode": "chat",
        "model_vendor": "meta",
        "output_cost_per_token": 3.54e-06,
        "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-70b-instruct-offer?tab=PlansAndPrice",
        "supports_tool_choice": true
    },
    "azure_ai/Meta-Llama-3.1-8B-Instruct": {
        "display_name": "Llama 3.1 8B",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "mode": "chat",
        "model_vendor": "meta",
        "output_cost_per_token": 6.1e-07,
        "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-8b-instruct-offer?tab=PlansAndPrice",
        "supports_tool_choice": true
    },
    "azure_ai/Phi-3-medium-128k-instruct": {
        "display_name": "Phi 3 Medium 128K",
        "input_cost_per_token": 1.7e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "microsoft",
        "output_cost_per_token": 6.8e-07,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "azure_ai/Phi-3-medium-4k-instruct": {
        "display_name": "Phi 3 Medium 4K",
        "input_cost_per_token": 1.7e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "microsoft",
        "output_cost_per_token": 6.8e-07,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "azure_ai/Phi-3-mini-128k-instruct": {
        "display_name": "Phi 3 Mini 128K",
        "input_cost_per_token": 1.3e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "microsoft",
        "output_cost_per_token": 5.2e-07,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "azure_ai/Phi-3-mini-4k-instruct": {
        "display_name": "Phi 3 Mini 4K",
        "input_cost_per_token": 1.3e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "microsoft",
        "output_cost_per_token": 5.2e-07,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "azure_ai/Phi-3-small-128k-instruct": {
        "display_name": "Phi 3 Small 128K",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "microsoft",
        "output_cost_per_token": 6e-07,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "azure_ai/Phi-3-small-8k-instruct": {
        "display_name": "Phi 3 Small 8K",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "microsoft",
        "output_cost_per_token": 6e-07,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "azure_ai/Phi-3.5-MoE-instruct": {
        "display_name": "Phi 3.5 MoE",
        "input_cost_per_token": 1.6e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "microsoft",
        "output_cost_per_token": 6.4e-07,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "azure_ai/Phi-3.5-mini-instruct": {
        "display_name": "Phi 3.5 Mini",
        "input_cost_per_token": 1.3e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "microsoft",
        "output_cost_per_token": 5.2e-07,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "azure_ai/Phi-3.5-vision-instruct": {
        "display_name": "Phi 3.5 Vision",
        "input_cost_per_token": 1.3e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "microsoft",
        "output_cost_per_token": 5.2e-07,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure_ai/Phi-4": {
        "display_name": "Phi 4",
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "microsoft",
        "output_cost_per_token": 5e-07,
        "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/affordable-innovation-unveiling-the-pricing-of-phi-3-slms-on-models-as-a-service/4156495",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "azure_ai/Phi-4-mini-instruct": {
        "display_name": "Phi 4 Mini",
        "input_cost_per_token": 7.5e-08,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "microsoft",
        "output_cost_per_token": 3e-07,
        "source": "https://techcommunity.microsoft.com/blog/Azure-AI-Services-blog/announcing-new-phi-pricing-empowering-your-business-with-small-language-models/4395112",
        "supports_function_calling": true
    },
    "azure_ai/Phi-4-multimodal-instruct": {
        "display_name": "Phi 4 Multimodal",
        "input_cost_per_audio_token": 4e-06,
        "input_cost_per_token": 8e-08,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "microsoft",
        "output_cost_per_token": 3.2e-07,
        "source": "https://techcommunity.microsoft.com/blog/Azure-AI-Services-blog/announcing-new-phi-pricing-empowering-your-business-with-small-language-models/4395112",
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_vision": true
    },
    "azure_ai/Phi-4-mini-reasoning": {
        "display_name": "Phi 4 Mini Reasoning",
        "input_cost_per_token": 8e-08,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "microsoft",
        "output_cost_per_token": 3.2e-07,
        "source": "https://azure.microsoft.com/en-us/pricing/details/ai-foundry-models/microsoft/",
        "supports_function_calling": true
    },
    "azure_ai/Phi-4-reasoning": {
        "display_name": "Phi 4 Reasoning",
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "microsoft",
        "output_cost_per_token": 5e-07,
        "source": "https://azure.microsoft.com/en-us/pricing/details/ai-foundry-models/microsoft/",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_reasoning": true
    },
    "azure_ai/mistral-document-ai-2505": {
        "display_name": "Mistral Document AI",
        "litellm_provider": "azure_ai",
        "mode": "ocr",
        "model_vendor": "mistral",
        "model_version": "2505",
        "ocr_cost_per_page": 0.003,
        "source": "https://devblogs.microsoft.com/foundry/whats-new-in-azure-ai-foundry-august-2025/#mistral-document-ai-(ocr)-%E2%80%94-serverless-in-foundry",
        "supported_endpoints": [
            "/v1/ocr"
        ]
    },
    "azure_ai/doc-intelligence/prebuilt-read": {
        "display_name": "Document Intelligence Read",
        "litellm_provider": "azure_ai",
        "mode": "ocr",
        "model_vendor": "microsoft",
        "ocr_cost_per_page": 0.0015,
        "source": "https://azure.microsoft.com/en-us/pricing/details/ai-document-intelligence/",
        "supported_endpoints": [
            "/v1/ocr"
        ]
    },
    "azure_ai/doc-intelligence/prebuilt-layout": {
        "display_name": "Document Intelligence Layout",
        "litellm_provider": "azure_ai",
        "mode": "ocr",
        "model_vendor": "microsoft",
        "ocr_cost_per_page": 0.01,
        "source": "https://azure.microsoft.com/en-us/pricing/details/ai-document-intelligence/",
        "supported_endpoints": [
            "/v1/ocr"
        ]
    },
    "azure_ai/doc-intelligence/prebuilt-document": {
        "display_name": "Document Intelligence Document",
        "litellm_provider": "azure_ai",
        "mode": "ocr",
        "model_vendor": "microsoft",
        "ocr_cost_per_page": 0.01,
        "source": "https://azure.microsoft.com/en-us/pricing/details/ai-document-intelligence/",
        "supported_endpoints": [
            "/v1/ocr"
        ]
    },
    "azure_ai/MAI-DS-R1": {
        "display_name": "MAI DeepSeek R1",
        "input_cost_per_token": 1.35e-06,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "microsoft",
        "output_cost_per_token": 5.4e-06,
        "source": "https://azure.microsoft.com/en-us/pricing/details/ai-foundry-models/microsoft/",
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "azure_ai/cohere-rerank-v3-english": {
        "display_name": "Cohere Rerank v3 English",
        "input_cost_per_query": 0.002,
        "input_cost_per_token": 0.0,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_query_tokens": 2048,
        "max_tokens": 4096,
        "mode": "rerank",
        "model_vendor": "cohere",
        "output_cost_per_token": 0.0
    },
    "azure_ai/cohere-rerank-v3-multilingual": {
        "display_name": "Cohere Rerank v3 Multilingual",
        "input_cost_per_query": 0.002,
        "input_cost_per_token": 0.0,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_query_tokens": 2048,
        "max_tokens": 4096,
        "mode": "rerank",
        "model_vendor": "cohere",
        "output_cost_per_token": 0.0
    },
    "azure_ai/cohere-rerank-v3.5": {
        "display_name": "Cohere Rerank v3.5",
        "input_cost_per_query": 0.002,
        "input_cost_per_token": 0.0,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_query_tokens": 2048,
        "max_tokens": 4096,
        "mode": "rerank",
        "model_vendor": "cohere",
        "output_cost_per_token": 0.0
    },
    "azure_ai/cohere-rerank-v4.0-pro": {
        "display_name": "Cohere Rerank V4.0 Pro",
        "model_vendor": "cohere",
        "model_version": "4.0",
        "input_cost_per_query": 0.0025,
        "input_cost_per_token": 0.0,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_query_tokens": 4096,
        "max_tokens": 32768,
        "mode": "rerank",
        "output_cost_per_token": 0.0
    },
    "azure_ai/cohere-rerank-v4.0-fast": {
        "display_name": "Cohere Rerank V4.0 Fast",
        "model_vendor": "cohere",
        "model_version": "4.0",
        "input_cost_per_query": 0.002,
        "input_cost_per_token": 0.0,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_query_tokens": 4096,
        "max_tokens": 32768,
        "mode": "rerank",
        "output_cost_per_token": 0.0
    },
    "azure_ai/deepseek-v3.2": {
        "display_name": "Deepseek V3.2",
        "model_vendor": "deepseek",
        "model_version": "3.2",
        "input_cost_per_token": 5.8e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.68e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "azure_ai/deepseek-v3.2-speciale": {
        "display_name": "Deepseek V3.2 Speciale",
        "model_vendor": "deepseek",
        "model_version": "3.2",
        "input_cost_per_token": 5.8e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.68e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "azure_ai/deepseek-r1": {
        "display_name": "DeepSeek R1",
        "input_cost_per_token": 1.35e-06,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "deepseek",
        "output_cost_per_token": 5.4e-06,
        "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/deepseek-r1-improved-performance-higher-limits-and-transparent-pricing/4386367",
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "azure_ai/deepseek-v3": {
        "display_name": "DeepSeek V3",
        "input_cost_per_token": 1.14e-06,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "deepseek",
        "output_cost_per_token": 4.56e-06,
        "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/announcing-deepseek-v3-on-azure-ai-foundry-and-github/4390438",
        "supports_tool_choice": true
    },
    "azure_ai/deepseek-v3-0324": {
        "display_name": "DeepSeek V3",
        "input_cost_per_token": 1.14e-06,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "deepseek",
        "model_version": "0324",
        "output_cost_per_token": 4.56e-06,
        "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/announcing-deepseek-v3-on-azure-ai-foundry-and-github/4390438",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "azure_ai/embed-v-4-0": {
        "display_name": "Cohere Embed v4",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_tokens": 128000,
        "mode": "embedding",
        "model_vendor": "cohere",
        "output_cost_per_token": 0.0,
        "output_vector_size": 3072,
        "source": "https://azuremarketplace.microsoft.com/pt-br/marketplace/apps/cohere.cohere-embed-4-offer?tab=PlansAndPrice",
        "supported_endpoints": [
            "/v1/embeddings"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supports_embedding_image_input": true
    },
    "azure_ai/global/grok-3": {
        "display_name": "Grok 3",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "model_vendor": "xai",
        "output_cost_per_token": 1.5e-05,
        "source": "https://devblogs.microsoft.com/foundry/announcing-grok-3-and-grok-3-mini-on-azure-ai-foundry/",
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "azure_ai/global/grok-3-mini": {
        "display_name": "Grok 3 Mini",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "model_vendor": "xai",
        "output_cost_per_token": 1.27e-06,
        "source": "https://devblogs.microsoft.com/foundry/announcing-grok-3-and-grok-3-mini-on-azure-ai-foundry/",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": false,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "azure_ai/grok-3": {
        "display_name": "Grok 3",
        "input_cost_per_token": 3.3e-06,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "model_vendor": "xai",
        "output_cost_per_token": 1.65e-05,
        "source": "https://devblogs.microsoft.com/foundry/announcing-grok-3-and-grok-3-mini-on-azure-ai-foundry/",
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "azure_ai/grok-3-mini": {
        "display_name": "Grok 3 Mini",
        "input_cost_per_token": 2.75e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "model_vendor": "xai",
        "output_cost_per_token": 1.38e-06,
        "source": "https://devblogs.microsoft.com/foundry/announcing-grok-3-and-grok-3-mini-on-azure-ai-foundry/",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": false,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "azure_ai/grok-4": {
        "display_name": "Grok 4",
        "input_cost_per_token": 5.5e-06,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "model_vendor": "xai",
        "output_cost_per_token": 2.75e-05,
        "source": "https://azure.microsoft.com/en-us/blog/grok-4-is-now-available-in-azure-ai-foundry-unlock-frontier-intelligence-and-business-ready-capabilities/",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "azure_ai/grok-4-fast-non-reasoning": {
        "display_name": "Grok 4 Fast Non-Reasoning",
        "input_cost_per_token": 4.3e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "model_vendor": "xai",
        "output_cost_per_token": 1.73e-06,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "azure_ai/grok-4-fast-reasoning": {
        "display_name": "Grok 4 Fast Reasoning",
        "input_cost_per_token": 4.3e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "model_vendor": "xai",
        "output_cost_per_token": 1.73e-06,
        "source": "https://techcommunity.microsoft.com/blog/azure-ai-foundry-blog/announcing-the-grok-4-fast-models-from-xai-now-available-in-azure-ai-foundry/4456701",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "azure_ai/grok-code-fast-1": {
        "display_name": "Grok Code Fast 1",
        "input_cost_per_token": 3.5e-06,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "model_vendor": "xai",
        "output_cost_per_token": 1.75e-05,
        "source": "https://azure.microsoft.com/en-us/blog/grok-4-is-now-available-in-azure-ai-foundry-unlock-frontier-intelligence-and-business-ready-capabilities/",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "azure_ai/jais-30b-chat": {
        "display_name": "JAIS 30B Chat",
        "input_cost_per_token": 0.0032,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "g42",
        "output_cost_per_token": 0.00971,
        "source": "https://azure.microsoft.com/en-us/products/ai-services/ai-foundry/models/jais-30b-chat"
    },
    "azure_ai/jamba-instruct": {
        "display_name": "Jamba Instruct",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 70000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "ai21",
        "output_cost_per_token": 7e-07,
        "supports_tool_choice": true
    },
    "azure_ai/ministral-3b": {
        "display_name": "Ministral 3B",
        "input_cost_per_token": 4e-08,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "mistral",
        "output_cost_per_token": 4e-08,
        "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.ministral-3b-2410-offer?tab=Overview",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "azure_ai/mistral-large": {
        "display_name": "Mistral Large",
        "input_cost_per_token": 4e-06,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "mistral",
        "output_cost_per_token": 1.2e-05,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "azure_ai/mistral-large-2407": {
        "display_name": "Mistral Large",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "mistral",
        "model_version": "2407",
        "output_cost_per_token": 6e-06,
        "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "azure_ai/mistral-large-latest": {
        "display_name": "Mistral Large",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "mistral",
        "output_cost_per_token": 6e-06,
        "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "azure_ai/mistral-large-3": {
        "display_name": "Mistral Large 3",
        "model_vendor": "mistral",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 256000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "source": "https://azure.microsoft.com/en-us/blog/introducing-mistral-large-3-in-microsoft-foundry-open-capable-and-ready-for-production-workloads/",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "azure_ai/mistral-medium-2505": {
        "display_name": "Mistral Medium",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "mistral",
        "model_version": "2505",
        "output_cost_per_token": 2e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "azure_ai/mistral-nemo": {
        "display_name": "Mistral Nemo",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "mistral",
        "output_cost_per_token": 1.5e-07,
        "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-nemo-12b-2407?tab=PlansAndPrice",
        "supports_function_calling": true
    },
    "azure_ai/mistral-small": {
        "display_name": "Mistral Small",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "mistral",
        "output_cost_per_token": 3e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "azure_ai/mistral-small-2503": {
        "display_name": "Mistral Small",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "azure_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "mistral",
        "model_version": "2503",
        "output_cost_per_token": 3e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "babbage-002": {
        "display_name": "Babbage 002",
        "model_vendor": "openai",
        "model_version": "002",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "text-completion-openai",
        "max_input_tokens": 16384,
        "max_output_tokens": 4096,
        "max_tokens": 16384,
        "mode": "completion",
        "output_cost_per_token": 4e-07
    },
    "bedrock/*/1-month-commitment/cohere.command-light-text-v14": {
        "display_name": "Command Light",
        "input_cost_per_second": 0.001902,
        "litellm_provider": "bedrock",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "cohere",
        "output_cost_per_second": 0.001902,
        "supports_tool_choice": true
    },
    "bedrock/*/1-month-commitment/cohere.command-text-v14": {
        "display_name": "Command",
        "input_cost_per_second": 0.011,
        "litellm_provider": "bedrock",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "cohere",
        "output_cost_per_second": 0.011,
        "supports_tool_choice": true
    },
    "bedrock/*/6-month-commitment/cohere.command-light-text-v14": {
        "display_name": "Command Light",
        "input_cost_per_second": 0.0011416,
        "litellm_provider": "bedrock",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "cohere",
        "output_cost_per_second": 0.0011416,
        "supports_tool_choice": true
    },
    "bedrock/*/6-month-commitment/cohere.command-text-v14": {
        "display_name": "Command",
        "input_cost_per_second": 0.0066027,
        "litellm_provider": "bedrock",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "cohere",
        "output_cost_per_second": 0.0066027,
        "supports_tool_choice": true
    },
    "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1": {
        "display_name": "Claude Instant",
        "input_cost_per_second": 0.01475,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.01475,
        "supports_tool_choice": true
    },
    "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1": {
        "display_name": "Claude 1",
        "input_cost_per_second": 0.0455,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.0455
    },
    "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1": {
        "display_name": "Claude 2.1",
        "input_cost_per_second": 0.0455,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.0455,
        "supports_tool_choice": true
    },
    "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1": {
        "display_name": "Claude Instant",
        "input_cost_per_second": 0.008194,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.008194,
        "supports_tool_choice": true
    },
    "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1": {
        "display_name": "Claude 1",
        "input_cost_per_second": 0.02527,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.02527
    },
    "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1": {
        "display_name": "Claude 2.1",
        "input_cost_per_second": 0.02527,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.02527,
        "supports_tool_choice": true
    },
    "bedrock/ap-northeast-1/anthropic.claude-instant-v1": {
        "display_name": "Claude Instant",
        "input_cost_per_token": 2.23e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 7.55e-06,
        "supports_tool_choice": true
    },
    "bedrock/ap-northeast-1/anthropic.claude-v1": {
        "display_name": "Claude 1",
        "input_cost_per_token": 8e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 2.4e-05,
        "supports_tool_choice": true
    },
    "bedrock/ap-northeast-1/anthropic.claude-v2:1": {
        "display_name": "Claude 2.1",
        "input_cost_per_token": 8e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 2.4e-05,
        "supports_tool_choice": true
    },
    "bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0": {
        "display_name": "Llama 3 70B",
        "input_cost_per_token": 3.18e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "meta",
        "model_version": "v1:0",
        "output_cost_per_token": 4.2e-06
    },
    "bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0": {
        "display_name": "Llama 3 8B",
        "input_cost_per_token": 3.6e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "meta",
        "model_version": "v1:0",
        "output_cost_per_token": 7.2e-07
    },
    "bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0": {
        "display_name": "Llama 3 70B",
        "input_cost_per_token": 3.05e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "meta",
        "model_version": "v1:0",
        "output_cost_per_token": 4.03e-06
    },
    "bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0": {
        "display_name": "Llama 3 8B",
        "input_cost_per_token": 3.5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "meta",
        "model_version": "v1:0",
        "output_cost_per_token": 6.9e-07
    },
    "bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1": {
        "display_name": "Claude Instant",
        "input_cost_per_second": 0.01635,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.01635,
        "supports_tool_choice": true
    },
    "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1": {
        "display_name": "Claude 1",
        "input_cost_per_second": 0.0415,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.0415
    },
    "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1": {
        "display_name": "Claude 2.1",
        "input_cost_per_second": 0.0415,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.0415,
        "supports_tool_choice": true
    },
    "bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1": {
        "display_name": "Claude Instant",
        "input_cost_per_second": 0.009083,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "model_vendor": "anthropic",
        "mode": "chat",
        "output_cost_per_second": 0.009083,
        "supports_tool_choice": true
    },
    "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1": {
        "display_name": "Claude 1",
        "input_cost_per_second": 0.02305,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.02305
    },
    "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1": {
        "display_name": "Claude 2.1",
        "input_cost_per_second": 0.02305,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.02305,
        "supports_tool_choice": true
    },
    "bedrock/eu-central-1/anthropic.claude-instant-v1": {
        "display_name": "Claude Instant",
        "input_cost_per_token": 2.48e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 8.38e-06,
        "supports_tool_choice": true
    },
    "bedrock/eu-central-1/anthropic.claude-v1": {
        "display_name": "Claude 1",
        "input_cost_per_token": 8e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 2.4e-05
    },
    "bedrock/eu-central-1/anthropic.claude-v2:1": {
        "display_name": "Claude 2.1",
        "input_cost_per_token": 8e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 2.4e-05,
        "supports_tool_choice": true
    },
    "bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0": {
        "display_name": "Llama 3 70B",
        "input_cost_per_token": 2.86e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "meta",
        "model_version": "v1:0",
        "output_cost_per_token": 3.78e-06
    },
    "bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0": {
        "display_name": "Llama 3 8B",
        "input_cost_per_token": 3.2e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "meta",
        "model_version": "v1:0",
        "output_cost_per_token": 6.5e-07
    },
    "bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0": {
        "display_name": "Llama 3 70B",
        "input_cost_per_token": 3.45e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "meta",
        "model_version": "v1:0",
        "output_cost_per_token": 4.55e-06
    },
    "bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0": {
        "display_name": "Llama 3 8B",
        "input_cost_per_token": 3.9e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "meta",
        "model_version": "v1:0",
        "output_cost_per_token": 7.8e-07
    },
    "bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2": {
        "display_name": "Mistral 7B",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "mistral",
        "model_version": "v0:2",
        "output_cost_per_token": 2.6e-07,
        "supports_tool_choice": true
    },
    "bedrock/eu-west-3/mistral.mistral-large-2402-v1:0": {
        "display_name": "Mistral Large",
        "input_cost_per_token": 1.04e-05,
        "litellm_provider": "bedrock",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "mistral",
        "model_version": "2402-v1:0",
        "output_cost_per_token": 3.12e-05,
        "supports_function_calling": true
    },
    "bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1": {
        "display_name": "Mixtral 8x7B",
        "input_cost_per_token": 5.9e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "mistral",
        "model_version": "v0:1",
        "output_cost_per_token": 9.1e-07,
        "supports_tool_choice": true
    },
    "bedrock/invoke/anthropic.claude-3-5-sonnet-20240620-v1:0": {
        "display_name": "Claude Sonnet 3.5",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "metadata": {
            "notes": "Anthropic via Invoke route does not currently support pdf input."
        },
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20240620-v1:0",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0": {
        "display_name": "Llama 3 70B",
        "input_cost_per_token": 4.45e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "meta",
        "model_version": "v1:0",
        "output_cost_per_token": 5.88e-06
    },
    "bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0": {
        "display_name": "Llama 3 8B",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "meta",
        "model_version": "v1:0",
        "output_cost_per_token": 1.01e-06
    },
    "bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1": {
        "display_name": "Claude Instant",
        "input_cost_per_second": 0.011,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.011,
        "supports_tool_choice": true
    },
    "bedrock/us-east-1/1-month-commitment/anthropic.claude-v1": {
        "display_name": "Claude 1",
        "input_cost_per_second": 0.0175,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.0175
    },
    "bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1": {
        "display_name": "Claude 2.1",
        "input_cost_per_second": 0.0175,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.0175,
        "supports_tool_choice": true
    },
    "bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1": {
        "display_name": "Claude Instant",
        "input_cost_per_second": 0.00611,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.00611,
        "supports_tool_choice": true
    },
    "bedrock/us-east-1/6-month-commitment/anthropic.claude-v1": {
        "display_name": "Claude 1",
        "input_cost_per_second": 0.00972,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.00972
    },
    "bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1": {
        "display_name": "Claude 2.1",
        "input_cost_per_second": 0.00972,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.00972,
        "supports_tool_choice": true
    },
    "bedrock/us-east-1/anthropic.claude-instant-v1": {
        "display_name": "Claude Instant",
        "input_cost_per_token": 8e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 2.4e-06,
        "supports_tool_choice": true
    },
    "bedrock/us-east-1/anthropic.claude-v1": {
        "display_name": "Claude 1",
        "input_cost_per_token": 8e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 2.4e-05,
        "supports_tool_choice": true
    },
    "bedrock/us-east-1/anthropic.claude-v2:1": {
        "display_name": "Claude 2.1",
        "input_cost_per_token": 8e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 2.4e-05,
        "supports_tool_choice": true
    },
    "bedrock/us-east-1/meta.llama3-70b-instruct-v1:0": {
        "display_name": "Llama 3 70B",
        "input_cost_per_token": 2.65e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "meta",
        "model_version": "v1:0",
        "output_cost_per_token": 3.5e-06
    },
    "bedrock/us-east-1/meta.llama3-8b-instruct-v1:0": {
        "display_name": "Llama 3 8B",
        "model_vendor": "meta",
        "model_version": "v1:0",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 6e-07
    },
    "bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2": {
        "display_name": "Mistral 7B",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "mistral",
        "model_version": "v0:2",
        "output_cost_per_token": 2e-07,
        "supports_tool_choice": true
    },
    "bedrock/us-east-1/mistral.mistral-large-2402-v1:0": {
        "display_name": "Mistral Large",
        "input_cost_per_token": 8e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "mistral",
        "model_version": "2402-v1:0",
        "output_cost_per_token": 2.4e-05,
        "supports_function_calling": true
    },
    "bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1": {
        "display_name": "Mixtral 8x7B",
        "input_cost_per_token": 4.5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "mistral",
        "model_version": "v0:1",
        "output_cost_per_token": 7e-07,
        "supports_tool_choice": true
    },
    "bedrock/us-gov-east-1/amazon.nova-pro-v1:0": {
        "display_name": "Nova Pro",
        "input_cost_per_token": 9.6e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 300000,
        "max_output_tokens": 10000,
        "max_tokens": 10000,
        "mode": "chat",
        "model_vendor": "amazon",
        "model_version": "v1:0",
        "output_cost_per_token": 3.84e-06,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "bedrock/us-gov-east-1/amazon.titan-embed-text-v1": {
        "display_name": "Titan Embed Text",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_tokens": 8192,
        "mode": "embedding",
        "model_vendor": "amazon",
        "output_cost_per_token": 0.0,
        "output_vector_size": 1536
    },
    "bedrock/us-gov-east-1/amazon.titan-embed-text-v2:0": {
        "display_name": "Titan Embed Text v2",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_tokens": 8192,
        "mode": "embedding",
        "model_vendor": "amazon",
        "model_version": "v2:0",
        "output_cost_per_token": 0.0,
        "output_vector_size": 1024
    },
    "bedrock/us-gov-east-1/amazon.titan-text-express-v1": {
        "display_name": "Titan Text Express",
        "input_cost_per_token": 1.3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 42000,
        "max_output_tokens": 8000,
        "max_tokens": 8000,
        "mode": "chat",
        "model_vendor": "amazon",
        "output_cost_per_token": 1.7e-06
    },
    "bedrock/us-gov-east-1/amazon.titan-text-lite-v1": {
        "display_name": "Titan Text Lite",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 42000,
        "max_output_tokens": 4000,
        "max_tokens": 4000,
        "mode": "chat",
        "model_vendor": "amazon",
        "output_cost_per_token": 4e-07
    },
    "bedrock/us-gov-east-1/amazon.titan-text-premier-v1:0": {
        "display_name": "Titan Text Premier",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 42000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "model_vendor": "amazon",
        "model_version": "v1:0",
        "output_cost_per_token": 1.5e-06
    },
    "bedrock/us-gov-east-1/anthropic.claude-3-5-sonnet-20240620-v1:0": {
        "display_name": "Claude Sonnet 3.5",
        "input_cost_per_token": 3.6e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20240620-v1:0",
        "output_cost_per_token": 1.8e-05,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "bedrock/us-gov-east-1/anthropic.claude-3-haiku-20240307-v1:0": {
        "display_name": "Claude Haiku 3",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20240307-v1:0",
        "output_cost_per_token": 1.5e-06,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "bedrock/us-gov-east-1/claude-sonnet-4-5-20250929-v1:0": {
        "display_name": "Claude Sonnet 4.5",
        "input_cost_per_token": 3.3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20250929-v1:0",
        "output_cost_per_token": 1.65e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "bedrock/us-gov-east-1/meta.llama3-70b-instruct-v1:0": {
        "display_name": "Llama 3 70B",
        "input_cost_per_token": 2.65e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8000,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "mode": "chat",
        "model_vendor": "meta",
        "model_version": "v1:0",
        "output_cost_per_token": 3.5e-06,
        "supports_pdf_input": true
    },
    "bedrock/us-gov-east-1/meta.llama3-8b-instruct-v1:0": {
        "display_name": "Llama 3 8B",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8000,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "mode": "chat",
        "model_vendor": "meta",
        "model_version": "v1:0",
        "output_cost_per_token": 2.65e-06,
        "supports_pdf_input": true
    },
    "bedrock/us-gov-west-1/amazon.nova-pro-v1:0": {
        "display_name": "Nova Pro",
        "input_cost_per_token": 9.6e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 300000,
        "max_output_tokens": 10000,
        "max_tokens": 10000,
        "mode": "chat",
        "model_vendor": "amazon",
        "model_version": "v1:0",
        "output_cost_per_token": 3.84e-06,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "bedrock/us-gov-west-1/amazon.titan-embed-text-v1": {
        "display_name": "Titan Embed Text",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_tokens": 8192,
        "mode": "embedding",
        "model_vendor": "amazon",
        "output_cost_per_token": 0.0,
        "output_vector_size": 1536
    },
    "bedrock/us-gov-west-1/amazon.titan-embed-text-v2:0": {
        "display_name": "Titan Embed Text v2",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_tokens": 8192,
        "mode": "embedding",
        "model_vendor": "amazon",
        "model_version": "v2:0",
        "output_cost_per_token": 0.0,
        "output_vector_size": 1024
    },
    "bedrock/us-gov-west-1/amazon.titan-text-express-v1": {
        "display_name": "Titan Text Express",
        "input_cost_per_token": 1.3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 42000,
        "max_output_tokens": 8000,
        "max_tokens": 8000,
        "mode": "chat",
        "model_vendor": "amazon",
        "output_cost_per_token": 1.7e-06
    },
    "bedrock/us-gov-west-1/amazon.titan-text-lite-v1": {
        "display_name": "Titan Text Lite",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 42000,
        "max_output_tokens": 4000,
        "max_tokens": 4000,
        "mode": "chat",
        "model_vendor": "amazon",
        "output_cost_per_token": 4e-07
    },
    "bedrock/us-gov-west-1/amazon.titan-text-premier-v1:0": {
        "display_name": "Titan Text Premier",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 42000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "model_vendor": "amazon",
        "model_version": "v1:0",
        "output_cost_per_token": 1.5e-06
    },
    "bedrock/us-gov-west-1/anthropic.claude-3-7-sonnet-20250219-v1:0": {
        "cache_creation_input_token_cost": 4.5e-06,
        "cache_read_input_token_cost": 3.6e-07,
        "display_name": "Claude Sonnet 3.7",
        "input_cost_per_token": 3.6e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20250219-v1:0",
        "output_cost_per_token": 1.8e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "bedrock/us-gov-west-1/anthropic.claude-3-5-sonnet-20240620-v1:0": {
        "display_name": "Claude Sonnet 3.5",
        "input_cost_per_token": 3.6e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20240620-v1:0",
        "output_cost_per_token": 1.8e-05,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "bedrock/us-gov-west-1/anthropic.claude-3-haiku-20240307-v1:0": {
        "display_name": "Claude Haiku 3",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20240307-v1:0",
        "output_cost_per_token": 1.5e-06,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "bedrock/us-gov-west-1/claude-sonnet-4-5-20250929-v1:0": {
        "display_name": "Claude Sonnet 4.5",
        "input_cost_per_token": 3.3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20250929-v1:0",
        "output_cost_per_token": 1.65e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "bedrock/us-gov-west-1/meta.llama3-70b-instruct-v1:0": {
        "display_name": "Llama 3 70B",
        "input_cost_per_token": 2.65e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8000,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "mode": "chat",
        "model_vendor": "meta",
        "model_version": "v1:0",
        "output_cost_per_token": 3.5e-06,
        "supports_pdf_input": true
    },
    "bedrock/us-gov-west-1/meta.llama3-8b-instruct-v1:0": {
        "display_name": "Llama 3 8B",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8000,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "mode": "chat",
        "model_vendor": "meta",
        "model_version": "v1:0",
        "output_cost_per_token": 2.65e-06,
        "supports_pdf_input": true
    },
    "bedrock/us-west-1/meta.llama3-70b-instruct-v1:0": {
        "display_name": "Llama 3 70B",
        "input_cost_per_token": 2.65e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "meta",
        "model_version": "v1:0",
        "output_cost_per_token": 3.5e-06
    },
    "bedrock/us-west-1/meta.llama3-8b-instruct-v1:0": {
        "display_name": "Llama 3 8B",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "meta",
        "model_version": "v1:0",
        "output_cost_per_token": 6e-07
    },
    "bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1": {
        "display_name": "Claude Instant",
        "input_cost_per_second": 0.011,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.011,
        "supports_tool_choice": true
    },
    "bedrock/us-west-2/1-month-commitment/anthropic.claude-v1": {
        "display_name": "Claude 1",
        "input_cost_per_second": 0.0175,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.0175
    },
    "bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1": {
        "display_name": "Claude 2",
        "input_cost_per_second": 0.0175,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "v2:1",
        "output_cost_per_second": 0.0175,
        "supports_tool_choice": true
    },
    "bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1": {
        "display_name": "Claude Instant",
        "input_cost_per_second": 0.00611,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.00611,
        "supports_tool_choice": true
    },
    "bedrock/us-west-2/6-month-commitment/anthropic.claude-v1": {
        "display_name": "Claude 1",
        "input_cost_per_second": 0.00972,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_second": 0.00972
    },
    "bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1": {
        "display_name": "Claude 2",
        "input_cost_per_second": 0.00972,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "v2:1",
        "output_cost_per_second": 0.00972,
        "supports_tool_choice": true
    },
    "bedrock/us-west-2/anthropic.claude-instant-v1": {
        "display_name": "Claude Instant",
        "input_cost_per_token": 8e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 2.4e-06,
        "supports_tool_choice": true
    },
    "bedrock/us-west-2/anthropic.claude-v1": {
        "display_name": "Claude 1",
        "input_cost_per_token": 8e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 2.4e-05,
        "supports_tool_choice": true
    },
    "bedrock/us-west-2/anthropic.claude-v2:1": {
        "display_name": "Claude 2",
        "input_cost_per_token": 8e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "v2:1",
        "output_cost_per_token": 2.4e-05,
        "supports_tool_choice": true
    },
    "bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2": {
        "display_name": "Mistral 7B",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "mistral",
        "model_version": "v0:2",
        "output_cost_per_token": 2e-07,
        "supports_tool_choice": true
    },
    "bedrock/us-west-2/mistral.mistral-large-2402-v1:0": {
        "display_name": "Mistral Large",
        "input_cost_per_token": 8e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "mistral",
        "model_version": "2402-v1:0",
        "output_cost_per_token": 2.4e-05,
        "supports_function_calling": true
    },
    "bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1": {
        "display_name": "Mixtral 8x7B",
        "input_cost_per_token": 4.5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "model_vendor": "mistral",
        "model_version": "v0:1",
        "output_cost_per_token": 7e-07,
        "supports_tool_choice": true
    },
    "bedrock/us.anthropic.claude-3-5-haiku-20241022-v1:0": {
        "cache_creation_input_token_cost": 1e-06,
        "cache_read_input_token_cost": 8e-08,
        "display_name": "Claude Haiku 3.5",
        "input_cost_per_token": 8e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20241022-v1:0",
        "output_cost_per_token": 4e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "cerebras/llama-3.3-70b": {
        "display_name": "Llama 3.3 70B",
        "input_cost_per_token": 8.5e-07,
        "litellm_provider": "cerebras",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "meta",
        "output_cost_per_token": 1.2e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "cerebras/llama3.1-70b": {
        "display_name": "Llama 3.1 70B",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "cerebras",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "meta",
        "output_cost_per_token": 6e-07,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "cerebras/llama3.1-8b": {
        "display_name": "Llama 3.1 8B",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "cerebras",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "meta",
        "output_cost_per_token": 1e-07,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "cerebras/gpt-oss-120b": {
        "display_name": "GPT-OSS 120B",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "cerebras",
        "max_input_tokens": 131072,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 6.9e-07,
        "source": "https://www.cerebras.ai/blog/openai-gpt-oss-120b-runs-fastest-on-cerebras",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "cerebras/qwen-3-32b": {
        "display_name": "Qwen 3 32B",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "cerebras",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "model_vendor": "alibaba",
        "output_cost_per_token": 8e-07,
        "source": "https://inference-docs.cerebras.ai/support/pricing",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "cerebras/zai-glm-4.6": {
        "display_name": "Zai Glm 4.6",
        "model_vendor": "zhipu",
        "model_version": "4.6",
        "input_cost_per_token": 2.25e-06,
        "litellm_provider": "cerebras",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 2.75e-06,
        "source": "https://www.cerebras.ai/pricing",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "chat-bison": {
        "display_name": "Chat Bison",
        "input_cost_per_character": 2.5e-07,
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-chat-models",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "google",
        "output_cost_per_character": 5e-07,
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "chat-bison-32k": {
        "display_name": "Chat Bison 32K",
        "input_cost_per_character": 2.5e-07,
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-chat-models",
        "max_input_tokens": 32000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "google",
        "output_cost_per_character": 5e-07,
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "chat-bison-32k@002": {
        "display_name": "Chat Bison 32K",
        "input_cost_per_character": 2.5e-07,
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-chat-models",
        "max_input_tokens": 32000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "google",
        "model_version": "002",
        "output_cost_per_character": 5e-07,
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "chat-bison@001": {
        "display_name": "Chat Bison",
        "input_cost_per_character": 2.5e-07,
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-chat-models",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "google",
        "model_version": "001",
        "output_cost_per_character": 5e-07,
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "chat-bison@002": {
        "deprecation_date": "2025-04-09",
        "display_name": "Chat Bison",
        "input_cost_per_character": 2.5e-07,
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-chat-models",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "google",
        "model_version": "002",
        "output_cost_per_character": 5e-07,
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "chatdolphin": {
        "display_name": "Chat Dolphin",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "nlp_cloud",
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "model_vendor": "nlp_cloud",
        "output_cost_per_token": 5e-07
    },
    "chatgpt-4o-latest": {
        "display_name": "ChatGPT-4o",
        "input_cost_per_token": 5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "openai",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "claude-3-5-haiku-20241022": {
        "cache_creation_input_token_cost": 1e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 8e-08,
        "deprecation_date": "2025-10-01",
        "display_name": "Claude Haiku 3.5",
        "input_cost_per_token": 8e-07,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20241022",
        "output_cost_per_token": 4e-06,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tool_use_system_prompt_tokens": 264
    },
    "claude-3-5-haiku-latest": {
        "cache_creation_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 1e-07,
        "deprecation_date": "2025-10-01",
        "display_name": "Claude Haiku 3.5",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 5e-06,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tool_use_system_prompt_tokens": 264
    },
    "claude-haiku-4-5-20251001": {
        "cache_creation_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost_above_1hr": 2e-06,
        "cache_read_input_token_cost": 1e-07,
        "display_name": "Claude Haiku 4.5",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20251001",
        "output_cost_per_token": 5e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_computer_use": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "claude-haiku-4-5": {
        "cache_creation_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost_above_1hr": 2e-06,
        "cache_read_input_token_cost": 1e-07,
        "display_name": "Claude Haiku 4.5",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 5e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_computer_use": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "claude-3-5-sonnet-20240620": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 3e-07,
        "deprecation_date": "2025-06-01",
        "display_name": "Claude Sonnet 3.5",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20240620",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-3-5-sonnet-20241022": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 3e-07,
        "deprecation_date": "2025-10-01",
        "display_name": "Claude Sonnet 3.5",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20241022",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-3-5-sonnet-latest": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 3e-07,
        "deprecation_date": "2025-06-01",
        "display_name": "Claude Sonnet 3.5",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-3-7-sonnet-20250219": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 3e-07,
        "deprecation_date": "2026-02-19",
        "display_name": "Claude Sonnet 3.7",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20250219",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-3-7-sonnet-latest": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 3e-07,
        "deprecation_date": "2025-06-01",
        "display_name": "Claude Sonnet 3.7",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-3-haiku-20240307": {
        "cache_creation_input_token_cost": 3e-07,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 3e-08,
        "display_name": "Claude Haiku 3",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20240307",
        "output_cost_per_token": 1.25e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 264
    },
    "claude-3-opus-20240229": {
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 1.5e-06,
        "deprecation_date": "2026-05-01",
        "display_name": "Claude Opus 3",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20240229",
        "output_cost_per_token": 7.5e-05,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 395
    },
    "claude-3-opus-latest": {
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 1.5e-06,
        "deprecation_date": "2025-03-01",
        "display_name": "Claude Opus 3",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 7.5e-05,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 395
    },
    "claude-4-opus-20250514": {
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "display_name": "Claude Opus 4",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20250514",
        "output_cost_per_token": 7.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-4-sonnet-20250514": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost": 3e-07,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "display_name": "Claude Sonnet 4",
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000,
        "max_tokens": 1000000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20250514",
        "output_cost_per_token": 1.5e-05,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-sonnet-4-5": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "display_name": "Claude Sonnet 4.5",
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 346
    },
    "claude-sonnet-4-5-20250929": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "display_name": "Claude Sonnet 4.5",
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20250929",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tool_use_system_prompt_tokens": 346
    },
    "claude-sonnet-4-5-20250929-v1:0": {
        "display_name": "Claude Sonnet 4.5",
        "model_vendor": "anthropic",
        "model_version": "20250929",
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-opus-4-1": {
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_creation_input_token_cost_above_1hr": 3e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "display_name": "Claude Opus 4.1",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 7.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-opus-4-1-20250805": {
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_creation_input_token_cost_above_1hr": 3e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "deprecation_date": "2026-08-05",
        "display_name": "Claude Opus 4.1",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20250805",
        "output_cost_per_token": 7.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-opus-4-20250514": {
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_creation_input_token_cost_above_1hr": 3e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "deprecation_date": "2026-05-14",
        "display_name": "Claude Opus 4",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20250514",
        "output_cost_per_token": 7.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-opus-4-5-20251101": {
        "cache_creation_input_token_cost": 6.25e-06,
        "cache_creation_input_token_cost_above_1hr": 1e-05,
        "cache_read_input_token_cost": 5e-07,
        "display_name": "Claude Opus 4.5",
        "input_cost_per_token": 5e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "model_version": "20251101",
        "output_cost_per_token": 2.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-opus-4-5": {
        "cache_creation_input_token_cost": 6.25e-06,
        "cache_creation_input_token_cost_above_1hr": 1e-05,
        "cache_read_input_token_cost": 5e-07,
        "display_name": "Claude Opus 4.5",
        "input_cost_per_token": 5e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "model_vendor": "anthropic",
        "output_cost_per_token": 2.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-sonnet-4-20250514": {
        "display_name": "Claude Sonnet 4",
        "model_vendor": "anthropic",
        "model_version": "20250514",
        "deprecation_date": "2026-05-14",
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "litellm_provider": "anthropic",
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "cloudflare/@cf/meta/llama-2-7b-chat-fp16": {
        "display_name": "Llama 2 7B Chat",
        "input_cost_per_token": 1.923e-06,
        "litellm_provider": "cloudflare",
        "max_input_tokens": 3072,
        "max_output_tokens": 3072,
        "max_tokens": 3072,
        "mode": "chat",
        "model_vendor": "meta",
        "output_cost_per_token": 1.923e-06
    },
    "cloudflare/@cf/meta/llama-2-7b-chat-int8": {
        "display_name": "Llama 2 7B Chat",
        "model_vendor": "meta",
        "input_cost_per_token": 1.923e-06,
        "litellm_provider": "cloudflare",
        "max_input_tokens": 2048,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "mode": "chat",
        "output_cost_per_token": 1.923e-06
    },
    "cloudflare/@cf/mistral/mistral-7b-instruct-v0.1": {
        "display_name": "Mistral 7B Instruct v0.1",
        "model_vendor": "mistral",
        "model_version": "v0.1",
        "input_cost_per_token": 1.923e-06,
        "litellm_provider": "cloudflare",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.923e-06
    },
    "cloudflare/@hf/thebloke/codellama-7b-instruct-awq": {
        "display_name": "CodeLlama 7B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1.923e-06,
        "litellm_provider": "cloudflare",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.923e-06
    },
    "code-bison": {
        "display_name": "Code Bison",
        "model_vendor": "google",
        "input_cost_per_character": 2.5e-07,
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-code-text-models",
        "max_input_tokens": 6144,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "chat",
        "output_cost_per_character": 5e-07,
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "code-bison-32k@002": {
        "display_name": "Code Bison 32K",
        "model_vendor": "google",
        "model_version": "002",
        "input_cost_per_character": 2.5e-07,
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-code-text-models",
        "max_input_tokens": 6144,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "completion",
        "output_cost_per_character": 5e-07,
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "code-bison32k": {
        "display_name": "Code Bison 32K",
        "model_vendor": "google",
        "input_cost_per_character": 2.5e-07,
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-code-text-models",
        "max_input_tokens": 6144,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "completion",
        "output_cost_per_character": 5e-07,
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "code-bison@001": {
        "display_name": "Code Bison",
        "model_vendor": "google",
        "model_version": "001",
        "input_cost_per_character": 2.5e-07,
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-code-text-models",
        "max_input_tokens": 6144,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "completion",
        "output_cost_per_character": 5e-07,
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "code-bison@002": {
        "display_name": "Code Bison",
        "model_vendor": "google",
        "model_version": "002",
        "input_cost_per_character": 2.5e-07,
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-code-text-models",
        "max_input_tokens": 6144,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "completion",
        "output_cost_per_character": 5e-07,
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "code-gecko": {
        "display_name": "Code Gecko",
        "model_vendor": "google",
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-code-text-models",
        "max_input_tokens": 2048,
        "max_output_tokens": 64,
        "max_tokens": 64,
        "mode": "completion",
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "code-gecko-latest": {
        "display_name": "Code Gecko",
        "model_vendor": "google",
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-code-text-models",
        "max_input_tokens": 2048,
        "max_output_tokens": 64,
        "max_tokens": 64,
        "mode": "completion",
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "code-gecko@001": {
        "display_name": "Code Gecko",
        "model_vendor": "google",
        "model_version": "001",
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-code-text-models",
        "max_input_tokens": 2048,
        "max_output_tokens": 64,
        "max_tokens": 64,
        "mode": "completion",
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "code-gecko@002": {
        "display_name": "Code Gecko",
        "model_vendor": "google",
        "model_version": "002",
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-code-text-models",
        "max_input_tokens": 2048,
        "max_output_tokens": 64,
        "max_tokens": 64,
        "mode": "completion",
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "codechat-bison": {
        "display_name": "CodeChat Bison",
        "model_vendor": "google",
        "input_cost_per_character": 2.5e-07,
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-code-chat-models",
        "max_input_tokens": 6144,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "chat",
        "output_cost_per_character": 5e-07,
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "codechat-bison-32k": {
        "display_name": "CodeChat Bison 32K",
        "model_vendor": "google",
        "input_cost_per_character": 2.5e-07,
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-code-chat-models",
        "max_input_tokens": 32000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 5e-07,
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "codechat-bison-32k@002": {
        "display_name": "CodeChat Bison 32K",
        "model_vendor": "google",
        "model_version": "002",
        "input_cost_per_character": 2.5e-07,
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-code-chat-models",
        "max_input_tokens": 32000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 5e-07,
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "codechat-bison@001": {
        "display_name": "CodeChat Bison",
        "model_vendor": "google",
        "model_version": "001",
        "input_cost_per_character": 2.5e-07,
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-code-chat-models",
        "max_input_tokens": 6144,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "chat",
        "output_cost_per_character": 5e-07,
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "codechat-bison@002": {
        "display_name": "CodeChat Bison",
        "model_vendor": "google",
        "model_version": "002",
        "input_cost_per_character": 2.5e-07,
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-code-chat-models",
        "max_input_tokens": 6144,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "chat",
        "output_cost_per_character": 5e-07,
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "codechat-bison@latest": {
        "display_name": "CodeChat Bison",
        "model_vendor": "google",
        "input_cost_per_character": 2.5e-07,
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-code-chat-models",
        "max_input_tokens": 6144,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "chat",
        "output_cost_per_character": 5e-07,
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "codestral/codestral-2405": {
        "display_name": "Codestral",
        "model_vendor": "mistral",
        "model_version": "2405",
        "input_cost_per_token": 0.0,
        "litellm_provider": "codestral",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "source": "https://docs.mistral.ai/capabilities/code_generation/",
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "codestral/codestral-latest": {
        "display_name": "Codestral",
        "model_vendor": "mistral",
        "input_cost_per_token": 0.0,
        "litellm_provider": "codestral",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "source": "https://docs.mistral.ai/capabilities/code_generation/",
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "codex-mini-latest": {
        "display_name": "Codex Mini",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 3.75e-07,
        "input_cost_per_token": 1.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "output_cost_per_token": 6e-06,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "cohere.command-light-text-v14": {
        "display_name": "Command Light",
        "model_vendor": "cohere",
        "model_version": "v14",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "supports_tool_choice": true
    },
    "cohere.command-r-plus-v1:0": {
        "display_name": "Command R+",
        "model_vendor": "cohere",
        "model_version": "v1:0",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_tool_choice": true
    },
    "cohere.command-r-v1:0": {
        "display_name": "Command R",
        "model_vendor": "cohere",
        "model_version": "v1:0",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "supports_tool_choice": true
    },
    "cohere.command-text-v14": {
        "display_name": "Command",
        "model_vendor": "cohere",
        "model_version": "v14",
        "input_cost_per_token": 1.5e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "supports_tool_choice": true
    },
    "cohere.embed-english-v3": {
        "display_name": "Embed English v3",
        "model_vendor": "cohere",
        "model_version": "v3",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 512,
        "max_tokens": 512,
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "supports_embedding_image_input": true
    },
    "cohere.embed-multilingual-v3": {
        "display_name": "Embed Multilingual v3",
        "model_vendor": "cohere",
        "model_version": "v3",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 512,
        "max_tokens": 512,
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "supports_embedding_image_input": true
    },
    "cohere.embed-v4:0": {
        "display_name": "Embed v4",
        "model_vendor": "cohere",
        "model_version": "v4:0",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128000,
        "max_tokens": 128000,
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "output_vector_size": 1536,
        "supports_embedding_image_input": true
    },
    "cohere/embed-v4.0": {
        "display_name": "Embed v4",
        "model_vendor": "cohere",
        "model_version": "v4.0",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "cohere",
        "max_input_tokens": 128000,
        "max_tokens": 128000,
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "output_vector_size": 1536,
        "supports_embedding_image_input": true
    },
    "cohere.rerank-v3-5:0": {
        "display_name": "Rerank v3.5",
        "model_vendor": "cohere",
        "model_version": "v3-5:0",
        "input_cost_per_query": 0.002,
        "input_cost_per_token": 0.0,
        "litellm_provider": "bedrock",
        "max_document_chunks_per_query": 100,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000,
        "max_query_tokens": 32000,
        "max_tokens": 32000,
        "max_tokens_per_document_chunk": 512,
        "mode": "rerank",
        "output_cost_per_token": 0.0
    },
    "command": {
        "display_name": "Command",
        "model_vendor": "cohere",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "cohere",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "completion",
        "output_cost_per_token": 2e-06
    },
    "command-a-03-2025": {
        "display_name": "Command A",
        "model_vendor": "cohere",
        "model_version": "03-2025",
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "cohere_chat",
        "max_input_tokens": 256000,
        "max_output_tokens": 8000,
        "max_tokens": 8000,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "command-light": {
        "display_name": "Command Light",
        "model_vendor": "cohere",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "cohere_chat",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "supports_tool_choice": true
    },
    "command-nightly": {
        "display_name": "Command Nightly",
        "model_vendor": "cohere",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "cohere",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "completion",
        "output_cost_per_token": 2e-06
    },
    "command-r": {
        "display_name": "Command R",
        "model_vendor": "cohere",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "cohere_chat",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "command-r-08-2024": {
        "display_name": "Command R",
        "model_vendor": "cohere",
        "model_version": "08-2024",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "cohere_chat",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "command-r-plus": {
        "display_name": "Command R+",
        "model_vendor": "cohere",
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "cohere_chat",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "command-r-plus-08-2024": {
        "display_name": "Command R+",
        "model_vendor": "cohere",
        "model_version": "08-2024",
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "cohere_chat",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "command-r7b-12-2024": {
        "display_name": "Command R 7B",
        "model_vendor": "cohere",
        "model_version": "12-2024",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "cohere_chat",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3.75e-08,
        "source": "https://docs.cohere.com/v2/docs/command-r7b",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "computer-use-preview": {
        "display_name": "Computer Use Preview",
        "model_vendor": "openai",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "azure",
        "max_input_tokens": 8192,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "chat",
        "output_cost_per_token": 1.2e-05,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": false,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "deepseek-chat": {
        "display_name": "DeepSeek Chat",
        "model_vendor": "deepseek",
        "cache_read_input_token_cost": 6e-08,
        "input_cost_per_token": 6e-07,
        "litellm_provider": "deepseek",
        "max_input_tokens": 131072,
        "max_output_tokens": 8192,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1.7e-06,
        "source": "https://api-docs.deepseek.com/quick_start/pricing",
        "supported_endpoints": [
            "/v1/chat/completions"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "deepseek-reasoner": {
        "display_name": "DeepSeek Reasoner",
        "model_vendor": "deepseek",
        "cache_read_input_token_cost": 6e-08,
        "input_cost_per_token": 6e-07,
        "litellm_provider": "deepseek",
        "max_input_tokens": 131072,
        "max_output_tokens": 65536,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1.7e-06,
        "source": "https://api-docs.deepseek.com/quick_start/pricing",
        "supported_endpoints": [
            "/v1/chat/completions"
        ],
        "supports_function_calling": false,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": false,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": false
    },
    "dashscope/qwen-coder": {
        "display_name": "Qwen Coder",
        "model_vendor": "alibaba",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "dashscope",
        "max_input_tokens": 1000000,
        "max_output_tokens": 16384,
        "max_tokens": 1000000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "dashscope/qwen-flash": {
        "display_name": "Qwen Flash",
        "model_vendor": "alibaba",
        "litellm_provider": "dashscope",
        "max_input_tokens": 997952,
        "max_output_tokens": 32768,
        "max_tokens": 1000000,
        "mode": "chat",
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "tiered_pricing": [
            {
                "input_cost_per_token": 5e-08,
                "output_cost_per_token": 4e-07,
                "range": [
                    0,
                    256000.0
                ]
            },
            {
                "input_cost_per_token": 2.5e-07,
                "output_cost_per_token": 2e-06,
                "range": [
                    256000.0,
                    1000000.0
                ]
            }
        ]
    },
    "dashscope/qwen-flash-2025-07-28": {
        "display_name": "Qwen Flash",
        "model_vendor": "alibaba",
        "model_version": "2025-07-28",
        "litellm_provider": "dashscope",
        "max_input_tokens": 997952,
        "max_output_tokens": 32768,
        "max_tokens": 1000000,
        "mode": "chat",
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "tiered_pricing": [
            {
                "input_cost_per_token": 5e-08,
                "output_cost_per_token": 4e-07,
                "range": [
                    0,
                    256000.0
                ]
            },
            {
                "input_cost_per_token": 2.5e-07,
                "output_cost_per_token": 2e-06,
                "range": [
                    256000.0,
                    1000000.0
                ]
            }
        ]
    },
    "dashscope/qwen-max": {
        "display_name": "Qwen Max",
        "model_vendor": "alibaba",
        "input_cost_per_token": 1.6e-06,
        "litellm_provider": "dashscope",
        "max_input_tokens": 30720,
        "max_output_tokens": 8192,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 6.4e-06,
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "dashscope/qwen-plus": {
        "display_name": "Qwen Plus",
        "model_vendor": "alibaba",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "dashscope",
        "max_input_tokens": 129024,
        "max_output_tokens": 16384,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1.2e-06,
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "dashscope/qwen-plus-2025-01-25": {
        "display_name": "Qwen Plus",
        "model_vendor": "alibaba",
        "model_version": "2025-01-25",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "dashscope",
        "max_input_tokens": 129024,
        "max_output_tokens": 8192,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1.2e-06,
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "dashscope/qwen-plus-2025-04-28": {
        "display_name": "Qwen Plus",
        "model_vendor": "alibaba",
        "model_version": "2025-04-28",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "dashscope",
        "max_input_tokens": 129024,
        "max_output_tokens": 16384,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_reasoning_token": 4e-06,
        "output_cost_per_token": 1.2e-06,
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "dashscope/qwen-plus-2025-07-14": {
        "display_name": "Qwen Plus",
        "model_vendor": "alibaba",
        "model_version": "2025-07-14",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "dashscope",
        "max_input_tokens": 129024,
        "max_output_tokens": 16384,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_reasoning_token": 4e-06,
        "output_cost_per_token": 1.2e-06,
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "dashscope/qwen-plus-2025-07-28": {
        "display_name": "Qwen Plus",
        "model_vendor": "alibaba",
        "model_version": "2025-07-28",
        "litellm_provider": "dashscope",
        "max_input_tokens": 997952,
        "max_output_tokens": 32768,
        "max_tokens": 1000000,
        "mode": "chat",
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "tiered_pricing": [
            {
                "input_cost_per_token": 4e-07,
                "output_cost_per_reasoning_token": 4e-06,
                "output_cost_per_token": 1.2e-06,
                "range": [
                    0,
                    256000.0
                ]
            },
            {
                "input_cost_per_token": 1.2e-06,
                "output_cost_per_reasoning_token": 1.2e-05,
                "output_cost_per_token": 3.6e-06,
                "range": [
                    256000.0,
                    1000000.0
                ]
            }
        ]
    },
    "dashscope/qwen-plus-2025-09-11": {
        "display_name": "Qwen Plus",
        "model_vendor": "alibaba",
        "model_version": "2025-09-11",
        "litellm_provider": "dashscope",
        "max_input_tokens": 997952,
        "max_output_tokens": 32768,
        "max_tokens": 1000000,
        "mode": "chat",
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "tiered_pricing": [
            {
                "input_cost_per_token": 4e-07,
                "output_cost_per_reasoning_token": 4e-06,
                "output_cost_per_token": 1.2e-06,
                "range": [
                    0,
                    256000.0
                ]
            },
            {
                "input_cost_per_token": 1.2e-06,
                "output_cost_per_reasoning_token": 1.2e-05,
                "output_cost_per_token": 3.6e-06,
                "range": [
                    256000.0,
                    1000000.0
                ]
            }
        ]
    },
    "dashscope/qwen-plus-latest": {
        "display_name": "Qwen Plus",
        "model_vendor": "alibaba",
        "litellm_provider": "dashscope",
        "max_input_tokens": 997952,
        "max_output_tokens": 32768,
        "max_tokens": 1000000,
        "mode": "chat",
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "tiered_pricing": [
            {
                "input_cost_per_token": 4e-07,
                "output_cost_per_reasoning_token": 4e-06,
                "output_cost_per_token": 1.2e-06,
                "range": [
                    0,
                    256000.0
                ]
            },
            {
                "input_cost_per_token": 1.2e-06,
                "output_cost_per_reasoning_token": 1.2e-05,
                "output_cost_per_token": 3.6e-06,
                "range": [
                    256000.0,
                    1000000.0
                ]
            }
        ]
    },
    "dashscope/qwen-turbo": {
        "display_name": "Qwen Turbo",
        "model_vendor": "alibaba",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "dashscope",
        "max_input_tokens": 129024,
        "max_output_tokens": 16384,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_reasoning_token": 5e-07,
        "output_cost_per_token": 2e-07,
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "dashscope/qwen-turbo-2024-11-01": {
        "display_name": "Qwen Turbo",
        "model_vendor": "alibaba",
        "model_version": "2024-11-01",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "dashscope",
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_tokens": 1000000,
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "dashscope/qwen-turbo-2025-04-28": {
        "display_name": "Qwen Turbo",
        "model_vendor": "alibaba",
        "model_version": "2025-04-28",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "dashscope",
        "max_input_tokens": 1000000,
        "max_output_tokens": 16384,
        "max_tokens": 1000000,
        "mode": "chat",
        "output_cost_per_reasoning_token": 5e-07,
        "output_cost_per_token": 2e-07,
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "dashscope/qwen-turbo-latest": {
        "display_name": "Qwen Turbo",
        "model_vendor": "alibaba",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "dashscope",
        "max_input_tokens": 1000000,
        "max_output_tokens": 16384,
        "max_tokens": 1000000,
        "mode": "chat",
        "output_cost_per_reasoning_token": 5e-07,
        "output_cost_per_token": 2e-07,
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "dashscope/qwen3-30b-a3b": {
        "display_name": "Qwen3 30B A3B",
        "model_vendor": "alibaba",
        "litellm_provider": "dashscope",
        "max_input_tokens": 129024,
        "max_output_tokens": 16384,
        "max_tokens": 131072,
        "mode": "chat",
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "dashscope/qwen3-coder-flash": {
        "display_name": "Qwen3 Coder Flash",
        "model_vendor": "alibaba",
        "litellm_provider": "dashscope",
        "max_input_tokens": 997952,
        "max_output_tokens": 65536,
        "max_tokens": 1000000,
        "mode": "chat",
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "tiered_pricing": [
            {
                "cache_read_input_token_cost": 8e-08,
                "input_cost_per_token": 3e-07,
                "output_cost_per_token": 1.5e-06,
                "range": [
                    0,
                    32000.0
                ]
            },
            {
                "cache_read_input_token_cost": 1.2e-07,
                "input_cost_per_token": 5e-07,
                "output_cost_per_token": 2.5e-06,
                "range": [
                    32000.0,
                    128000.0
                ]
            },
            {
                "cache_read_input_token_cost": 2e-07,
                "input_cost_per_token": 8e-07,
                "output_cost_per_token": 4e-06,
                "range": [
                    128000.0,
                    256000.0
                ]
            },
            {
                "cache_read_input_token_cost": 4e-07,
                "input_cost_per_token": 1.6e-06,
                "output_cost_per_token": 9.6e-06,
                "range": [
                    256000.0,
                    1000000.0
                ]
            }
        ]
    },
    "dashscope/qwen3-coder-flash-2025-07-28": {
        "display_name": "Qwen3 Coder Flash",
        "model_vendor": "alibaba",
        "model_version": "2025-07-28",
        "litellm_provider": "dashscope",
        "max_input_tokens": 997952,
        "max_output_tokens": 65536,
        "max_tokens": 1000000,
        "mode": "chat",
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "tiered_pricing": [
            {
                "input_cost_per_token": 3e-07,
                "output_cost_per_token": 1.5e-06,
                "range": [
                    0,
                    32000.0
                ]
            },
            {
                "input_cost_per_token": 5e-07,
                "output_cost_per_token": 2.5e-06,
                "range": [
                    32000.0,
                    128000.0
                ]
            },
            {
                "input_cost_per_token": 8e-07,
                "output_cost_per_token": 4e-06,
                "range": [
                    128000.0,
                    256000.0
                ]
            },
            {
                "input_cost_per_token": 1.6e-06,
                "output_cost_per_token": 9.6e-06,
                "range": [
                    256000.0,
                    1000000.0
                ]
            }
        ]
    },
    "dashscope/qwen3-coder-plus": {
        "display_name": "Qwen3 Coder Plus",
        "model_vendor": "alibaba",
        "litellm_provider": "dashscope",
        "max_input_tokens": 997952,
        "max_output_tokens": 65536,
        "max_tokens": 1000000,
        "mode": "chat",
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "tiered_pricing": [
            {
                "cache_read_input_token_cost": 1e-07,
                "input_cost_per_token": 1e-06,
                "output_cost_per_token": 5e-06,
                "range": [
                    0,
                    32000.0
                ]
            },
            {
                "cache_read_input_token_cost": 1.8e-07,
                "input_cost_per_token": 1.8e-06,
                "output_cost_per_token": 9e-06,
                "range": [
                    32000.0,
                    128000.0
                ]
            },
            {
                "cache_read_input_token_cost": 3e-07,
                "input_cost_per_token": 3e-06,
                "output_cost_per_token": 1.5e-05,
                "range": [
                    128000.0,
                    256000.0
                ]
            },
            {
                "cache_read_input_token_cost": 6e-07,
                "input_cost_per_token": 6e-06,
                "output_cost_per_token": 6e-05,
                "range": [
                    256000.0,
                    1000000.0
                ]
            }
        ]
    },
    "dashscope/qwen3-coder-plus-2025-07-22": {
        "display_name": "Qwen3 Coder Plus",
        "model_vendor": "alibaba",
        "model_version": "2025-07-22",
        "litellm_provider": "dashscope",
        "max_input_tokens": 997952,
        "max_output_tokens": 65536,
        "max_tokens": 1000000,
        "mode": "chat",
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "tiered_pricing": [
            {
                "input_cost_per_token": 1e-06,
                "output_cost_per_token": 5e-06,
                "range": [
                    0,
                    32000.0
                ]
            },
            {
                "input_cost_per_token": 1.8e-06,
                "output_cost_per_token": 9e-06,
                "range": [
                    32000.0,
                    128000.0
                ]
            },
            {
                "input_cost_per_token": 3e-06,
                "output_cost_per_token": 1.5e-05,
                "range": [
                    128000.0,
                    256000.0
                ]
            },
            {
                "input_cost_per_token": 6e-06,
                "output_cost_per_token": 6e-05,
                "range": [
                    256000.0,
                    1000000.0
                ]
            }
        ]
    },
    "dashscope/qwen3-max-preview": {
        "display_name": "Qwen3 Max Preview",
        "model_vendor": "alibaba",
        "litellm_provider": "dashscope",
        "max_input_tokens": 258048,
        "max_output_tokens": 65536,
        "max_tokens": 262144,
        "mode": "chat",
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "tiered_pricing": [
            {
                "input_cost_per_token": 1.2e-06,
                "output_cost_per_token": 6e-06,
                "range": [
                    0,
                    32000.0
                ]
            },
            {
                "input_cost_per_token": 2.4e-06,
                "output_cost_per_token": 1.2e-05,
                "range": [
                    32000.0,
                    128000.0
                ]
            },
            {
                "input_cost_per_token": 3e-06,
                "output_cost_per_token": 1.5e-05,
                "range": [
                    128000.0,
                    252000.0
                ]
            }
        ]
    },
    "dashscope/qwq-plus": {
        "display_name": "QWQ Plus",
        "model_vendor": "alibaba",
        "input_cost_per_token": 8e-07,
        "litellm_provider": "dashscope",
        "max_input_tokens": 98304,
        "max_output_tokens": 8192,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 2.4e-06,
        "source": "https://www.alibabacloud.com/help/en/model-studio/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "databricks/databricks-bge-large-en": {
        "display_name": "BGE Large EN",
        "model_vendor": "baai",
        "input_cost_per_token": 1.0003e-07,
        "input_dbu_cost_per_token": 1.429e-06,
        "litellm_provider": "databricks",
        "max_input_tokens": 512,
        "max_tokens": 512,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "output_dbu_cost_per_token": 0.0,
        "output_vector_size": 1024,
        "source": "https://www.databricks.com/product/pricing/foundation-model-serving"
    },
    "databricks/databricks-claude-3-7-sonnet": {
        "display_name": "Claude Sonnet 3.7",
        "model_vendor": "anthropic",
        "input_cost_per_token": 2.9999900000000002e-06,
        "input_dbu_cost_per_token": 4.2857e-05,
        "litellm_provider": "databricks",
        "max_input_tokens": 200000,
        "max_output_tokens": 128000,
        "max_tokens": 200000,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 1.5000020000000002e-05,
        "output_dbu_cost_per_token": 0.000214286,
        "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "databricks/databricks-claude-haiku-4-5": {
        "display_name": "Claude Haiku 4.5",
        "model_vendor": "anthropic",
        "input_cost_per_token": 1.00002e-06,
        "input_dbu_cost_per_token": 1.4286e-05,
        "litellm_provider": "databricks",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 200000,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 5.00003e-06,
        "output_dbu_cost_per_token": 7.1429e-05,
        "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "databricks/databricks-claude-opus-4": {
        "display_name": "Claude Opus 4",
        "model_vendor": "anthropic",
        "input_cost_per_token": 1.5000020000000002e-05,
        "input_dbu_cost_per_token": 0.000214286,
        "litellm_provider": "databricks",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 200000,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 7.500003000000001e-05,
        "output_dbu_cost_per_token": 0.001071429,
        "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "databricks/databricks-claude-opus-4-1": {
        "display_name": "Claude Opus 4.1",
        "model_vendor": "anthropic",
        "input_cost_per_token": 1.5000020000000002e-05,
        "input_dbu_cost_per_token": 0.000214286,
        "litellm_provider": "databricks",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 200000,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 7.500003000000001e-05,
        "output_dbu_cost_per_token": 0.001071429,
        "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "databricks/databricks-claude-opus-4-5": {
        "display_name": "Claude Opus 4.5",
        "model_vendor": "anthropic",
        "input_cost_per_token": 5.00003e-06,
        "input_dbu_cost_per_token": 7.1429e-05,
        "litellm_provider": "databricks",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 200000,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 2.5000010000000002e-05,
        "output_dbu_cost_per_token": 0.000357143,
        "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "databricks/databricks-claude-sonnet-4": {
        "display_name": "Claude Sonnet 4",
        "model_vendor": "anthropic",
        "input_cost_per_token": 2.9999900000000002e-06,
        "input_dbu_cost_per_token": 4.2857e-05,
        "litellm_provider": "databricks",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 200000,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 1.5000020000000002e-05,
        "output_dbu_cost_per_token": 0.000214286,
        "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "databricks/databricks-claude-sonnet-4-1": {
        "display_name": "Claude Sonnet 4.1",
        "model_vendor": "anthropic",
        "input_cost_per_token": 2.9999900000000002e-06,
        "input_dbu_cost_per_token": 4.2857e-05,
        "litellm_provider": "databricks",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 200000,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 1.5000020000000002e-05,
        "output_dbu_cost_per_token": 0.000214286,
        "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "databricks/databricks-claude-sonnet-4-5": {
        "display_name": "Claude Sonnet 4.5",
        "model_vendor": "anthropic",
        "input_cost_per_token": 2.9999900000000002e-06,
        "input_dbu_cost_per_token": 4.2857e-05,
        "litellm_provider": "databricks",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 200000,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 1.5000020000000002e-05,
        "output_dbu_cost_per_token": 0.000214286,
        "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "databricks/databricks-gemini-2-5-flash": {
        "display_name": "Gemini 2.5 Flash",
        "model_vendor": "google",
        "input_cost_per_token": 3.0001999999999996e-07,
        "input_dbu_cost_per_token": 4.285999999999999e-06,
        "litellm_provider": "databricks",
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_tokens": 1048576,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 2.49998e-06,
        "output_dbu_cost_per_token": 3.5714e-05,
        "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "databricks/databricks-gemini-2-5-pro": {
        "display_name": "Gemini 2.5 Pro",
        "model_vendor": "google",
        "input_cost_per_token": 1.24999e-06,
        "input_dbu_cost_per_token": 1.7857e-05,
        "litellm_provider": "databricks",
        "max_input_tokens": 1048576,
        "max_output_tokens": 65536,
        "max_tokens": 1048576,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 9.999990000000002e-06,
        "output_dbu_cost_per_token": 0.000142857,
        "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "databricks/databricks-gemma-3-12b": {
        "display_name": "Gemma 3 12B",
        "model_vendor": "google",
        "input_cost_per_token": 1.5000999999999998e-07,
        "input_dbu_cost_per_token": 2.1429999999999996e-06,
        "litellm_provider": "databricks",
        "max_input_tokens": 128000,
        "max_output_tokens": 32000,
        "max_tokens": 128000,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 5.0001e-07,
        "output_dbu_cost_per_token": 7.143e-06,
        "source": "https://www.databricks.com/product/pricing/foundation-model-serving"
    },
    "databricks/databricks-gpt-5": {
        "display_name": "GPT-5",
        "model_vendor": "openai",
        "input_cost_per_token": 1.24999e-06,
        "input_dbu_cost_per_token": 1.7857e-05,
        "litellm_provider": "databricks",
        "max_input_tokens": 400000,
        "max_output_tokens": 128000,
        "max_tokens": 400000,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 9.999990000000002e-06,
        "output_dbu_cost_per_token": 0.000142857,
        "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving"
    },
    "databricks/databricks-gpt-5-1": {
        "display_name": "GPT-5.1",
        "model_vendor": "openai",
        "input_cost_per_token": 1.24999e-06,
        "input_dbu_cost_per_token": 1.7857e-05,
        "litellm_provider": "databricks",
        "max_input_tokens": 400000,
        "max_output_tokens": 128000,
        "max_tokens": 400000,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 9.999990000000002e-06,
        "output_dbu_cost_per_token": 0.000142857,
        "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving"
    },
    "databricks/databricks-gpt-5-mini": {
        "display_name": "GPT-5 Mini",
        "model_vendor": "openai",
        "input_cost_per_token": 2.4997000000000006e-07,
        "input_dbu_cost_per_token": 3.571e-06,
        "litellm_provider": "databricks",
        "max_input_tokens": 400000,
        "max_output_tokens": 128000,
        "max_tokens": 400000,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 1.9999700000000004e-06,
        "output_dbu_cost_per_token": 2.8571e-05,
        "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving"
    },
    "databricks/databricks-gpt-5-nano": {
        "display_name": "GPT-5 Nano",
        "model_vendor": "openai",
        "input_cost_per_token": 4.998e-08,
        "input_dbu_cost_per_token": 7.14e-07,
        "litellm_provider": "databricks",
        "max_input_tokens": 400000,
        "max_output_tokens": 128000,
        "max_tokens": 400000,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 3.9998000000000007e-07,
        "output_dbu_cost_per_token": 5.714000000000001e-06,
        "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving"
    },
    "databricks/databricks-gpt-oss-120b": {
        "display_name": "GPT OSS 120B",
        "model_vendor": "databricks",
        "input_cost_per_token": 1.5000999999999998e-07,
        "input_dbu_cost_per_token": 2.1429999999999996e-06,
        "litellm_provider": "databricks",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 5.9997e-07,
        "output_dbu_cost_per_token": 8.571e-06,
        "source": "https://www.databricks.com/product/pricing/foundation-model-serving"
    },
    "databricks/databricks-gpt-oss-20b": {
        "display_name": "GPT OSS 20B",
        "model_vendor": "databricks",
        "input_cost_per_token": 7e-08,
        "input_dbu_cost_per_token": 1e-06,
        "litellm_provider": "databricks",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 3.0001999999999996e-07,
        "output_dbu_cost_per_token": 4.285999999999999e-06,
        "source": "https://www.databricks.com/product/pricing/foundation-model-serving"
    },
    "databricks/databricks-gte-large-en": {
        "display_name": "GTE Large EN",
        "model_vendor": "alibaba",
        "input_cost_per_token": 1.2999000000000001e-07,
        "input_dbu_cost_per_token": 1.857e-06,
        "litellm_provider": "databricks",
        "max_input_tokens": 8192,
        "max_tokens": 8192,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "output_dbu_cost_per_token": 0.0,
        "output_vector_size": 1024,
        "source": "https://www.databricks.com/product/pricing/foundation-model-serving"
    },
    "databricks/databricks-llama-2-70b-chat": {
        "display_name": "Llama 2 70B Chat",
        "model_vendor": "meta",
        "input_cost_per_token": 5.0001e-07,
        "input_dbu_cost_per_token": 7.143e-06,
        "litellm_provider": "databricks",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 1.5000300000000002e-06,
        "output_dbu_cost_per_token": 2.1429e-05,
        "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
        "supports_tool_choice": true
    },
    "databricks/databricks-llama-4-maverick": {
        "display_name": "Llama 4 Maverick",
        "model_vendor": "meta",
        "input_cost_per_token": 5.0001e-07,
        "input_dbu_cost_per_token": 7.143e-06,
        "litellm_provider": "databricks",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "metadata": {
            "notes": "Databricks documentation now provides both DBU costs (_dbu_cost_per_token) and dollar costs(_cost_per_token)."
        },
        "mode": "chat",
        "output_cost_per_token": 1.5000300000000002e-06,
        "output_dbu_cost_per_token": 2.1429e-05,
        "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
        "supports_tool_choice": true
    },
    "databricks/databricks-meta-llama-3-1-405b-instruct": {
        "display_name": "Llama 3.1 405B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 5.00003e-06,
        "input_dbu_cost_per_token": 7.1429e-05,
        "litellm_provider": "databricks",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 1.5000020000000002e-05,
        "output_dbu_cost_per_token": 0.000214286,
        "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
        "supports_tool_choice": true
    },
    "databricks/databricks-meta-llama-3-1-8b-instruct": {
        "display_name": "Llama 3.1 8B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1.5000999999999998e-07,
        "input_dbu_cost_per_token": 2.1429999999999996e-06,
        "litellm_provider": "databricks",
        "max_input_tokens": 200000,
        "max_output_tokens": 128000,
        "max_tokens": 200000,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 4.5003000000000007e-07,
        "output_dbu_cost_per_token": 6.429000000000001e-06,
        "source": "https://www.databricks.com/product/pricing/foundation-model-serving"
    },
    "databricks/databricks-meta-llama-3-3-70b-instruct": {
        "display_name": "Llama 3.3 70B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 5.0001e-07,
        "input_dbu_cost_per_token": 7.143e-06,
        "litellm_provider": "databricks",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 1.5000300000000002e-06,
        "output_dbu_cost_per_token": 2.1429e-05,
        "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
        "supports_tool_choice": true
    },
    "databricks/databricks-meta-llama-3-70b-instruct": {
        "display_name": "Llama 3 70B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1.00002e-06,
        "input_dbu_cost_per_token": 1.4286e-05,
        "litellm_provider": "databricks",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 2.9999900000000002e-06,
        "output_dbu_cost_per_token": 4.2857e-05,
        "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
        "supports_tool_choice": true
    },
    "databricks/databricks-mixtral-8x7b-instruct": {
        "display_name": "Mixtral 8x7B Instruct",
        "model_vendor": "mistral",
        "input_cost_per_token": 5.0001e-07,
        "input_dbu_cost_per_token": 7.143e-06,
        "litellm_provider": "databricks",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 1.00002e-06,
        "output_dbu_cost_per_token": 1.4286e-05,
        "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
        "supports_tool_choice": true
    },
    "databricks/databricks-mpt-30b-instruct": {
        "display_name": "MPT 30B Instruct",
        "model_vendor": "databricks",
        "input_cost_per_token": 1.00002e-06,
        "input_dbu_cost_per_token": 1.4286e-05,
        "litellm_provider": "databricks",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 1.00002e-06,
        "output_dbu_cost_per_token": 1.4286e-05,
        "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
        "supports_tool_choice": true
    },
    "databricks/databricks-mpt-7b-instruct": {
        "display_name": "MPT 7B Instruct",
        "model_vendor": "databricks",
        "input_cost_per_token": 5.0001e-07,
        "input_dbu_cost_per_token": 7.143e-06,
        "litellm_provider": "databricks",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "output_dbu_cost_per_token": 0.0,
        "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
        "supports_tool_choice": true
    },
    "dataforseo/search": {
        "display_name": "DataForSEO Search",
        "model_vendor": "dataforseo",
        "input_cost_per_query": 0.003,
        "litellm_provider": "dataforseo",
        "mode": "search"
    },
    "davinci-002": {
        "display_name": "Davinci 002",
        "model_vendor": "openai",
        "model_version": "002",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "text-completion-openai",
        "max_input_tokens": 16384,
        "max_output_tokens": 4096,
        "max_tokens": 16384,
        "mode": "completion",
        "output_cost_per_token": 2e-06
    },
    "deepgram/base": {
        "display_name": "Deepgram Base",
        "model_vendor": "deepgram",
        "input_cost_per_second": 0.00020833,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0125/60 seconds = $0.00020833 per second",
            "original_pricing_per_minute": 0.0125
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/base-conversationalai": {
        "display_name": "Deepgram Base Conversational AI",
        "model_vendor": "deepgram",
        "input_cost_per_second": 0.00020833,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0125/60 seconds = $0.00020833 per second",
            "original_pricing_per_minute": 0.0125
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/base-finance": {
        "display_name": "Deepgram Base Finance",
        "model_vendor": "deepgram",
        "input_cost_per_second": 0.00020833,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0125/60 seconds = $0.00020833 per second",
            "original_pricing_per_minute": 0.0125
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/base-general": {
        "display_name": "Deepgram Base General",
        "model_vendor": "deepgram",
        "input_cost_per_second": 0.00020833,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0125/60 seconds = $0.00020833 per second",
            "original_pricing_per_minute": 0.0125
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/base-meeting": {
        "display_name": "Deepgram Base Meeting",
        "model_vendor": "deepgram",
        "input_cost_per_second": 0.00020833,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0125/60 seconds = $0.00020833 per second",
            "original_pricing_per_minute": 0.0125
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/base-phonecall": {
        "display_name": "Deepgram Base Phone Call",
        "model_vendor": "deepgram",
        "input_cost_per_second": 0.00020833,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0125/60 seconds = $0.00020833 per second",
            "original_pricing_per_minute": 0.0125
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/base-video": {
        "display_name": "Deepgram Base Video",
        "model_vendor": "deepgram",
        "input_cost_per_second": 0.00020833,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0125/60 seconds = $0.00020833 per second",
            "original_pricing_per_minute": 0.0125
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/base-voicemail": {
        "display_name": "Deepgram Base Voicemail",
        "model_vendor": "deepgram",
        "input_cost_per_second": 0.00020833,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0125/60 seconds = $0.00020833 per second",
            "original_pricing_per_minute": 0.0125
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/enhanced": {
        "display_name": "Deepgram Enhanced",
        "model_vendor": "deepgram",
        "input_cost_per_second": 0.00024167,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0145/60 seconds = $0.00024167 per second",
            "original_pricing_per_minute": 0.0145
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/enhanced-finance": {
        "display_name": "Deepgram Enhanced Finance",
        "model_vendor": "deepgram",
        "input_cost_per_second": 0.00024167,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0145/60 seconds = $0.00024167 per second",
            "original_pricing_per_minute": 0.0145
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/enhanced-general": {
        "display_name": "Deepgram Enhanced General",
        "model_vendor": "deepgram",
        "input_cost_per_second": 0.00024167,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0145/60 seconds = $0.00024167 per second",
            "original_pricing_per_minute": 0.0145
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/enhanced-meeting": {
        "display_name": "Deepgram Enhanced Meeting",
        "model_vendor": "deepgram",
        "input_cost_per_second": 0.00024167,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0145/60 seconds = $0.00024167 per second",
            "original_pricing_per_minute": 0.0145
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/enhanced-phonecall": {
        "display_name": "Deepgram Enhanced Phone Call",
        "model_vendor": "deepgram",
        "input_cost_per_second": 0.00024167,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0145/60 seconds = $0.00024167 per second",
            "original_pricing_per_minute": 0.0145
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/nova": {
        "display_name": "Deepgram Nova",
        "model_vendor": "deepgram",
        "input_cost_per_second": 7.167e-05,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0043/60 seconds = $0.00007167 per second",
            "original_pricing_per_minute": 0.0043
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/nova-2": {
        "display_name": "Deepgram Nova 2",
        "model_vendor": "deepgram",
        "input_cost_per_second": 7.167e-05,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0043/60 seconds = $0.00007167 per second",
            "original_pricing_per_minute": 0.0043
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/nova-2-atc": {
        "display_name": "Deepgram Nova 2 ATC",
        "model_vendor": "deepgram",
        "input_cost_per_second": 7.167e-05,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0043/60 seconds = $0.00007167 per second",
            "original_pricing_per_minute": 0.0043
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/nova-2-automotive": {
        "display_name": "Deepgram Nova 2 Automotive",
        "model_vendor": "deepgram",
        "input_cost_per_second": 7.167e-05,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0043/60 seconds = $0.00007167 per second",
            "original_pricing_per_minute": 0.0043
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/nova-2-conversationalai": {
        "display_name": "Deepgram Nova 2 Conversational AI",
        "model_vendor": "deepgram",
        "input_cost_per_second": 7.167e-05,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0043/60 seconds = $0.00007167 per second",
            "original_pricing_per_minute": 0.0043
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/nova-2-drivethru": {
        "display_name": "Deepgram Nova 2 Drive-Thru",
        "model_vendor": "deepgram",
        "input_cost_per_second": 7.167e-05,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0043/60 seconds = $0.00007167 per second",
            "original_pricing_per_minute": 0.0043
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/nova-2-finance": {
        "display_name": "Deepgram Nova 2 Finance",
        "model_vendor": "deepgram",
        "input_cost_per_second": 7.167e-05,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0043/60 seconds = $0.00007167 per second",
            "original_pricing_per_minute": 0.0043
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/nova-2-general": {
        "display_name": "Deepgram Nova 2 General",
        "model_vendor": "deepgram",
        "input_cost_per_second": 7.167e-05,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0043/60 seconds = $0.00007167 per second",
            "original_pricing_per_minute": 0.0043
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/nova-2-meeting": {
        "display_name": "Deepgram Nova 2 Meeting",
        "model_vendor": "deepgram",
        "input_cost_per_second": 7.167e-05,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0043/60 seconds = $0.00007167 per second",
            "original_pricing_per_minute": 0.0043
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/nova-2-phonecall": {
        "display_name": "Deepgram Nova 2 Phone Call",
        "model_vendor": "deepgram",
        "input_cost_per_second": 7.167e-05,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0043/60 seconds = $0.00007167 per second",
            "original_pricing_per_minute": 0.0043
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/nova-2-video": {
        "display_name": "Deepgram Nova 2 Video",
        "model_vendor": "deepgram",
        "input_cost_per_second": 7.167e-05,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0043/60 seconds = $0.00007167 per second",
            "original_pricing_per_minute": 0.0043
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/nova-2-voicemail": {
        "display_name": "Deepgram Nova 2 Voicemail",
        "model_vendor": "deepgram",
        "input_cost_per_second": 7.167e-05,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0043/60 seconds = $0.00007167 per second",
            "original_pricing_per_minute": 0.0043
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/nova-3": {
        "display_name": "Deepgram Nova 3",
        "model_vendor": "deepgram",
        "input_cost_per_second": 7.167e-05,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0043/60 seconds = $0.00007167 per second",
            "original_pricing_per_minute": 0.0043
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/nova-3-general": {
        "display_name": "Deepgram Nova 3 General",
        "model_vendor": "deepgram",
        "input_cost_per_second": 7.167e-05,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0043/60 seconds = $0.00007167 per second",
            "original_pricing_per_minute": 0.0043
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/nova-3-medical": {
        "display_name": "Deepgram Nova 3 Medical",
        "model_vendor": "deepgram",
        "input_cost_per_second": 8.667e-05,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0052/60 seconds = $0.00008667 per second (multilingual)",
            "original_pricing_per_minute": 0.0052
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/nova-general": {
        "display_name": "Deepgram Nova General",
        "model_vendor": "deepgram",
        "input_cost_per_second": 7.167e-05,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0043/60 seconds = $0.00007167 per second",
            "original_pricing_per_minute": 0.0043
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/nova-phonecall": {
        "display_name": "Deepgram Nova Phone Call",
        "model_vendor": "deepgram",
        "input_cost_per_second": 7.167e-05,
        "litellm_provider": "deepgram",
        "metadata": {
            "calculation": "$0.0043/60 seconds = $0.00007167 per second",
            "original_pricing_per_minute": 0.0043
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/whisper": {
        "display_name": "Deepgram Whisper",
        "model_vendor": "deepgram",
        "input_cost_per_second": 0.0001,
        "litellm_provider": "deepgram",
        "metadata": {
            "notes": "Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models"
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/whisper-base": {
        "display_name": "Deepgram Whisper Base",
        "model_vendor": "deepgram",
        "input_cost_per_second": 0.0001,
        "litellm_provider": "deepgram",
        "metadata": {
            "notes": "Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models"
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/whisper-large": {
        "display_name": "Deepgram Whisper Large",
        "model_vendor": "deepgram",
        "input_cost_per_second": 0.0001,
        "litellm_provider": "deepgram",
        "metadata": {
            "notes": "Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models"
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/whisper-medium": {
        "display_name": "Deepgram Whisper Medium",
        "model_vendor": "deepgram",
        "input_cost_per_second": 0.0001,
        "litellm_provider": "deepgram",
        "metadata": {
            "notes": "Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models"
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/whisper-small": {
        "display_name": "Deepgram Whisper Small",
        "model_vendor": "deepgram",
        "input_cost_per_second": 0.0001,
        "litellm_provider": "deepgram",
        "metadata": {
            "notes": "Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models"
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepgram/whisper-tiny": {
        "display_name": "Deepgram Whisper Tiny",
        "model_vendor": "deepgram",
        "input_cost_per_second": 0.0001,
        "litellm_provider": "deepgram",
        "metadata": {
            "notes": "Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models"
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://deepgram.com/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "deepinfra/Gryphe/MythoMax-L2-13b": {
        "display_name": "MythoMax L2 13B",
        "model_vendor": "gryphe",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 8e-08,
        "output_cost_per_token": 9e-08,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/NousResearch/Hermes-3-Llama-3.1-405B": {
        "display_name": "Hermes 3 Llama 3.1 405B",
        "model_vendor": "nousresearch",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 1e-06,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/NousResearch/Hermes-3-Llama-3.1-70B": {
        "display_name": "Hermes 3 Llama 3.1 70B",
        "model_vendor": "nousresearch",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 3e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": false
    },
    "deepinfra/Qwen/QwQ-32B": {
        "display_name": "QwQ 32B",
        "model_vendor": "alibaba",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 4e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/Qwen/Qwen2.5-72B-Instruct": {
        "display_name": "Qwen 2.5 72B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 3.9e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/Qwen/Qwen2.5-7B-Instruct": {
        "display_name": "Qwen 2.5 7B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": false
    },
    "deepinfra/Qwen/Qwen2.5-VL-32B-Instruct": {
        "display_name": "Qwen 2.5 VL 32B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 6e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "deepinfra/Qwen/Qwen3-14B": {
        "display_name": "Qwen 3 14B",
        "model_vendor": "alibaba",
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960,
        "input_cost_per_token": 6e-08,
        "output_cost_per_token": 2.4e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/Qwen/Qwen3-235B-A22B": {
        "display_name": "Qwen 3 235B A22B",
        "model_vendor": "alibaba",
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960,
        "input_cost_per_token": 1.8e-07,
        "output_cost_per_token": 5.4e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/Qwen/Qwen3-235B-A22B-Instruct-2507": {
        "display_name": "Qwen 3 235B A22B Instruct",
        "model_vendor": "alibaba",
        "model_version": "2507",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 9e-08,
        "output_cost_per_token": 6e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/Qwen/Qwen3-235B-A22B-Thinking-2507": {
        "display_name": "Qwen 3 235B A22B Thinking",
        "model_vendor": "alibaba",
        "model_version": "2507",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.9e-06,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/Qwen/Qwen3-30B-A3B": {
        "display_name": "Qwen 3 30B A3B",
        "model_vendor": "alibaba",
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960,
        "input_cost_per_token": 8e-08,
        "output_cost_per_token": 2.9e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/Qwen/Qwen3-32B": {
        "display_name": "Qwen 3 32B",
        "model_vendor": "alibaba",
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 2.8e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
        "display_name": "Qwen 3 Coder 480B A35B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 1.6e-06,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo": {
        "display_name": "Qwen 3 Coder 480B A35B Instruct Turbo",
        "model_vendor": "alibaba",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 2.9e-07,
        "output_cost_per_token": 1.2e-06,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/Qwen/Qwen3-Next-80B-A3B-Instruct": {
        "display_name": "Qwen 3 Next 80B A3B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 1.4e-07,
        "output_cost_per_token": 1.4e-06,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/Qwen/Qwen3-Next-80B-A3B-Thinking": {
        "display_name": "Qwen 3 Next 80B A3B Thinking",
        "model_vendor": "alibaba",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 1.4e-07,
        "output_cost_per_token": 1.4e-06,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/Sao10K/L3-8B-Lunaris-v1-Turbo": {
        "display_name": "L3 8B Lunaris v1 Turbo",
        "model_vendor": "sao10k",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 5e-08,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": false
    },
    "deepinfra/Sao10K/L3.1-70B-Euryale-v2.2": {
        "display_name": "L3.1 70B Euryale v2.2",
        "model_vendor": "sao10k",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 6.5e-07,
        "output_cost_per_token": 7.5e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": false
    },
    "deepinfra/Sao10K/L3.3-70B-Euryale-v2.3": {
        "display_name": "L3.3 70B Euryale v2.3",
        "model_vendor": "sao10k",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 6.5e-07,
        "output_cost_per_token": 7.5e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": false
    },
    "deepinfra/allenai/olmOCR-7B-0725-FP8": {
        "display_name": "OLMoCR 7B",
        "model_vendor": "allenai",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2.7e-07,
        "output_cost_per_token": 1.5e-06,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": false
    },
    "deepinfra/anthropic/claude-3-7-sonnet-latest": {
        "display_name": "Claude 3.7 Sonnet",
        "model_vendor": "anthropic",
        "max_tokens": 200000,
        "max_input_tokens": 200000,
        "max_output_tokens": 200000,
        "input_cost_per_token": 3.3e-06,
        "output_cost_per_token": 1.65e-05,
        "cache_read_input_token_cost": 3.3e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/anthropic/claude-4-opus": {
        "display_name": "Claude Opus 4",
        "model_vendor": "anthropic",
        "max_tokens": 200000,
        "max_input_tokens": 200000,
        "max_output_tokens": 200000,
        "input_cost_per_token": 1.65e-05,
        "output_cost_per_token": 8.25e-05,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/anthropic/claude-4-sonnet": {
        "display_name": "Claude Sonnet 4",
        "model_vendor": "anthropic",
        "max_tokens": 200000,
        "max_input_tokens": 200000,
        "max_output_tokens": 200000,
        "input_cost_per_token": 3.3e-06,
        "output_cost_per_token": 1.65e-05,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/deepseek-ai/DeepSeek-R1": {
        "display_name": "DeepSeek R1",
        "model_vendor": "deepseek",
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "input_cost_per_token": 7e-07,
        "output_cost_per_token": 2.4e-06,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-0528": {
        "display_name": "DeepSeek R1 0528",
        "model_vendor": "deepseek",
        "model_version": "0528",
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 2.15e-06,
        "cache_read_input_token_cost": 4e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-0528-Turbo": {
        "display_name": "DeepSeek R1 0528 Turbo",
        "model_vendor": "deepseek",
        "model_version": "0528",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 3e-06,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
        "display_name": "DeepSeek R1 Distill Llama 70B",
        "model_vendor": "deepseek",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 6e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": false
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": {
        "display_name": "DeepSeek R1 Distill Qwen 32B",
        "model_vendor": "deepseek",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2.7e-07,
        "output_cost_per_token": 2.7e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-Turbo": {
        "display_name": "DeepSeek R1 Turbo",
        "model_vendor": "deepseek",
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960,
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 3e-06,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/deepseek-ai/DeepSeek-V3": {
        "display_name": "DeepSeek V3",
        "model_vendor": "deepseek",
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "input_cost_per_token": 3.8e-07,
        "output_cost_per_token": 8.9e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/deepseek-ai/DeepSeek-V3-0324": {
        "display_name": "DeepSeek V3 0324",
        "model_vendor": "deepseek",
        "model_version": "0324",
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 8.8e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/deepseek-ai/DeepSeek-V3.1": {
        "display_name": "DeepSeek V3.1",
        "model_vendor": "deepseek",
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "input_cost_per_token": 2.7e-07,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": 2.16e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true,
        "supports_reasoning": true
    },
    "deepinfra/deepseek-ai/DeepSeek-V3.1-Terminus": {
        "display_name": "DeepSeek V3.1 Terminus",
        "model_vendor": "deepseek",
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "input_cost_per_token": 2.7e-07,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": 2.16e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/google/gemini-2.0-flash-001": {
        "display_name": "Gemini 2.0 Flash",
        "model_vendor": "google",
        "max_tokens": 1000000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 1000000,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/google/gemini-2.5-flash": {
        "display_name": "Gemini 2.5 Flash",
        "model_vendor": "google",
        "max_tokens": 1000000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 1000000,
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.5e-06,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/google/gemini-2.5-pro": {
        "display_name": "Gemini 2.5 Pro",
        "model_vendor": "google",
        "max_tokens": 1000000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 1000000,
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/google/gemma-3-12b-it": {
        "display_name": "Gemma 3 12B IT",
        "model_vendor": "google",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/google/gemma-3-27b-it": {
        "display_name": "Gemma 3 27B IT",
        "model_vendor": "google",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 9e-08,
        "output_cost_per_token": 1.6e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/google/gemma-3-4b-it": {
        "display_name": "Gemma 3 4B IT",
        "model_vendor": "google",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 8e-08,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/meta-llama/Llama-3.2-11B-Vision-Instruct": {
        "display_name": "Llama 3.2 11B Vision Instruct",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 4.9e-08,
        "output_cost_per_token": 4.9e-08,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": false
    },
    "deepinfra/meta-llama/Llama-3.2-3B-Instruct": {
        "display_name": "Llama 3.2 3B Instruct",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-08,
        "output_cost_per_token": 2e-08,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/meta-llama/Llama-3.3-70B-Instruct": {
        "display_name": "Llama 3.3 70B Instruct",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2.3e-07,
        "output_cost_per_token": 4e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/meta-llama/Llama-3.3-70B-Instruct-Turbo": {
        "display_name": "Llama 3.3 70B Instruct Turbo",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 1.3e-07,
        "output_cost_per_token": 3.9e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
        "display_name": "Llama 4 Maverick 17B 128E Instruct",
        "model_vendor": "meta",
        "max_tokens": 1048576,
        "max_input_tokens": 1048576,
        "max_output_tokens": 1048576,
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
        "display_name": "Llama 4 Scout 17B 16E Instruct",
        "model_vendor": "meta",
        "max_tokens": 327680,
        "max_input_tokens": 327680,
        "max_output_tokens": 327680,
        "input_cost_per_token": 8e-08,
        "output_cost_per_token": 3e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/meta-llama/Llama-Guard-3-8B": {
        "display_name": "Llama Guard 3 8B",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 5.5e-08,
        "output_cost_per_token": 5.5e-08,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": false
    },
    "deepinfra/meta-llama/Llama-Guard-4-12B": {
        "display_name": "Llama Guard 4 12B",
        "model_vendor": "meta",
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "input_cost_per_token": 1.8e-07,
        "output_cost_per_token": 1.8e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": false
    },
    "deepinfra/meta-llama/Meta-Llama-3-8B-Instruct": {
        "display_name": "Meta Llama 3 8B Instruct",
        "model_vendor": "meta",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-08,
        "output_cost_per_token": 6e-08,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct": {
        "display_name": "Meta Llama 3.1 70B Instruct",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 4e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
        "display_name": "Meta Llama 3.1 70B Instruct Turbo",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 2.8e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct": {
        "display_name": "Meta Llama 3.1 8B Instruct",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 3e-08,
        "output_cost_per_token": 5e-08,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
        "display_name": "Meta Llama 3.1 8B Instruct Turbo",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-08,
        "output_cost_per_token": 3e-08,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/microsoft/WizardLM-2-8x22B": {
        "display_name": "WizardLM 2 8x22B",
        "model_vendor": "microsoft",
        "max_tokens": 65536,
        "max_input_tokens": 65536,
        "max_output_tokens": 65536,
        "input_cost_per_token": 4.8e-07,
        "output_cost_per_token": 4.8e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": false
    },
    "deepinfra/microsoft/phi-4": {
        "display_name": "Phi 4",
        "model_vendor": "microsoft",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 7e-08,
        "output_cost_per_token": 1.4e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/mistralai/Mistral-Nemo-Instruct-2407": {
        "display_name": "Mistral Nemo Instruct",
        "model_vendor": "mistral",
        "model_version": "2407",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-08,
        "output_cost_per_token": 4e-08,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/mistralai/Mistral-Small-24B-Instruct-2501": {
        "display_name": "Mistral Small 24B Instruct",
        "model_vendor": "mistral",
        "model_version": "2501",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 8e-08,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/mistralai/Mistral-Small-3.2-24B-Instruct-2506": {
        "display_name": "Mistral Small 3.2 24B Instruct",
        "model_vendor": "mistral",
        "model_version": "2506",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 7.5e-08,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1": {
        "display_name": "Mixtral 8x7B Instruct v0.1",
        "model_vendor": "mistral",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 4e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/moonshotai/Kimi-K2-Instruct": {
        "display_name": "Kimi K2 Instruct",
        "model_vendor": "moonshot",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 2e-06,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/moonshotai/Kimi-K2-Instruct-0905": {
        "display_name": "Kimi K2 Instruct 0905",
        "model_vendor": "moonshot",
        "model_version": "0905",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": 4e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/nvidia/Llama-3.1-Nemotron-70B-Instruct": {
        "display_name": "Llama 3.1 Nemotron 70B Instruct",
        "model_vendor": "nvidia",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 6e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/nvidia/Llama-3.3-Nemotron-Super-49B-v1.5": {
        "display_name": "Llama 3.3 Nemotron Super 49B v1.5",
        "model_vendor": "nvidia",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/nvidia/NVIDIA-Nemotron-Nano-9B-v2": {
        "display_name": "NVIDIA Nemotron Nano 9B v2",
        "model_vendor": "nvidia",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 1.6e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/openai/gpt-oss-120b": {
        "display_name": "GPT-OSS 120B",
        "model_vendor": "openai",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 4.5e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/openai/gpt-oss-20b": {
        "display_name": "GPT-OSS 20B",
        "model_vendor": "openai",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 1.5e-07,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepinfra/zai-org/GLM-4.5": {
        "display_name": "GLM 4.5",
        "model_vendor": "zhipu",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 1.6e-06,
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "deepseek/deepseek-chat": {
        "display_name": "DeepSeek Chat",
        "model_vendor": "deepseek",
        "cache_creation_input_token_cost": 0.0,
        "cache_read_input_token_cost": 7e-08,
        "input_cost_per_token": 2.7e-07,
        "input_cost_per_token_cache_hit": 7e-08,
        "litellm_provider": "deepseek",
        "max_input_tokens": 65536,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.1e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "deepseek/deepseek-coder": {
        "display_name": "DeepSeek Coder",
        "model_vendor": "deepseek",
        "input_cost_per_token": 1.4e-07,
        "input_cost_per_token_cache_hit": 1.4e-08,
        "litellm_provider": "deepseek",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 2.8e-07,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "deepseek/deepseek-r1": {
        "display_name": "DeepSeek R1",
        "model_vendor": "deepseek",
        "input_cost_per_token": 5.5e-07,
        "input_cost_per_token_cache_hit": 1.4e-07,
        "litellm_provider": "deepseek",
        "max_input_tokens": 65536,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2.19e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "deepseek/deepseek-reasoner": {
        "display_name": "DeepSeek Reasoner",
        "model_vendor": "deepseek",
        "input_cost_per_token": 5.5e-07,
        "input_cost_per_token_cache_hit": 1.4e-07,
        "litellm_provider": "deepseek",
        "max_input_tokens": 65536,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2.19e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "deepseek/deepseek-v3": {
        "display_name": "DeepSeek V3",
        "model_vendor": "deepseek",
        "cache_creation_input_token_cost": 0.0,
        "cache_read_input_token_cost": 7e-08,
        "input_cost_per_token": 2.7e-07,
        "input_cost_per_token_cache_hit": 7e-08,
        "litellm_provider": "deepseek",
        "max_input_tokens": 65536,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.1e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "deepseek/deepseek-v3.2": {
        "display_name": "DeepSeek V3.2",
        "model_vendor": "deepseek",
        "model_version": "v3.2",
        "input_cost_per_token": 2.8e-07,
        "input_cost_per_token_cache_hit": 2.8e-08,
        "litellm_provider": "deepseek",
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "deepseek.v3-v1:0": {
        "display_name": "DeepSeek V3",
        "model_vendor": "deepseek",
        "input_cost_per_token": 5.8e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 163840,
        "max_output_tokens": 81920,
        "max_tokens": 163840,
        "mode": "chat",
        "output_cost_per_token": 1.68e-06,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "dolphin": {
        "display_name": "Dolphin",
        "model_vendor": "nlp_cloud",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "nlp_cloud",
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "completion",
        "output_cost_per_token": 5e-07
    },
    "doubao-embedding": {
        "display_name": "Doubao Embedding",
        "model_vendor": "volcengine",
        "input_cost_per_token": 0.0,
        "litellm_provider": "volcengine",
        "max_input_tokens": 4096,
        "max_tokens": 4096,
        "metadata": {
            "notes": "Volcengine Doubao embedding model - standard version with 2560 dimensions"
        },
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "output_vector_size": 2560
    },
    "doubao-embedding-large": {
        "display_name": "Doubao Embedding Large",
        "model_vendor": "volcengine",
        "input_cost_per_token": 0.0,
        "litellm_provider": "volcengine",
        "max_input_tokens": 4096,
        "max_tokens": 4096,
        "metadata": {
            "notes": "Volcengine Doubao embedding model - large version with 2048 dimensions"
        },
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "output_vector_size": 2048
    },
    "doubao-embedding-large-text-240915": {
        "display_name": "Doubao Embedding Large Text 240915",
        "model_vendor": "volcengine",
        "model_version": "240915",
        "input_cost_per_token": 0.0,
        "litellm_provider": "volcengine",
        "max_input_tokens": 4096,
        "max_tokens": 4096,
        "metadata": {
            "notes": "Volcengine Doubao embedding model - text-240915 version with 4096 dimensions"
        },
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "output_vector_size": 4096
    },
    "doubao-embedding-large-text-250515": {
        "display_name": "Doubao Embedding Large Text 250515",
        "model_vendor": "volcengine",
        "model_version": "250515",
        "input_cost_per_token": 0.0,
        "litellm_provider": "volcengine",
        "max_input_tokens": 4096,
        "max_tokens": 4096,
        "metadata": {
            "notes": "Volcengine Doubao embedding model - text-250515 version with 2048 dimensions"
        },
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "output_vector_size": 2048
    },
    "doubao-embedding-text-240715": {
        "display_name": "Doubao Embedding Text 240715",
        "model_vendor": "volcengine",
        "model_version": "240715",
        "input_cost_per_token": 0.0,
        "litellm_provider": "volcengine",
        "max_input_tokens": 4096,
        "max_tokens": 4096,
        "metadata": {
            "notes": "Volcengine Doubao embedding model - text-240715 version with 2560 dimensions"
        },
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "output_vector_size": 2560
    },
    "exa_ai/search": {
        "display_name": "Exa AI Search",
        "model_vendor": "exa_ai",
        "litellm_provider": "exa_ai",
        "mode": "search",
        "tiered_pricing": [
            {
                "input_cost_per_query": 0.005,
                "max_results_range": [
                    0,
                    25
                ]
            },
            {
                "input_cost_per_query": 0.025,
                "max_results_range": [
                    26,
                    100
                ]
            }
        ]
    },
    "firecrawl/search": {
        "display_name": "Firecrawl Search",
        "model_vendor": "firecrawl",
        "litellm_provider": "firecrawl",
        "mode": "search",
        "tiered_pricing": [
            {
                "input_cost_per_query": 0.00166,
                "max_results_range": [
                    1,
                    10
                ]
            },
            {
                "input_cost_per_query": 0.00332,
                "max_results_range": [
                    11,
                    20
                ]
            },
            {
                "input_cost_per_query": 0.00498,
                "max_results_range": [
                    21,
                    30
                ]
            },
            {
                "input_cost_per_query": 0.00664,
                "max_results_range": [
                    31,
                    40
                ]
            },
            {
                "input_cost_per_query": 0.0083,
                "max_results_range": [
                    41,
                    50
                ]
            },
            {
                "input_cost_per_query": 0.00996,
                "max_results_range": [
                    51,
                    60
                ]
            },
            {
                "input_cost_per_query": 0.01162,
                "max_results_range": [
                    61,
                    70
                ]
            },
            {
                "input_cost_per_query": 0.01328,
                "max_results_range": [
                    71,
                    80
                ]
            },
            {
                "input_cost_per_query": 0.01494,
                "max_results_range": [
                    81,
                    90
                ]
            },
            {
                "input_cost_per_query": 0.0166,
                "max_results_range": [
                    91,
                    100
                ]
            }
        ],
        "metadata": {
            "notes": "Firecrawl search pricing: $83 for 100,000 credits, 2 credits per 10 results. Cost = ceiling(limit/10) * 2 * $0.00083"
        }
    },
    "perplexity/search": {
        "display_name": "Perplexity Search",
        "model_vendor": "perplexity",
        "input_cost_per_query": 0.005,
        "litellm_provider": "perplexity",
        "mode": "search"
    },
    "searxng/search": {
        "display_name": "SearXNG Search",
        "model_vendor": "searxng",
        "litellm_provider": "searxng",
        "mode": "search",
        "input_cost_per_query": 0.0,
        "metadata": {
            "notes": "SearXNG is an open-source metasearch engine. Free to use when self-hosted or using public instances."
        }
    },
    "elevenlabs/scribe_v1": {
        "display_name": "ElevenLabs Scribe v1",
        "model_vendor": "elevenlabs",
        "input_cost_per_second": 6.11e-05,
        "litellm_provider": "elevenlabs",
        "metadata": {
            "calculation": "$0.22/hour = $0.00366/minute = $0.0000611 per second (enterprise pricing)",
            "notes": "ElevenLabs Scribe v1 - state-of-the-art speech recognition model with 99 language support",
            "original_pricing_per_hour": 0.22
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://elevenlabs.io/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "elevenlabs/scribe_v1_experimental": {
        "display_name": "ElevenLabs Scribe v1 Experimental",
        "model_vendor": "elevenlabs",
        "input_cost_per_second": 6.11e-05,
        "litellm_provider": "elevenlabs",
        "metadata": {
            "calculation": "$0.22/hour = $0.00366/minute = $0.0000611 per second (enterprise pricing)",
            "notes": "ElevenLabs Scribe v1 experimental - enhanced version of the main Scribe model",
            "original_pricing_per_hour": 0.22
        },
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0,
        "source": "https://elevenlabs.io/pricing",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "embed-english-light-v2.0": {
        "display_name": "Embed English Light v2.0",
        "model_vendor": "cohere",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "cohere",
        "max_input_tokens": 1024,
        "max_tokens": 1024,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "embed-english-light-v3.0": {
        "display_name": "Embed English Light v3.0",
        "model_vendor": "cohere",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "cohere",
        "max_input_tokens": 1024,
        "max_tokens": 1024,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "embed-english-v2.0": {
        "display_name": "Embed English v2.0",
        "model_vendor": "cohere",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "cohere",
        "max_input_tokens": 4096,
        "max_tokens": 4096,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "embed-english-v3.0": {
        "display_name": "Embed English v3.0",
        "model_vendor": "cohere",
        "input_cost_per_image": 0.0001,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "cohere",
        "max_input_tokens": 1024,
        "max_tokens": 1024,
        "metadata": {
            "notes": "'supports_image_input' is a deprecated field. Use 'supports_embedding_image_input' instead."
        },
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "supports_embedding_image_input": true,
        "supports_image_input": true
    },
    "embed-multilingual-v2.0": {
        "display_name": "Embed Multilingual v2.0",
        "model_vendor": "cohere",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "cohere",
        "max_input_tokens": 768,
        "max_tokens": 768,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "embed-multilingual-v3.0": {
        "display_name": "Embed Multilingual v3.0",
        "model_vendor": "cohere",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "cohere",
        "max_input_tokens": 1024,
        "max_tokens": 1024,
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "supports_embedding_image_input": true
    },
    "embed-multilingual-light-v3.0": {
        "display_name": "Embed Multilingual Light v3.0",
        "model_vendor": "cohere",
        "input_cost_per_token": 0.0001,
        "litellm_provider": "cohere",
        "max_input_tokens": 1024,
        "max_tokens": 1024,
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "supports_embedding_image_input": true
    },
    "eu.amazon.nova-lite-v1:0": {
        "display_name": "Amazon Nova Lite",
        "model_vendor": "amazon",
        "input_cost_per_token": 7.8e-08,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 300000,
        "max_output_tokens": 10000,
        "max_tokens": 10000,
        "mode": "chat",
        "output_cost_per_token": 3.12e-07,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "eu.amazon.nova-micro-v1:0": {
        "display_name": "Amazon Nova Micro",
        "model_vendor": "amazon",
        "input_cost_per_token": 4.6e-08,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 10000,
        "max_tokens": 10000,
        "mode": "chat",
        "output_cost_per_token": 1.84e-07,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true
    },
    "eu.amazon.nova-pro-v1:0": {
        "display_name": "Amazon Nova Pro",
        "model_vendor": "amazon",
        "input_cost_per_token": 1.05e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 300000,
        "max_output_tokens": 10000,
        "max_tokens": 10000,
        "mode": "chat",
        "output_cost_per_token": 4.2e-06,
        "source": "https://aws.amazon.com/bedrock/pricing/",
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "eu.anthropic.claude-3-5-haiku-20241022-v1:0": {
        "display_name": "Claude 3.5 Haiku",
        "model_vendor": "anthropic",
        "model_version": "20241022",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.25e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "eu.anthropic.claude-haiku-4-5-20251001-v1:0": {
        "display_name": "Claude Haiku 4.5",
        "model_vendor": "anthropic",
        "model_version": "20251001",
        "cache_creation_input_token_cost": 1.375e-06,
        "cache_read_input_token_cost": 1.1e-07,
        "input_cost_per_token": 1.1e-06,
        "deprecation_date": "2026-10-15",
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 5.5e-06,
        "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 346
    },
    "eu.anthropic.claude-3-5-sonnet-20240620-v1:0": {
        "display_name": "Claude 3.5 Sonnet",
        "model_vendor": "anthropic",
        "model_version": "20240620",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "eu.anthropic.claude-3-5-sonnet-20241022-v2:0": {
        "display_name": "Claude 3.5 Sonnet v2",
        "model_vendor": "anthropic",
        "model_version": "20241022",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "eu.anthropic.claude-3-7-sonnet-20250219-v1:0": {
        "display_name": "Claude 3.7 Sonnet",
        "model_vendor": "anthropic",
        "model_version": "20250219",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "eu.anthropic.claude-3-haiku-20240307-v1:0": {
        "display_name": "Claude 3 Haiku",
        "model_vendor": "anthropic",
        "model_version": "20240307",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.25e-06,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "eu.anthropic.claude-3-opus-20240229-v1:0": {
        "display_name": "Claude 3 Opus",
        "model_vendor": "anthropic",
        "model_version": "20240229",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "eu.anthropic.claude-3-sonnet-20240229-v1:0": {
        "display_name": "Claude 3 Sonnet",
        "model_vendor": "anthropic",
        "model_version": "20240229",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "eu.anthropic.claude-opus-4-1-20250805-v1:0": {
        "display_name": "Claude Opus 4.1",
        "model_vendor": "anthropic",
        "model_version": "20250805",
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "eu.anthropic.claude-opus-4-20250514-v1:0": {
        "display_name": "Claude Opus 4",
        "model_vendor": "anthropic",
        "model_version": "20250514",
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "eu.anthropic.claude-sonnet-4-20250514-v1:0": {
        "display_name": "Claude Sonnet 4",
        "model_vendor": "anthropic",
        "model_version": "20250514",
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "eu.anthropic.claude-sonnet-4-5-20250929-v1:0": {
        "display_name": "Claude Sonnet 4.5",
        "model_vendor": "anthropic",
        "model_version": "20250929",
        "cache_creation_input_token_cost": 4.125e-06,
        "cache_read_input_token_cost": 3.3e-07,
        "input_cost_per_token": 3.3e-06,
        "input_cost_per_token_above_200k_tokens": 6.6e-06,
        "output_cost_per_token_above_200k_tokens": 2.475e-05,
        "cache_creation_input_token_cost_above_200k_tokens": 8.25e-06,
        "cache_read_input_token_cost_above_200k_tokens": 6.6e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 1.65e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 346
    },
    "eu.meta.llama3-2-1b-instruct-v1:0": {
        "display_name": "Llama 3.2 1B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1.3e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.3e-07,
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "eu.meta.llama3-2-3b-instruct-v1:0": {
        "display_name": "Llama 3.2 3B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1.9e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.9e-07,
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "eu.mistral.pixtral-large-2502-v1:0": {
        "display_name": "Pixtral Large",
        "model_vendor": "mistral",
        "model_version": "2502",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "fal_ai/bria/text-to-image/3.2": {
        "display_name": "Bria Text-to-Image 3.2",
        "model_vendor": "bria",
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "output_cost_per_image": 0.0398,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "fal_ai/fal-ai/flux-pro/v1.1": {
        "display_name": "Flux Pro v1.1",
        "model_vendor": "fal_ai",
        "model_version": "1.1",
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "output_cost_per_image": 0.04,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "fal_ai/fal-ai/flux-pro/v1.1-ultra": {
        "display_name": "Flux Pro v1.1 Ultra",
        "model_vendor": "fal_ai",
        "model_version": "1.1-ultra",
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "output_cost_per_image": 0.06,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "fal_ai/fal-ai/flux/schnell": {
        "display_name": "Flux Schnell",
        "model_vendor": "black_forest_labs",
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "output_cost_per_image": 0.003,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "fal_ai/fal-ai/bytedance/seedream/v3/text-to-image": {
        "display_name": "SeedReam v3",
        "model_vendor": "bytedance",
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "output_cost_per_image": 0.03,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "fal_ai/fal-ai/bytedance/dreamina/v3.1/text-to-image": {
        "display_name": "Dreamina v3.1",
        "model_vendor": "bytedance",
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "output_cost_per_image": 0.03,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "fal_ai/fal-ai/ideogram/v3": {
        "display_name": "Ideogram v3",
        "model_vendor": "ideogram",
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "output_cost_per_image": 0.06,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "fal_ai/fal-ai/imagen4/preview": {
        "display_name": "Imagen 4 Preview",
        "model_vendor": "google",
        "model_version": "4-preview",
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "output_cost_per_image": 0.0398,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "fal_ai/fal-ai/imagen4/preview/fast": {
        "display_name": "Imagen 4 Preview Fast",
        "model_vendor": "google",
        "model_version": "4-preview-fast",
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "output_cost_per_image": 0.02,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "fal_ai/fal-ai/imagen4/preview/ultra": {
        "display_name": "Imagen 4 Preview Ultra",
        "model_vendor": "google",
        "model_version": "4-preview-ultra",
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "output_cost_per_image": 0.06,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "fal_ai/fal-ai/recraft/v3/text-to-image": {
        "display_name": "Recraft v3",
        "model_vendor": "recraft",
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "output_cost_per_image": 0.0398,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "fal_ai/fal-ai/stable-diffusion-v35-medium": {
        "display_name": "Stable Diffusion v3.5 Medium",
        "model_vendor": "stability_ai",
        "model_version": "3.5-medium",
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "output_cost_per_image": 0.0398,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "featherless_ai/featherless-ai/Qwerky-72B": {
        "display_name": "Qwerky 72B",
        "model_vendor": "featherless_ai",
        "litellm_provider": "featherless_ai",
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "max_tokens": 32768,
        "mode": "chat"
    },
    "featherless_ai/featherless-ai/Qwerky-QwQ-32B": {
        "display_name": "Qwerky QwQ 32B",
        "model_vendor": "featherless_ai",
        "litellm_provider": "featherless_ai",
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "max_tokens": 32768,
        "mode": "chat"
    },
    "fireworks-ai-4.1b-to-16b": {
        "display_name": "Fireworks AI 4.1B-16B Tier",
        "model_vendor": "fireworks_ai",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "output_cost_per_token": 2e-07
    },
    "fireworks-ai-56b-to-176b": {
        "display_name": "Fireworks AI 56B-176B Tier",
        "model_vendor": "fireworks_ai",
        "input_cost_per_token": 1.2e-06,
        "litellm_provider": "fireworks_ai",
        "output_cost_per_token": 1.2e-06
    },
    "fireworks-ai-above-16b": {
        "display_name": "Fireworks AI Above 16B Tier",
        "model_vendor": "fireworks_ai",
        "input_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "output_cost_per_token": 9e-07
    },
    "fireworks-ai-default": {
        "display_name": "Fireworks AI Default Tier",
        "model_vendor": "fireworks_ai",
        "input_cost_per_token": 0.0,
        "litellm_provider": "fireworks_ai",
        "output_cost_per_token": 0.0
    },
    "fireworks-ai-embedding-150m-to-350m": {
        "display_name": "Fireworks AI Embedding 150M-350M Tier",
        "model_vendor": "fireworks_ai",
        "input_cost_per_token": 1.6e-08,
        "litellm_provider": "fireworks_ai-embedding-models",
        "output_cost_per_token": 0.0
    },
    "fireworks-ai-embedding-up-to-150m": {
        "display_name": "Fireworks AI Embedding Up to 150M Tier",
        "model_vendor": "fireworks_ai",
        "input_cost_per_token": 8e-09,
        "litellm_provider": "fireworks_ai-embedding-models",
        "output_cost_per_token": 0.0
    },
    "fireworks-ai-moe-up-to-56b": {
        "display_name": "Fireworks AI MoE Up to 56B Tier",
        "model_vendor": "fireworks_ai",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "fireworks_ai",
        "output_cost_per_token": 5e-07
    },
    "fireworks-ai-up-to-4b": {
        "display_name": "Fireworks AI Up to 4B Tier",
        "model_vendor": "fireworks_ai",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "output_cost_per_token": 2e-07
    },
    "fireworks_ai/WhereIsAI/UAE-Large-V1": {
        "display_name": "UAE Large V1",
        "model_vendor": "whereisai",
        "input_cost_per_token": 1.6e-08,
        "litellm_provider": "fireworks_ai-embedding-models",
        "max_input_tokens": 512,
        "max_tokens": 512,
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "source": "https://fireworks.ai/pricing"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct": {
        "display_name": "DeepSeek Coder V2 Instruct",
        "model_vendor": "deepseek",
        "input_cost_per_token": 1.2e-06,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 65536,
        "max_output_tokens": 65536,
        "max_tokens": 65536,
        "mode": "chat",
        "output_cost_per_token": 1.2e-06,
        "source": "https://fireworks.ai/pricing",
        "supports_function_calling": false,
        "supports_response_schema": true,
        "supports_tool_choice": false
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1": {
        "display_name": "DeepSeek R1",
        "model_vendor": "deepseek",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 20480,
        "max_tokens": 20480,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "source": "https://fireworks.ai/pricing",
        "supports_response_schema": true,
        "supports_tool_choice": false
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-0528": {
        "display_name": "DeepSeek R1 0528",
        "model_vendor": "deepseek",
        "model_version": "0528",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 160000,
        "max_output_tokens": 160000,
        "max_tokens": 160000,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "source": "https://fireworks.ai/pricing",
        "supports_response_schema": true,
        "supports_tool_choice": false
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-basic": {
        "display_name": "DeepSeek R1 Basic",
        "model_vendor": "deepseek",
        "input_cost_per_token": 5.5e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 20480,
        "max_tokens": 20480,
        "mode": "chat",
        "output_cost_per_token": 2.19e-06,
        "source": "https://fireworks.ai/pricing",
        "supports_response_schema": true,
        "supports_tool_choice": false
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3": {
        "display_name": "DeepSeek V3",
        "model_vendor": "deepseek",
        "input_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 9e-07,
        "source": "https://fireworks.ai/pricing",
        "supports_response_schema": true,
        "supports_tool_choice": false
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3-0324": {
        "display_name": "DeepSeek V3 0324",
        "model_vendor": "deepseek",
        "model_version": "0324",
        "input_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "max_tokens": 163840,
        "mode": "chat",
        "output_cost_per_token": 9e-07,
        "source": "https://fireworks.ai/models/fireworks/deepseek-v3-0324",
        "supports_response_schema": true,
        "supports_tool_choice": false
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3p1": {
        "display_name": "DeepSeek V3 Plus",
        "model_vendor": "deepseek",
        "input_cost_per_token": 5.6e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.68e-06,
        "source": "https://fireworks.ai/pricing",
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3p1-terminus": {
        "display_name": "DeepSeek V3 Plus Terminus",
        "model_vendor": "deepseek",
        "input_cost_per_token": 5.6e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.68e-06,
        "source": "https://fireworks.ai/pricing",
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3p2": {
        "display_name": "DeepSeek V3p2",
        "model_vendor": "deepseek",
        "input_cost_per_token": 1.2e-06,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "max_tokens": 163840,
        "mode": "chat",
        "output_cost_per_token": 1.2e-06,
        "source": "https://fireworks.ai/models/fireworks/deepseek-v3p2",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "fireworks_ai/accounts/fireworks/models/firefunction-v2": {
        "display_name": "FireFunction V2",
        "model_vendor": "fireworks_ai",
        "input_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 9e-07,
        "source": "https://fireworks.ai/pricing",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "fireworks_ai/accounts/fireworks/models/glm-4p5": {
        "display_name": "GLM-4 Plus",
        "model_vendor": "zhipu",
        "input_cost_per_token": 5.5e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 96000,
        "max_tokens": 96000,
        "mode": "chat",
        "output_cost_per_token": 2.19e-06,
        "source": "https://fireworks.ai/models/fireworks/glm-4p5",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "fireworks_ai/accounts/fireworks/models/glm-4p5-air": {
        "display_name": "GLM-4 Plus Air",
        "model_vendor": "zhipu",
        "model_version": "4.5-air",
        "input_cost_per_token": 2.2e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 96000,
        "max_tokens": 96000,
        "mode": "chat",
        "output_cost_per_token": 8.8e-07,
        "source": "https://artificialanalysis.ai/models/glm-4-5-air",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "fireworks_ai/accounts/fireworks/models/glm-4p6": {
        "display_name": "GLM-4.6",
        "model_vendor": "zhipu",
        "input_cost_per_token": 5.5e-07,
        "output_cost_per_token": 2.19e-06,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 202800,
        "max_output_tokens": 202800,
        "max_tokens": 202800,
        "mode": "chat",
        "source": "https://fireworks.ai/pricing",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "fireworks_ai/accounts/fireworks/models/gpt-oss-120b": {
        "display_name": "GPT-OSS 120B",
        "model_vendor": "openai",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "source": "https://fireworks.ai/pricing",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "fireworks_ai/accounts/fireworks/models/gpt-oss-20b": {
        "display_name": "GPT-OSS 20B",
        "model_vendor": "openai",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "source": "https://fireworks.ai/pricing",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "fireworks_ai/accounts/fireworks/models/kimi-k2-instruct": {
        "display_name": "Kimi K2 Instruct",
        "model_vendor": "moonshot",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 16384,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 2.5e-06,
        "source": "https://fireworks.ai/models/fireworks/kimi-k2-instruct",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "fireworks_ai/accounts/fireworks/models/kimi-k2-instruct-0905": {
        "display_name": "Kimi K2 Instruct 0905",
        "model_vendor": "moonshot",
        "model_version": "0905",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 262144,
        "max_output_tokens": 32768,
        "max_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 2.5e-06,
        "source": "https://app.fireworks.ai/models/fireworks/kimi-k2-instruct-0905",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "fireworks_ai/accounts/fireworks/models/kimi-k2-thinking": {
        "display_name": "Kimi K2 Thinking",
        "model_vendor": "moonshot",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "max_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 2.5e-06,
        "source": "https://fireworks.ai/pricing",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct": {
        "display_name": "Llama 3.1 405B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 3e-06,
        "source": "https://fireworks.ai/pricing",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct": {
        "display_name": "Llama 3.1 8B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-07,
        "source": "https://fireworks.ai/pricing",
        "supports_function_calling": false,
        "supports_response_schema": true,
        "supports_tool_choice": false
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct": {
        "display_name": "Llama 3.2 11B Vision Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "source": "https://fireworks.ai/pricing",
        "supports_function_calling": false,
        "supports_response_schema": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct": {
        "display_name": "Llama 3.2 1B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-07,
        "source": "https://fireworks.ai/pricing",
        "supports_function_calling": false,
        "supports_response_schema": true,
        "supports_tool_choice": false
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct": {
        "display_name": "Llama 3.2 3B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-07,
        "source": "https://fireworks.ai/pricing",
        "supports_function_calling": false,
        "supports_response_schema": true,
        "supports_tool_choice": false
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-90b-vision-instruct": {
        "display_name": "Llama 3.2 90B Vision Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 9e-07,
        "source": "https://fireworks.ai/pricing",
        "supports_response_schema": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "fireworks_ai/accounts/fireworks/models/llama4-maverick-instruct-basic": {
        "display_name": "Llama 4 Maverick Instruct Basic",
        "model_vendor": "meta",
        "input_cost_per_token": 2.2e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 8.8e-07,
        "source": "https://fireworks.ai/pricing",
        "supports_response_schema": true,
        "supports_tool_choice": false
    },
    "fireworks_ai/accounts/fireworks/models/llama4-scout-instruct-basic": {
        "display_name": "Llama 4 Scout Instruct Basic",
        "model_vendor": "meta",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "source": "https://fireworks.ai/pricing",
        "supports_response_schema": true,
        "supports_tool_choice": false
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf": {
        "display_name": "Mixtral 8x22B Instruct",
        "model_vendor": "mistral",
        "input_cost_per_token": 1.2e-06,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 65536,
        "max_output_tokens": 65536,
        "max_tokens": 65536,
        "mode": "chat",
        "output_cost_per_token": 1.2e-06,
        "source": "https://fireworks.ai/pricing",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct": {
        "display_name": "Qwen 2 72B Instruct",
        "model_vendor": "alibaba",
        "input_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 9e-07,
        "source": "https://fireworks.ai/pricing",
        "supports_function_calling": false,
        "supports_response_schema": true,
        "supports_tool_choice": false
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct": {
        "display_name": "Qwen 2.5 Coder 32B Instruct",
        "model_vendor": "alibaba",
        "input_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 9e-07,
        "source": "https://fireworks.ai/pricing",
        "supports_function_calling": false,
        "supports_response_schema": true,
        "supports_tool_choice": false
    },
    "fireworks_ai/accounts/fireworks/models/yi-large": {
        "display_name": "Yi Large",
        "model_vendor": "01_ai",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "fireworks_ai",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 3e-06,
        "source": "https://fireworks.ai/pricing",
        "supports_function_calling": false,
        "supports_response_schema": true,
        "supports_tool_choice": false
    },
    "fireworks_ai/nomic-ai/nomic-embed-text-v1": {
        "display_name": "Nomic Embed Text V1",
        "model_vendor": "nomic",
        "input_cost_per_token": 8e-09,
        "litellm_provider": "fireworks_ai-embedding-models",
        "max_input_tokens": 8192,
        "max_tokens": 8192,
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "source": "https://fireworks.ai/pricing"
    },
    "fireworks_ai/nomic-ai/nomic-embed-text-v1.5": {
        "display_name": "Nomic Embed Text V1.5",
        "model_vendor": "nomic",
        "input_cost_per_token": 8e-09,
        "litellm_provider": "fireworks_ai-embedding-models",
        "max_input_tokens": 8192,
        "max_tokens": 8192,
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "source": "https://fireworks.ai/pricing"
    },
    "fireworks_ai/thenlper/gte-base": {
        "display_name": "GTE Base",
        "model_vendor": "thenlper",
        "input_cost_per_token": 8e-09,
        "litellm_provider": "fireworks_ai-embedding-models",
        "max_input_tokens": 512,
        "max_tokens": 512,
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "source": "https://fireworks.ai/pricing"
    },
    "fireworks_ai/thenlper/gte-large": {
        "display_name": "GTE Large",
        "model_vendor": "thenlper",
        "input_cost_per_token": 1.6e-08,
        "litellm_provider": "fireworks_ai-embedding-models",
        "max_input_tokens": 512,
        "max_tokens": 512,
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "source": "https://fireworks.ai/pricing"
    },
    "friendliai/meta-llama-3.1-70b-instruct": {
        "display_name": "Llama 3.1 70B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "friendliai",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "friendliai/meta-llama-3.1-8b-instruct": {
        "display_name": "Llama 3.1 8B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "friendliai",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:babbage-002": {
        "display_name": "Babbage 002",
        "model_vendor": "openai",
        "model_version": "002",
        "input_cost_per_token": 1.6e-06,
        "input_cost_per_token_batches": 2e-07,
        "litellm_provider": "text-completion-openai",
        "max_input_tokens": 16384,
        "max_output_tokens": 4096,
        "max_tokens": 16384,
        "mode": "completion",
        "output_cost_per_token": 1.6e-06,
        "output_cost_per_token_batches": 2e-07
    },
    "ft:davinci-002": {
        "display_name": "Davinci 002",
        "model_vendor": "openai",
        "model_version": "002",
        "input_cost_per_token": 1.2e-05,
        "input_cost_per_token_batches": 1e-06,
        "litellm_provider": "text-completion-openai",
        "max_input_tokens": 16384,
        "max_output_tokens": 4096,
        "max_tokens": 16384,
        "mode": "completion",
        "output_cost_per_token": 1.2e-05,
        "output_cost_per_token_batches": 1e-06
    },
    "ft:gpt-3.5-turbo": {
        "display_name": "GPT-3.5 Turbo Fine-tuned",
        "model_vendor": "openai",
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_batches": 1.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "output_cost_per_token_batches": 3e-06,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:gpt-3.5-turbo-0125": {
        "display_name": "GPT-3.5 Turbo 0125 Fine-tuned",
        "model_vendor": "openai",
        "model_version": "0125",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:gpt-3.5-turbo-0613": {
        "display_name": "GPT-3.5 Turbo 0613 Fine-tuned",
        "model_vendor": "openai",
        "model_version": "0613",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:gpt-3.5-turbo-1106": {
        "display_name": "GPT-3.5 Turbo 1106 Fine-tuned",
        "model_vendor": "openai",
        "model_version": "1106",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:gpt-4-0613": {
        "display_name": "GPT-4 0613 Fine-tuned",
        "model_vendor": "openai",
        "model_version": "0613",
        "input_cost_per_token": 3e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "source": "OpenAI needs to add pricing for this ft model, will be updated when added by OpenAI. Defaulting to base model pricing",
        "supports_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:gpt-4o-2024-08-06": {
        "display_name": "GPT-4o Fine-tuned",
        "model_vendor": "openai",
        "model_version": "2024-08-06",
        "cache_read_input_token_cost": 1.875e-06,
        "input_cost_per_token": 3.75e-06,
        "input_cost_per_token_batches": 1.875e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "output_cost_per_token_batches": 7.5e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "ft:gpt-4o-2024-11-20": {
        "display_name": "GPT-4o Fine-tuned",
        "model_vendor": "openai",
        "model_version": "2024-11-20",
        "cache_creation_input_token_cost": 1.875e-06,
        "input_cost_per_token": 3.75e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:gpt-4o-mini-2024-07-18": {
        "display_name": "GPT-4o Mini Fine-tuned",
        "model_vendor": "openai",
        "model_version": "2024-07-18",
        "cache_read_input_token_cost": 1.5e-07,
        "input_cost_per_token": 3e-07,
        "input_cost_per_token_batches": 1.5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1.2e-06,
        "output_cost_per_token_batches": 6e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:gpt-4.1-2025-04-14": {
        "display_name": "GPT-4.1 Fine-tuned",
        "model_vendor": "openai",
        "model_version": "2025-04-14",
        "cache_read_input_token_cost": 7.5e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_batches": 1.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 1.2e-05,
        "output_cost_per_token_batches": 6e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:gpt-4.1-mini-2025-04-14": {
        "display_name": "GPT-4.1 Mini Fine-tuned",
        "model_vendor": "openai",
        "model_version": "2025-04-14",
        "cache_read_input_token_cost": 2e-07,
        "input_cost_per_token": 8e-07,
        "input_cost_per_token_batches": 4e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 3.2e-06,
        "output_cost_per_token_batches": 1.6e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:gpt-4.1-nano-2025-04-14": {
        "display_name": "GPT-4.1 Nano Fine-tuned",
        "model_vendor": "openai",
        "model_version": "2025-04-14",
        "cache_read_input_token_cost": 5e-08,
        "input_cost_per_token": 2e-07,
        "input_cost_per_token_batches": 1e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 8e-07,
        "output_cost_per_token_batches": 4e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:o4-mini-2025-04-16": {
        "display_name": "O4 Mini Fine-tuned",
        "model_vendor": "openai",
        "model_version": "2025-04-16",
        "cache_read_input_token_cost": 1e-06,
        "input_cost_per_token": 4e-06,
        "input_cost_per_token_batches": 2e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 1.6e-05,
        "output_cost_per_token_batches": 8e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "gemini-1.0-pro": {
        "display_name": "Gemini 1.0 Pro",
        "model_vendor": "google",
        "input_cost_per_character": 1.25e-07,
        "input_cost_per_image": 0.0025,
        "input_cost_per_token": 5e-07,
        "input_cost_per_video_per_second": 0.002,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 32760,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 3.75e-07,
        "output_cost_per_token": 1.5e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#google_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "gemini-1.0-pro-001": {
        "display_name": "Gemini 1.0 Pro 001",
        "model_vendor": "google",
        "model_version": "1.0-001",
        "deprecation_date": "2025-04-09",
        "input_cost_per_character": 1.25e-07,
        "input_cost_per_image": 0.0025,
        "input_cost_per_token": 5e-07,
        "input_cost_per_video_per_second": 0.002,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 32760,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 3.75e-07,
        "output_cost_per_token": 1.5e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "gemini-1.0-pro-002": {
        "display_name": "Gemini 1.0 Pro 002",
        "model_vendor": "google",
        "model_version": "1.0-002",
        "deprecation_date": "2025-04-09",
        "input_cost_per_character": 1.25e-07,
        "input_cost_per_image": 0.0025,
        "input_cost_per_token": 5e-07,
        "input_cost_per_video_per_second": 0.002,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 32760,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 3.75e-07,
        "output_cost_per_token": 1.5e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "gemini-1.0-pro-vision": {
        "display_name": "Gemini 1.0 Pro Vision",
        "model_vendor": "google",
        "input_cost_per_image": 0.0025,
        "input_cost_per_token": 5e-07,
        "litellm_provider": "vertex_ai-vision-models",
        "max_images_per_prompt": 16,
        "max_input_tokens": 16384,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "max_video_length": 2,
        "max_videos_per_prompt": 1,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini-1.0-pro-vision-001": {
        "display_name": "Gemini 1.0 Pro Vision 001",
        "model_vendor": "google",
        "model_version": "1.0-001",
        "deprecation_date": "2025-04-09",
        "input_cost_per_image": 0.0025,
        "input_cost_per_token": 5e-07,
        "litellm_provider": "vertex_ai-vision-models",
        "max_images_per_prompt": 16,
        "max_input_tokens": 16384,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "max_video_length": 2,
        "max_videos_per_prompt": 1,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini-1.0-ultra": {
        "display_name": "Gemini 1.0 Ultra",
        "model_vendor": "google",
        "model_version": "1.0-ultra",
        "input_cost_per_character": 1.25e-07,
        "input_cost_per_image": 0.0025,
        "input_cost_per_token": 5e-07,
        "input_cost_per_video_per_second": 0.002,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 8192,
        "max_output_tokens": 2048,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 3.75e-07,
        "output_cost_per_token": 1.5e-06,
        "source": "As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "gemini-1.0-ultra-001": {
        "display_name": "Gemini 1.0 Ultra 001",
        "model_vendor": "google",
        "model_version": "1.0-ultra-001",
        "input_cost_per_character": 1.25e-07,
        "input_cost_per_image": 0.0025,
        "input_cost_per_token": 5e-07,
        "input_cost_per_video_per_second": 0.002,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 8192,
        "max_output_tokens": 2048,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 3.75e-07,
        "output_cost_per_token": 1.5e-06,
        "source": "As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "gemini-1.5-flash": {
        "display_name": "Gemini 1.5 Flash",
        "model_vendor": "google",
        "model_version": "1.5-flash",
        "input_cost_per_audio_per_second": 2e-06,
        "input_cost_per_audio_per_second_above_128k_tokens": 4e-06,
        "input_cost_per_character": 1.875e-08,
        "input_cost_per_character_above_128k_tokens": 2.5e-07,
        "input_cost_per_image": 2e-05,
        "input_cost_per_image_above_128k_tokens": 4e-05,
        "input_cost_per_token": 7.5e-08,
        "input_cost_per_token_above_128k_tokens": 1e-06,
        "input_cost_per_video_per_second": 2e-05,
        "input_cost_per_video_per_second_above_128k_tokens": 4e-05,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_character": 7.5e-08,
        "output_cost_per_character_above_128k_tokens": 1.5e-07,
        "output_cost_per_token": 3e-07,
        "output_cost_per_token_above_128k_tokens": 6e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini-1.5-flash-001": {
        "display_name": "Gemini 1.5 Flash 001",
        "model_vendor": "google",
        "model_version": "1.5-flash-001",
        "deprecation_date": "2025-05-24",
        "input_cost_per_audio_per_second": 2e-06,
        "input_cost_per_audio_per_second_above_128k_tokens": 4e-06,
        "input_cost_per_character": 1.875e-08,
        "input_cost_per_character_above_128k_tokens": 2.5e-07,
        "input_cost_per_image": 2e-05,
        "input_cost_per_image_above_128k_tokens": 4e-05,
        "input_cost_per_token": 7.5e-08,
        "input_cost_per_token_above_128k_tokens": 1e-06,
        "input_cost_per_video_per_second": 2e-05,
        "input_cost_per_video_per_second_above_128k_tokens": 4e-05,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_character": 7.5e-08,
        "output_cost_per_character_above_128k_tokens": 1.5e-07,
        "output_cost_per_token": 3e-07,
        "output_cost_per_token_above_128k_tokens": 6e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini-1.5-flash-002": {
        "display_name": "Gemini 1.5 Flash 002",
        "model_vendor": "google",
        "model_version": "1.5-flash-002",
        "deprecation_date": "2025-09-24",
        "input_cost_per_audio_per_second": 2e-06,
        "input_cost_per_audio_per_second_above_128k_tokens": 4e-06,
        "input_cost_per_character": 1.875e-08,
        "input_cost_per_character_above_128k_tokens": 2.5e-07,
        "input_cost_per_image": 2e-05,
        "input_cost_per_image_above_128k_tokens": 4e-05,
        "input_cost_per_token": 7.5e-08,
        "input_cost_per_token_above_128k_tokens": 1e-06,
        "input_cost_per_video_per_second": 2e-05,
        "input_cost_per_video_per_second_above_128k_tokens": 4e-05,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_character": 7.5e-08,
        "output_cost_per_character_above_128k_tokens": 1.5e-07,
        "output_cost_per_token": 3e-07,
        "output_cost_per_token_above_128k_tokens": 6e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-flash",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini-1.5-flash-exp-0827": {
        "display_name": "Gemini 1.5 Flash Exp 0827",
        "model_vendor": "google",
        "model_version": "1.5-flash-exp-0827",
        "input_cost_per_audio_per_second": 2e-06,
        "input_cost_per_audio_per_second_above_128k_tokens": 4e-06,
        "input_cost_per_character": 1.875e-08,
        "input_cost_per_character_above_128k_tokens": 2.5e-07,
        "input_cost_per_image": 2e-05,
        "input_cost_per_image_above_128k_tokens": 4e-05,
        "input_cost_per_token": 4.688e-09,
        "input_cost_per_token_above_128k_tokens": 1e-06,
        "input_cost_per_video_per_second": 2e-05,
        "input_cost_per_video_per_second_above_128k_tokens": 4e-05,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_character": 1.875e-08,
        "output_cost_per_character_above_128k_tokens": 3.75e-08,
        "output_cost_per_token": 4.6875e-09,
        "output_cost_per_token_above_128k_tokens": 9.375e-09,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini-1.5-flash-preview-0514": {
        "display_name": "Gemini 1.5 Flash Preview 0514",
        "model_vendor": "google",
        "model_version": "1.5-flash-preview-0514",
        "input_cost_per_audio_per_second": 2e-06,
        "input_cost_per_audio_per_second_above_128k_tokens": 4e-06,
        "input_cost_per_character": 1.875e-08,
        "input_cost_per_character_above_128k_tokens": 2.5e-07,
        "input_cost_per_image": 2e-05,
        "input_cost_per_image_above_128k_tokens": 4e-05,
        "input_cost_per_token": 7.5e-08,
        "input_cost_per_token_above_128k_tokens": 1e-06,
        "input_cost_per_video_per_second": 2e-05,
        "input_cost_per_video_per_second_above_128k_tokens": 4e-05,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_character": 1.875e-08,
        "output_cost_per_character_above_128k_tokens": 3.75e-08,
        "output_cost_per_token": 4.6875e-09,
        "output_cost_per_token_above_128k_tokens": 9.375e-09,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini-1.5-pro": {
        "display_name": "Gemini 1.5 Pro",
        "model_vendor": "google",
        "model_version": "1.5-pro",
        "input_cost_per_audio_per_second": 3.125e-05,
        "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-05,
        "input_cost_per_character": 3.125e-07,
        "input_cost_per_character_above_128k_tokens": 6.25e-07,
        "input_cost_per_image": 0.00032875,
        "input_cost_per_image_above_128k_tokens": 0.0006575,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_128k_tokens": 2.5e-06,
        "input_cost_per_video_per_second": 0.00032875,
        "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 1.25e-06,
        "output_cost_per_character_above_128k_tokens": 2.5e-06,
        "output_cost_per_token": 5e-06,
        "output_cost_per_token_above_128k_tokens": 1e-05,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini-1.5-pro-001": {
        "display_name": "Gemini 1.5 Pro 001",
        "model_vendor": "google",
        "model_version": "1.5-pro-001",
        "deprecation_date": "2025-05-24",
        "input_cost_per_audio_per_second": 3.125e-05,
        "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-05,
        "input_cost_per_character": 3.125e-07,
        "input_cost_per_character_above_128k_tokens": 6.25e-07,
        "input_cost_per_image": 0.00032875,
        "input_cost_per_image_above_128k_tokens": 0.0006575,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_128k_tokens": 2.5e-06,
        "input_cost_per_video_per_second": 0.00032875,
        "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 1.25e-06,
        "output_cost_per_character_above_128k_tokens": 2.5e-06,
        "output_cost_per_token": 5e-06,
        "output_cost_per_token_above_128k_tokens": 1e-05,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini-1.5-pro-002": {
        "display_name": "Gemini 1.5 Pro 002",
        "model_vendor": "google",
        "model_version": "1.5-pro-002",
        "deprecation_date": "2025-09-24",
        "input_cost_per_audio_per_second": 3.125e-05,
        "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-05,
        "input_cost_per_character": 3.125e-07,
        "input_cost_per_character_above_128k_tokens": 6.25e-07,
        "input_cost_per_image": 0.00032875,
        "input_cost_per_image_above_128k_tokens": 0.0006575,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_128k_tokens": 2.5e-06,
        "input_cost_per_video_per_second": 0.00032875,
        "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 1.25e-06,
        "output_cost_per_character_above_128k_tokens": 2.5e-06,
        "output_cost_per_token": 5e-06,
        "output_cost_per_token_above_128k_tokens": 1e-05,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-pro",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini-1.5-pro-preview-0215": {
        "display_name": "Gemini 1.5 Pro Preview 0215",
        "model_vendor": "google",
        "model_version": "1.5-pro-preview-0215",
        "input_cost_per_audio_per_second": 3.125e-05,
        "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-05,
        "input_cost_per_character": 3.125e-07,
        "input_cost_per_character_above_128k_tokens": 6.25e-07,
        "input_cost_per_image": 0.00032875,
        "input_cost_per_image_above_128k_tokens": 0.0006575,
        "input_cost_per_token": 7.8125e-08,
        "input_cost_per_token_above_128k_tokens": 1.5625e-07,
        "input_cost_per_video_per_second": 0.00032875,
        "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 1.25e-06,
        "output_cost_per_character_above_128k_tokens": 2.5e-06,
        "output_cost_per_token": 3.125e-07,
        "output_cost_per_token_above_128k_tokens": 6.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gemini-1.5-pro-preview-0409": {
        "display_name": "Gemini 1.5 Pro Preview 0409",
        "model_vendor": "google",
        "model_version": "1.5-pro-preview-0409",
        "input_cost_per_audio_per_second": 3.125e-05,
        "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-05,
        "input_cost_per_character": 3.125e-07,
        "input_cost_per_character_above_128k_tokens": 6.25e-07,
        "input_cost_per_image": 0.00032875,
        "input_cost_per_image_above_128k_tokens": 0.0006575,
        "input_cost_per_token": 7.8125e-08,
        "input_cost_per_token_above_128k_tokens": 1.5625e-07,
        "input_cost_per_video_per_second": 0.00032875,
        "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 1.25e-06,
        "output_cost_per_character_above_128k_tokens": 2.5e-06,
        "output_cost_per_token": 3.125e-07,
        "output_cost_per_token_above_128k_tokens": 6.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "gemini-1.5-pro-preview-0514": {
        "display_name": "Gemini 1.5 Pro Preview 0514",
        "model_vendor": "google",
        "model_version": "1.5-pro-preview-0514",
        "input_cost_per_audio_per_second": 3.125e-05,
        "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-05,
        "input_cost_per_character": 3.125e-07,
        "input_cost_per_character_above_128k_tokens": 6.25e-07,
        "input_cost_per_image": 0.00032875,
        "input_cost_per_image_above_128k_tokens": 0.0006575,
        "input_cost_per_token": 7.8125e-08,
        "input_cost_per_token_above_128k_tokens": 1.5625e-07,
        "input_cost_per_video_per_second": 0.00032875,
        "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 1.25e-06,
        "output_cost_per_character_above_128k_tokens": 2.5e-06,
        "output_cost_per_token": 3.125e-07,
        "output_cost_per_token_above_128k_tokens": 6.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gemini-2.0-flash": {
        "display_name": "Gemini 2.0 Flash",
        "model_vendor": "google",
        "model_version": "2.0-flash",
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_audio_token": 7e-07,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "source": "https://ai.google.dev/pricing#2_0flash",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.0-flash-001": {
        "display_name": "Gemini 2.0 Flash 001",
        "model_vendor": "google",
        "model_version": "2.0-flash-001",
        "cache_read_input_token_cost": 3.75e-08,
        "deprecation_date": "2026-02-05",
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.0-flash-exp": {
        "display_name": "Gemini 2.0 Flash Experimental",
        "model_vendor": "google",
        "cache_read_input_token_cost": 3.75e-08,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "input_cost_per_character": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_token": 1.5e-07,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_character": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "output_cost_per_token": 6e-07,
        "output_cost_per_token_above_128k_tokens": 0,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.0-flash-lite": {
        "display_name": "Gemini 2.0 Flash Lite",
        "model_vendor": "google",
        "cache_read_input_token_cost": 1.875e-08,
        "input_cost_per_audio_token": 7.5e-08,
        "input_cost_per_token": 7.5e-08,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 50,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.0-flash-lite-001": {
        "display_name": "Gemini 2.0 Flash Lite 001",
        "model_vendor": "google",
        "model_version": "2.0-flash-lite-001",
        "cache_read_input_token_cost": 1.875e-08,
        "deprecation_date": "2026-02-25",
        "input_cost_per_audio_token": 7.5e-08,
        "input_cost_per_token": 7.5e-08,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 50,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.0-flash-live-preview-04-09": {
        "display_name": "Gemini 2.0 Flash Live Preview 04-09",
        "model_vendor": "google",
        "model_version": "2.0-flash-live-preview-04-09",
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_audio_token": 3e-06,
        "input_cost_per_image": 3e-06,
        "input_cost_per_token": 5e-07,
        "input_cost_per_video_per_second": 3e-06,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_audio_token": 1.2e-05,
        "output_cost_per_token": 2e-06,
        "rpm": 10,
        "source": "https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini#gemini-2-0-flash-live-preview-04-09",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 250000
    },
    "gemini-2.0-flash-preview-image-generation": {
        "display_name": "Gemini 2.0 Flash Preview Image Generation",
        "model_vendor": "google",
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_audio_token": 7e-07,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "source": "https://ai.google.dev/pricing#2_0flash",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.0-flash-thinking-exp": {
        "display_name": "Gemini 2.0 Flash Thinking Experimental",
        "model_vendor": "google",
        "cache_read_input_token_cost": 0.0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "input_cost_per_character": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_character": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.0-flash-thinking-exp-01-21": {
        "display_name": "Gemini 2.0 Flash Thinking Experimental 01-21",
        "model_vendor": "google",
        "model_version": "2.0-flash-thinking-exp-01-21",
        "cache_read_input_token_cost": 0.0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "input_cost_per_character": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65536,
        "max_pdf_size_mb": 30,
        "max_tokens": 65536,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_character": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_output": false,
        "supports_function_calling": false,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": false,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.0-pro-exp-02-05": {
        "display_name": "Gemini 2.0 Pro Experimental 02-05",
        "model_vendor": "google",
        "model_version": "2.0-pro-exp-02-05",
        "cache_read_input_token_cost": 3.125e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_video_input": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-flash": {
        "display_name": "Gemini 2.5 Flash",
        "model_vendor": "google",
        "cache_read_input_token_cost": 3e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 2.5e-06,
        "output_cost_per_token": 2.5e-06,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-flash-image": {
        "display_name": "Gemini 2.5 Flash Image",
        "model_vendor": "google",
        "cache_read_input_token_cost": 3e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "max_pdf_size_mb": 30,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "image_generation",
        "output_cost_per_image": 0.039,
        "output_cost_per_reasoning_token": 2.5e-06,
        "output_cost_per_token": 2.5e-06,
        "rpm": 100000,
        "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-flash-image",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": false,
        "tpm": 8000000
    },
    "gemini-2.5-flash-image-preview": {
        "display_name": "Gemini 2.5 Flash Image Preview",
        "model_vendor": "google",
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "image_generation",
        "output_cost_per_image": 0.039,
        "output_cost_per_reasoning_token": 3e-05,
        "output_cost_per_token": 3e-05,
        "rpm": 100000,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 8000000
    },
    "gemini-3-pro-image-preview": {
        "display_name": "Gemini 3 Pro Image Preview",
        "model_vendor": "google",
        "input_cost_per_image": 0.0011,
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_batches": 1e-06,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 65536,
        "max_output_tokens": 32768,
        "max_tokens": 65536,
        "mode": "image_generation",
        "output_cost_per_image": 0.134,
        "output_cost_per_image_token": 0.00012,
        "output_cost_per_token": 1.2e-05,
        "output_cost_per_token_batches": 6e-06,
        "source": "https://ai.google.dev/gemini-api/docs/pricing",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": false,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-flash-lite": {
        "display_name": "Gemini 2.5 Flash Lite",
        "model_vendor": "google",
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_audio_token": 5e-07,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 4e-07,
        "output_cost_per_token": 4e-07,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-flash-lite-preview-09-2025": {
        "display_name": "Gemini 2.5 Flash Lite Preview 09-2025",
        "model_vendor": "google",
        "model_version": "2.5-flash-lite-preview-09-2025",
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_audio_token": 3e-07,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 4e-07,
        "output_cost_per_token": 4e-07,
        "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-flash-preview-09-2025": {
        "display_name": "Gemini 2.5 Flash Preview 09-2025",
        "model_vendor": "google",
        "model_version": "2.5-flash-preview-09-2025",
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 2.5e-06,
        "output_cost_per_token": 2.5e-06,
        "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-live-2.5-flash-preview-native-audio-09-2025": {
        "display_name": "Gemini Live 2.5 Flash Preview Native Audio 09-2025",
        "model_vendor": "google",
        "model_version": "live-2.5-flash-preview-native-audio-09-2025",
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_audio_token": 3e-06,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_audio_token": 1.2e-05,
        "output_cost_per_token": 2e-06,
        "source": "https://ai.google.dev/gemini-api/docs/pricing",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini/gemini-live-2.5-flash-preview-native-audio-09-2025": {
        "display_name": "Gemini Live 2.5 Flash Preview Native Audio 09-2025",
        "model_vendor": "google",
        "model_version": "live-2.5-flash-preview-native-audio-09-2025",
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_audio_token": 3e-06,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_audio_token": 1.2e-05,
        "output_cost_per_token": 2e-06,
        "rpm": 100000,
        "source": "https://ai.google.dev/gemini-api/docs/pricing",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 8000000
    },
    "gemini-2.5-flash-lite-preview-06-17": {
        "display_name": "Gemini 2.5 Flash Lite Preview 06-17",
        "model_vendor": "google",
        "model_version": "2.5-flash-lite-preview-06-17",
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_audio_token": 5e-07,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 4e-07,
        "output_cost_per_token": 4e-07,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-flash-preview-04-17": {
        "display_name": "Gemini 2.5 Flash Preview 04-17",
        "model_vendor": "google",
        "model_version": "2.5-flash-preview-04-17",
        "cache_read_input_token_cost": 3.75e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 3.5e-06,
        "output_cost_per_token": 6e-07,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-flash-preview-05-20": {
        "display_name": "Gemini 2.5 Flash Preview 05-20",
        "model_vendor": "google",
        "model_version": "2.5-flash-preview-05-20",
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 2.5e-06,
        "output_cost_per_token": 2.5e-06,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-pro": {
        "display_name": "Gemini 2.5 Pro",
        "model_vendor": "google",
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost_above_200k_tokens": 2.5e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_video_input": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-3-pro-preview": {
        "display_name": "Gemini 3 Pro Preview",
        "model_vendor": "google",
        "cache_read_input_token_cost": 2e-07,
        "cache_read_input_token_cost_above_200k_tokens": 4e-07,
        "cache_creation_input_token_cost_above_200k_tokens": 2.5e-07,
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_above_200k_tokens": 4e-06,
        "input_cost_per_token_batches": 1e-06,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1.2e-05,
        "output_cost_per_token_above_200k_tokens": 1.8e-05,
        "output_cost_per_token_batches": 6e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_video_input": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "vertex_ai/gemini-3-pro-preview": {
        "display_name": "Gemini 3 Pro Preview",
        "model_vendor": "google",
        "cache_read_input_token_cost": 2e-07,
        "cache_read_input_token_cost_above_200k_tokens": 4e-07,
        "cache_creation_input_token_cost_above_200k_tokens": 2.5e-07,
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_above_200k_tokens": 4e-06,
        "input_cost_per_token_batches": 1e-06,
        "litellm_provider": "vertex_ai",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1.2e-05,
        "output_cost_per_token_above_200k_tokens": 1.8e-05,
        "output_cost_per_token_batches": 6e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_video_input": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-pro-exp-03-25": {
        "display_name": "Gemini 2.5 Pro Experimental 03-25",
        "model_vendor": "google",
        "model_version": "2.5-pro-exp-03-25",
        "cache_read_input_token_cost": 3.125e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_video_input": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-pro-preview-03-25": {
        "display_name": "Gemini 2.5 Pro Preview 03-25",
        "model_vendor": "google",
        "model_version": "2.5-pro-preview-03-25",
        "cache_read_input_token_cost": 3.125e-07,
        "input_cost_per_audio_token": 1.25e-06,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-pro-preview-05-06": {
        "display_name": "Gemini 2.5 Pro Preview 05-06",
        "model_vendor": "google",
        "model_version": "2.5-pro-preview-05-06",
        "cache_read_input_token_cost": 3.125e-07,
        "input_cost_per_audio_token": 1.25e-06,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supported_regions": [
            "global"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-pro-preview-06-05": {
        "display_name": "Gemini 2.5 Pro Preview 06-05",
        "model_vendor": "google",
        "model_version": "2.5-pro-preview-06-05",
        "cache_read_input_token_cost": 3.125e-07,
        "input_cost_per_audio_token": 1.25e-06,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-pro-preview-tts": {
        "display_name": "Gemini 2.5 Pro Preview TTS",
        "model_vendor": "google",
        "cache_read_input_token_cost": 3.125e-07,
        "input_cost_per_audio_token": 7e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "audio"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-embedding-001": {
        "display_name": "Gemini Embedding 001",
        "model_vendor": "google",
        "model_version": "embedding-001",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "vertex_ai-embedding-models",
        "max_input_tokens": 2048,
        "max_tokens": 2048,
        "mode": "embedding",
        "output_cost_per_token": 0,
        "output_vector_size": 3072,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models"
    },
    "gemini-flash-experimental": {
        "display_name": "Gemini Flash Experimental",
        "model_vendor": "google",
        "input_cost_per_character": 0,
        "input_cost_per_token": 0,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 0,
        "output_cost_per_token": 0,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental",
        "supports_function_calling": false,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "gemini-pro": {
        "display_name": "Gemini Pro",
        "model_vendor": "google",
        "input_cost_per_character": 1.25e-07,
        "input_cost_per_image": 0.0025,
        "input_cost_per_token": 5e-07,
        "input_cost_per_video_per_second": 0.002,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 32760,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 3.75e-07,
        "output_cost_per_token": 1.5e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "gemini-pro-experimental": {
        "display_name": "Gemini Pro Experimental",
        "model_vendor": "google",
        "input_cost_per_character": 0,
        "input_cost_per_token": 0,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 0,
        "output_cost_per_token": 0,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental",
        "supports_function_calling": false,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "gemini-pro-vision": {
        "display_name": "Gemini Pro Vision",
        "model_vendor": "google",
        "input_cost_per_image": 0.0025,
        "input_cost_per_token": 5e-07,
        "litellm_provider": "vertex_ai-vision-models",
        "max_images_per_prompt": 16,
        "max_input_tokens": 16384,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "max_video_length": 2,
        "max_videos_per_prompt": 1,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini/gemini-embedding-001": {
        "display_name": "Gemini Embedding 001",
        "model_vendor": "google",
        "model_version": "embedding-001",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "gemini",
        "max_input_tokens": 2048,
        "max_tokens": 2048,
        "mode": "embedding",
        "output_cost_per_token": 0,
        "output_vector_size": 3072,
        "rpm": 10000,
        "source": "https://ai.google.dev/gemini-api/docs/embeddings#model-versions",
        "tpm": 10000000
    },
    "gemini/gemini-1.5-flash": {
        "display_name": "Gemini 1.5 Flash",
        "model_vendor": "google",
        "input_cost_per_token": 7.5e-08,
        "input_cost_per_token_above_128k_tokens": 1.5e-07,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "output_cost_per_token_above_128k_tokens": 6e-07,
        "rpm": 2000,
        "source": "https://ai.google.dev/pricing",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tpm": 4000000
    },
    "gemini/gemini-1.5-flash-001": {
        "display_name": "Gemini 1.5 Flash 001",
        "model_vendor": "google",
        "model_version": "1.5-flash-001",
        "cache_creation_input_token_cost": 1e-06,
        "cache_read_input_token_cost": 1.875e-08,
        "deprecation_date": "2025-05-24",
        "input_cost_per_token": 7.5e-08,
        "input_cost_per_token_above_128k_tokens": 1.5e-07,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "output_cost_per_token_above_128k_tokens": 6e-07,
        "rpm": 2000,
        "source": "https://ai.google.dev/pricing",
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tpm": 4000000
    },
    "gemini/gemini-1.5-flash-002": {
        "display_name": "Gemini 1.5 Flash 002",
        "model_vendor": "google",
        "model_version": "1.5-flash-002",
        "cache_creation_input_token_cost": 1e-06,
        "cache_read_input_token_cost": 1.875e-08,
        "deprecation_date": "2025-09-24",
        "input_cost_per_token": 7.5e-08,
        "input_cost_per_token_above_128k_tokens": 1.5e-07,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "output_cost_per_token_above_128k_tokens": 6e-07,
        "rpm": 2000,
        "source": "https://ai.google.dev/pricing",
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tpm": 4000000
    },
    "gemini/gemini-1.5-flash-8b": {
        "display_name": "Gemini 1.5 Flash 8B",
        "model_vendor": "google",
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "rpm": 4000,
        "source": "https://ai.google.dev/pricing",
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tpm": 4000000
    },
    "gemini/gemini-1.5-flash-8b-exp-0827": {
        "display_name": "Gemini 1.5 Flash 8B Experimental 0827",
        "model_vendor": "google",
        "model_version": "1.5-flash-8b-exp-0827",
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "rpm": 4000,
        "source": "https://ai.google.dev/pricing",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tpm": 4000000
    },
    "gemini/gemini-1.5-flash-8b-exp-0924": {
        "display_name": "Gemini 1.5 Flash 8B Experimental 0924",
        "model_vendor": "google",
        "model_version": "1.5-flash-8b-exp-0924",
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "rpm": 4000,
        "source": "https://ai.google.dev/pricing",
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tpm": 4000000
    },
    "gemini/gemini-1.5-flash-exp-0827": {
        "display_name": "Gemini 1.5 Flash Experimental 0827",
        "model_vendor": "google",
        "model_version": "1.5-flash-exp-0827",
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "rpm": 2000,
        "source": "https://ai.google.dev/pricing",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tpm": 4000000
    },
    "gemini/gemini-1.5-flash-latest": {
        "display_name": "Gemini 1.5 Flash Latest",
        "model_vendor": "google",
        "input_cost_per_token": 7.5e-08,
        "input_cost_per_token_above_128k_tokens": 1.5e-07,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "output_cost_per_token_above_128k_tokens": 6e-07,
        "rpm": 2000,
        "source": "https://ai.google.dev/pricing",
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tpm": 4000000
    },
    "gemini/gemini-1.5-pro": {
        "display_name": "Gemini 1.5 Pro",
        "model_vendor": "google",
        "input_cost_per_token": 3.5e-06,
        "input_cost_per_token_above_128k_tokens": 7e-06,
        "litellm_provider": "gemini",
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.05e-05,
        "output_cost_per_token_above_128k_tokens": 2.1e-05,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tpm": 4000000
    },
    "gemini/gemini-1.5-pro-001": {
        "display_name": "Gemini 1.5 Pro 001",
        "model_vendor": "google",
        "model_version": "1.5-pro-001",
        "deprecation_date": "2025-05-24",
        "input_cost_per_token": 3.5e-06,
        "input_cost_per_token_above_128k_tokens": 7e-06,
        "litellm_provider": "gemini",
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.05e-05,
        "output_cost_per_token_above_128k_tokens": 2.1e-05,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing",
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tpm": 4000000
    },
    "gemini/gemini-1.5-pro-002": {
        "display_name": "Gemini 1.5 Pro 002",
        "model_vendor": "google",
        "model_version": "1.5-pro-002",
        "deprecation_date": "2025-09-24",
        "input_cost_per_token": 3.5e-06,
        "input_cost_per_token_above_128k_tokens": 7e-06,
        "litellm_provider": "gemini",
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.05e-05,
        "output_cost_per_token_above_128k_tokens": 2.1e-05,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing",
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tpm": 4000000
    },
    "gemini/gemini-1.5-pro-exp-0801": {
        "display_name": "Gemini 1.5 Pro Experimental 0801",
        "model_vendor": "google",
        "model_version": "1.5-pro-exp-0801",
        "input_cost_per_token": 3.5e-06,
        "input_cost_per_token_above_128k_tokens": 7e-06,
        "litellm_provider": "gemini",
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.05e-05,
        "output_cost_per_token_above_128k_tokens": 2.1e-05,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tpm": 4000000
    },
    "gemini/gemini-1.5-pro-exp-0827": {
        "display_name": "Gemini 1.5 Pro Experimental 0827",
        "model_vendor": "google",
        "model_version": "1.5-pro-exp-0827",
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tpm": 4000000
    },
    "gemini/gemini-1.5-pro-latest": {
        "display_name": "Gemini 1.5 Pro Latest",
        "model_vendor": "google",
        "input_cost_per_token": 3.5e-06,
        "input_cost_per_token_above_128k_tokens": 7e-06,
        "litellm_provider": "gemini",
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.05e-06,
        "output_cost_per_token_above_128k_tokens": 2.1e-05,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tpm": 4000000
    },
    "gemini/gemini-2.0-flash": {
        "display_name": "Gemini 2.0 Flash",
        "model_vendor": "google",
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_audio_token": 7e-07,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "rpm": 10000,
        "source": "https://ai.google.dev/pricing#2_0flash",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 10000000
    },
    "gemini/gemini-2.0-flash-001": {
        "display_name": "Gemini 2.0 Flash 001",
        "model_vendor": "google",
        "model_version": "2.0-flash-001",
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_audio_token": 7e-07,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "rpm": 10000,
        "source": "https://ai.google.dev/pricing#2_0flash",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 10000000
    },
    "gemini/gemini-2.0-flash-exp": {
        "display_name": "Gemini 2.0 Flash Experimental",
        "model_vendor": "google",
        "cache_read_input_token_cost": 0.0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "input_cost_per_character": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_character": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "rpm": 10,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 4000000
    },
    "gemini/gemini-2.0-flash-lite": {
        "display_name": "Gemini 2.0 Flash Lite",
        "model_vendor": "google",
        "cache_read_input_token_cost": 1.875e-08,
        "input_cost_per_audio_token": 7.5e-08,
        "input_cost_per_token": 7.5e-08,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 50,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "rpm": 4000,
        "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.0-flash-lite",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 4000000
    },
    "gemini/gemini-2.0-flash-lite-preview-02-05": {
        "display_name": "Gemini 2.0 Flash Lite Preview 02-05",
        "model_vendor": "google",
        "model_version": "2.0-flash-lite-preview-02-05",
        "cache_read_input_token_cost": 1.875e-08,
        "input_cost_per_audio_token": 7.5e-08,
        "input_cost_per_token": 7.5e-08,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "rpm": 60000,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash-lite",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 10000000
    },
    "gemini/gemini-2.0-flash-live-001": {
        "display_name": "Gemini 2.0 Flash Live 001",
        "model_vendor": "google",
        "model_version": "2.0-flash-live-001",
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_audio_token": 2.1e-06,
        "input_cost_per_image": 2.1e-06,
        "input_cost_per_token": 3.5e-07,
        "input_cost_per_video_per_second": 2.1e-06,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_audio_token": 8.5e-06,
        "output_cost_per_token": 1.5e-06,
        "rpm": 10,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2-0-flash-live-001",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 250000
    },
    "gemini/gemini-2.0-flash-preview-image-generation": {
        "display_name": "Gemini 2.0 Flash Preview Image Generation",
        "model_vendor": "google",
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_audio_token": 7e-07,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "rpm": 10000,
        "source": "https://ai.google.dev/pricing#2_0flash",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 10000000
    },
    "gemini/gemini-2.0-flash-thinking-exp": {
        "display_name": "Gemini 2.0 Flash Thinking Experimental",
        "model_vendor": "google",
        "cache_read_input_token_cost": 0.0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "input_cost_per_character": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65536,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_character": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "rpm": 10,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 4000000
    },
    "gemini/gemini-2.0-flash-thinking-exp-01-21": {
        "display_name": "Gemini 2.0 Flash Thinking Experimental 01-21",
        "model_vendor": "google",
        "model_version": "2.0-flash-thinking-exp-01-21",
        "cache_read_input_token_cost": 0.0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "input_cost_per_character": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65536,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_character": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "rpm": 10,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 4000000
    },
    "gemini/gemini-2.0-pro-exp-02-05": {
        "display_name": "Gemini 2.0 Pro Experimental 02-05",
        "model_vendor": "google",
        "model_version": "2.0-pro-exp-02-05",
        "cache_read_input_token_cost": 0.0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "input_cost_per_character": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_character": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "rpm": 2,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_video_input": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 1000000
    },
    "gemini/gemini-2.5-flash": {
        "display_name": "Gemini 2.5 Flash",
        "model_vendor": "google",
        "cache_read_input_token_cost": 3e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 2.5e-06,
        "output_cost_per_token": 2.5e-06,
        "rpm": 100000,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 8000000
    },
    "gemini/gemini-2.5-flash-image": {
        "display_name": "Gemini 2.5 Flash Image",
        "model_vendor": "google",
        "cache_read_input_token_cost": 3e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "supports_reasoning": false,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "max_pdf_size_mb": 30,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "image_generation",
        "output_cost_per_image": 0.039,
        "output_cost_per_reasoning_token": 2.5e-06,
        "output_cost_per_token": 2.5e-06,
        "rpm": 100000,
        "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-flash-image",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 8000000
    },
    "gemini/gemini-2.5-flash-image-preview": {
        "display_name": "Gemini 2.5 Flash Image Preview",
        "model_vendor": "google",
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "image_generation",
        "output_cost_per_image": 0.039,
        "output_cost_per_reasoning_token": 3e-05,
        "output_cost_per_token": 3e-05,
        "rpm": 100000,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 8000000
    },
    "gemini/gemini-3-pro-image-preview": {
        "display_name": "Gemini 3 Pro Image Preview",
        "model_vendor": "google",
        "input_cost_per_image": 0.0011,
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_batches": 1e-06,
        "litellm_provider": "gemini",
        "max_input_tokens": 65536,
        "max_output_tokens": 32768,
        "max_tokens": 65536,
        "mode": "image_generation",
        "output_cost_per_image": 0.134,
        "output_cost_per_image_token": 0.00012,
        "output_cost_per_token": 1.2e-05,
        "rpm": 1000,
        "tpm": 4000000,
        "output_cost_per_token_batches": 6e-06,
        "source": "https://ai.google.dev/gemini-api/docs/pricing",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": false,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini/gemini-2.5-flash-lite": {
        "display_name": "Gemini 2.5 Flash Lite",
        "model_vendor": "google",
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_audio_token": 5e-07,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 4e-07,
        "output_cost_per_token": 4e-07,
        "rpm": 15,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-lite",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 250000
    },
    "gemini/gemini-2.5-flash-lite-preview-09-2025": {
        "display_name": "Gemini 2.5 Flash Lite Preview 09-2025",
        "model_vendor": "google",
        "model_version": "2.5-flash-lite-preview-09-2025",
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_audio_token": 3e-07,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 4e-07,
        "output_cost_per_token": 4e-07,
        "rpm": 15,
        "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 250000
    },
    "gemini/gemini-2.5-flash-preview-09-2025": {
        "display_name": "Gemini 2.5 Flash Preview 09-2025",
        "model_vendor": "google",
        "model_version": "2.5-flash-preview-09-2025",
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 2.5e-06,
        "output_cost_per_token": 2.5e-06,
        "rpm": 15,
        "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 250000
    },
    "gemini/gemini-flash-latest": {
        "display_name": "Gemini Flash Latest",
        "model_vendor": "google",
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 2.5e-06,
        "output_cost_per_token": 2.5e-06,
        "rpm": 15,
        "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 250000
    },
    "gemini/gemini-flash-lite-latest": {
        "display_name": "Gemini Flash Lite Latest",
        "model_vendor": "google",
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_audio_token": 3e-07,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 4e-07,
        "output_cost_per_token": 4e-07,
        "rpm": 15,
        "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 250000
    },
    "gemini/gemini-2.5-flash-lite-preview-06-17": {
        "display_name": "Gemini 2.5 Flash Lite Preview 06-17",
        "model_vendor": "google",
        "model_version": "2.5-flash-lite-preview-06-17",
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_audio_token": 5e-07,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 4e-07,
        "output_cost_per_token": 4e-07,
        "rpm": 15,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-lite",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 250000
    },
    "gemini/gemini-2.5-flash-preview-04-17": {
        "display_name": "Gemini 2.5 Flash Preview 04-17",
        "model_vendor": "google",
        "model_version": "2.5-flash-preview-04-17",
        "cache_read_input_token_cost": 3.75e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 3.5e-06,
        "output_cost_per_token": 6e-07,
        "rpm": 10,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 250000
    },
    "gemini/gemini-2.5-flash-preview-05-20": {
        "display_name": "Gemini 2.5 Flash Preview 05-20",
        "model_vendor": "google",
        "model_version": "2.5-flash-preview-05-20",
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 2.5e-06,
        "output_cost_per_token": 2.5e-06,
        "rpm": 10,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 250000
    },
    "gemini/gemini-2.5-flash-preview-tts": {
        "display_name": "Gemini 2.5 Flash Preview TTS",
        "model_vendor": "google",
        "cache_read_input_token_cost": 3.75e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 3.5e-06,
        "output_cost_per_token": 6e-07,
        "rpm": 10,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions"
        ],
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "audio"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 250000
    },
    "gemini/gemini-2.5-pro": {
        "display_name": "Gemini 2.5 Pro",
        "model_vendor": "google",
        "cache_read_input_token_cost": 3.125e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "rpm": 2000,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_video_input": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 800000
    },
    "gemini/gemini-2.5-computer-use-preview-10-2025": {
        "display_name": "Gemini 2.5 Computer Use Preview 10 2025",
        "model_vendor": "google",
        "model_version": "2.5",
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "litellm_provider": "gemini",
        "max_images_per_prompt": 3000,
        "max_input_tokens": 128000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "rpm": 2000,
        "source": "https://ai.google.dev/gemini-api/docs/computer-use",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tpm": 800000
    },
    "gemini/gemini-3-pro-preview": {
        "display_name": "Gemini 3 Pro Preview",
        "model_vendor": "google",
        "cache_read_input_token_cost": 2e-07,
        "cache_read_input_token_cost_above_200k_tokens": 4e-07,
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_above_200k_tokens": 4e-06,
        "input_cost_per_token_batches": 1e-06,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1.2e-05,
        "output_cost_per_token_above_200k_tokens": 1.8e-05,
        "output_cost_per_token_batches": 6e-06,
        "rpm": 2000,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_video_input": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 800000
    },
    "gemini/gemini-2.5-pro-exp-03-25": {
        "display_name": "Gemini 2.5 Pro Experimental 03-25",
        "model_vendor": "google",
        "model_version": "2.5-pro-exp-03-25",
        "cache_read_input_token_cost": 0.0,
        "input_cost_per_token": 0.0,
        "input_cost_per_token_above_200k_tokens": 0.0,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "output_cost_per_token_above_200k_tokens": 0.0,
        "rpm": 5,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_video_input": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 250000
    },
    "gemini/gemini-2.5-pro-preview-03-25": {
        "display_name": "Gemini 2.5 Pro Preview 03-25",
        "model_vendor": "google",
        "model_version": "2.5-pro-preview-03-25",
        "cache_read_input_token_cost": 3.125e-07,
        "input_cost_per_audio_token": 7e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "rpm": 10000,
        "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 10000000
    },
    "gemini/gemini-2.5-pro-preview-05-06": {
        "display_name": "Gemini 2.5 Pro Preview 05-06",
        "model_vendor": "google",
        "model_version": "2.5-pro-preview-05-06",
        "cache_read_input_token_cost": 3.125e-07,
        "input_cost_per_audio_token": 7e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "rpm": 10000,
        "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 10000000
    },
    "gemini/gemini-2.5-pro-preview-06-05": {
        "display_name": "Gemini 2.5 Pro Preview 06-05",
        "model_vendor": "google",
        "model_version": "2.5-pro-preview-06-05",
        "cache_read_input_token_cost": 3.125e-07,
        "input_cost_per_audio_token": 7e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "rpm": 10000,
        "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 10000000
    },
    "gemini/gemini-2.5-pro-preview-tts": {
        "display_name": "Gemini 2.5 Pro Preview TTS",
        "model_vendor": "google",
        "cache_read_input_token_cost": 3.125e-07,
        "input_cost_per_audio_token": 7e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "rpm": 10000,
        "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "audio"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 10000000
    },
    "gemini/gemini-exp-1114": {
        "display_name": "Gemini Experimental 1114",
        "model_vendor": "google",
        "model_version": "exp-1114",
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "metadata": {
            "notes": "Rate limits not documented for gemini-exp-1114. Assuming same as gemini-1.5-pro.",
            "supports_tool_choice": true
        },
        "mode": "chat",
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tpm": 4000000
    },
    "gemini/gemini-exp-1206": {
        "display_name": "Gemini Experimental 1206",
        "model_vendor": "google",
        "model_version": "exp-1206",
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "metadata": {
            "notes": "Rate limits not documented for gemini-exp-1206. Assuming same as gemini-1.5-pro.",
            "supports_tool_choice": true
        },
        "mode": "chat",
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tpm": 4000000
    },
    "gemini/gemini-gemma-2-27b-it": {
        "display_name": "Gemma 2 27B IT",
        "model_vendor": "google",
        "input_cost_per_token": 3.5e-07,
        "litellm_provider": "gemini",
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.05e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini/gemini-gemma-2-9b-it": {
        "display_name": "Gemma 2 9B IT",
        "model_vendor": "google",
        "input_cost_per_token": 3.5e-07,
        "litellm_provider": "gemini",
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.05e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini/gemini-pro": {
        "display_name": "Gemini Pro",
        "model_vendor": "google",
        "input_cost_per_token": 3.5e-07,
        "input_cost_per_token_above_128k_tokens": 7e-07,
        "litellm_provider": "gemini",
        "max_input_tokens": 32760,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.05e-06,
        "output_cost_per_token_above_128k_tokens": 2.1e-06,
        "rpd": 30000,
        "rpm": 360,
        "source": "https://ai.google.dev/gemini-api/docs/models/gemini",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "tpm": 120000
    },
    "gemini/gemini-pro-vision": {
        "display_name": "Gemini Pro Vision",
        "model_vendor": "google",
        "input_cost_per_token": 3.5e-07,
        "input_cost_per_token_above_128k_tokens": 7e-07,
        "litellm_provider": "gemini",
        "max_input_tokens": 30720,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "mode": "chat",
        "output_cost_per_token": 1.05e-06,
        "output_cost_per_token_above_128k_tokens": 2.1e-06,
        "rpd": 30000,
        "rpm": 360,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tpm": 120000
    },
    "gemini/gemma-3-27b-it": {
        "display_name": "Gemma 3 27B IT",
        "model_vendor": "google",
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "input_cost_per_character": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "max_input_tokens": 131072,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "source": "https://aistudio.google.com",
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini/imagen-3.0-fast-generate-001": {
        "display_name": "Imagen 3.0 Fast Generate 001",
        "model_vendor": "google",
        "model_version": "3.0-fast-generate-001",
        "litellm_provider": "gemini",
        "mode": "image_generation",
        "output_cost_per_image": 0.02,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "gemini/imagen-3.0-generate-001": {
        "display_name": "Imagen 3.0 Generate 001",
        "model_vendor": "google",
        "model_version": "3.0-generate-001",
        "litellm_provider": "gemini",
        "mode": "image_generation",
        "output_cost_per_image": 0.04,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "gemini/imagen-3.0-generate-002": {
        "display_name": "Imagen 3.0 Generate 002",
        "model_vendor": "google",
        "model_version": "3.0-generate-002",
        "litellm_provider": "gemini",
        "mode": "image_generation",
        "output_cost_per_image": 0.04,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "gemini/imagen-4.0-fast-generate-001": {
        "display_name": "Imagen 4.0 Fast Generate 001",
        "model_vendor": "google",
        "model_version": "4.0-fast-generate-001",
        "litellm_provider": "gemini",
        "mode": "image_generation",
        "output_cost_per_image": 0.02,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "gemini/imagen-4.0-generate-001": {
        "display_name": "Imagen 4.0 Generate 001",
        "model_vendor": "google",
        "model_version": "4.0-generate-001",
        "litellm_provider": "gemini",
        "mode": "image_generation",
        "output_cost_per_image": 0.04,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "gemini/imagen-4.0-ultra-generate-001": {
        "display_name": "Imagen 4.0 Ultra Generate 001",
        "model_vendor": "google",
        "model_version": "4.0-ultra-generate-001",
        "litellm_provider": "gemini",
        "mode": "image_generation",
        "output_cost_per_image": 0.06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "gemini/learnlm-1.5-pro-experimental": {
        "display_name": "LearnLM 1.5 Pro Experimental",
        "model_vendor": "google",
        "model_version": "1.5-pro-experimental",
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "input_cost_per_character": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "max_input_tokens": 32767,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "source": "https://aistudio.google.com",
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini/veo-2.0-generate-001": {
        "display_name": "Veo 2.0 Generate 001",
        "model_vendor": "google",
        "model_version": "2.0-generate-001",
        "litellm_provider": "gemini",
        "max_input_tokens": 1024,
        "max_tokens": 1024,
        "mode": "video_generation",
        "output_cost_per_second": 0.35,
        "source": "https://ai.google.dev/gemini-api/docs/video",
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "video"
        ]
    },
    "gemini/veo-3.0-fast-generate-preview": {
        "display_name": "Veo 3.0 Fast Generate Preview",
        "model_vendor": "google",
        "model_version": "3.0-fast-generate-preview",
        "litellm_provider": "gemini",
        "max_input_tokens": 1024,
        "max_tokens": 1024,
        "mode": "video_generation",
        "output_cost_per_second": 0.4,
        "source": "https://ai.google.dev/gemini-api/docs/video",
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "video"
        ]
    },
    "gemini/veo-3.0-generate-preview": {
        "display_name": "Veo 3.0 Generate Preview",
        "model_vendor": "google",
        "model_version": "3.0-generate-preview",
        "litellm_provider": "gemini",
        "max_input_tokens": 1024,
        "max_tokens": 1024,
        "mode": "video_generation",
        "output_cost_per_second": 0.75,
        "source": "https://ai.google.dev/gemini-api/docs/video",
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "video"
        ]
    },
    "gemini/veo-3.1-fast-generate-preview": {
        "display_name": "Veo 3.1 Fast Generate Preview",
        "model_vendor": "google",
        "model_version": "3.1-fast-generate-preview",
        "litellm_provider": "gemini",
        "max_input_tokens": 1024,
        "max_tokens": 1024,
        "mode": "video_generation",
        "output_cost_per_second": 0.15,
        "source": "https://ai.google.dev/gemini-api/docs/video",
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "video"
        ]
    },
    "gemini/veo-3.1-generate-preview": {
        "display_name": "Veo 3.1 Generate Preview",
        "model_vendor": "google",
        "model_version": "3.1-generate-preview",
        "litellm_provider": "gemini",
        "max_input_tokens": 1024,
        "max_tokens": 1024,
        "mode": "video_generation",
        "output_cost_per_second": 0.4,
        "source": "https://ai.google.dev/gemini-api/docs/video",
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "video"
        ]
    },
    "github_copilot/claude-haiku-4.5": {
        "display_name": "Claude Haiku 4.5",
        "model_vendor": "anthropic",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 128000,
        "max_output_tokens": 16000,
        "max_tokens": 16000,
        "mode": "chat",
        "supported_endpoints": [
            "/chat/completions"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true
    },
    "github_copilot/claude-opus-4.5": {
        "display_name": "Claude Opus 4.5",
        "model_vendor": "anthropic",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 128000,
        "max_output_tokens": 16000,
        "max_tokens": 16000,
        "mode": "chat",
        "supported_endpoints": [
            "/chat/completions"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true
    },
    "github_copilot/claude-opus-41": {
        "display_name": "Claude Opus 41",
        "model_vendor": "anthropic",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 80000,
        "max_output_tokens": 16000,
        "max_tokens": 16000,
        "mode": "chat",
        "supported_endpoints": [
            "/chat/completions"
        ],
        "supports_vision": true
    },
    "github_copilot/claude-sonnet-4": {
        "display_name": "Claude Sonnet 4",
        "model_vendor": "anthropic",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 128000,
        "max_output_tokens": 16000,
        "max_tokens": 16000,
        "mode": "chat",
        "supported_endpoints": [
            "/chat/completions"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true
    },
    "github_copilot/claude-sonnet-4.5": {
        "display_name": "Claude Sonnet 4.5",
        "model_vendor": "anthropic",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 128000,
        "max_output_tokens": 16000,
        "max_tokens": 16000,
        "mode": "chat",
        "supported_endpoints": [
            "/chat/completions"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true
    },
    "github_copilot/gemini-2.5-pro": {
        "display_name": "Gemini 2.5 Pro",
        "model_vendor": "google",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 128000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true
    },
    "github_copilot/gemini-3-pro-preview": {
        "display_name": "Gemini 3 Pro Preview",
        "model_vendor": "google",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 128000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true
    },
    "github_copilot/gpt-3.5-turbo": {
        "display_name": "GPT 3.5 Turbo",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 16384,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "supports_function_calling": true
    },
    "github_copilot/gpt-3.5-turbo-0613": {
        "display_name": "GPT 3.5 Turbo 0613",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 16384,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "supports_function_calling": true
    },
    "github_copilot/gpt-4": {
        "display_name": "GPT 4",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "supports_function_calling": true
    },
    "github_copilot/gpt-4-0613": {
        "display_name": "GPT 4 0613",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "supports_function_calling": true
    },
    "github_copilot/gpt-4-o-preview": {
        "display_name": "GPT 4 o Preview",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 64000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true
    },
    "github_copilot/gpt-4.1": {
        "display_name": "GPT 4.1",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "github_copilot/gpt-4.1-2025-04-14": {
        "display_name": "GPT 4.1 2025 04 14",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "github_copilot/gpt-41-copilot": {
        "display_name": "GPT 41 Copilot",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "mode": "completion"
    },
    "github_copilot/gpt-4o": {
        "display_name": "GPT 4o",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 64000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true
    },
    "github_copilot/gpt-4o-2024-05-13": {
        "display_name": "GPT 4o 2024 05 13",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 64000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true
    },
    "github_copilot/gpt-4o-2024-08-06": {
        "display_name": "GPT 4o 2024 08 06",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 64000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true
    },
    "github_copilot/gpt-4o-2024-11-20": {
        "display_name": "GPT 4o 2024 11 20",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 64000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true
    },
    "github_copilot/gpt-4o-mini": {
        "display_name": "GPT 4o Mini",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 64000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true
    },
    "github_copilot/gpt-4o-mini-2024-07-18": {
        "display_name": "GPT 4o Mini 2024 07 18",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 64000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true
    },
    "github_copilot/gpt-5": {
        "display_name": "GPT 5",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "supported_endpoints": [
            "/chat/completions",
            "/responses"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "github_copilot/gpt-5-mini": {
        "display_name": "GPT 5 Mini",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 128000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "github_copilot/gpt-5.1": {
        "display_name": "GPT 5.1",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 128000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "supported_endpoints": [
            "/chat/completions",
            "/responses"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "github_copilot/gpt-5.1-codex-max": {
        "display_name": "GPT 5.1 Codex Max",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "supported_endpoints": [
            "/responses"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "github_copilot/gpt-5.2": {
        "display_name": "GPT 5.2",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 128000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "supported_endpoints": [
            "/chat/completions",
            "/responses"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "github_copilot/text-embedding-3-small": {
        "display_name": "Text Embedding 3 Small",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 8191,
        "max_tokens": 8191,
        "mode": "embedding"
    },
    "github_copilot/text-embedding-3-small-inference": {
        "display_name": "Text Embedding 3 Small Inference",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 8191,
        "max_tokens": 8191,
        "mode": "embedding"
    },
    "github_copilot/text-embedding-ada-002": {
        "display_name": "Text Embedding Ada 002",
        "model_vendor": "openai",
        "litellm_provider": "github_copilot",
        "max_input_tokens": 8191,
        "max_tokens": 8191,
        "mode": "embedding"
    },
    "gigachat/GigaChat-2-Lite": {
        "input_cost_per_token": 0.0,
        "litellm_provider": "gigachat",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "supports_function_calling": true,
        "supports_system_messages": true
    },
    "gigachat/GigaChat-2-Max": {
        "input_cost_per_token": 0.0,
        "litellm_provider": "gigachat",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "supports_function_calling": true,
        "supports_system_messages": true,
        "supports_vision": true
    },
    "gigachat/GigaChat-2-Pro": {
        "input_cost_per_token": 0.0,
        "litellm_provider": "gigachat",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "supports_function_calling": true,
        "supports_system_messages": true,
        "supports_vision": true
    },
    "gigachat/Embeddings": {
        "input_cost_per_token": 0.0,
        "litellm_provider": "gigachat",
        "max_input_tokens": 512,
        "max_tokens": 512,
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "output_vector_size": 1024
    },
    "gigachat/Embeddings-2": {
        "input_cost_per_token": 0.0,
        "litellm_provider": "gigachat",
        "max_input_tokens": 512,
        "max_tokens": 512,
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "output_vector_size": 1024
    },
    "gigachat/EmbeddingsGigaR": {
        "input_cost_per_token": 0.0,
        "litellm_provider": "gigachat",
        "max_input_tokens": 4096,
        "max_tokens": 4096,
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "output_vector_size": 2560
    },
    "google.gemma-3-12b-it": {
        "display_name": "Gemma 3 12B It",
        "model_vendor": "google",
        "input_cost_per_token": 9e-08,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2.9e-07,
        "supports_system_messages": true,
        "supports_vision": true
    },
    "google.gemma-3-27b-it": {
        "display_name": "Gemma 3 27B It",
        "model_vendor": "google",
        "input_cost_per_token": 2.3e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 3.8e-07,
        "supports_system_messages": true,
        "supports_vision": true
    },
    "google.gemma-3-4b-it": {
        "display_name": "Gemma 3 4B It",
        "model_vendor": "google",
        "input_cost_per_token": 4e-08,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 8e-08,
        "supports_system_messages": true,
        "supports_vision": true
    },
    "google_pse/search": {
        "display_name": "Google PSE Search",
        "model_vendor": "google",
        "input_cost_per_query": 0.005,
        "litellm_provider": "google_pse",
        "mode": "search"
    },
    "global.anthropic.claude-sonnet-4-5-20250929-v1:0": {
        "display_name": "Claude Sonnet 4.5",
        "model_vendor": "anthropic",
        "model_version": "20250929",
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 346
    },
    "global.anthropic.claude-sonnet-4-20250514-v1:0": {
        "display_name": "Claude Sonnet 4",
        "model_vendor": "anthropic",
        "model_version": "20250514",
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "global.anthropic.claude-haiku-4-5-20251001-v1:0": {
        "display_name": "Claude Haiku 4.5",
        "model_vendor": "anthropic",
        "model_version": "20251001",
        "cache_creation_input_token_cost": 1.25e-06,
        "cache_read_input_token_cost": 1e-07,
        "input_cost_per_token": 1e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 346
    },
    "global.amazon.nova-2-lite-v1:0": {
        "display_name": "Amazon.nova 2 Lite V1:0",
        "model_vendor": "amazon",
        "model_version": "0",
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 2.5e-06,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_video_input": true,
        "supports_vision": true
    },
    "gpt-3.5-turbo": {
        "display_name": "GPT-3.5 Turbo",
        "model_vendor": "openai",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "max_tokens": 4097,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo-0125": {
        "display_name": "GPT-3.5 Turbo 0125",
        "model_vendor": "openai",
        "model_version": "0125",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "max_tokens": 16385,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo-0301": {
        "display_name": "GPT-3.5 Turbo 0301",
        "model_vendor": "openai",
        "model_version": "0301",
        "input_cost_per_token": 1.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 4097,
        "max_output_tokens": 4096,
        "max_tokens": 4097,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo-0613": {
        "display_name": "GPT-3.5 Turbo 0613",
        "model_vendor": "openai",
        "model_version": "0613",
        "input_cost_per_token": 1.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 4097,
        "max_output_tokens": 4096,
        "max_tokens": 4097,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo-1106": {
        "display_name": "GPT-3.5 Turbo 1106",
        "model_vendor": "openai",
        "model_version": "1106",
        "deprecation_date": "2026-09-28",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "max_tokens": 16385,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo-16k": {
        "display_name": "GPT-3.5 Turbo 16K",
        "model_vendor": "openai",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "max_tokens": 16385,
        "mode": "chat",
        "output_cost_per_token": 4e-06,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo-16k-0613": {
        "display_name": "GPT-3.5 Turbo 16K 0613",
        "model_vendor": "openai",
        "model_version": "0613",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "max_tokens": 16385,
        "mode": "chat",
        "output_cost_per_token": 4e-06,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo-instruct": {
        "display_name": "GPT-3.5 Turbo Instruct",
        "model_vendor": "openai",
        "input_cost_per_token": 1.5e-06,
        "litellm_provider": "text-completion-openai",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "completion",
        "output_cost_per_token": 2e-06
    },
    "gpt-3.5-turbo-instruct-0914": {
        "display_name": "GPT-3.5 Turbo Instruct 0914",
        "model_vendor": "openai",
        "model_version": "0914",
        "input_cost_per_token": 1.5e-06,
        "litellm_provider": "text-completion-openai",
        "max_input_tokens": 8192,
        "max_output_tokens": 4097,
        "max_tokens": 4097,
        "mode": "completion",
        "output_cost_per_token": 2e-06
    },
    "gpt-4": {
        "display_name": "GPT-4",
        "model_vendor": "openai",
        "input_cost_per_token": 3e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-0125-preview": {
        "display_name": "GPT-4 0125 Preview",
        "model_vendor": "openai",
        "model_version": "0125-preview",
        "deprecation_date": "2026-03-26",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-0314": {
        "display_name": "GPT-4 0314",
        "model_vendor": "openai",
        "model_version": "0314",
        "input_cost_per_token": 3e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-0613": {
        "display_name": "GPT-4 0613",
        "model_vendor": "openai",
        "model_version": "0613",
        "deprecation_date": "2025-06-06",
        "input_cost_per_token": 3e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-1106-preview": {
        "display_name": "GPT-4 1106 Preview",
        "model_vendor": "openai",
        "model_version": "1106-preview",
        "deprecation_date": "2026-03-26",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-1106-vision-preview": {
        "display_name": "GPT-4 1106 Vision Preview",
        "model_vendor": "openai",
        "model_version": "1106-vision-preview",
        "deprecation_date": "2024-12-06",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4-32k": {
        "display_name": "GPT-4 32K",
        "model_vendor": "openai",
        "input_cost_per_token": 6e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 0.00012,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-32k-0314": {
        "display_name": "GPT-4 32K 0314",
        "model_vendor": "openai",
        "model_version": "0314",
        "input_cost_per_token": 6e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 0.00012,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-32k-0613": {
        "display_name": "GPT-4 32K 0613",
        "model_vendor": "openai",
        "model_version": "0613",
        "input_cost_per_token": 6e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 0.00012,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-turbo": {
        "display_name": "GPT-4 Turbo",
        "model_vendor": "openai",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4-turbo-2024-04-09": {
        "display_name": "GPT-4 Turbo",
        "model_vendor": "openai",
        "model_version": "2024-04-09",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4-turbo-preview": {
        "display_name": "GPT-4 Turbo Preview",
        "model_vendor": "openai",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-vision-preview": {
        "display_name": "GPT-4 Vision Preview",
        "model_vendor": "openai",
        "deprecation_date": "2024-12-06",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4.1": {
        "display_name": "GPT-4.1",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 5e-07,
        "cache_read_input_token_cost_priority": 8.75e-07,
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_batches": 1e-06,
        "input_cost_per_token_priority": 3.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "output_cost_per_token_batches": 4e-06,
        "output_cost_per_token_priority": 1.4e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "gpt-4.1-2025-04-14": {
        "display_name": "GPT-4.1",
        "model_vendor": "openai",
        "model_version": "2025-04-14",
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_batches": 1e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "output_cost_per_token_batches": 4e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "gpt-4.1-mini": {
        "display_name": "GPT-4.1 Mini",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 1e-07,
        "cache_read_input_token_cost_priority": 1.75e-07,
        "input_cost_per_token": 4e-07,
        "input_cost_per_token_batches": 2e-07,
        "input_cost_per_token_priority": 7e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 1.6e-06,
        "output_cost_per_token_batches": 8e-07,
        "output_cost_per_token_priority": 2.8e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "gpt-4.1-mini-2025-04-14": {
        "display_name": "GPT-4.1 Mini",
        "model_vendor": "openai",
        "model_version": "2025-04-14",
        "cache_read_input_token_cost": 1e-07,
        "input_cost_per_token": 4e-07,
        "input_cost_per_token_batches": 2e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 1.6e-06,
        "output_cost_per_token_batches": 8e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "gpt-4.1-nano": {
        "display_name": "GPT-4.1 Nano",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 2.5e-08,
        "cache_read_input_token_cost_priority": 5e-08,
        "input_cost_per_token": 1e-07,
        "input_cost_per_token_batches": 5e-08,
        "input_cost_per_token_priority": 2e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "output_cost_per_token_batches": 2e-07,
        "output_cost_per_token_priority": 8e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "gpt-4.1-nano-2025-04-14": {
        "display_name": "GPT-4.1 Nano",
        "model_vendor": "openai",
        "model_version": "2025-04-14",
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_token": 1e-07,
        "input_cost_per_token_batches": 5e-08,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "output_cost_per_token_batches": 2e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "gpt-4.5-preview": {
        "display_name": "GPT-4.5 Preview",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 3.75e-05,
        "input_cost_per_token": 7.5e-05,
        "input_cost_per_token_batches": 3.75e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 0.00015,
        "output_cost_per_token_batches": 7.5e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4.5-preview-2025-02-27": {
        "display_name": "GPT-4.5 Preview",
        "model_vendor": "openai",
        "model_version": "2025-02-27",
        "cache_read_input_token_cost": 3.75e-05,
        "deprecation_date": "2025-07-14",
        "input_cost_per_token": 7.5e-05,
        "input_cost_per_token_batches": 3.75e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 0.00015,
        "output_cost_per_token_batches": 7.5e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o": {
        "display_name": "GPT-4o",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 1.25e-06,
        "cache_read_input_token_cost_priority": 2.125e-06,
        "input_cost_per_token": 2.5e-06,
        "input_cost_per_token_batches": 1.25e-06,
        "input_cost_per_token_priority": 4.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_batches": 5e-06,
        "output_cost_per_token_priority": 1.7e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "gpt-4o-2024-05-13": {
        "display_name": "GPT-4o",
        "model_vendor": "openai",
        "model_version": "2024-05-13",
        "input_cost_per_token": 5e-06,
        "input_cost_per_token_batches": 2.5e-06,
        "input_cost_per_token_priority": 8.75e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "output_cost_per_token_batches": 7.5e-06,
        "output_cost_per_token_priority": 2.625e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o-2024-08-06": {
        "display_name": "GPT-4o",
        "model_vendor": "openai",
        "model_version": "2024-08-06",
        "cache_read_input_token_cost": 1.25e-06,
        "input_cost_per_token": 2.5e-06,
        "input_cost_per_token_batches": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_batches": 5e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "gpt-4o-2024-11-20": {
        "display_name": "GPT-4o",
        "model_vendor": "openai",
        "model_version": "2024-11-20",
        "cache_read_input_token_cost": 1.25e-06,
        "input_cost_per_token": 2.5e-06,
        "input_cost_per_token_batches": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_batches": 5e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "gpt-4o-audio-preview": {
        "display_name": "GPT-4o Audio Preview",
        "model_vendor": "openai",
        "input_cost_per_audio_token": 0.0001,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_audio_token": 0.0002,
        "output_cost_per_token": 1e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-audio-preview-2024-10-01": {
        "display_name": "GPT-4o Audio Preview",
        "model_vendor": "openai",
        "model_version": "2024-10-01",
        "input_cost_per_audio_token": 0.0001,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_audio_token": 0.0002,
        "output_cost_per_token": 1e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-audio-preview-2024-12-17": {
        "display_name": "GPT-4o Audio Preview",
        "model_vendor": "openai",
        "model_version": "2024-12-17",
        "input_cost_per_audio_token": 4e-05,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 1e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-audio-preview-2025-06-03": {
        "display_name": "GPT-4o Audio Preview",
        "model_vendor": "openai",
        "model_version": "2025-06-03",
        "input_cost_per_audio_token": 4e-05,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 1e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-mini": {
        "display_name": "GPT-4o Mini",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 7.5e-08,
        "cache_read_input_token_cost_priority": 1.25e-07,
        "input_cost_per_token": 1.5e-07,
        "input_cost_per_token_batches": 7.5e-08,
        "input_cost_per_token_priority": 2.5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "output_cost_per_token_batches": 3e-07,
        "output_cost_per_token_priority": 1e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "gpt-4o-mini-2024-07-18": {
        "display_name": "GPT-4o Mini",
        "model_vendor": "openai",
        "model_version": "2024-07-18",
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_token": 1.5e-07,
        "input_cost_per_token_batches": 7.5e-08,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "output_cost_per_token_batches": 3e-07,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.03,
            "search_context_size_low": 0.025,
            "search_context_size_medium": 0.0275
        },
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "gpt-4o-mini-audio-preview": {
        "display_name": "GPT-4o Mini Audio Preview",
        "model_vendor": "openai",
        "input_cost_per_audio_token": 1e-05,
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_audio_token": 2e-05,
        "output_cost_per_token": 6e-07,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-mini-audio-preview-2024-12-17": {
        "display_name": "GPT-4o Mini Audio Preview",
        "model_vendor": "openai",
        "model_version": "2024-12-17",
        "input_cost_per_audio_token": 1e-05,
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_audio_token": 2e-05,
        "output_cost_per_token": 6e-07,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-mini-realtime-preview": {
        "display_name": "GPT-4o Mini Realtime Preview",
        "model_vendor": "openai",
        "cache_creation_input_audio_token_cost": 3e-07,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_audio_token": 1e-05,
        "input_cost_per_token": 6e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 2e-05,
        "output_cost_per_token": 2.4e-06,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-mini-realtime-preview-2024-12-17": {
        "display_name": "GPT-4o Mini Realtime Preview",
        "model_vendor": "openai",
        "model_version": "2024-12-17",
        "cache_creation_input_audio_token_cost": 3e-07,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_audio_token": 1e-05,
        "input_cost_per_token": 6e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 2e-05,
        "output_cost_per_token": 2.4e-06,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-mini-search-preview": {
        "display_name": "GPT-4o Mini Search Preview",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_token": 1.5e-07,
        "input_cost_per_token_batches": 7.5e-08,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "output_cost_per_token_batches": 3e-07,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.03,
            "search_context_size_low": 0.025,
            "search_context_size_medium": 0.0275
        },
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gpt-4o-mini-search-preview-2025-03-11": {
        "display_name": "GPT-4o Mini Search Preview",
        "model_vendor": "openai",
        "model_version": "2025-03-11",
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_token": 1.5e-07,
        "input_cost_per_token_batches": 7.5e-08,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "output_cost_per_token_batches": 3e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o-mini-transcribe": {
        "display_name": "GPT-4o Mini Transcribe",
        "model_vendor": "openai",
        "input_cost_per_audio_token": 3e-06,
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 16000,
        "max_output_tokens": 2000,
        "mode": "audio_transcription",
        "output_cost_per_token": 5e-06,
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "gpt-4o-mini-tts": {
        "display_name": "GPT-4o Mini TTS",
        "model_vendor": "openai",
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "openai",
        "mode": "audio_speech",
        "output_cost_per_audio_token": 1.2e-05,
        "output_cost_per_second": 0.00025,
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/audio/speech"
        ],
        "supported_modalities": [
            "text",
            "audio"
        ],
        "supported_output_modalities": [
            "audio"
        ]
    },
    "gpt-4o-realtime-preview": {
        "display_name": "GPT-4o Realtime Preview",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 2.5e-06,
        "input_cost_per_audio_token": 4e-05,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 2e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-realtime-preview-2024-10-01": {
        "display_name": "GPT-4o Realtime Preview",
        "model_vendor": "openai",
        "model_version": "2024-10-01",
        "cache_creation_input_audio_token_cost": 2e-05,
        "cache_read_input_token_cost": 2.5e-06,
        "input_cost_per_audio_token": 0.0001,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 0.0002,
        "output_cost_per_token": 2e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-realtime-preview-2024-12-17": {
        "display_name": "GPT-4o Realtime Preview",
        "model_vendor": "openai",
        "model_version": "2024-12-17",
        "cache_read_input_token_cost": 2.5e-06,
        "input_cost_per_audio_token": 4e-05,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 2e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-realtime-preview-2025-06-03": {
        "display_name": "GPT-4o Realtime Preview",
        "model_vendor": "openai",
        "model_version": "2025-06-03",
        "cache_read_input_token_cost": 2.5e-06,
        "input_cost_per_audio_token": 4e-05,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 2e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-search-preview": {
        "display_name": "GPT-4o Search Preview",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 1.25e-06,
        "input_cost_per_token": 2.5e-06,
        "input_cost_per_token_batches": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_batches": 5e-06,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.05,
            "search_context_size_low": 0.03,
            "search_context_size_medium": 0.035
        },
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gpt-4o-search-preview-2025-03-11": {
        "display_name": "GPT-4o Search Preview",
        "model_vendor": "openai",
        "model_version": "2025-03-11",
        "cache_read_input_token_cost": 1.25e-06,
        "input_cost_per_token": 2.5e-06,
        "input_cost_per_token_batches": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_batches": 5e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o-transcribe": {
        "display_name": "GPT-4o Transcribe",
        "model_vendor": "openai",
        "input_cost_per_audio_token": 6e-06,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 16000,
        "max_output_tokens": 2000,
        "mode": "audio_transcription",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "gpt-5": {
        "display_name": "GPT-5",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 1.25e-07,
        "cache_read_input_token_cost_flex": 6.25e-08,
        "cache_read_input_token_cost_priority": 2.5e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_flex": 6.25e-07,
        "input_cost_per_token_priority": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_flex": 5e-06,
        "output_cost_per_token_priority": 2e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "gpt-5.1": {
        "display_name": "GPT-5.1",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 1.25e-07,
        "cache_read_input_token_cost_priority": 2.5e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_priority": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_priority": 2e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "gpt-5.1-2025-11-13": {
        "display_name": "GPT-5.1",
        "model_vendor": "openai",
        "model_version": "2025-11-13",
        "cache_read_input_token_cost": 1.25e-07,
        "cache_read_input_token_cost_priority": 2.5e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_priority": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_priority": 2e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "gpt-5.1-chat-latest": {
        "display_name": "GPT-5.1 Chat Latest",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 1.25e-07,
        "cache_read_input_token_cost_priority": 2.5e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_priority": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_priority": 2e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": false,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "gpt-5.2": {
        "display_name": "GPT 5.2",
        "model_vendor": "openai",
        "model_version": "5.2",
        "cache_read_input_token_cost": 1.75e-07,
        "cache_read_input_token_cost_priority": 3.5e-07,
        "input_cost_per_token": 1.75e-06,
        "input_cost_per_token_priority": 3.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 400000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.4e-05,
        "output_cost_per_token_priority": 2.8e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "gpt-5.2-2025-12-11": {
        "display_name": "GPT 5.2 2025 12 11",
        "model_vendor": "openai",
        "model_version": "2025-12-11",
        "cache_read_input_token_cost": 1.75e-07,
        "cache_read_input_token_cost_priority": 3.5e-07,
        "input_cost_per_token": 1.75e-06,
        "input_cost_per_token_priority": 3.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 400000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.4e-05,
        "output_cost_per_token_priority": 2.8e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "gpt-5.2-chat-latest": {
        "display_name": "GPT 5.2 Chat Latest",
        "model_vendor": "openai",
        "model_version": "5.2",
        "cache_read_input_token_cost": 1.75e-07,
        "cache_read_input_token_cost_priority": 3.5e-07,
        "input_cost_per_token": 1.75e-06,
        "input_cost_per_token_priority": 3.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1.4e-05,
        "output_cost_per_token_priority": 2.8e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5.2-pro": {
        "display_name": "GPT 5.2 Pro",
        "model_vendor": "openai",
        "model_version": "5.2",
        "input_cost_per_token": 2.1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 400000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "output_cost_per_token": 0.000168,
        "supported_endpoints": [
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gpt-5.2-pro-2025-12-11": {
        "display_name": "GPT 5.2 Pro 2025 12 11",
        "model_vendor": "openai",
        "model_version": "2025-12-11",
        "input_cost_per_token": 2.1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 400000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "output_cost_per_token": 0.000168,
        "supported_endpoints": [
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gpt-5-pro": {
        "display_name": "GPT-5 Pro",
        "model_vendor": "openai",
        "input_cost_per_token": 1.5e-05,
        "input_cost_per_token_batches": 7.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 400000,
        "max_output_tokens": 272000,
        "max_tokens": 272000,
        "mode": "responses",
        "output_cost_per_token": 0.00012,
        "output_cost_per_token_batches": 6e-05,
        "supported_endpoints": [
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": false,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gpt-5-pro-2025-10-06": {
        "display_name": "GPT-5 Pro",
        "model_vendor": "openai",
        "model_version": "2025-10-06",
        "input_cost_per_token": 1.5e-05,
        "input_cost_per_token_batches": 7.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 400000,
        "max_output_tokens": 272000,
        "max_tokens": 272000,
        "mode": "responses",
        "output_cost_per_token": 0.00012,
        "output_cost_per_token_batches": 6e-05,
        "supported_endpoints": [
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": false,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gpt-5-2025-08-07": {
        "display_name": "GPT-5",
        "model_vendor": "openai",
        "model_version": "2025-08-07",
        "cache_read_input_token_cost": 1.25e-07,
        "cache_read_input_token_cost_flex": 6.25e-08,
        "cache_read_input_token_cost_priority": 2.5e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_flex": 6.25e-07,
        "input_cost_per_token_priority": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_flex": 5e-06,
        "output_cost_per_token_priority": 2e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "gpt-5-chat": {
        "display_name": "GPT-5 Chat",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 1.25e-07,
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": false,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "gpt-5-chat-latest": {
        "display_name": "GPT-5 Chat Latest",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 1.25e-07,
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": false,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "gpt-5-codex": {
        "display_name": "GPT-5 Codex",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 1.25e-07,
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5.1-codex": {
        "display_name": "GPT-5.1 Codex",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 1.25e-07,
        "cache_read_input_token_cost_priority": 2.5e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_priority": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_priority": 2e-05,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5.1-codex-max": {
        "display_name": "GPT 5.1 Codex Max",
        "model_vendor": "openai",
        "model_version": "5.1",
        "cache_read_input_token_cost": 1.25e-07,
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 400000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5.1-codex-mini": {
        "display_name": "GPT-5.1 Codex Mini",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 2.5e-08,
        "cache_read_input_token_cost_priority": 4.5e-08,
        "input_cost_per_token": 2.5e-07,
        "input_cost_per_token_priority": 4.5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "output_cost_per_token": 2e-06,
        "output_cost_per_token_priority": 3.6e-06,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5-mini": {
        "display_name": "GPT-5 Mini",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 2.5e-08,
        "cache_read_input_token_cost_flex": 1.25e-08,
        "cache_read_input_token_cost_priority": 4.5e-08,
        "input_cost_per_token": 2.5e-07,
        "input_cost_per_token_flex": 1.25e-07,
        "input_cost_per_token_priority": 4.5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "output_cost_per_token_flex": 1e-06,
        "output_cost_per_token_priority": 3.6e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "gpt-5-mini-2025-08-07": {
        "display_name": "GPT-5 Mini",
        "model_vendor": "openai",
        "model_version": "2025-08-07",
        "cache_read_input_token_cost": 2.5e-08,
        "cache_read_input_token_cost_flex": 1.25e-08,
        "cache_read_input_token_cost_priority": 4.5e-08,
        "input_cost_per_token": 2.5e-07,
        "input_cost_per_token_flex": 1.25e-07,
        "input_cost_per_token_priority": 4.5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "output_cost_per_token_flex": 1e-06,
        "output_cost_per_token_priority": 3.6e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "gpt-5-nano": {
        "display_name": "GPT-5 Nano",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 5e-09,
        "cache_read_input_token_cost_flex": 2.5e-09,
        "input_cost_per_token": 5e-08,
        "input_cost_per_token_flex": 2.5e-08,
        "input_cost_per_token_priority": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "output_cost_per_token_flex": 2e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5-nano-2025-08-07": {
        "display_name": "GPT-5 Nano",
        "model_vendor": "openai",
        "model_version": "2025-08-07",
        "cache_read_input_token_cost": 5e-09,
        "cache_read_input_token_cost_flex": 2.5e-09,
        "input_cost_per_token": 5e-08,
        "input_cost_per_token_flex": 2.5e-08,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "output_cost_per_token_flex": 2e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-image-1": {
        "display_name": "GPT Image 1",
        "model_vendor": "openai",
        "input_cost_per_image": 0.042,
        "input_cost_per_pixel": 4.0054321e-08,
        "input_cost_per_token": 5e-06,
        "input_cost_per_image_token": 1e-05,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "output_cost_per_token": 4e-05,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "gpt-image-1-mini": {
        "display_name": "GPT Image 1 Mini",
        "model_vendor": "openai",
        "cache_read_input_image_token_cost": 2.5e-07,
        "cache_read_input_token_cost": 2e-07,
        "input_cost_per_image_token": 2.5e-06,
        "input_cost_per_token": 2e-06,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_image_token": 8e-06,
        "supported_endpoints": [
            "/v1/images/generations",
            "/v1/images/edits"
        ]
    },
    "gpt-realtime": {
        "display_name": "GPT Realtime",
        "model_vendor": "openai",
        "cache_creation_input_audio_token_cost": 4e-07,
        "cache_read_input_token_cost": 4e-07,
        "input_cost_per_audio_token": 3.2e-05,
        "input_cost_per_image": 5e-06,
        "input_cost_per_token": 4e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 32000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 6.4e-05,
        "output_cost_per_token": 1.6e-05,
        "supported_endpoints": [
            "/v1/realtime"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-realtime-mini": {
        "display_name": "GPT Realtime Mini",
        "model_vendor": "openai",
        "cache_creation_input_audio_token_cost": 3e-07,
        "cache_read_input_audio_token_cost": 3e-07,
        "input_cost_per_audio_token": 1e-05,
        "input_cost_per_token": 6e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 2e-05,
        "output_cost_per_token": 2.4e-06,
        "supported_endpoints": [
            "/v1/realtime"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-realtime-2025-08-28": {
        "display_name": "GPT Realtime",
        "model_vendor": "openai",
        "model_version": "2025-08-28",
        "cache_creation_input_audio_token_cost": 4e-07,
        "cache_read_input_token_cost": 4e-07,
        "input_cost_per_audio_token": 3.2e-05,
        "input_cost_per_image": 5e-06,
        "input_cost_per_token": 4e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 32000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 6.4e-05,
        "output_cost_per_token": 1.6e-05,
        "supported_endpoints": [
            "/v1/realtime"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gradient_ai/alibaba-qwen3-32b": {
        "display_name": "Qwen3 32B",
        "model_vendor": "alibaba",
        "litellm_provider": "gradient_ai",
        "max_tokens": 2048,
        "mode": "chat",
        "supported_endpoints": [
            "/v1/chat/completions"
        ],
        "supported_modalities": [
            "text"
        ],
        "supports_tool_choice": false
    },
    "gradient_ai/anthropic-claude-3-opus": {
        "display_name": "Claude 3 Opus",
        "model_vendor": "anthropic",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "gradient_ai",
        "max_tokens": 1024,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "supported_endpoints": [
            "/v1/chat/completions"
        ],
        "supported_modalities": [
            "text"
        ],
        "supports_tool_choice": false
    },
    "gradient_ai/anthropic-claude-3.5-haiku": {
        "display_name": "Claude 3.5 Haiku",
        "model_vendor": "anthropic",
        "input_cost_per_token": 8e-07,
        "litellm_provider": "gradient_ai",
        "max_tokens": 1024,
        "mode": "chat",
        "output_cost_per_token": 4e-06,
        "supported_endpoints": [
            "/v1/chat/completions"
        ],
        "supported_modalities": [
            "text"
        ],
        "supports_tool_choice": false
    },
    "gradient_ai/anthropic-claude-3.5-sonnet": {
        "display_name": "Claude 3.5 Sonnet",
        "model_vendor": "anthropic",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "gradient_ai",
        "max_tokens": 1024,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supported_endpoints": [
            "/v1/chat/completions"
        ],
        "supported_modalities": [
            "text"
        ],
        "supports_tool_choice": false
    },
    "gradient_ai/anthropic-claude-3.7-sonnet": {
        "display_name": "Claude 3.7 Sonnet",
        "model_vendor": "anthropic",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "gradient_ai",
        "max_tokens": 1024,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supported_endpoints": [
            "/v1/chat/completions"
        ],
        "supported_modalities": [
            "text"
        ],
        "supports_tool_choice": false
    },
    "gradient_ai/deepseek-r1-distill-llama-70b": {
        "display_name": "DeepSeek R1 Distill Llama 70B",
        "model_vendor": "deepseek",
        "input_cost_per_token": 9.9e-07,
        "litellm_provider": "gradient_ai",
        "max_tokens": 8000,
        "mode": "chat",
        "output_cost_per_token": 9.9e-07,
        "supported_endpoints": [
            "/v1/chat/completions"
        ],
        "supported_modalities": [
            "text"
        ],
        "supports_tool_choice": false
    },
    "gradient_ai/llama3-8b-instruct": {
        "display_name": "Llama 3 8B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "gradient_ai",
        "max_tokens": 512,
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "supported_endpoints": [
            "/v1/chat/completions"
        ],
        "supported_modalities": [
            "text"
        ],
        "supports_tool_choice": false
    },
    "gradient_ai/llama3.3-70b-instruct": {
        "display_name": "Llama 3.3 70B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 6.5e-07,
        "litellm_provider": "gradient_ai",
        "max_tokens": 2048,
        "mode": "chat",
        "output_cost_per_token": 6.5e-07,
        "supported_endpoints": [
            "/v1/chat/completions"
        ],
        "supported_modalities": [
            "text"
        ],
        "supports_tool_choice": false
    },
    "gradient_ai/mistral-nemo-instruct-2407": {
        "display_name": "Mistral Nemo Instruct 2407",
        "model_vendor": "mistralai",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "gradient_ai",
        "max_tokens": 512,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "supported_endpoints": [
            "/v1/chat/completions"
        ],
        "supported_modalities": [
            "text"
        ],
        "supports_tool_choice": false
    },
    "gradient_ai/openai-gpt-4o": {
        "display_name": "GPT-4o",
        "model_vendor": "openai",
        "litellm_provider": "gradient_ai",
        "max_tokens": 16384,
        "mode": "chat",
        "supported_endpoints": [
            "/v1/chat/completions"
        ],
        "supported_modalities": [
            "text"
        ],
        "supports_tool_choice": false
    },
    "gradient_ai/openai-gpt-4o-mini": {
        "display_name": "GPT-4o Mini",
        "model_vendor": "openai",
        "litellm_provider": "gradient_ai",
        "max_tokens": 16384,
        "mode": "chat",
        "supported_endpoints": [
            "/v1/chat/completions"
        ],
        "supported_modalities": [
            "text"
        ],
        "supports_tool_choice": false
    },
    "gradient_ai/openai-o3": {
        "display_name": "o3",
        "model_vendor": "openai",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "gradient_ai",
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "supported_endpoints": [
            "/v1/chat/completions"
        ],
        "supported_modalities": [
            "text"
        ],
        "supports_tool_choice": false
    },
    "gradient_ai/openai-o3-mini": {
        "display_name": "o3 Mini",
        "model_vendor": "openai",
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "gradient_ai",
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 4.4e-06,
        "supported_endpoints": [
            "/v1/chat/completions"
        ],
        "supported_modalities": [
            "text"
        ],
        "supports_tool_choice": false
    },
    "lemonade/Qwen3-Coder-30B-A3B-Instruct-GGUF": {
        "display_name": "Qwen3 Coder 30B A3B Instruct",
        "model_vendor": "alibaba",
        "input_cost_per_token": 0,
        "litellm_provider": "lemonade",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 0,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "lemonade/gpt-oss-20b-mxfp4-GGUF": {
        "display_name": "GPT OSS 20B",
        "model_vendor": "openai",
        "input_cost_per_token": 0,
        "litellm_provider": "lemonade",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 0,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "lemonade/gpt-oss-120b-mxfp-GGUF": {
        "display_name": "GPT OSS 120B",
        "model_vendor": "openai",
        "input_cost_per_token": 0,
        "litellm_provider": "lemonade",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 0,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "lemonade/Gemma-3-4b-it-GGUF": {
        "display_name": "Gemma 3 4B IT",
        "model_vendor": "google",
        "input_cost_per_token": 0,
        "litellm_provider": "lemonade",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 0,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "lemonade/Qwen3-4B-Instruct-2507-GGUF": {
        "display_name": "Qwen3 4B Instruct 2507",
        "model_vendor": "alibaba",
        "input_cost_per_token": 0,
        "litellm_provider": "lemonade",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 0,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "amazon-nova/nova-micro-v1": {
        "display_name": "Nova Micro V1",
        "model_vendor": "amazon",
        "input_cost_per_token": 3.5e-08,
        "litellm_provider": "amazon_nova",
        "max_input_tokens": 128000,
        "max_output_tokens": 10000,
        "max_tokens": 10000,
        "mode": "chat",
        "output_cost_per_token": 1.4e-07,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true
    },
    "amazon-nova/nova-lite-v1": {
        "display_name": "Nova Lite V1",
        "model_vendor": "amazon",
        "input_cost_per_token": 6e-08,
        "litellm_provider": "amazon_nova",
        "max_input_tokens": 300000,
        "max_output_tokens": 10000,
        "max_tokens": 10000,
        "mode": "chat",
        "output_cost_per_token": 2.4e-07,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "amazon-nova/nova-premier-v1": {
        "display_name": "Nova Premier V1",
        "model_vendor": "amazon",
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "amazon_nova",
        "max_input_tokens": 1000000,
        "max_output_tokens": 10000,
        "max_tokens": 10000,
        "mode": "chat",
        "output_cost_per_token": 1.25e-05,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": false,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "amazon-nova/nova-pro-v1": {
        "display_name": "Nova Pro V1",
        "model_vendor": "amazon",
        "input_cost_per_token": 8e-07,
        "litellm_provider": "amazon_nova",
        "max_input_tokens": 300000,
        "max_output_tokens": 10000,
        "max_tokens": 10000,
        "mode": "chat",
        "output_cost_per_token": 3.2e-06,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "groq/deepseek-r1-distill-llama-70b": {
        "display_name": "DeepSeek R1 Distill Llama 70B",
        "model_vendor": "deepseek",
        "input_cost_per_token": 7.5e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 9.9e-07,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": false,
        "supports_tool_choice": true
    },
    "groq/distil-whisper-large-v3-en": {
        "display_name": "Distil Whisper Large V3 EN",
        "model_vendor": "openai",
        "input_cost_per_second": 5.56e-06,
        "litellm_provider": "groq",
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0
    },
    "groq/gemma-7b-it": {
        "display_name": "Gemma 7B IT",
        "model_vendor": "google",
        "deprecation_date": "2024-12-18",
        "input_cost_per_token": 7e-08,
        "litellm_provider": "groq",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 7e-08,
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true
    },
    "groq/gemma2-9b-it": {
        "display_name": "Gemma 2 9B IT",
        "model_vendor": "google",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "supports_function_calling": false,
        "supports_response_schema": false,
        "supports_tool_choice": false
    },
    "groq/llama-3.1-405b-reasoning": {
        "display_name": "Llama 3.1 405B Reasoning",
        "model_vendor": "meta",
        "input_cost_per_token": 5.9e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 7.9e-07,
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true
    },
    "groq/llama-3.1-70b-versatile": {
        "display_name": "Llama 3.1 70B Versatile",
        "model_vendor": "meta",
        "deprecation_date": "2025-01-24",
        "input_cost_per_token": 5.9e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 7.9e-07,
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true
    },
    "groq/llama-3.1-8b-instant": {
        "display_name": "Llama 3.1 8B Instant",
        "model_vendor": "meta",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "groq",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 8e-08,
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true
    },
    "groq/llama-3.2-11b-text-preview": {
        "display_name": "Llama 3.2 11B Text Preview",
        "model_vendor": "meta",
        "deprecation_date": "2024-10-28",
        "input_cost_per_token": 1.8e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.8e-07,
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true
    },
    "groq/llama-3.2-11b-vision-preview": {
        "display_name": "Llama 3.2 11B Vision Preview",
        "model_vendor": "meta",
        "deprecation_date": "2025-04-14",
        "input_cost_per_token": 1.8e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.8e-07,
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "groq/llama-3.2-1b-preview": {
        "display_name": "Llama 3.2 1B Preview",
        "model_vendor": "meta",
        "deprecation_date": "2025-04-14",
        "input_cost_per_token": 4e-08,
        "litellm_provider": "groq",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 4e-08,
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true
    },
    "groq/llama-3.2-3b-preview": {
        "display_name": "Llama 3.2 3B Preview",
        "model_vendor": "meta",
        "deprecation_date": "2025-04-14",
        "input_cost_per_token": 6e-08,
        "litellm_provider": "groq",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 6e-08,
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true
    },
    "groq/llama-3.2-90b-text-preview": {
        "display_name": "Llama 3.2 90B Text Preview",
        "model_vendor": "meta",
        "deprecation_date": "2024-11-25",
        "input_cost_per_token": 9e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 9e-07,
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true
    },
    "groq/llama-3.2-90b-vision-preview": {
        "display_name": "Llama 3.2 90B Vision Preview",
        "model_vendor": "meta",
        "deprecation_date": "2025-04-14",
        "input_cost_per_token": 9e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 9e-07,
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "groq/llama-3.3-70b-specdec": {
        "display_name": "Llama 3.3 70B SpecDec",
        "model_vendor": "meta",
        "deprecation_date": "2025-04-14",
        "input_cost_per_token": 5.9e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 9.9e-07,
        "supports_tool_choice": true
    },
    "groq/llama-3.3-70b-versatile": {
        "display_name": "Llama 3.3 70B Versatile",
        "model_vendor": "meta",
        "input_cost_per_token": 5.9e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 7.9e-07,
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true
    },
    "groq/llama-guard-3-8b": {
        "display_name": "Llama Guard 3 8B",
        "model_vendor": "meta",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2e-07
    },
    "groq/llama2-70b-4096": {
        "display_name": "Llama 2 70B",
        "model_vendor": "meta",
        "input_cost_per_token": 7e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 8e-07,
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true
    },
    "groq/llama3-groq-70b-8192-tool-use-preview": {
        "display_name": "Llama 3 Groq 70B Tool Use Preview",
        "model_vendor": "meta",
        "deprecation_date": "2025-01-06",
        "input_cost_per_token": 8.9e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 8.9e-07,
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true
    },
    "groq/llama3-groq-8b-8192-tool-use-preview": {
        "display_name": "Llama 3 Groq 8B Tool Use Preview",
        "model_vendor": "meta",
        "deprecation_date": "2025-01-06",
        "input_cost_per_token": 1.9e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.9e-07,
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true
    },
    "groq/meta-llama/llama-4-maverick-17b-128e-instruct": {
        "display_name": "Llama 4 Maverick 17B 128E Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 131072,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "groq/meta-llama/llama-4-scout-17b-16e-instruct": {
        "display_name": "Llama 4 Scout 17B 16E Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1.1e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 131072,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 3.4e-07,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "groq/mistral-saba-24b": {
        "display_name": "Mistral Saba 24B",
        "model_vendor": "mistralai",
        "input_cost_per_token": 7.9e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 32000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 7.9e-07
    },
    "groq/mixtral-8x7b-32768": {
        "display_name": "Mixtral 8x7B",
        "model_vendor": "mistralai",
        "deprecation_date": "2025-03-20",
        "input_cost_per_token": 2.4e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 2.4e-07,
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true
    },
    "groq/moonshotai/kimi-k2-instruct": {
        "display_name": "Kimi K2 Instruct",
        "model_vendor": "moonshot",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "groq",
        "max_input_tokens": 131072,
        "max_output_tokens": 16384,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 3e-06,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "groq/moonshotai/kimi-k2-instruct-0905": {
        "display_name": "Kimi K2 Instruct 0905",
        "model_vendor": "moonshot",
        "model_version": "0905",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": 5e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 262144,
        "max_output_tokens": 16384,
        "max_tokens": 278528,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "groq/openai/gpt-oss-120b": {
        "display_name": "GPT OSS 120B",
        "model_vendor": "openai",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 131072,
        "max_output_tokens": 32766,
        "max_tokens": 32766,
        "mode": "chat",
        "output_cost_per_token": 7.5e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "groq/openai/gpt-oss-20b": {
        "display_name": "GPT OSS 20B",
        "model_vendor": "openai",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 131072,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 5e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "groq/playai-tts": {
        "display_name": "PlayAI TTS",
        "model_vendor": "playai",
        "input_cost_per_character": 5e-05,
        "litellm_provider": "groq",
        "max_input_tokens": 10000,
        "max_output_tokens": 10000,
        "max_tokens": 10000,
        "mode": "audio_speech"
    },
    "groq/qwen/qwen3-32b": {
        "display_name": "Qwen 3 32B",
        "model_vendor": "alibaba",
        "input_cost_per_token": 2.9e-07,
        "litellm_provider": "groq",
        "max_input_tokens": 131000,
        "max_output_tokens": 131000,
        "max_tokens": 131000,
        "mode": "chat",
        "output_cost_per_token": 5.9e-07,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": false,
        "supports_tool_choice": true
    },
    "groq/whisper-large-v3": {
        "display_name": "Whisper Large V3",
        "model_vendor": "openai",
        "model_version": "large-v3",
        "input_cost_per_second": 3.083e-05,
        "litellm_provider": "groq",
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0
    },
    "groq/whisper-large-v3-turbo": {
        "display_name": "Whisper Large V3 Turbo",
        "model_vendor": "openai",
        "model_version": "large-v3-turbo",
        "input_cost_per_second": 1.111e-05,
        "litellm_provider": "groq",
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0
    },
    "hd/1024-x-1024/dall-e-3": {
        "display_name": "DALL-E 3 HD 1024x1024",
        "model_vendor": "openai",
        "input_cost_per_pixel": 7.629e-08,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0
    },
    "hd/1024-x-1792/dall-e-3": {
        "display_name": "DALL-E 3 HD 1024x1792",
        "model_vendor": "openai",
        "input_cost_per_pixel": 6.539e-08,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0
    },
    "hd/1792-x-1024/dall-e-3": {
        "display_name": "DALL-E 3 HD 1792x1024",
        "model_vendor": "openai",
        "input_cost_per_pixel": 6.539e-08,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0
    },
    "heroku/claude-3-5-haiku": {
        "display_name": "Claude 3.5 Haiku",
        "model_vendor": "anthropic",
        "litellm_provider": "heroku",
        "max_tokens": 4096,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "heroku/claude-3-5-sonnet-latest": {
        "display_name": "Claude 3.5 Sonnet",
        "model_vendor": "anthropic",
        "litellm_provider": "heroku",
        "max_tokens": 8192,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "heroku/claude-3-7-sonnet": {
        "display_name": "Claude 3.7 Sonnet",
        "model_vendor": "anthropic",
        "litellm_provider": "heroku",
        "max_tokens": 8192,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "heroku/claude-4-sonnet": {
        "display_name": "Claude Sonnet 4",
        "model_vendor": "anthropic",
        "litellm_provider": "heroku",
        "max_tokens": 8192,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "high/1024-x-1024/gpt-image-1": {
        "display_name": "GPT Image 1 High 1024x1024",
        "model_vendor": "openai",
        "input_cost_per_image": 0.167,
        "input_cost_per_pixel": 1.59263611e-07,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "high/1024-x-1536/gpt-image-1": {
        "display_name": "GPT Image 1 High 1024x1536",
        "model_vendor": "openai",
        "input_cost_per_image": 0.25,
        "input_cost_per_pixel": 1.58945719e-07,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "high/1536-x-1024/gpt-image-1": {
        "display_name": "GPT Image 1 High 1536x1024",
        "model_vendor": "openai",
        "input_cost_per_image": 0.25,
        "input_cost_per_pixel": 1.58945719e-07,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "hyperbolic/NousResearch/Hermes-3-Llama-3.1-70B": {
        "display_name": "Hermes 3 Llama 3.1 70B",
        "model_vendor": "nousresearch",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "hyperbolic",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "hyperbolic/Qwen/QwQ-32B": {
        "display_name": "QwQ 32B",
        "model_vendor": "alibaba",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "hyperbolic",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "hyperbolic/Qwen/Qwen2.5-72B-Instruct": {
        "display_name": "Qwen 2.5 72B Instruct",
        "model_vendor": "alibaba",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "hyperbolic",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "hyperbolic/Qwen/Qwen2.5-Coder-32B-Instruct": {
        "display_name": "Qwen 2.5 Coder 32B Instruct",
        "model_vendor": "alibaba",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "hyperbolic",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "hyperbolic/Qwen/Qwen3-235B-A22B": {
        "display_name": "Qwen 3 235B A22B",
        "model_vendor": "alibaba",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "hyperbolic",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "hyperbolic/deepseek-ai/DeepSeek-R1": {
        "display_name": "DeepSeek R1",
        "model_vendor": "deepseek",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "hyperbolic",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "hyperbolic/deepseek-ai/DeepSeek-R1-0528": {
        "display_name": "DeepSeek R1 0528",
        "model_vendor": "deepseek",
        "model_version": "0528",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "hyperbolic",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 2.5e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "hyperbolic/deepseek-ai/DeepSeek-V3": {
        "display_name": "DeepSeek V3",
        "model_vendor": "deepseek",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "hyperbolic",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "hyperbolic/deepseek-ai/DeepSeek-V3-0324": {
        "display_name": "DeepSeek V3 0324",
        "model_vendor": "deepseek",
        "model_version": "0324",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "hyperbolic",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "hyperbolic/meta-llama/Llama-3.2-3B-Instruct": {
        "display_name": "Llama 3.2 3B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "hyperbolic",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "hyperbolic/meta-llama/Llama-3.3-70B-Instruct": {
        "display_name": "Llama 3.3 70B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "hyperbolic",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "hyperbolic/meta-llama/Meta-Llama-3-70B-Instruct": {
        "display_name": "Meta Llama 3 70B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "hyperbolic",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct": {
        "display_name": "Meta Llama 3.1 405B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "hyperbolic",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct": {
        "display_name": "Meta Llama 3.1 70B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "hyperbolic",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct": {
        "display_name": "Meta Llama 3.1 8B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "hyperbolic",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "hyperbolic/moonshotai/Kimi-K2-Instruct": {
        "display_name": "Kimi K2 Instruct",
        "model_vendor": "moonshot",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "hyperbolic",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "j2-light": {
        "display_name": "J2 Light",
        "model_vendor": "ai21",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "ai21",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "completion",
        "output_cost_per_token": 3e-06
    },
    "j2-mid": {
        "display_name": "J2 Mid",
        "model_vendor": "ai21",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "ai21",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "completion",
        "output_cost_per_token": 1e-05
    },
    "j2-ultra": {
        "display_name": "J2 Ultra",
        "model_vendor": "ai21",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "ai21",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "completion",
        "output_cost_per_token": 1.5e-05
    },
    "jamba-1.5": {
        "display_name": "Jamba 1.5",
        "model_vendor": "ai21",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "ai21",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "supports_tool_choice": true
    },
    "jamba-1.5-large": {
        "display_name": "Jamba 1.5 Large",
        "model_vendor": "ai21",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "ai21",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "supports_tool_choice": true
    },
    "jamba-1.5-large@001": {
        "display_name": "Jamba 1.5 Large @001",
        "model_vendor": "ai21",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "ai21",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "supports_tool_choice": true
    },
    "jamba-1.5-mini": {
        "display_name": "Jamba 1.5 Mini",
        "model_vendor": "ai21",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "ai21",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "supports_tool_choice": true
    },
    "jamba-1.5-mini@001": {
        "display_name": "Jamba 1.5 Mini @001",
        "model_vendor": "ai21",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "ai21",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "supports_tool_choice": true
    },
    "jamba-large-1.6": {
        "display_name": "Jamba Large 1.6",
        "model_vendor": "ai21",
        "model_version": "1.6",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "ai21",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "supports_tool_choice": true
    },
    "jamba-large-1.7": {
        "display_name": "Jamba Large 1.7",
        "model_vendor": "ai21",
        "model_version": "1.7",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "ai21",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "supports_tool_choice": true
    },
    "jamba-mini-1.6": {
        "display_name": "Jamba Mini 1.6",
        "model_vendor": "ai21",
        "model_version": "1.6",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "ai21",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "supports_tool_choice": true
    },
    "jamba-mini-1.7": {
        "display_name": "Jamba Mini 1.7",
        "model_vendor": "ai21",
        "model_version": "1.7",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "ai21",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "supports_tool_choice": true
    },
    "jina-reranker-v2-base-multilingual": {
        "display_name": "Jina Reranker V2 Base Multilingual",
        "model_vendor": "jina",
        "input_cost_per_token": 1.8e-08,
        "litellm_provider": "jina_ai",
        "max_document_chunks_per_query": 2048,
        "max_input_tokens": 1024,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "rerank",
        "output_cost_per_token": 1.8e-08
    },
    "jp.anthropic.claude-sonnet-4-5-20250929-v1:0": {
        "display_name": "Claude Sonnet 4.5",
        "model_vendor": "anthropic",
        "model_version": "20250929",
        "cache_creation_input_token_cost": 4.125e-06,
        "cache_read_input_token_cost": 3.3e-07,
        "input_cost_per_token": 3.3e-06,
        "input_cost_per_token_above_200k_tokens": 6.6e-06,
        "output_cost_per_token_above_200k_tokens": 2.475e-05,
        "cache_creation_input_token_cost_above_200k_tokens": 8.25e-06,
        "cache_read_input_token_cost_above_200k_tokens": 6.6e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 1.65e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 346
    },
    "jp.anthropic.claude-haiku-4-5-20251001-v1:0": {
        "display_name": "Claude Haiku 4.5",
        "model_vendor": "anthropic",
        "model_version": "20251001",
        "cache_creation_input_token_cost": 1.375e-06,
        "cache_read_input_token_cost": 1.1e-07,
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 5.5e-06,
        "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 346
    },
    "lambda_ai/deepseek-llama3.3-70b": {
        "display_name": "DeepSeek Llama 3.3 70B",
        "model_vendor": "deepseek",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "lambda_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_reasoning": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "lambda_ai/deepseek-r1-0528": {
        "display_name": "DeepSeek R1 0528",
        "model_vendor": "deepseek",
        "model_version": "0528",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "lambda_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_reasoning": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "lambda_ai/deepseek-r1-671b": {
        "display_name": "DeepSeek R1 671B",
        "model_vendor": "deepseek",
        "input_cost_per_token": 8e-07,
        "litellm_provider": "lambda_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 8e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_reasoning": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "lambda_ai/deepseek-v3-0324": {
        "display_name": "DeepSeek V3 0324",
        "model_vendor": "deepseek",
        "model_version": "0324",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "lambda_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "lambda_ai/hermes3-405b": {
        "display_name": "Hermes 3 405B",
        "model_vendor": "nousresearch",
        "input_cost_per_token": 8e-07,
        "litellm_provider": "lambda_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 8e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "lambda_ai/hermes3-70b": {
        "display_name": "Hermes 3 70B",
        "model_vendor": "nousresearch",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "lambda_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "lambda_ai/hermes3-8b": {
        "display_name": "Hermes 3 8B",
        "model_vendor": "nousresearch",
        "input_cost_per_token": 2.5e-08,
        "litellm_provider": "lambda_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 4e-08,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "lambda_ai/lfm-40b": {
        "display_name": "LFM 40B",
        "model_vendor": "lambda",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "lambda_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "lambda_ai/lfm-7b": {
        "display_name": "LFM 7B",
        "model_vendor": "lambda",
        "input_cost_per_token": 2.5e-08,
        "litellm_provider": "lambda_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 4e-08,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "lambda_ai/llama-4-maverick-17b-128e-instruct-fp8": {
        "display_name": "Llama 4 Maverick 17B 128E Instruct FP8",
        "model_vendor": "meta",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "lambda_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 8192,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "lambda_ai/llama-4-scout-17b-16e-instruct": {
        "display_name": "Llama 4 Scout 17B 16E Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "lambda_ai",
        "max_input_tokens": 16384,
        "max_output_tokens": 8192,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "lambda_ai/llama3.1-405b-instruct-fp8": {
        "display_name": "Llama 3.1 405B Instruct FP8",
        "model_vendor": "meta",
        "input_cost_per_token": 8e-07,
        "litellm_provider": "lambda_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 8e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "lambda_ai/llama3.1-70b-instruct-fp8": {
        "display_name": "Llama 3.1 70B Instruct FP8",
        "model_vendor": "meta",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "lambda_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "lambda_ai/llama3.1-8b-instruct": {
        "display_name": "Llama 3.1 8B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 2.5e-08,
        "litellm_provider": "lambda_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 4e-08,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "lambda_ai/llama3.1-nemotron-70b-instruct-fp8": {
        "display_name": "Llama 3.1 Nemotron 70B Instruct FP8",
        "model_vendor": "nvidia",
        "model_version": "3.1-nemotron",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "lambda_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "lambda_ai/llama3.2-11b-vision-instruct": {
        "display_name": "Llama 3.2 11B Vision Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1.5e-08,
        "litellm_provider": "lambda_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 2.5e-08,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "lambda_ai/llama3.2-3b-instruct": {
        "display_name": "Llama 3.2 3B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1.5e-08,
        "litellm_provider": "lambda_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 2.5e-08,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "lambda_ai/llama3.3-70b-instruct-fp8": {
        "display_name": "Llama 3.3 70B Instruct FP8",
        "model_vendor": "meta",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "lambda_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "lambda_ai/qwen25-coder-32b-instruct": {
        "display_name": "Qwen 2.5 Coder 32B Instruct",
        "model_vendor": "alibaba",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "lambda_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "lambda_ai/qwen3-32b-fp8": {
        "display_name": "Qwen 3 32B FP8",
        "model_vendor": "alibaba",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "lambda_ai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_reasoning": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "low/1024-x-1024/gpt-image-1": {
        "display_name": "GPT Image 1 Low 1024x1024",
        "model_vendor": "openai",
        "input_cost_per_image": 0.011,
        "input_cost_per_pixel": 1.0490417e-08,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "low/1024-x-1536/gpt-image-1": {
        "display_name": "GPT Image 1 Low 1024x1536",
        "model_vendor": "openai",
        "input_cost_per_image": 0.016,
        "input_cost_per_pixel": 1.0172526e-08,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "low/1536-x-1024/gpt-image-1": {
        "display_name": "GPT Image 1 Low 1536x1024",
        "model_vendor": "openai",
        "input_cost_per_image": 0.016,
        "input_cost_per_pixel": 1.0172526e-08,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "luminous-base": {
        "display_name": "Luminous Base",
        "model_vendor": "aleph_alpha",
        "input_cost_per_token": 3e-05,
        "litellm_provider": "aleph_alpha",
        "max_tokens": 2048,
        "mode": "completion",
        "output_cost_per_token": 3.3e-05
    },
    "luminous-base-control": {
        "display_name": "Luminous Base Control",
        "model_vendor": "aleph_alpha",
        "input_cost_per_token": 3.75e-05,
        "litellm_provider": "aleph_alpha",
        "max_tokens": 2048,
        "mode": "chat",
        "output_cost_per_token": 4.125e-05
    },
    "luminous-extended": {
        "display_name": "Luminous Extended",
        "model_vendor": "aleph_alpha",
        "input_cost_per_token": 4.5e-05,
        "litellm_provider": "aleph_alpha",
        "max_tokens": 2048,
        "mode": "completion",
        "output_cost_per_token": 4.95e-05
    },
    "luminous-extended-control": {
        "display_name": "Luminous Extended Control",
        "model_vendor": "aleph_alpha",
        "input_cost_per_token": 5.625e-05,
        "litellm_provider": "aleph_alpha",
        "max_tokens": 2048,
        "mode": "chat",
        "output_cost_per_token": 6.1875e-05
    },
    "luminous-supreme": {
        "display_name": "Luminous Supreme",
        "model_vendor": "aleph_alpha",
        "input_cost_per_token": 0.000175,
        "litellm_provider": "aleph_alpha",
        "max_tokens": 2048,
        "mode": "completion",
        "output_cost_per_token": 0.0001925
    },
    "luminous-supreme-control": {
        "display_name": "Luminous Supreme Control",
        "model_vendor": "aleph_alpha",
        "input_cost_per_token": 0.00021875,
        "litellm_provider": "aleph_alpha",
        "max_tokens": 2048,
        "mode": "chat",
        "output_cost_per_token": 0.000240625
    },
    "max-x-max/50-steps/stability.stable-diffusion-xl-v0": {
        "display_name": "Stable Diffusion XL V0 50 Steps",
        "model_vendor": "stability",
        "model_version": "xl-v0",
        "litellm_provider": "bedrock",
        "max_input_tokens": 77,
        "max_tokens": 77,
        "mode": "image_generation",
        "output_cost_per_image": 0.036
    },
    "max-x-max/max-steps/stability.stable-diffusion-xl-v0": {
        "display_name": "Stable Diffusion XL V0 Max Steps",
        "model_vendor": "stability",
        "model_version": "xl-v0",
        "litellm_provider": "bedrock",
        "max_input_tokens": 77,
        "max_tokens": 77,
        "mode": "image_generation",
        "output_cost_per_image": 0.072
    },
    "medium/1024-x-1024/gpt-image-1": {
        "display_name": "GPT Image 1 Medium 1024x1024",
        "model_vendor": "openai",
        "input_cost_per_image": 0.042,
        "input_cost_per_pixel": 4.0054321e-08,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "medium/1024-x-1536/gpt-image-1": {
        "display_name": "GPT Image 1 Medium 1024x1536",
        "model_vendor": "openai",
        "input_cost_per_image": 0.063,
        "input_cost_per_pixel": 4.0054321e-08,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "medium/1536-x-1024/gpt-image-1": {
        "display_name": "GPT Image 1 Medium 1536x1024",
        "model_vendor": "openai",
        "input_cost_per_image": 0.063,
        "input_cost_per_pixel": 4.0054321e-08,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "low/1024-x-1024/gpt-image-1-mini": {
        "display_name": "GPT Image 1 Mini Low 1024x1024",
        "model_vendor": "openai",
        "model_version": "1-mini",
        "input_cost_per_image": 0.005,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "low/1024-x-1536/gpt-image-1-mini": {
        "display_name": "GPT Image 1 Mini Low 1024x1536",
        "model_vendor": "openai",
        "model_version": "1-mini",
        "input_cost_per_image": 0.006,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "low/1536-x-1024/gpt-image-1-mini": {
        "display_name": "GPT Image 1 Mini Low 1536x1024",
        "model_vendor": "openai",
        "model_version": "1-mini",
        "input_cost_per_image": 0.006,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "medium/1024-x-1024/gpt-image-1-mini": {
        "display_name": "GPT Image 1 Mini Medium 1024x1024",
        "model_vendor": "openai",
        "model_version": "1-mini",
        "input_cost_per_image": 0.011,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "medium/1024-x-1536/gpt-image-1-mini": {
        "display_name": "GPT Image 1 Mini Medium 1024x1536",
        "model_vendor": "openai",
        "model_version": "1-mini",
        "input_cost_per_image": 0.015,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "medium/1536-x-1024/gpt-image-1-mini": {
        "display_name": "GPT Image 1 Mini Medium 1536x1024",
        "model_vendor": "openai",
        "model_version": "1-mini",
        "input_cost_per_image": 0.015,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "medlm-large": {
        "display_name": "MedLM Large",
        "model_vendor": "google",
        "input_cost_per_character": 5e-06,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 8192,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "chat",
        "output_cost_per_character": 1.5e-05,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "medlm-medium": {
        "display_name": "MedLM Medium",
        "model_vendor": "google",
        "input_cost_per_character": 5e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 32768,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 1e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "meta.llama2-13b-chat-v1": {
        "display_name": "Llama 2 13B Chat",
        "model_vendor": "meta",
        "input_cost_per_token": 7.5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1e-06
    },
    "meta.llama2-70b-chat-v1": {
        "display_name": "Llama 2 70B Chat",
        "model_vendor": "meta",
        "input_cost_per_token": 1.95e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 2.56e-06
    },
    "meta.llama3-1-405b-instruct-v1:0": {
        "display_name": "Llama 3.1 405B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 5.32e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.6e-05,
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "meta.llama3-1-70b-instruct-v1:0": {
        "display_name": "Llama 3.1 70B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 9.9e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 9.9e-07,
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "meta.llama3-1-8b-instruct-v1:0": {
        "display_name": "Llama 3.1 8B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 2.2e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 2.2e-07,
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "meta.llama3-2-11b-instruct-v1:0": {
        "display_name": "Llama 3.2 11B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 3.5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 3.5e-07,
        "supports_function_calling": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "meta.llama3-2-1b-instruct-v1:0": {
        "display_name": "Llama 3.2 1B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-07,
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "meta.llama3-2-3b-instruct-v1:0": {
        "display_name": "Llama 3.2 3B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-07,
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "meta.llama3-2-90b-instruct-v1:0": {
        "display_name": "Llama 3.2 90B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "supports_function_calling": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "meta.llama3-3-70b-instruct-v1:0": {
        "display_name": "Llama 3.3 70B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 7.2e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 7.2e-07,
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "meta.llama3-70b-instruct-v1:0": {
        "display_name": "Llama 3 70B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 2.65e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 3.5e-06
    },
    "meta.llama3-8b-instruct-v1:0": {
        "display_name": "Llama 3 8B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 6e-07
    },
    "meta.llama4-maverick-17b-instruct-v1:0": {
        "display_name": "Llama 4 Maverick 17B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 2.4e-07,
        "input_cost_per_token_batches": 1.2e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 9.7e-07,
        "output_cost_per_token_batches": 4.85e-07,
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "code"
        ],
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "meta.llama4-scout-17b-instruct-v1:0": {
        "display_name": "Llama 4 Scout 17B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1.7e-07,
        "input_cost_per_token_batches": 8.5e-08,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6.6e-07,
        "output_cost_per_token_batches": 3.3e-07,
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "code"
        ],
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "meta_llama/Llama-3.3-70B-Instruct": {
        "display_name": "Llama 3.3 70B Instruct",
        "model_vendor": "meta",
        "litellm_provider": "meta_llama",
        "max_input_tokens": 128000,
        "max_output_tokens": 4028,
        "max_tokens": 128000,
        "mode": "chat",
        "source": "https://llama.developer.meta.com/docs/models",
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "meta_llama/Llama-3.3-8B-Instruct": {
        "display_name": "Llama 3.3 8B Instruct",
        "model_vendor": "meta",
        "litellm_provider": "meta_llama",
        "max_input_tokens": 128000,
        "max_output_tokens": 4028,
        "max_tokens": 128000,
        "mode": "chat",
        "source": "https://llama.developer.meta.com/docs/models",
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
        "display_name": "Llama 4 Maverick 17B 128E Instruct FP8",
        "model_vendor": "meta",
        "litellm_provider": "meta_llama",
        "max_input_tokens": 1000000,
        "max_output_tokens": 4028,
        "max_tokens": 128000,
        "mode": "chat",
        "source": "https://llama.developer.meta.com/docs/models",
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8": {
        "display_name": "Llama 4 Scout 17B 16E Instruct FP8",
        "model_vendor": "meta",
        "litellm_provider": "meta_llama",
        "max_input_tokens": 10000000,
        "max_output_tokens": 4028,
        "max_tokens": 128000,
        "mode": "chat",
        "source": "https://llama.developer.meta.com/docs/models",
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "minimax.minimax-m2": {
        "display_name": "Minimax M2",
        "model_vendor": "minimax",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.2e-06,
        "supports_system_messages": true
    },
    "mistral.magistral-small-2509": {
        "display_name": "Magistral Small 2509",
        "model_vendor": "mistral",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_system_messages": true
    },
    "mistral.ministral-3-14b-instruct": {
        "display_name": "Ministral 3 14B Instruct",
        "model_vendor": "mistral",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "supports_function_calling": true,
        "supports_system_messages": true
    },
    "mistral.ministral-3-3b-instruct": {
        "display_name": "Ministral 3 3B Instruct",
        "model_vendor": "mistral",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1e-07,
        "supports_function_calling": true,
        "supports_system_messages": true
    },
    "mistral.ministral-3-8b-instruct": {
        "display_name": "Ministral 3 8B Instruct",
        "model_vendor": "mistral",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-07,
        "supports_function_calling": true,
        "supports_system_messages": true
    },
    "mistral.mistral-7b-instruct-v0:2": {
        "display_name": "Mistral 7B Instruct V0.2",
        "model_vendor": "mistralai",
        "model_version": "0.2",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "supports_tool_choice": true
    },
    "mistral.mistral-large-2402-v1:0": {
        "display_name": "Mistral Large 2402",
        "model_vendor": "mistralai",
        "model_version": "2402",
        "input_cost_per_token": 8e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 2.4e-05,
        "supports_function_calling": true
    },
    "mistral.mistral-large-2407-v1:0": {
        "display_name": "Mistral Large 2407",
        "model_vendor": "mistralai",
        "model_version": "2407",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 9e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "mistral.mistral-large-3-675b-instruct": {
        "display_name": "Mistral Large 3 675B Instruct",
        "model_vendor": "mistral",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "supports_function_calling": true,
        "supports_system_messages": true
    },
    "mistral.mistral-small-2402-v1:0": {
        "display_name": "Mistral Small 2402",
        "model_vendor": "mistralai",
        "model_version": "2402",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 3e-06,
        "supports_function_calling": true
    },
    "mistral.mixtral-8x7b-instruct-v0:1": {
        "display_name": "Mixtral 8x7B Instruct V0.1",
        "model_vendor": "mistralai",
        "input_cost_per_token": 4.5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 7e-07,
        "supports_tool_choice": true
    },
    "mistral.voxtral-mini-3b-2507": {
        "display_name": "Voxtral Mini 3B 2507",
        "model_vendor": "mistral",
        "input_cost_per_token": 4e-08,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 4e-08,
        "supports_audio_input": true,
        "supports_system_messages": true
    },
    "mistral.voxtral-small-24b-2507": {
        "display_name": "Voxtral Small 24B 2507",
        "model_vendor": "mistral",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "supports_audio_input": true,
        "supports_system_messages": true
    },
    "mistral/codestral-2405": {
        "display_name": "Codestral 2405",
        "model_vendor": "mistralai",
        "model_version": "2405",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "mistral",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 3e-06,
        "supports_assistant_prefill": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/codestral-2508": {
        "display_name": "Mistral Codestral 2508",
        "model_vendor": "mistral",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 9e-07,
        "source": "https://mistral.ai/news/codestral-25-08",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/codestral-latest": {
        "display_name": "Codestral Latest",
        "model_vendor": "mistralai",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "mistral",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 3e-06,
        "supports_assistant_prefill": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/codestral-mamba-latest": {
        "display_name": "Codestral Mamba Latest",
        "model_vendor": "mistralai",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 2.5e-07,
        "source": "https://mistral.ai/technology/",
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "mistral/devstral-medium-2507": {
        "display_name": "Devstral Medium 2507",
        "model_vendor": "mistralai",
        "model_version": "2507",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "source": "https://mistral.ai/news/devstral",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/devstral-small-2505": {
        "display_name": "Devstral Small 2505",
        "model_vendor": "mistralai",
        "model_version": "2505",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "source": "https://mistral.ai/news/devstral",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/devstral-small-2507": {
        "display_name": "Devstral Small 2507",
        "model_vendor": "mistralai",
        "model_version": "2507",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "source": "https://mistral.ai/news/devstral",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/labs-devstral-small-2512": {
        "display_name": "Mistral Labs Devstral Small 2512",
        "model_vendor": "mistral",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "source": "https://docs.mistral.ai/models/devstral-small-2-25-12",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/devstral-2512": {
        "display_name": "Mistral Devstral 2512",
        "model_vendor": "mistral",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "source": "https://mistral.ai/news/devstral-2-vibe-cli",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/magistral-medium-2506": {
        "display_name": "Magistral Medium 2506",
        "model_vendor": "mistralai",
        "model_version": "2506",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "mistral",
        "max_input_tokens": 40000,
        "max_output_tokens": 40000,
        "max_tokens": 40000,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "source": "https://mistral.ai/news/magistral",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/magistral-medium-2509": {
        "display_name": "Magistral Medium 2509",
        "model_vendor": "mistralai",
        "model_version": "2509",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "mistral",
        "max_input_tokens": 40000,
        "max_output_tokens": 40000,
        "max_tokens": 40000,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "source": "https://mistral.ai/news/magistral",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/mistral-ocr-latest": {
        "display_name": "Mistral OCR Latest",
        "model_vendor": "mistralai",
        "litellm_provider": "mistral",
        "ocr_cost_per_page": 0.001,
        "annotation_cost_per_page": 0.003,
        "mode": "ocr",
        "supported_endpoints": [
            "/v1/ocr"
        ],
        "source": "https://mistral.ai/pricing#api-pricing"
    },
    "mistral/mistral-ocr-2505-completion": {
        "display_name": "Mistral OCR 2505 Completion",
        "model_vendor": "mistralai",
        "model_version": "2505",
        "litellm_provider": "mistral",
        "ocr_cost_per_page": 0.001,
        "annotation_cost_per_page": 0.003,
        "mode": "ocr",
        "supported_endpoints": [
            "/v1/ocr"
        ],
        "source": "https://mistral.ai/pricing#api-pricing"
    },
    "mistral/magistral-medium-latest": {
        "display_name": "Magistral Medium Latest",
        "model_vendor": "mistralai",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "mistral",
        "max_input_tokens": 40000,
        "max_output_tokens": 40000,
        "max_tokens": 40000,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "source": "https://mistral.ai/news/magistral",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/magistral-small-2506": {
        "display_name": "Magistral Small 2506",
        "model_vendor": "mistralai",
        "model_version": "2506",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 40000,
        "max_output_tokens": 40000,
        "max_tokens": 40000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "source": "https://mistral.ai/pricing#api-pricing",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/magistral-small-latest": {
        "display_name": "Magistral Small Latest",
        "model_vendor": "mistralai",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 40000,
        "max_output_tokens": 40000,
        "max_tokens": 40000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "source": "https://mistral.ai/pricing#api-pricing",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/mistral-embed": {
        "display_name": "Mistral Embed",
        "model_vendor": "mistralai",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 8192,
        "max_tokens": 8192,
        "mode": "embedding"
    },
    "mistral/codestral-embed": {
        "display_name": "Codestral Embed",
        "model_vendor": "mistralai",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 8192,
        "max_tokens": 8192,
        "mode": "embedding"
    },
    "mistral/codestral-embed-2505": {
        "display_name": "Codestral Embed 2505",
        "model_vendor": "mistralai",
        "model_version": "2505",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 8192,
        "max_tokens": 8192,
        "mode": "embedding"
    },
    "mistral/mistral-large-2402": {
        "display_name": "Mistral Large 2402",
        "model_vendor": "mistralai",
        "model_version": "2402",
        "input_cost_per_token": 4e-06,
        "litellm_provider": "mistral",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 1.2e-05,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/mistral-large-2407": {
        "display_name": "Mistral Large 2407",
        "model_vendor": "mistralai",
        "model_version": "2407",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "mistral",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 9e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/mistral-large-2411": {
        "display_name": "Mistral Large 2411",
        "model_vendor": "mistralai",
        "model_version": "2411",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "mistral",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/mistral-large-latest": {
        "display_name": "Mistral Large Latest",
        "model_vendor": "mistralai",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "mistral",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/mistral-large-3": {
        "display_name": "Mistral Mistral Large 3",
        "model_vendor": "mistral",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 256000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "source": "https://docs.mistral.ai/models/mistral-large-3-25-12",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "mistral/mistral-medium": {
        "display_name": "Mistral Medium",
        "model_vendor": "mistralai",
        "input_cost_per_token": 2.7e-06,
        "litellm_provider": "mistral",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 8.1e-06,
        "supports_assistant_prefill": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/mistral-medium-2312": {
        "display_name": "Mistral Medium 2312",
        "model_vendor": "mistralai",
        "model_version": "2312",
        "input_cost_per_token": 2.7e-06,
        "litellm_provider": "mistral",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 8.1e-06,
        "supports_assistant_prefill": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/mistral-medium-2505": {
        "display_name": "Mistral Medium 2505",
        "model_vendor": "mistralai",
        "model_version": "2505",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 131072,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/mistral-medium-latest": {
        "display_name": "Mistral Medium Latest",
        "model_vendor": "mistralai",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 131072,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/mistral-small": {
        "display_name": "Mistral Small",
        "model_vendor": "mistralai",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/mistral-small-latest": {
        "display_name": "Mistral Small Latest",
        "model_vendor": "mistralai",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/mistral-tiny": {
        "display_name": "Mistral Tiny",
        "model_vendor": "mistralai",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 2.5e-07,
        "supports_assistant_prefill": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/open-codestral-mamba": {
        "display_name": "Open Codestral Mamba",
        "model_vendor": "mistralai",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 2.5e-07,
        "source": "https://mistral.ai/technology/",
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "mistral/open-mistral-7b": {
        "display_name": "Open Mistral 7B",
        "model_vendor": "mistralai",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 2.5e-07,
        "supports_assistant_prefill": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/open-mistral-nemo": {
        "display_name": "Open Mistral Nemo",
        "model_vendor": "mistralai",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "source": "https://mistral.ai/technology/",
        "supports_assistant_prefill": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/open-mistral-nemo-2407": {
        "display_name": "Open Mistral Nemo 2407",
        "model_vendor": "mistralai",
        "model_version": "2407",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "source": "https://mistral.ai/technology/",
        "supports_assistant_prefill": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/open-mixtral-8x22b": {
        "display_name": "Open Mixtral 8x22B",
        "model_vendor": "mistralai",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "mistral",
        "max_input_tokens": 65336,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/open-mixtral-8x7b": {
        "display_name": "Open Mixtral 8x7B",
        "model_vendor": "mistralai",
        "input_cost_per_token": 7e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 7e-07,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "mistral/pixtral-12b-2409": {
        "display_name": "Pixtral 12B 2409",
        "model_vendor": "mistralai",
        "model_version": "2409",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "mistral",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-07,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "mistral/pixtral-large-2411": {
        "display_name": "Pixtral Large 2411",
        "model_vendor": "mistralai",
        "model_version": "2411",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "mistral",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "mistral/pixtral-large-latest": {
        "display_name": "Pixtral Large Latest",
        "model_vendor": "mistralai",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "mistral",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "moonshot.kimi-k2-thinking": {
        "display_name": "Kimi K2 Thinking",
        "model_vendor": "moonshot",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2.5e-06,
        "supports_reasoning": true,
        "supports_system_messages": true
    },
    "moonshot/kimi-k2-0711-preview": {
        "display_name": "Kimi K2 0711 Preview",
        "model_vendor": "moonshot",
        "model_version": "k2-0711",
        "cache_read_input_token_cost": 1.5e-07,
        "input_cost_per_token": 6e-07,
        "litellm_provider": "moonshot",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 2.5e-06,
        "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "moonshot/kimi-k2-0905-preview": {
        "display_name": "Kimi K2 0905 Preview",
        "model_vendor": "moonshot",
        "model_version": "0905-preview",
        "cache_read_input_token_cost": 1.5e-07,
        "input_cost_per_token": 6e-07,
        "litellm_provider": "moonshot",
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "max_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 2.5e-06,
        "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "moonshot/kimi-k2-turbo-preview": {
        "display_name": "Kimi K2 Turbo Preview",
        "model_vendor": "moonshot",
        "model_version": "turbo-preview",
        "cache_read_input_token_cost": 1.5e-07,
        "input_cost_per_token": 1.15e-06,
        "litellm_provider": "moonshot",
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "max_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "moonshot/kimi-latest": {
        "display_name": "Kimi Latest",
        "model_vendor": "moonshot",
        "cache_read_input_token_cost": 1.5e-07,
        "input_cost_per_token": 2e-06,
        "litellm_provider": "moonshot",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "source": "https://platform.moonshot.ai/docs/pricing",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "moonshot/kimi-latest-128k": {
        "display_name": "Kimi Latest 128K",
        "model_vendor": "moonshot",
        "cache_read_input_token_cost": 1.5e-07,
        "input_cost_per_token": 2e-06,
        "litellm_provider": "moonshot",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "source": "https://platform.moonshot.ai/docs/pricing",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "moonshot/kimi-latest-32k": {
        "display_name": "Kimi Latest 32K",
        "model_vendor": "moonshot",
        "cache_read_input_token_cost": 1.5e-07,
        "input_cost_per_token": 1e-06,
        "litellm_provider": "moonshot",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 3e-06,
        "source": "https://platform.moonshot.ai/docs/pricing",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "moonshot/kimi-latest-8k": {
        "display_name": "Kimi Latest 8K",
        "model_vendor": "moonshot",
        "cache_read_input_token_cost": 1.5e-07,
        "input_cost_per_token": 2e-07,
        "litellm_provider": "moonshot",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "source": "https://platform.moonshot.ai/docs/pricing",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "moonshot/kimi-thinking-preview": {
        "display_name": "Kimi Thinking Preview",
        "model_vendor": "moonshot",
        "cache_read_input_token_cost": 1.5e-07,
        "input_cost_per_token": 6e-07,
        "litellm_provider": "moonshot",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 2.5e-06,
        "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
        "supports_vision": true
    },
    "moonshot/kimi-k2-thinking": {
        "display_name": "Kimi K2 Thinking",
        "model_vendor": "moonshot",
        "cache_read_input_token_cost": 1.5e-07,
        "input_cost_per_token": 6e-07,
        "litellm_provider": "moonshot",
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "max_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 2.5e-06,
        "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "moonshot/kimi-k2-thinking-turbo": {
        "display_name": "Kimi K2 Thinking Turbo",
        "model_vendor": "moonshot",
        "model_version": "thinking-turbo",
        "cache_read_input_token_cost": 1.5e-07,
        "input_cost_per_token": 1.15e-06,
        "litellm_provider": "moonshot",
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "max_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "moonshot/moonshot-v1-128k": {
        "display_name": "Moonshot V1 128K",
        "model_vendor": "moonshot",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "moonshot",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "source": "https://platform.moonshot.ai/docs/pricing",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "moonshot/moonshot-v1-128k-0430": {
        "display_name": "Moonshot V1 128K 0430",
        "model_vendor": "moonshot",
        "model_version": "0430",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "moonshot",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "source": "https://platform.moonshot.ai/docs/pricing",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "moonshot/moonshot-v1-128k-vision-preview": {
        "display_name": "Moonshot V1 128K Vision Preview",
        "model_vendor": "moonshot",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "moonshot",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "source": "https://platform.moonshot.ai/docs/pricing",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "moonshot/moonshot-v1-32k": {
        "display_name": "Moonshot V1 32K",
        "model_vendor": "moonshot",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "moonshot",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 3e-06,
        "source": "https://platform.moonshot.ai/docs/pricing",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "moonshot/moonshot-v1-32k-0430": {
        "display_name": "Moonshot V1 32K 0430",
        "model_vendor": "moonshot",
        "model_version": "0430",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "moonshot",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 3e-06,
        "source": "https://platform.moonshot.ai/docs/pricing",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "moonshot/moonshot-v1-32k-vision-preview": {
        "display_name": "Moonshot V1 32K Vision Preview",
        "model_vendor": "moonshot",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "moonshot",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 3e-06,
        "source": "https://platform.moonshot.ai/docs/pricing",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "moonshot/moonshot-v1-8k": {
        "display_name": "Moonshot V1 8K",
        "model_vendor": "moonshot",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "moonshot",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "source": "https://platform.moonshot.ai/docs/pricing",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "moonshot/moonshot-v1-8k-0430": {
        "display_name": "Moonshot V1 8K 0430",
        "model_vendor": "moonshot",
        "model_version": "0430",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "moonshot",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "source": "https://platform.moonshot.ai/docs/pricing",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "moonshot/moonshot-v1-8k-vision-preview": {
        "display_name": "Moonshot V1 8K Vision Preview",
        "model_vendor": "moonshot",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "moonshot",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "source": "https://platform.moonshot.ai/docs/pricing",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "moonshot/moonshot-v1-auto": {
        "display_name": "Moonshot V1 Auto",
        "model_vendor": "moonshot",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "moonshot",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "source": "https://platform.moonshot.ai/docs/pricing",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "morph/morph-v3-fast": {
        "display_name": "Morph V3 Fast",
        "model_vendor": "morph",
        "input_cost_per_token": 8e-07,
        "litellm_provider": "morph",
        "max_input_tokens": 16000,
        "max_output_tokens": 16000,
        "max_tokens": 16000,
        "mode": "chat",
        "output_cost_per_token": 1.2e-06,
        "supports_function_calling": false,
        "supports_parallel_function_calling": false,
        "supports_system_messages": true,
        "supports_tool_choice": false,
        "supports_vision": false
    },
    "morph/morph-v3-large": {
        "display_name": "Morph V3 Large",
        "model_vendor": "morph",
        "input_cost_per_token": 9e-07,
        "litellm_provider": "morph",
        "max_input_tokens": 16000,
        "max_output_tokens": 16000,
        "max_tokens": 16000,
        "mode": "chat",
        "output_cost_per_token": 1.9e-06,
        "supports_function_calling": false,
        "supports_parallel_function_calling": false,
        "supports_system_messages": true,
        "supports_tool_choice": false,
        "supports_vision": false
    },
    "multimodalembedding": {
        "display_name": "Multimodal Embedding",
        "model_vendor": "google",
        "input_cost_per_character": 2e-07,
        "input_cost_per_image": 0.0001,
        "input_cost_per_token": 8e-07,
        "input_cost_per_video_per_second": 0.0005,
        "input_cost_per_video_per_second_above_15s_interval": 0.002,
        "input_cost_per_video_per_second_above_8s_interval": 0.001,
        "litellm_provider": "vertex_ai-embedding-models",
        "max_input_tokens": 2048,
        "max_tokens": 2048,
        "mode": "embedding",
        "output_cost_per_token": 0,
        "output_vector_size": 768,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models",
        "supported_endpoints": [
            "/v1/embeddings"
        ],
        "supported_modalities": [
            "text",
            "image",
            "video"
        ]
    },
    "multimodalembedding@001": {
        "display_name": "Multimodal Embedding 001",
        "model_vendor": "google",
        "model_version": "001",
        "input_cost_per_character": 2e-07,
        "input_cost_per_image": 0.0001,
        "input_cost_per_token": 8e-07,
        "input_cost_per_video_per_second": 0.0005,
        "input_cost_per_video_per_second_above_15s_interval": 0.002,
        "input_cost_per_video_per_second_above_8s_interval": 0.001,
        "litellm_provider": "vertex_ai-embedding-models",
        "max_input_tokens": 2048,
        "max_tokens": 2048,
        "mode": "embedding",
        "output_cost_per_token": 0,
        "output_vector_size": 768,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models",
        "supported_endpoints": [
            "/v1/embeddings"
        ],
        "supported_modalities": [
            "text",
            "image",
            "video"
        ]
    },
    "nscale/Qwen/QwQ-32B": {
        "display_name": "QwQ 32B",
        "model_vendor": "alibaba",
        "input_cost_per_token": 1.8e-07,
        "litellm_provider": "nscale",
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models"
    },
    "nscale/Qwen/Qwen2.5-Coder-32B-Instruct": {
        "display_name": "Qwen 2.5 Coder 32B Instruct",
        "model_vendor": "alibaba",
        "input_cost_per_token": 6e-08,
        "litellm_provider": "nscale",
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models"
    },
    "nscale/Qwen/Qwen2.5-Coder-3B-Instruct": {
        "display_name": "Qwen 2.5 Coder 3B Instruct",
        "model_vendor": "alibaba",
        "input_cost_per_token": 1e-08,
        "litellm_provider": "nscale",
        "mode": "chat",
        "output_cost_per_token": 3e-08,
        "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models"
    },
    "nscale/Qwen/Qwen2.5-Coder-7B-Instruct": {
        "display_name": "Qwen 2.5 Coder 7B Instruct",
        "model_vendor": "alibaba",
        "input_cost_per_token": 1e-08,
        "litellm_provider": "nscale",
        "mode": "chat",
        "output_cost_per_token": 3e-08,
        "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models"
    },
    "nscale/black-forest-labs/FLUX.1-schnell": {
        "display_name": "FLUX.1 Schnell",
        "model_vendor": "black_forest_labs",
        "input_cost_per_pixel": 1.3e-09,
        "litellm_provider": "nscale",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "source": "https://docs.nscale.com/docs/inference/serverless-models/current#image-models",
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
        "display_name": "DeepSeek R1 Distill Llama 70B",
        "model_vendor": "deepseek",
        "input_cost_per_token": 3.75e-07,
        "litellm_provider": "nscale",
        "metadata": {
            "notes": "Pricing listed as $0.75/1M tokens total. Assumed 50/50 split for input/output."
        },
        "mode": "chat",
        "output_cost_per_token": 3.75e-07,
        "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models"
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-8B": {
        "display_name": "DeepSeek R1 Distill Llama 8B",
        "model_vendor": "deepseek",
        "input_cost_per_token": 2.5e-08,
        "litellm_provider": "nscale",
        "metadata": {
            "notes": "Pricing listed as $0.05/1M tokens total. Assumed 50/50 split for input/output."
        },
        "mode": "chat",
        "output_cost_per_token": 2.5e-08,
        "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models"
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B": {
        "display_name": "DeepSeek R1 Distill Qwen 1.5B",
        "model_vendor": "deepseek",
        "input_cost_per_token": 9e-08,
        "litellm_provider": "nscale",
        "metadata": {
            "notes": "Pricing listed as $0.18/1M tokens total. Assumed 50/50 split for input/output."
        },
        "mode": "chat",
        "output_cost_per_token": 9e-08,
        "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models"
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B": {
        "display_name": "DeepSeek R1 Distill Qwen 14B",
        "model_vendor": "deepseek",
        "input_cost_per_token": 7e-08,
        "litellm_provider": "nscale",
        "metadata": {
            "notes": "Pricing listed as $0.14/1M tokens total. Assumed 50/50 split for input/output."
        },
        "mode": "chat",
        "output_cost_per_token": 7e-08,
        "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models"
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": {
        "display_name": "DeepSeek R1 Distill Qwen 32B",
        "model_vendor": "deepseek",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "nscale",
        "metadata": {
            "notes": "Pricing listed as $0.30/1M tokens total. Assumed 50/50 split for input/output."
        },
        "mode": "chat",
        "output_cost_per_token": 1.5e-07,
        "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models"
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B": {
        "display_name": "DeepSeek R1 Distill Qwen 7B",
        "model_vendor": "deepseek",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "nscale",
        "metadata": {
            "notes": "Pricing listed as $0.40/1M tokens total. Assumed 50/50 split for input/output."
        },
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models"
    },
    "nscale/meta-llama/Llama-3.1-8B-Instruct": {
        "display_name": "Llama 3.1 8B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 3e-08,
        "litellm_provider": "nscale",
        "metadata": {
            "notes": "Pricing listed as $0.06/1M tokens total. Assumed 50/50 split for input/output."
        },
        "mode": "chat",
        "output_cost_per_token": 3e-08,
        "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models"
    },
    "nscale/meta-llama/Llama-3.3-70B-Instruct": {
        "display_name": "Llama 3.3 70B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "nscale",
        "metadata": {
            "notes": "Pricing listed as $0.40/1M tokens total. Assumed 50/50 split for input/output."
        },
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models"
    },
    "nscale/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
        "display_name": "Llama 4 Scout 17B 16E Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 9e-08,
        "litellm_provider": "nscale",
        "mode": "chat",
        "output_cost_per_token": 2.9e-07,
        "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models"
    },
    "nscale/mistralai/mixtral-8x22b-instruct-v0.1": {
        "display_name": "Mixtral 8x22B Instruct v0.1",
        "model_vendor": "mistralai",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "nscale",
        "metadata": {
            "notes": "Pricing listed as $1.20/1M tokens total. Assumed 50/50 split for input/output."
        },
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models"
    },
    "nscale/stabilityai/stable-diffusion-xl-base-1.0": {
        "display_name": "Stable Diffusion XL Base 1.0",
        "model_vendor": "stability",
        "model_version": "xl-1.0",
        "input_cost_per_pixel": 3e-09,
        "litellm_provider": "nscale",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "source": "https://docs.nscale.com/docs/inference/serverless-models/current#image-models",
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "nvidia.nemotron-nano-12b-v2": {
        "display_name": "Nemotron Nano 12B V2",
        "model_vendor": "nvidia",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "supports_system_messages": true,
        "supports_vision": true
    },
    "nvidia.nemotron-nano-9b-v2": {
        "display_name": "Nemotron Nano 9B V2",
        "model_vendor": "nvidia",
        "input_cost_per_token": 6e-08,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2.3e-07,
        "supports_system_messages": true
    },
    "o1": {
        "display_name": "o1",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 7.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o1-2024-12-17": {
        "display_name": "o1",
        "model_vendor": "openai",
        "model_version": "2024-12-17",
        "cache_read_input_token_cost": 7.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o1-mini": {
        "display_name": "o1 Mini",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 5.5e-07,
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "max_tokens": 65536,
        "mode": "chat",
        "output_cost_per_token": 4.4e-06,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_vision": true
    },
    "o1-mini-2024-09-12": {
        "display_name": "o1 Mini",
        "model_vendor": "openai",
        "model_version": "2024-09-12",
        "deprecation_date": "2025-10-27",
        "cache_read_input_token_cost": 1.5e-06,
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "max_tokens": 65536,
        "mode": "chat",
        "output_cost_per_token": 1.2e-05,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_vision": true
    },
    "o1-preview": {
        "display_name": "o1 Preview",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 7.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_vision": true
    },
    "o1-preview-2024-09-12": {
        "display_name": "o1 Preview",
        "model_vendor": "openai",
        "model_version": "2024-09-12",
        "cache_read_input_token_cost": 7.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_vision": true
    },
    "o1-pro": {
        "display_name": "o1 Pro",
        "model_vendor": "openai",
        "input_cost_per_token": 0.00015,
        "input_cost_per_token_batches": 7.5e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "output_cost_per_token": 0.0006,
        "output_cost_per_token_batches": 0.0003,
        "supported_endpoints": [
            "/v1/responses",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": false,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o1-pro-2025-03-19": {
        "display_name": "o1 Pro",
        "model_vendor": "openai",
        "model_version": "2025-03-19",
        "input_cost_per_token": 0.00015,
        "input_cost_per_token_batches": 7.5e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "output_cost_per_token": 0.0006,
        "output_cost_per_token_batches": 0.0003,
        "supported_endpoints": [
            "/v1/responses",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": false,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o3": {
        "display_name": "o3",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 5e-07,
        "cache_read_input_token_cost_flex": 2.5e-07,
        "cache_read_input_token_cost_priority": 8.75e-07,
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_flex": 1e-06,
        "input_cost_per_token_priority": 3.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "output_cost_per_token_flex": 4e-06,
        "output_cost_per_token_priority": 1.4e-05,
        "supported_endpoints": [
            "/v1/responses",
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "o3-2025-04-16": {
        "display_name": "o3",
        "model_vendor": "openai",
        "model_version": "2025-04-16",
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 2e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "supported_endpoints": [
            "/v1/responses",
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "o3-deep-research": {
        "display_name": "o3 Deep Research",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 2.5e-06,
        "input_cost_per_token": 1e-05,
        "input_cost_per_token_batches": 5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "output_cost_per_token": 4e-05,
        "output_cost_per_token_batches": 2e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o3-deep-research-2025-06-26": {
        "display_name": "o3 Deep Research",
        "model_vendor": "openai",
        "model_version": "2025-06-26",
        "cache_read_input_token_cost": 2.5e-06,
        "input_cost_per_token": 1e-05,
        "input_cost_per_token_batches": 5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "output_cost_per_token": 4e-05,
        "output_cost_per_token_batches": 2e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o3-mini": {
        "display_name": "o3 Mini",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 5.5e-07,
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 4.4e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "o3-mini-2025-01-31": {
        "display_name": "o3 Mini",
        "model_vendor": "openai",
        "model_version": "2025-01-31",
        "cache_read_input_token_cost": 5.5e-07,
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 4.4e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "o3-pro": {
        "display_name": "o3 Pro",
        "model_vendor": "openai",
        "input_cost_per_token": 2e-05,
        "input_cost_per_token_batches": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "output_cost_per_token": 8e-05,
        "output_cost_per_token_batches": 4e-05,
        "supported_endpoints": [
            "/v1/responses",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o3-pro-2025-06-10": {
        "display_name": "o3 Pro",
        "model_vendor": "openai",
        "model_version": "2025-06-10",
        "input_cost_per_token": 2e-05,
        "input_cost_per_token_batches": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "output_cost_per_token": 8e-05,
        "output_cost_per_token_batches": 4e-05,
        "supported_endpoints": [
            "/v1/responses",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o4-mini": {
        "display_name": "o4 Mini",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 2.75e-07,
        "cache_read_input_token_cost_flex": 1.375e-07,
        "cache_read_input_token_cost_priority": 5e-07,
        "input_cost_per_token": 1.1e-06,
        "input_cost_per_token_flex": 5.5e-07,
        "input_cost_per_token_priority": 2e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 4.4e-06,
        "output_cost_per_token_flex": 2.2e-06,
        "output_cost_per_token_priority": 8e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "o4-mini-2025-04-16": {
        "display_name": "o4 Mini",
        "model_vendor": "openai",
        "model_version": "2025-04-16",
        "cache_read_input_token_cost": 2.75e-07,
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 4.4e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "o4-mini-deep-research": {
        "display_name": "o4 Mini Deep Research",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_batches": 1e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "output_cost_per_token": 8e-06,
        "output_cost_per_token_batches": 4e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o4-mini-deep-research-2025-06-26": {
        "display_name": "o4 Mini Deep Research",
        "model_vendor": "openai",
        "model_version": "2025-06-26",
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_batches": 1e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "output_cost_per_token": 8e-06,
        "output_cost_per_token_batches": 4e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "oci/meta.llama-3.1-405b-instruct": {
        "display_name": "Llama 3.1 405B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1.068e-05,
        "litellm_provider": "oci",
        "max_input_tokens": 128000,
        "max_output_tokens": 4000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.068e-05,
        "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
        "supports_function_calling": true,
        "supports_response_schema": false
    },
    "oci/meta.llama-3.2-90b-vision-instruct": {
        "display_name": "Llama 3.2 90B Vision Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "oci",
        "max_input_tokens": 128000,
        "max_output_tokens": 4000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
        "supports_function_calling": true,
        "supports_response_schema": false
    },
    "oci/meta.llama-3.3-70b-instruct": {
        "display_name": "Llama 3.3 70B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 7.2e-07,
        "litellm_provider": "oci",
        "max_input_tokens": 128000,
        "max_output_tokens": 4000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 7.2e-07,
        "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
        "supports_function_calling": true,
        "supports_response_schema": false
    },
    "oci/meta.llama-4-maverick-17b-128e-instruct-fp8": {
        "display_name": "Llama 4 Maverick 17B 128E Instruct FP8",
        "model_vendor": "meta",
        "input_cost_per_token": 7.2e-07,
        "litellm_provider": "oci",
        "max_input_tokens": 512000,
        "max_output_tokens": 4000,
        "max_tokens": 512000,
        "mode": "chat",
        "output_cost_per_token": 7.2e-07,
        "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
        "supports_function_calling": true,
        "supports_response_schema": false
    },
    "oci/meta.llama-4-scout-17b-16e-instruct": {
        "display_name": "Llama 4 Scout 17B 16E Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 7.2e-07,
        "litellm_provider": "oci",
        "max_input_tokens": 192000,
        "max_output_tokens": 4000,
        "max_tokens": 192000,
        "mode": "chat",
        "output_cost_per_token": 7.2e-07,
        "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
        "supports_function_calling": true,
        "supports_response_schema": false
    },
    "oci/xai.grok-3": {
        "display_name": "Grok 3",
        "model_vendor": "xai",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "oci",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1.5e-07,
        "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
        "supports_function_calling": true,
        "supports_response_schema": false
    },
    "oci/xai.grok-3-fast": {
        "display_name": "Grok 3 Fast",
        "model_vendor": "xai",
        "input_cost_per_token": 5e-06,
        "litellm_provider": "oci",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 2.5e-05,
        "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
        "supports_function_calling": true,
        "supports_response_schema": false
    },
    "oci/xai.grok-3-mini": {
        "display_name": "Grok 3 Mini",
        "model_vendor": "xai",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "oci",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 5e-07,
        "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
        "supports_function_calling": true,
        "supports_response_schema": false
    },
    "oci/xai.grok-3-mini-fast": {
        "display_name": "Grok 3 Mini Fast",
        "model_vendor": "xai",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "oci",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 4e-06,
        "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
        "supports_function_calling": true,
        "supports_response_schema": false
    },
    "oci/xai.grok-4": {
        "display_name": "Grok 4",
        "model_vendor": "xai",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "oci",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-07,
        "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
        "supports_function_calling": true,
        "supports_response_schema": false
    },
    "oci/cohere.command-latest": {
        "display_name": "Command Latest",
        "model_vendor": "cohere",
        "input_cost_per_token": 1.56e-06,
        "litellm_provider": "oci",
        "max_input_tokens": 128000,
        "max_output_tokens": 4000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.56e-06,
        "source": "https://www.oracle.com/cloud/ai/generative-ai/pricing/",
        "supports_function_calling": true,
        "supports_response_schema": false
    },
    "oci/cohere.command-a-03-2025": {
        "display_name": "Command A 03-2025",
        "model_vendor": "cohere",
        "model_version": "03-2025",
        "input_cost_per_token": 1.56e-06,
        "litellm_provider": "oci",
        "max_input_tokens": 256000,
        "max_output_tokens": 4000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 1.56e-06,
        "source": "https://www.oracle.com/cloud/ai/generative-ai/pricing/",
        "supports_function_calling": true,
        "supports_response_schema": false
    },
    "oci/cohere.command-plus-latest": {
        "display_name": "Command Plus Latest",
        "model_vendor": "cohere",
        "input_cost_per_token": 1.56e-06,
        "litellm_provider": "oci",
        "max_input_tokens": 128000,
        "max_output_tokens": 4000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.56e-06,
        "source": "https://www.oracle.com/cloud/ai/generative-ai/pricing/",
        "supports_function_calling": true,
        "supports_response_schema": false
    },
    "ollama/codegeex4": {
        "display_name": "CodeGeeX4",
        "model_vendor": "zhipu",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 32768,
        "max_output_tokens": 8192,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "supports_function_calling": false
    },
    "ollama/codegemma": {
        "display_name": "CodeGemma",
        "model_vendor": "google",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "completion",
        "output_cost_per_token": 0.0
    },
    "ollama/codellama": {
        "display_name": "Code Llama",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "completion",
        "output_cost_per_token": 0.0
    },
    "ollama/deepseek-coder-v2-base": {
        "display_name": "DeepSeek Coder V2 Base",
        "model_vendor": "deepseek",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "completion",
        "output_cost_per_token": 0.0,
        "supports_function_calling": true
    },
    "ollama/deepseek-coder-v2-instruct": {
        "display_name": "DeepSeek Coder V2 Instruct",
        "model_vendor": "deepseek",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 32768,
        "max_output_tokens": 8192,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "supports_function_calling": true
    },
    "ollama/deepseek-coder-v2-lite-base": {
        "display_name": "DeepSeek Coder V2 Lite Base",
        "model_vendor": "deepseek",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "completion",
        "output_cost_per_token": 0.0,
        "supports_function_calling": true
    },
    "ollama/deepseek-coder-v2-lite-instruct": {
        "display_name": "DeepSeek Coder V2 Lite Instruct",
        "model_vendor": "deepseek",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 32768,
        "max_output_tokens": 8192,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "supports_function_calling": true
    },
    "ollama/deepseek-v3.1:671b-cloud": {
        "display_name": "DeepSeek V3.1 671B Cloud",
        "model_vendor": "deepseek",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "max_tokens": 163840,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "supports_function_calling": true
    },
    "ollama/gpt-oss:120b-cloud": {
        "display_name": "GPT-OSS 120B Cloud",
        "model_vendor": "openai",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "supports_function_calling": true
    },
    "ollama/gpt-oss:20b-cloud": {
        "display_name": "GPT-OSS 20B Cloud",
        "model_vendor": "openai",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "supports_function_calling": true
    },
    "ollama/internlm2_5-20b-chat": {
        "display_name": "InternLM 2.5 20B Chat",
        "model_vendor": "shanghai_ai_lab",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 32768,
        "max_output_tokens": 8192,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "supports_function_calling": true
    },
    "ollama/llama2": {
        "display_name": "Llama 2",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 0.0
    },
    "ollama/llama2-uncensored": {
        "display_name": "Llama 2 Uncensored",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "completion",
        "output_cost_per_token": 0.0
    },
    "ollama/llama2:13b": {
        "display_name": "Llama 2 13B",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 0.0
    },
    "ollama/llama2:70b": {
        "display_name": "Llama 2 70B",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 0.0
    },
    "ollama/llama2:7b": {
        "display_name": "Llama 2 7B",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 0.0
    },
    "ollama/llama3": {
        "display_name": "Llama 3",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 0.0
    },
    "ollama/llama3.1": {
        "display_name": "Llama 3.1",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "supports_function_calling": true
    },
    "ollama/llama3:70b": {
        "display_name": "Llama 3 70B",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 0.0
    },
    "ollama/llama3:8b": {
        "display_name": "Llama 3 8B",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 0.0
    },
    "ollama/mistral": {
        "display_name": "Mistral",
        "model_vendor": "mistralai",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "completion",
        "output_cost_per_token": 0.0,
        "supports_function_calling": true
    },
    "ollama/mistral-7B-Instruct-v0.1": {
        "display_name": "Mistral 7B Instruct v0.1",
        "model_vendor": "mistralai",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "supports_function_calling": true
    },
    "ollama/mistral-7B-Instruct-v0.2": {
        "display_name": "Mistral 7B Instruct v0.2",
        "model_vendor": "mistralai",
        "model_version": "0.2",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "supports_function_calling": true
    },
    "ollama/mistral-large-instruct-2407": {
        "display_name": "Mistral Large Instruct 2407",
        "model_vendor": "mistralai",
        "model_version": "2407",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 65536,
        "max_output_tokens": 8192,
        "max_tokens": 65536,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "supports_function_calling": true
    },
    "ollama/mixtral-8x22B-Instruct-v0.1": {
        "display_name": "Mixtral 8x22B Instruct v0.1",
        "model_vendor": "mistralai",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 65536,
        "max_output_tokens": 65536,
        "max_tokens": 65536,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "supports_function_calling": true
    },
    "ollama/mixtral-8x7B-Instruct-v0.1": {
        "display_name": "Mixtral 8x7B Instruct v0.1",
        "model_vendor": "mistralai",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "supports_function_calling": true
    },
    "ollama/orca-mini": {
        "display_name": "Orca Mini",
        "model_vendor": "microsoft",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "completion",
        "output_cost_per_token": 0.0
    },
    "ollama/qwen3-coder:480b-cloud": {
        "display_name": "Qwen 3 Coder 480B Cloud",
        "model_vendor": "alibaba",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "max_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "supports_function_calling": true
    },
    "ollama/vicuna": {
        "display_name": "Vicuna",
        "model_vendor": "lmsys",
        "input_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "max_input_tokens": 2048,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "mode": "completion",
        "output_cost_per_token": 0.0
    },
    "omni-moderation-2024-09-26": {
        "display_name": "Omni Moderation",
        "model_vendor": "openai",
        "model_version": "2024-09-26",
        "input_cost_per_token": 0.0,
        "litellm_provider": "openai",
        "max_input_tokens": 32768,
        "max_output_tokens": 0,
        "max_tokens": 32768,
        "mode": "moderation",
        "output_cost_per_token": 0.0
    },
    "omni-moderation-latest": {
        "display_name": "Omni Moderation Latest",
        "model_vendor": "openai",
        "input_cost_per_token": 0.0,
        "litellm_provider": "openai",
        "max_input_tokens": 32768,
        "max_output_tokens": 0,
        "max_tokens": 32768,
        "mode": "moderation",
        "output_cost_per_token": 0.0
    },
    "omni-moderation-latest-intents": {
        "display_name": "Omni Moderation Latest Intents",
        "model_vendor": "openai",
        "input_cost_per_token": 0.0,
        "litellm_provider": "openai",
        "max_input_tokens": 32768,
        "max_output_tokens": 0,
        "max_tokens": 32768,
        "mode": "moderation",
        "output_cost_per_token": 0.0
    },
    "openai.gpt-oss-120b-1:0": {
        "display_name": "GPT-OSS 120B",
        "model_vendor": "openai",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "openai.gpt-oss-20b-1:0": {
        "display_name": "GPT-OSS 20B",
        "model_vendor": "openai",
        "input_cost_per_token": 7e-08,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "openai.gpt-oss-safeguard-120b": {
        "display_name": "GPT Oss Safeguard 120B",
        "model_vendor": "openai",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "supports_system_messages": true
    },
    "openai.gpt-oss-safeguard-20b": {
        "display_name": "GPT Oss Safeguard 20B",
        "model_vendor": "openai",
        "input_cost_per_token": 7e-08,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "supports_system_messages": true
    },
    "openrouter/anthropic/claude-2": {
        "display_name": "Claude 2",
        "model_vendor": "anthropic",
        "input_cost_per_token": 1.102e-05,
        "litellm_provider": "openrouter",
        "max_output_tokens": 8191,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 3.268e-05,
        "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3-5-haiku": {
        "display_name": "Claude 3.5 Haiku",
        "model_vendor": "anthropic",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "openrouter",
        "max_tokens": 200000,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3-5-haiku-20241022": {
        "display_name": "Claude 3.5 Haiku",
        "model_vendor": "anthropic",
        "model_version": "20241022",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "tool_use_system_prompt_tokens": 264
    },
    "openrouter/anthropic/claude-3-haiku": {
        "display_name": "Claude 3 Haiku",
        "model_vendor": "anthropic",
        "input_cost_per_image": 0.0004,
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "openrouter",
        "max_tokens": 200000,
        "mode": "chat",
        "output_cost_per_token": 1.25e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/anthropic/claude-3-haiku-20240307": {
        "display_name": "Claude 3 Haiku",
        "model_vendor": "anthropic",
        "model_version": "20240307",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.25e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 264
    },
    "openrouter/anthropic/claude-3-opus": {
        "display_name": "Claude 3 Opus",
        "model_vendor": "anthropic",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "openrouter",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 395
    },
    "openrouter/anthropic/claude-3-sonnet": {
        "display_name": "Claude 3 Sonnet",
        "model_vendor": "anthropic",
        "input_cost_per_image": 0.0048,
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openrouter",
        "max_tokens": 200000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/anthropic/claude-3.5-sonnet": {
        "display_name": "Claude 3.5 Sonnet",
        "model_vendor": "anthropic",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "openrouter/anthropic/claude-3.5-sonnet:beta": {
        "display_name": "Claude 3.5 Sonnet Beta",
        "model_vendor": "anthropic",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "openrouter/anthropic/claude-3.7-sonnet": {
        "display_name": "Claude 3.7 Sonnet",
        "model_vendor": "anthropic",
        "input_cost_per_image": 0.0048,
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 200000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "openrouter/anthropic/claude-3.7-sonnet:beta": {
        "display_name": "Claude 3.7 Sonnet Beta",
        "model_vendor": "anthropic",
        "input_cost_per_image": 0.0048,
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 200000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "openrouter/anthropic/claude-instant-v1": {
        "display_name": "Claude Instant v1",
        "model_vendor": "anthropic",
        "input_cost_per_token": 1.63e-06,
        "litellm_provider": "openrouter",
        "max_output_tokens": 8191,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 5.51e-06,
        "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-opus-4": {
        "display_name": "Claude Opus 4",
        "model_vendor": "anthropic",
        "input_cost_per_image": 0.0048,
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "openrouter",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "openrouter/anthropic/claude-opus-4.1": {
        "display_name": "Claude Opus 4.1",
        "model_vendor": "anthropic",
        "input_cost_per_image": 0.0048,
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_creation_input_token_cost_above_1hr": 3e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "openrouter",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "openrouter/anthropic/claude-sonnet-4": {
        "display_name": "Claude Sonnet 4",
        "model_vendor": "anthropic",
        "input_cost_per_image": 0.0048,
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost": 3e-07,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "litellm_provider": "openrouter",
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "openrouter/anthropic/claude-opus-4.5": {
        "display_name": "Claude Opus 4.5",
        "model_vendor": "anthropic",
        "cache_creation_input_token_cost": 6.25e-06,
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 2.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "openrouter/anthropic/claude-sonnet-4.5": {
        "display_name": "Claude Sonnet 4.5",
        "model_vendor": "anthropic",
        "input_cost_per_image": 0.0048,
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 1000000,
        "max_output_tokens": 1000000,
        "max_tokens": 1000000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "openrouter/anthropic/claude-haiku-4.5": {
        "display_name": "Claude Haiku 4.5",
        "model_vendor": "anthropic",
        "cache_creation_input_token_cost": 1.25e-06,
        "cache_read_input_token_cost": 1e-07,
        "input_cost_per_token": 1e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 200000,
        "max_output_tokens": 200000,
        "max_tokens": 200000,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 346
    },
    "openrouter/bytedance/ui-tars-1.5-7b": {
        "display_name": "UI-TARS 1.5 7B",
        "model_vendor": "bytedance",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 131072,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "source": "https://openrouter.ai/api/v1/models/bytedance/ui-tars-1.5-7b",
        "supports_tool_choice": true
    },
    "openrouter/cognitivecomputations/dolphin-mixtral-8x7b": {
        "display_name": "Dolphin Mixtral 8x7B",
        "model_vendor": "cognitivecomputations",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "openrouter",
        "max_tokens": 32769,
        "mode": "chat",
        "output_cost_per_token": 5e-07,
        "supports_tool_choice": true
    },
    "openrouter/cohere/command-r-plus": {
        "display_name": "Command R Plus",
        "model_vendor": "cohere",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openrouter",
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_tool_choice": true
    },
    "openrouter/databricks/dbrx-instruct": {
        "display_name": "DBRX Instruct",
        "model_vendor": "databricks",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "openrouter",
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "supports_tool_choice": true
    },
    "openrouter/deepseek/deepseek-chat": {
        "display_name": "DeepSeek Chat",
        "model_vendor": "deepseek",
        "input_cost_per_token": 1.4e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 65536,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2.8e-07,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "openrouter/deepseek/deepseek-chat-v3-0324": {
        "display_name": "DeepSeek Chat V3 0324",
        "model_vendor": "deepseek",
        "model_version": "0324",
        "input_cost_per_token": 1.4e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 65536,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2.8e-07,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "openrouter/deepseek/deepseek-chat-v3.1": {
        "display_name": "DeepSeek Chat V3.1",
        "model_vendor": "deepseek",
        "input_cost_per_token": 2e-07,
        "input_cost_per_token_cache_hit": 2e-08,
        "litellm_provider": "openrouter",
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 8e-07,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "openrouter/deepseek/deepseek-v3.2": {
        "display_name": "DeepSeek V3.2",
        "model_vendor": "deepseek",
        "model_version": "v3.2",
        "input_cost_per_token": 2.8e-07,
        "input_cost_per_token_cache_hit": 2.8e-08,
        "litellm_provider": "openrouter",
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "openrouter/deepseek/deepseek-v3.2-exp": {
        "display_name": "DeepSeek V3.2 Experimental",
        "model_vendor": "deepseek",
        "input_cost_per_token": 2e-07,
        "input_cost_per_token_cache_hit": 2e-08,
        "litellm_provider": "openrouter",
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": false,
        "supports_tool_choice": true
    },
    "openrouter/deepseek/deepseek-coder": {
        "display_name": "DeepSeek Coder",
        "model_vendor": "deepseek",
        "input_cost_per_token": 1.4e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 66000,
        "max_output_tokens": 4096,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2.8e-07,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "openrouter/deepseek/deepseek-r1": {
        "display_name": "DeepSeek R1",
        "model_vendor": "deepseek",
        "input_cost_per_token": 5.5e-07,
        "input_cost_per_token_cache_hit": 1.4e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 65336,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2.19e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "openrouter/deepseek/deepseek-r1-0528": {
        "display_name": "DeepSeek R1 0528",
        "model_vendor": "deepseek",
        "model_version": "0528",
        "input_cost_per_token": 5e-07,
        "input_cost_per_token_cache_hit": 1.4e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 65336,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2.15e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "openrouter/fireworks/firellava-13b": {
        "display_name": "FireLLaVA 13B",
        "model_vendor": "fireworks",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "openrouter",
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "supports_tool_choice": true
    },
    "openrouter/google/gemini-2.0-flash-001": {
        "display_name": "Gemini 2.0 Flash 001",
        "model_vendor": "google",
        "input_cost_per_audio_token": 7e-07,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "openrouter",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/google/gemini-2.5-flash": {
        "display_name": "Gemini 2.5 Flash",
        "model_vendor": "google",
        "input_cost_per_audio_token": 7e-07,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "openrouter",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 2.5e-06,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/google/gemini-2.5-pro": {
        "display_name": "Gemini 2.5 Pro",
        "model_vendor": "google",
        "input_cost_per_audio_token": 7e-07,
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "openrouter",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/google/gemini-3-pro-preview": {
        "display_name": "Gemini 3 Pro Preview",
        "model_vendor": "google",
        "cache_read_input_token_cost": 2e-07,
        "cache_read_input_token_cost_above_200k_tokens": 4e-07,
        "cache_creation_input_token_cost_above_200k_tokens": 2.5e-07,
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_above_200k_tokens": 4e-06,
        "input_cost_per_token_batches": 1e-06,
        "litellm_provider": "openrouter",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1.2e-05,
        "output_cost_per_token_above_200k_tokens": 1.8e-05,
        "output_cost_per_token_batches": 6e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_video_input": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "openrouter/google/gemini-pro-1.5": {
        "display_name": "Gemini Pro 1.5",
        "model_vendor": "google",
        "input_cost_per_image": 0.00265,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 7.5e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/google/gemini-pro-vision": {
        "display_name": "Gemini Pro Vision",
        "model_vendor": "google",
        "input_cost_per_image": 0.0025,
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "openrouter",
        "max_tokens": 45875,
        "mode": "chat",
        "output_cost_per_token": 3.75e-07,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/google/palm-2-chat-bison": {
        "display_name": "PaLM 2 Chat Bison",
        "model_vendor": "google",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "openrouter",
        "max_tokens": 25804,
        "mode": "chat",
        "output_cost_per_token": 5e-07,
        "supports_tool_choice": true
    },
    "openrouter/google/palm-2-codechat-bison": {
        "display_name": "PaLM 2 Codechat Bison",
        "model_vendor": "google",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "openrouter",
        "max_tokens": 20070,
        "mode": "chat",
        "output_cost_per_token": 5e-07,
        "supports_tool_choice": true
    },
    "openrouter/gryphe/mythomax-l2-13b": {
        "display_name": "MythoMax L2 13B",
        "model_vendor": "gryphe",
        "input_cost_per_token": 1.875e-06,
        "litellm_provider": "openrouter",
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.875e-06,
        "supports_tool_choice": true
    },
    "openrouter/jondurbin/airoboros-l2-70b-2.1": {
        "display_name": "Airoboros L2 70B 2.1",
        "model_vendor": "jondurbin",
        "model_version": "2.1",
        "input_cost_per_token": 1.3875e-05,
        "litellm_provider": "openrouter",
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.3875e-05,
        "supports_tool_choice": true
    },
    "openrouter/mancer/weaver": {
        "display_name": "Weaver",
        "model_vendor": "mancer",
        "input_cost_per_token": 5.625e-06,
        "litellm_provider": "openrouter",
        "max_tokens": 8000,
        "mode": "chat",
        "output_cost_per_token": 5.625e-06,
        "supports_tool_choice": true
    },
    "openrouter/meta-llama/codellama-34b-instruct": {
        "display_name": "Code Llama 34B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "openrouter",
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 5e-07,
        "supports_tool_choice": true
    },
    "openrouter/meta-llama/llama-2-13b-chat": {
        "display_name": "Llama 2 13B Chat",
        "model_vendor": "meta",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "openrouter",
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "supports_tool_choice": true
    },
    "openrouter/meta-llama/llama-2-70b-chat": {
        "display_name": "Llama 2 70B Chat",
        "model_vendor": "meta",
        "input_cost_per_token": 1.5e-06,
        "litellm_provider": "openrouter",
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "supports_tool_choice": true
    },
    "openrouter/meta-llama/llama-3-70b-instruct": {
        "display_name": "Llama 3 70B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 5.9e-07,
        "litellm_provider": "openrouter",
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 7.9e-07,
        "supports_tool_choice": true
    },
    "openrouter/meta-llama/llama-3-70b-instruct:nitro": {
        "display_name": "Llama 3 70B Instruct Nitro",
        "model_vendor": "meta",
        "input_cost_per_token": 9e-07,
        "litellm_provider": "openrouter",
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 9e-07,
        "supports_tool_choice": true
    },
    "openrouter/meta-llama/llama-3-8b-instruct:extended": {
        "display_name": "Llama 3 8B Instruct Extended",
        "model_vendor": "meta",
        "input_cost_per_token": 2.25e-07,
        "litellm_provider": "openrouter",
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 2.25e-06,
        "supports_tool_choice": true
    },
    "openrouter/meta-llama/llama-3-8b-instruct:free": {
        "display_name": "Llama 3 8B Instruct Free",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "openrouter",
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "supports_tool_choice": true
    },
    "openrouter/microsoft/wizardlm-2-8x22b:nitro": {
        "display_name": "WizardLM 2 8x22B Nitro",
        "model_vendor": "microsoft",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "openrouter",
        "max_tokens": 65536,
        "mode": "chat",
        "output_cost_per_token": 1e-06,
        "supports_tool_choice": true
    },
    "openrouter/minimax/minimax-m2": {
        "display_name": "MiniMax M2",
        "model_vendor": "minimax",
        "input_cost_per_token": 2.55e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 204800,
        "max_output_tokens": 204800,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 1.02e-06,
        "supports_function_calling": true,
        "supports_prompt_caching": false,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "openrouter/mistralai/devstral-2512:free": {
        "display_name": "Mistralai Devstral 2512:free",
        "model_vendor": "mistral",
        "input_cost_per_image": 0,
        "input_cost_per_token": 0,
        "litellm_provider": "openrouter",
        "max_input_tokens": 262144,
        "max_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 0,
        "supports_function_calling": true,
        "supports_prompt_caching": false,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "openrouter/mistralai/devstral-2512": {
        "display_name": "Mistralai Devstral 2512",
        "model_vendor": "mistral",
        "input_cost_per_image": 0,
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 262144,
        "max_output_tokens": 65536,
        "max_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "supports_function_calling": true,
        "supports_prompt_caching": false,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "openrouter/mistralai/ministral-3b-2512": {
        "display_name": "Mistralai Ministral 3B 2512",
        "model_vendor": "mistral",
        "input_cost_per_image": 0,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1e-07,
        "supports_function_calling": true,
        "supports_prompt_caching": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/mistralai/ministral-8b-2512": {
        "display_name": "Mistralai Ministral 8B 2512",
        "model_vendor": "mistral",
        "input_cost_per_image": 0,
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 262144,
        "max_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 1.5e-07,
        "supports_function_calling": true,
        "supports_prompt_caching": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/mistralai/ministral-14b-2512": {
        "display_name": "Mistralai Ministral 14B 2512",
        "model_vendor": "mistral",
        "input_cost_per_image": 0,
        "input_cost_per_token": 2e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 262144,
        "max_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "supports_function_calling": true,
        "supports_prompt_caching": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/mistralai/mistral-large-2512": {
        "display_name": "Mistralai Mistral Large 2512",
        "model_vendor": "mistral",
        "input_cost_per_image": 0,
        "input_cost_per_token": 5e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 262144,
        "max_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "supports_function_calling": true,
        "supports_prompt_caching": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/mistralai/mistral-7b-instruct": {
        "display_name": "Mistral 7B Instruct",
        "model_vendor": "mistralai",
        "input_cost_per_token": 1.3e-07,
        "litellm_provider": "openrouter",
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.3e-07,
        "supports_tool_choice": true
    },
    "openrouter/mistralai/mistral-7b-instruct:free": {
        "display_name": "Mistral 7B Instruct Free",
        "model_vendor": "mistralai",
        "input_cost_per_token": 0.0,
        "litellm_provider": "openrouter",
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "supports_tool_choice": true
    },
    "openrouter/mistralai/mistral-large": {
        "display_name": "Mistral Large",
        "model_vendor": "mistralai",
        "input_cost_per_token": 8e-06,
        "litellm_provider": "openrouter",
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 2.4e-05,
        "supports_tool_choice": true
    },
    "openrouter/mistralai/mistral-small-3.1-24b-instruct": {
        "display_name": "Mistral Small 3.1 24B Instruct",
        "model_vendor": "mistralai",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "openrouter",
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "supports_tool_choice": true
    },
    "openrouter/mistralai/mistral-small-3.2-24b-instruct": {
        "display_name": "Mistral Small 3.2 24B Instruct",
        "model_vendor": "mistralai",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "openrouter",
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "supports_tool_choice": true
    },
    "openrouter/mistralai/mixtral-8x22b-instruct": {
        "display_name": "Mixtral 8x22B Instruct",
        "model_vendor": "mistralai",
        "input_cost_per_token": 6.5e-07,
        "litellm_provider": "openrouter",
        "max_tokens": 65536,
        "mode": "chat",
        "output_cost_per_token": 6.5e-07,
        "supports_tool_choice": true
    },
    "openrouter/nousresearch/nous-hermes-llama2-13b": {
        "display_name": "Nous Hermes Llama2 13B",
        "model_vendor": "nousresearch",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "openrouter",
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "supports_tool_choice": true
    },
    "openrouter/openai/gpt-3.5-turbo": {
        "display_name": "GPT-3.5 Turbo",
        "model_vendor": "openai",
        "input_cost_per_token": 1.5e-06,
        "litellm_provider": "openrouter",
        "max_tokens": 4095,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "supports_tool_choice": true
    },
    "openrouter/openai/gpt-3.5-turbo-16k": {
        "display_name": "GPT-3.5 Turbo 16K",
        "model_vendor": "openai",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openrouter",
        "max_tokens": 16383,
        "mode": "chat",
        "output_cost_per_token": 4e-06,
        "supports_tool_choice": true
    },
    "openrouter/openai/gpt-4": {
        "display_name": "GPT-4",
        "model_vendor": "openai",
        "input_cost_per_token": 3e-05,
        "litellm_provider": "openrouter",
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_tool_choice": true
    },
    "openrouter/openai/gpt-4-vision-preview": {
        "display_name": "GPT-4 Vision Preview",
        "model_vendor": "openai",
        "input_cost_per_image": 0.01445,
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openrouter",
        "max_tokens": 130000,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/openai/gpt-4.1": {
        "display_name": "GPT-4.1",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 2e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/openai/gpt-4.1-2025-04-14": {
        "display_name": "GPT-4.1",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 2e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/openai/gpt-4.1-mini": {
        "display_name": "GPT-4.1 Mini",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 1e-07,
        "input_cost_per_token": 4e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 1.6e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/openai/gpt-4.1-mini-2025-04-14": {
        "display_name": "GPT-4.1 Mini",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 1e-07,
        "input_cost_per_token": 4e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 1.6e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/openai/gpt-4.1-nano": {
        "display_name": "GPT-4.1 Nano",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/openai/gpt-4.1-nano-2025-04-14": {
        "display_name": "GPT-4.1 Nano",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/openai/gpt-4o": {
        "display_name": "GPT-4o",
        "model_vendor": "openai",
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/openai/gpt-4o-2024-05-13": {
        "display_name": "GPT-4o",
        "model_vendor": "openai",
        "input_cost_per_token": 5e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/openai/gpt-5-chat": {
        "display_name": "GPT-5 Chat",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 1.25e-07,
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "openrouter/openai/gpt-5-codex": {
        "display_name": "GPT-5 Codex",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 1.25e-07,
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "openrouter/openai/gpt-5": {
        "display_name": "GPT-5",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 1.25e-07,
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "openrouter/openai/gpt-5-mini": {
        "display_name": "GPT-5 Mini",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "openrouter/openai/gpt-5-nano": {
        "display_name": "GPT-5 Nano",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 5e-09,
        "input_cost_per_token": 5e-08,
        "litellm_provider": "openrouter",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "openrouter/openai/gpt-5.2": {
        "display_name": "Openai GPT 5.2",
        "model_vendor": "openai",
        "model_version": "5.2",
        "input_cost_per_image": 0,
        "cache_read_input_token_cost": 1.75e-07,
        "input_cost_per_token": 1.75e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 400000,
        "max_output_tokens": 128000,
        "max_tokens": 400000,
        "mode": "chat",
        "output_cost_per_token": 1.4e-05,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/openai/gpt-5.2-chat": {
        "display_name": "Openai GPT 5.2 Chat",
        "model_vendor": "openai",
        "model_version": "5.2",
        "input_cost_per_image": 0,
        "cache_read_input_token_cost": 1.75e-07,
        "input_cost_per_token": 1.75e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.4e-05,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/openai/gpt-5.2-pro": {
        "display_name": "Openai GPT 5.2 Pro",
        "model_vendor": "openai",
        "model_version": "5.2",
        "input_cost_per_image": 0,
        "input_cost_per_token": 2.1e-05,
        "litellm_provider": "openrouter",
        "max_input_tokens": 400000,
        "max_output_tokens": 128000,
        "max_tokens": 400000,
        "mode": "chat",
        "output_cost_per_token": 0.000168,
        "supports_function_calling": true,
        "supports_prompt_caching": false,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/openai/gpt-oss-120b": {
        "display_name": "GPT-OSS 120B",
        "model_vendor": "openai",
        "input_cost_per_token": 1.8e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 131072,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 8e-07,
        "source": "https://openrouter.ai/openai/gpt-oss-120b",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "openrouter/openai/gpt-oss-20b": {
        "display_name": "GPT-OSS 20B",
        "model_vendor": "openai",
        "input_cost_per_token": 1.8e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 131072,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 8e-07,
        "source": "https://openrouter.ai/openai/gpt-oss-20b",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "openrouter/openai/o1": {
        "display_name": "o1",
        "model_vendor": "openai",
        "cache_read_input_token_cost": 7.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "openrouter",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/openai/o1-mini": {
        "display_name": "o1 Mini",
        "model_vendor": "openai",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "max_tokens": 65536,
        "mode": "chat",
        "output_cost_per_token": 1.2e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "openrouter/openai/o1-mini-2024-09-12": {
        "display_name": "o1 Mini",
        "model_vendor": "openai",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "max_tokens": 65536,
        "mode": "chat",
        "output_cost_per_token": 1.2e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "openrouter/openai/o1-preview": {
        "display_name": "o1 Preview",
        "model_vendor": "openai",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "openrouter",
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "openrouter/openai/o1-preview-2024-09-12": {
        "display_name": "o1 Preview",
        "model_vendor": "openai",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "openrouter",
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "openrouter/openai/o3-mini": {
        "display_name": "o3 Mini",
        "model_vendor": "openai",
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "max_tokens": 65536,
        "mode": "chat",
        "output_cost_per_token": 4.4e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "openrouter/openai/o3-mini-high": {
        "display_name": "o3 Mini High",
        "model_vendor": "openai",
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "max_tokens": 65536,
        "mode": "chat",
        "output_cost_per_token": 4.4e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "openrouter/pygmalionai/mythalion-13b": {
        "display_name": "Mythalion 13B",
        "model_vendor": "pygmalionai",
        "input_cost_per_token": 1.875e-06,
        "litellm_provider": "openrouter",
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.875e-06,
        "supports_tool_choice": true
    },
    "openrouter/qwen/qwen-2.5-coder-32b-instruct": {
        "display_name": "Qwen 2.5 Coder 32B Instruct",
        "model_vendor": "alibaba",
        "input_cost_per_token": 1.8e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 33792,
        "max_output_tokens": 33792,
        "max_tokens": 33792,
        "mode": "chat",
        "output_cost_per_token": 1.8e-07,
        "supports_tool_choice": true
    },
    "openrouter/qwen/qwen-vl-plus": {
        "display_name": "Qwen VL Plus",
        "model_vendor": "alibaba",
        "input_cost_per_token": 2.1e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 8192,
        "max_output_tokens": 2048,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 6.3e-07,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openrouter/qwen/qwen3-coder": {
        "display_name": "Qwen3 Coder",
        "model_vendor": "alibaba",
        "input_cost_per_token": 2.2e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 262100,
        "max_output_tokens": 262100,
        "max_tokens": 262100,
        "mode": "chat",
        "output_cost_per_token": 9.5e-07,
        "source": "https://openrouter.ai/qwen/qwen3-coder",
        "supports_tool_choice": true,
        "supports_function_calling": true
    },
    "openrouter/switchpoint/router": {
        "display_name": "Switchpoint Router",
        "model_vendor": "switchpoint",
        "input_cost_per_token": 8.5e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 3.4e-06,
        "source": "https://openrouter.ai/switchpoint/router",
        "supports_tool_choice": true
    },
    "openrouter/undi95/remm-slerp-l2-13b": {
        "display_name": "ReMM SLERP L2 13B",
        "model_vendor": "undi95",
        "input_cost_per_token": 1.875e-06,
        "litellm_provider": "openrouter",
        "max_tokens": 6144,
        "mode": "chat",
        "output_cost_per_token": 1.875e-06,
        "supports_tool_choice": true
    },
    "openrouter/x-ai/grok-4": {
        "display_name": "Grok 4",
        "model_vendor": "xai",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openrouter",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "source": "https://openrouter.ai/x-ai/grok-4",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "openrouter/x-ai/grok-4-fast:free": {
        "display_name": "Grok 4 Fast Free",
        "model_vendor": "xai",
        "input_cost_per_token": 0,
        "litellm_provider": "openrouter",
        "max_input_tokens": 2000000,
        "max_output_tokens": 30000,
        "max_tokens": 2000000,
        "mode": "chat",
        "output_cost_per_token": 0,
        "source": "https://openrouter.ai/x-ai/grok-4-fast:free",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "supports_web_search": false
    },
    "openrouter/z-ai/glm-4.6": {
        "display_name": "GLM 4.6",
        "model_vendor": "zhipu",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 202800,
        "max_output_tokens": 131000,
        "max_tokens": 202800,
        "mode": "chat",
        "output_cost_per_token": 1.75e-06,
        "source": "https://openrouter.ai/z-ai/glm-4.6",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "openrouter/z-ai/glm-4.6:exacto": {
        "display_name": "GLM 4.6 Exacto",
        "model_vendor": "zhipu",
        "input_cost_per_token": 4.5e-07,
        "litellm_provider": "openrouter",
        "max_input_tokens": 202800,
        "max_output_tokens": 131000,
        "max_tokens": 202800,
        "mode": "chat",
        "output_cost_per_token": 1.9e-06,
        "source": "https://openrouter.ai/z-ai/glm-4.6:exacto",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "ovhcloud/DeepSeek-R1-Distill-Llama-70B": {
        "display_name": "DeepSeek R1 Distill Llama 70B",
        "model_vendor": "deepseek",
        "input_cost_per_token": 6.7e-07,
        "litellm_provider": "ovhcloud",
        "max_input_tokens": 131000,
        "max_output_tokens": 131000,
        "max_tokens": 131000,
        "mode": "chat",
        "output_cost_per_token": 6.7e-07,
        "source": "https://endpoints.ai.cloud.ovh.net/models/deepseek-r1-distill-llama-70b",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "ovhcloud/Llama-3.1-8B-Instruct": {
        "display_name": "Llama 3.1 8B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "ovhcloud",
        "max_input_tokens": 131000,
        "max_output_tokens": 131000,
        "max_tokens": 131000,
        "mode": "chat",
        "output_cost_per_token": 1e-07,
        "source": "https://endpoints.ai.cloud.ovh.net/models/llama-3-1-8b-instruct",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "ovhcloud/Meta-Llama-3_1-70B-Instruct": {
        "display_name": "Meta Llama 3.1 70B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 6.7e-07,
        "litellm_provider": "ovhcloud",
        "max_input_tokens": 131000,
        "max_output_tokens": 131000,
        "max_tokens": 131000,
        "mode": "chat",
        "output_cost_per_token": 6.7e-07,
        "source": "https://endpoints.ai.cloud.ovh.net/models/meta-llama-3-1-70b-instruct",
        "supports_function_calling": false,
        "supports_response_schema": false,
        "supports_tool_choice": false
    },
    "ovhcloud/Meta-Llama-3_3-70B-Instruct": {
        "display_name": "Meta Llama 3.3 70B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 6.7e-07,
        "litellm_provider": "ovhcloud",
        "max_input_tokens": 131000,
        "max_output_tokens": 131000,
        "max_tokens": 131000,
        "mode": "chat",
        "output_cost_per_token": 6.7e-07,
        "source": "https://endpoints.ai.cloud.ovh.net/models/meta-llama-3-3-70b-instruct",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "ovhcloud/Mistral-7B-Instruct-v0.3": {
        "display_name": "Mistral 7B Instruct v0.3",
        "model_vendor": "mistralai",
        "model_version": "0.3",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "ovhcloud",
        "max_input_tokens": 127000,
        "max_output_tokens": 127000,
        "max_tokens": 127000,
        "mode": "chat",
        "output_cost_per_token": 1e-07,
        "source": "https://endpoints.ai.cloud.ovh.net/models/mistral-7b-instruct-v0-3",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "ovhcloud/Mistral-Nemo-Instruct-2407": {
        "display_name": "Mistral Nemo Instruct 2407",
        "model_vendor": "mistralai",
        "model_version": "2407",
        "input_cost_per_token": 1.3e-07,
        "litellm_provider": "ovhcloud",
        "max_input_tokens": 118000,
        "max_output_tokens": 118000,
        "max_tokens": 118000,
        "mode": "chat",
        "output_cost_per_token": 1.3e-07,
        "source": "https://endpoints.ai.cloud.ovh.net/models/mistral-nemo-instruct-2407",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "ovhcloud/Mistral-Small-3.2-24B-Instruct-2506": {
        "display_name": "Mistral Small 3.2 24B Instruct 2506",
        "model_vendor": "mistralai",
        "input_cost_per_token": 9e-08,
        "litellm_provider": "ovhcloud",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 2.8e-07,
        "source": "https://endpoints.ai.cloud.ovh.net/models/mistral-small-3-2-24b-instruct-2506",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "ovhcloud/Mixtral-8x7B-Instruct-v0.1": {
        "display_name": "Mixtral 8x7B Instruct v0.1",
        "model_vendor": "mistralai",
        "input_cost_per_token": 6.3e-07,
        "litellm_provider": "ovhcloud",
        "max_input_tokens": 32000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 6.3e-07,
        "source": "https://endpoints.ai.cloud.ovh.net/models/mixtral-8x7b-instruct-v0-1",
        "supports_function_calling": false,
        "supports_response_schema": true,
        "supports_tool_choice": false
    },
    "ovhcloud/Qwen2.5-Coder-32B-Instruct": {
        "display_name": "Qwen 2.5 Coder 32B Instruct",
        "model_vendor": "alibaba",
        "input_cost_per_token": 8.7e-07,
        "litellm_provider": "ovhcloud",
        "max_input_tokens": 32000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 8.7e-07,
        "source": "https://endpoints.ai.cloud.ovh.net/models/qwen2-5-coder-32b-instruct",
        "supports_function_calling": false,
        "supports_response_schema": true,
        "supports_tool_choice": false
    },
    "ovhcloud/Qwen2.5-VL-72B-Instruct": {
        "display_name": "Qwen 2.5 VL 72B Instruct",
        "model_vendor": "alibaba",
        "input_cost_per_token": 9.1e-07,
        "litellm_provider": "ovhcloud",
        "max_input_tokens": 32000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 9.1e-07,
        "source": "https://endpoints.ai.cloud.ovh.net/models/qwen2-5-vl-72b-instruct",
        "supports_function_calling": false,
        "supports_response_schema": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "ovhcloud/Qwen3-32B": {
        "display_name": "Qwen3 32B",
        "model_vendor": "alibaba",
        "input_cost_per_token": 8e-08,
        "litellm_provider": "ovhcloud",
        "max_input_tokens": 32000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 2.3e-07,
        "source": "https://endpoints.ai.cloud.ovh.net/models/qwen3-32b",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "ovhcloud/gpt-oss-120b": {
        "display_name": "GPT-OSS 120B",
        "model_vendor": "openai",
        "input_cost_per_token": 8e-08,
        "litellm_provider": "ovhcloud",
        "max_input_tokens": 131000,
        "max_output_tokens": 131000,
        "max_tokens": 131000,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "source": "https://endpoints.ai.cloud.ovh.net/models/gpt-oss-120b",
        "supports_function_calling": false,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": false
    },
    "ovhcloud/gpt-oss-20b": {
        "display_name": "GPT-OSS 20B",
        "model_vendor": "openai",
        "input_cost_per_token": 4e-08,
        "litellm_provider": "ovhcloud",
        "max_input_tokens": 131000,
        "max_output_tokens": 131000,
        "max_tokens": 131000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-07,
        "source": "https://endpoints.ai.cloud.ovh.net/models/gpt-oss-20b",
        "supports_function_calling": false,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": false
    },
    "ovhcloud/llava-v1.6-mistral-7b-hf": {
        "display_name": "LLaVA v1.6 Mistral 7B",
        "model_vendor": "liuhaotian",
        "model_version": "1.6",
        "input_cost_per_token": 2.9e-07,
        "litellm_provider": "ovhcloud",
        "max_input_tokens": 32000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 2.9e-07,
        "source": "https://endpoints.ai.cloud.ovh.net/models/llava-next-mistral-7b",
        "supports_function_calling": false,
        "supports_response_schema": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "ovhcloud/mamba-codestral-7B-v0.1": {
        "display_name": "Mamba Codestral 7B v0.1",
        "model_vendor": "mistralai",
        "input_cost_per_token": 1.9e-07,
        "litellm_provider": "ovhcloud",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 1.9e-07,
        "source": "https://endpoints.ai.cloud.ovh.net/models/mamba-codestral-7b-v0-1",
        "supports_function_calling": false,
        "supports_response_schema": true,
        "supports_tool_choice": false
    },
    "palm/chat-bison": {
        "display_name": "PaLM Chat Bison",
        "model_vendor": "google",
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "palm",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "palm/chat-bison-001": {
        "display_name": "PaLM Chat Bison 001",
        "model_vendor": "google",
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "palm",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "palm/text-bison": {
        "display_name": "PaLM Text Bison",
        "model_vendor": "google",
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "palm",
        "max_input_tokens": 8192,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "completion",
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "palm/text-bison-001": {
        "display_name": "PaLM Text Bison 001",
        "model_vendor": "google",
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "palm",
        "max_input_tokens": 8192,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "completion",
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "palm/text-bison-safety-off": {
        "display_name": "PaLM Text Bison Safety Off",
        "model_vendor": "google",
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "palm",
        "max_input_tokens": 8192,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "completion",
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "palm/text-bison-safety-recitation-off": {
        "display_name": "PaLM Text Bison Safety Recitation Off",
        "model_vendor": "google",
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "palm",
        "max_input_tokens": 8192,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "completion",
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "parallel_ai/search": {
        "display_name": "Parallel AI Search",
        "model_vendor": "parallel_ai",
        "input_cost_per_query": 0.004,
        "litellm_provider": "parallel_ai",
        "mode": "search"
    },
    "parallel_ai/search-pro": {
        "display_name": "Parallel AI Search Pro",
        "model_vendor": "parallel_ai",
        "input_cost_per_query": 0.009,
        "litellm_provider": "parallel_ai",
        "mode": "search"
    },
    "perplexity/codellama-34b-instruct": {
        "display_name": "Code Llama 34B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 3.5e-07,
        "litellm_provider": "perplexity",
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1.4e-06
    },
    "perplexity/codellama-70b-instruct": {
        "display_name": "Code Llama 70B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 7e-07,
        "litellm_provider": "perplexity",
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 2.8e-06
    },
    "perplexity/llama-2-70b-chat": {
        "display_name": "Llama 2 70B Chat",
        "model_vendor": "meta",
        "input_cost_per_token": 7e-07,
        "litellm_provider": "perplexity",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 2.8e-06
    },
    "perplexity/llama-3.1-70b-instruct": {
        "display_name": "Llama 3.1 70B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "perplexity",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1e-06
    },
    "perplexity/llama-3.1-8b-instruct": {
        "display_name": "Llama 3.1 8B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "perplexity",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 2e-07
    },
    "perplexity/llama-3.1-sonar-huge-128k-online": {
        "display_name": "Llama 3.1 Sonar Huge 128K Online",
        "model_vendor": "perplexity",
        "deprecation_date": "2025-02-22",
        "input_cost_per_token": 5e-06,
        "litellm_provider": "perplexity",
        "max_input_tokens": 127072,
        "max_output_tokens": 127072,
        "max_tokens": 127072,
        "mode": "chat",
        "output_cost_per_token": 5e-06
    },
    "perplexity/llama-3.1-sonar-large-128k-chat": {
        "display_name": "Llama 3.1 Sonar Large 128K Chat",
        "model_vendor": "perplexity",
        "deprecation_date": "2025-02-22",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "perplexity",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1e-06
    },
    "perplexity/llama-3.1-sonar-large-128k-online": {
        "display_name": "Llama 3.1 Sonar Large 128K Online",
        "model_vendor": "perplexity",
        "deprecation_date": "2025-02-22",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "perplexity",
        "max_input_tokens": 127072,
        "max_output_tokens": 127072,
        "max_tokens": 127072,
        "mode": "chat",
        "output_cost_per_token": 1e-06
    },
    "perplexity/llama-3.1-sonar-small-128k-chat": {
        "display_name": "Llama 3.1 Sonar Small 128K Chat",
        "model_vendor": "perplexity",
        "deprecation_date": "2025-02-22",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "perplexity",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 2e-07
    },
    "perplexity/llama-3.1-sonar-small-128k-online": {
        "display_name": "Llama 3.1 Sonar Small 128K Online",
        "model_vendor": "perplexity",
        "deprecation_date": "2025-02-22",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "perplexity",
        "max_input_tokens": 127072,
        "max_output_tokens": 127072,
        "max_tokens": 127072,
        "mode": "chat",
        "output_cost_per_token": 2e-07
    },
    "perplexity/mistral-7b-instruct": {
        "display_name": "Mistral 7B Instruct",
        "model_vendor": "mistralai",
        "input_cost_per_token": 7e-08,
        "litellm_provider": "perplexity",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 2.8e-07
    },
    "perplexity/mixtral-8x7b-instruct": {
        "display_name": "Mixtral 8x7B Instruct",
        "model_vendor": "mistralai",
        "input_cost_per_token": 7e-08,
        "litellm_provider": "perplexity",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 2.8e-07
    },
    "perplexity/pplx-70b-chat": {
        "display_name": "PPLX 70B Chat",
        "model_vendor": "perplexity",
        "input_cost_per_token": 7e-07,
        "litellm_provider": "perplexity",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 2.8e-06
    },
    "perplexity/pplx-70b-online": {
        "display_name": "PPLX 70B Online",
        "model_vendor": "perplexity",
        "input_cost_per_request": 0.005,
        "input_cost_per_token": 0.0,
        "litellm_provider": "perplexity",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 2.8e-06
    },
    "perplexity/pplx-7b-chat": {
        "display_name": "PPLX 7B Chat",
        "model_vendor": "perplexity",
        "input_cost_per_token": 7e-08,
        "litellm_provider": "perplexity",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2.8e-07
    },
    "perplexity/pplx-7b-online": {
        "display_name": "PPLX 7B Online",
        "model_vendor": "perplexity",
        "input_cost_per_request": 0.005,
        "input_cost_per_token": 0.0,
        "litellm_provider": "perplexity",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 2.8e-07
    },
    "perplexity/sonar": {
        "display_name": "Sonar",
        "model_vendor": "perplexity",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "perplexity",
        "max_input_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-06,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.012,
            "search_context_size_low": 0.005,
            "search_context_size_medium": 0.008
        },
        "supports_web_search": true
    },
    "perplexity/sonar-deep-research": {
        "display_name": "Sonar Deep Research",
        "model_vendor": "perplexity",
        "citation_cost_per_token": 2e-06,
        "input_cost_per_token": 2e-06,
        "litellm_provider": "perplexity",
        "max_input_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_reasoning_token": 3e-06,
        "output_cost_per_token": 8e-06,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.005,
            "search_context_size_low": 0.005,
            "search_context_size_medium": 0.005
        },
        "supports_reasoning": true,
        "supports_web_search": true
    },
    "perplexity/sonar-medium-chat": {
        "display_name": "Sonar Medium Chat",
        "model_vendor": "perplexity",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "perplexity",
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1.8e-06
    },
    "perplexity/sonar-medium-online": {
        "display_name": "Sonar Medium Online",
        "model_vendor": "perplexity",
        "input_cost_per_request": 0.005,
        "input_cost_per_token": 0,
        "litellm_provider": "perplexity",
        "max_input_tokens": 12000,
        "max_output_tokens": 12000,
        "max_tokens": 12000,
        "mode": "chat",
        "output_cost_per_token": 1.8e-06
    },
    "perplexity/sonar-pro": {
        "display_name": "Sonar Pro",
        "model_vendor": "perplexity",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "perplexity",
        "max_input_tokens": 200000,
        "max_output_tokens": 8000,
        "max_tokens": 8000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.014,
            "search_context_size_low": 0.006,
            "search_context_size_medium": 0.01
        },
        "supports_web_search": true
    },
    "perplexity/sonar-reasoning": {
        "display_name": "Sonar Reasoning",
        "model_vendor": "perplexity",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "perplexity",
        "max_input_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.014,
            "search_context_size_low": 0.005,
            "search_context_size_medium": 0.008
        },
        "supports_reasoning": true,
        "supports_web_search": true
    },
    "perplexity/sonar-reasoning-pro": {
        "display_name": "Sonar Reasoning Pro",
        "model_vendor": "perplexity",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "perplexity",
        "max_input_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.014,
            "search_context_size_low": 0.006,
            "search_context_size_medium": 0.01
        },
        "supports_reasoning": true,
        "supports_web_search": true
    },
    "perplexity/sonar-small-chat": {
        "display_name": "Sonar Small Chat",
        "model_vendor": "perplexity",
        "input_cost_per_token": 7e-08,
        "litellm_provider": "perplexity",
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 2.8e-07
    },
    "perplexity/sonar-small-online": {
        "display_name": "Sonar Small Online",
        "model_vendor": "perplexity",
        "input_cost_per_request": 0.005,
        "input_cost_per_token": 0,
        "litellm_provider": "perplexity",
        "max_input_tokens": 12000,
        "max_output_tokens": 12000,
        "max_tokens": 12000,
        "mode": "chat",
        "output_cost_per_token": 2.8e-07
    },
    "publicai/swiss-ai/apertus-8b-instruct": {
        "display_name": "Apertus 8B Instruct",
        "model_vendor": "swiss_ai",
        "input_cost_per_token": 0.0,
        "litellm_provider": "publicai",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "source": "https://platform.publicai.co/docs",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "publicai/swiss-ai/apertus-70b-instruct": {
        "display_name": "Apertus 70B Instruct",
        "model_vendor": "swiss_ai",
        "input_cost_per_token": 0.0,
        "litellm_provider": "publicai",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "source": "https://platform.publicai.co/docs",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "publicai/aisingapore/Gemma-SEA-LION-v4-27B-IT": {
        "display_name": "Gemma SEA-LION v4 27B IT",
        "model_vendor": "aisingapore",
        "input_cost_per_token": 0.0,
        "litellm_provider": "publicai",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "source": "https://platform.publicai.co/docs",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "publicai/BSC-LT/salamandra-7b-instruct-tools-16k": {
        "display_name": "Salamandra 7B Instruct Tools 16K",
        "model_vendor": "bsc_lt",
        "input_cost_per_token": 0.0,
        "litellm_provider": "publicai",
        "max_input_tokens": 16384,
        "max_output_tokens": 4096,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "source": "https://platform.publicai.co/docs",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "publicai/BSC-LT/ALIA-40b-instruct_Q8_0": {
        "display_name": "ALIA 40B Instruct Q8",
        "model_vendor": "bsc_lt",
        "input_cost_per_token": 0.0,
        "litellm_provider": "publicai",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "source": "https://platform.publicai.co/docs",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "publicai/allenai/Olmo-3-7B-Instruct": {
        "display_name": "Olmo 3 7B Instruct",
        "model_vendor": "allenai",
        "input_cost_per_token": 0.0,
        "litellm_provider": "publicai",
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "source": "https://platform.publicai.co/docs",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "publicai/aisingapore/Qwen-SEA-LION-v4-32B-IT": {
        "display_name": "Qwen SEA-LION v4 32B IT",
        "model_vendor": "aisingapore",
        "input_cost_per_token": 0.0,
        "litellm_provider": "publicai",
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "source": "https://platform.publicai.co/docs",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "publicai/allenai/Olmo-3-7B-Think": {
        "display_name": "Olmo 3 7B Think",
        "model_vendor": "allenai",
        "input_cost_per_token": 0.0,
        "litellm_provider": "publicai",
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "source": "https://platform.publicai.co/docs",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_reasoning": true
    },
    "publicai/allenai/Olmo-3-32B-Think": {
        "display_name": "Olmo 3 32B Think",
        "model_vendor": "allenai",
        "input_cost_per_token": 0.0,
        "litellm_provider": "publicai",
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "source": "https://platform.publicai.co/docs",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_reasoning": true
    },
    "qwen.qwen3-coder-480b-a35b-v1:0": {
        "display_name": "Qwen3 Coder 480B A35B v1",
        "model_vendor": "alibaba",
        "input_cost_per_token": 2.2e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 262000,
        "max_output_tokens": 65536,
        "max_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 1.8e-06,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "qwen.qwen3-235b-a22b-2507-v1:0": {
        "display_name": "Qwen3 235B A22B 2507 v1",
        "model_vendor": "alibaba",
        "input_cost_per_token": 2.2e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 262144,
        "max_output_tokens": 131072,
        "max_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 8.8e-07,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "qwen.qwen3-coder-30b-a3b-v1:0": {
        "display_name": "Qwen3 Coder 30B A3B v1",
        "model_vendor": "alibaba",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 262144,
        "max_output_tokens": 131072,
        "max_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "qwen.qwen3-32b-v1:0": {
        "display_name": "Qwen3 32B v1",
        "model_vendor": "alibaba",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 131072,
        "max_output_tokens": 16384,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "qwen.qwen3-next-80b-a3b": {
        "display_name": "Qwen3 Next 80B A3b",
        "model_vendor": "alibaba",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.2e-06,
        "supports_function_calling": true,
        "supports_system_messages": true
    },
    "qwen.qwen3-vl-235b-a22b": {
        "display_name": "Qwen3 VL 235B A22b",
        "model_vendor": "alibaba",
        "input_cost_per_token": 5.3e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2.66e-06,
        "supports_function_calling": true,
        "supports_system_messages": true,
        "supports_vision": true
    },
    "recraft/recraftv2": {
        "display_name": "Recraft v2",
        "model_vendor": "recraft",
        "litellm_provider": "recraft",
        "mode": "image_generation",
        "output_cost_per_image": 0.022,
        "source": "https://www.recraft.ai/docs#pricing",
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "recraft/recraftv3": {
        "display_name": "Recraft v3",
        "model_vendor": "recraft",
        "litellm_provider": "recraft",
        "mode": "image_generation",
        "output_cost_per_image": 0.04,
        "source": "https://www.recraft.ai/docs#pricing",
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "replicate/meta/llama-2-13b": {
        "display_name": "Llama 2 13B",
        "model_vendor": "meta",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "replicate",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 5e-07,
        "supports_tool_choice": true
    },
    "replicate/meta/llama-2-13b-chat": {
        "display_name": "Llama 2 13B Chat",
        "model_vendor": "meta",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "replicate",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 5e-07,
        "supports_tool_choice": true
    },
    "replicate/meta/llama-2-70b": {
        "display_name": "Llama 2 70B",
        "model_vendor": "meta",
        "input_cost_per_token": 6.5e-07,
        "litellm_provider": "replicate",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 2.75e-06,
        "supports_tool_choice": true
    },
    "replicate/meta/llama-2-70b-chat": {
        "display_name": "Llama 2 70B Chat",
        "model_vendor": "meta",
        "input_cost_per_token": 6.5e-07,
        "litellm_provider": "replicate",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 2.75e-06,
        "supports_tool_choice": true
    },
    "replicate/meta/llama-2-7b": {
        "display_name": "Llama 2 7B",
        "model_vendor": "meta",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "replicate",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 2.5e-07,
        "supports_tool_choice": true
    },
    "replicate/meta/llama-2-7b-chat": {
        "display_name": "Llama 2 7B Chat",
        "model_vendor": "meta",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "replicate",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 2.5e-07,
        "supports_tool_choice": true
    },
    "replicate/meta/llama-3-70b": {
        "display_name": "Llama 3 70B",
        "model_vendor": "meta",
        "input_cost_per_token": 6.5e-07,
        "litellm_provider": "replicate",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2.75e-06,
        "supports_tool_choice": true
    },
    "replicate/meta/llama-3-70b-instruct": {
        "display_name": "Llama 3 70B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 6.5e-07,
        "litellm_provider": "replicate",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2.75e-06,
        "supports_tool_choice": true
    },
    "replicate/meta/llama-3-8b": {
        "display_name": "Llama 3 8B",
        "model_vendor": "meta",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "replicate",
        "max_input_tokens": 8086,
        "max_output_tokens": 8086,
        "max_tokens": 8086,
        "mode": "chat",
        "output_cost_per_token": 2.5e-07,
        "supports_tool_choice": true
    },
    "replicate/meta/llama-3-8b-instruct": {
        "display_name": "Llama 3 8B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "replicate",
        "max_input_tokens": 8086,
        "max_output_tokens": 8086,
        "max_tokens": 8086,
        "mode": "chat",
        "output_cost_per_token": 2.5e-07,
        "supports_tool_choice": true
    },
    "replicate/mistralai/mistral-7b-instruct-v0.2": {
        "display_name": "Mistral 7B Instruct v0.2",
        "model_vendor": "mistralai",
        "model_version": "0.2",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "replicate",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 2.5e-07,
        "supports_tool_choice": true
    },
    "replicate/mistralai/mistral-7b-v0.1": {
        "display_name": "Mistral 7B v0.1",
        "model_vendor": "mistralai",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "replicate",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 2.5e-07,
        "supports_tool_choice": true
    },
    "replicate/mistralai/mixtral-8x7b-instruct-v0.1": {
        "display_name": "Mixtral 8x7B Instruct v0.1",
        "model_vendor": "mistralai",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "replicate",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1e-06,
        "supports_tool_choice": true
    },
    "rerank-english-v2.0": {
        "display_name": "Rerank English v2.0",
        "model_vendor": "cohere",
        "input_cost_per_query": 0.002,
        "input_cost_per_token": 0.0,
        "litellm_provider": "cohere",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_query_tokens": 2048,
        "max_tokens": 4096,
        "mode": "rerank",
        "output_cost_per_token": 0.0
    },
    "rerank-english-v3.0": {
        "display_name": "Rerank English v3.0",
        "model_vendor": "cohere",
        "input_cost_per_query": 0.002,
        "input_cost_per_token": 0.0,
        "litellm_provider": "cohere",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_query_tokens": 2048,
        "max_tokens": 4096,
        "mode": "rerank",
        "output_cost_per_token": 0.0
    },
    "rerank-multilingual-v2.0": {
        "display_name": "Rerank Multilingual v2.0",
        "model_vendor": "cohere",
        "input_cost_per_query": 0.002,
        "input_cost_per_token": 0.0,
        "litellm_provider": "cohere",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_query_tokens": 2048,
        "max_tokens": 4096,
        "mode": "rerank",
        "output_cost_per_token": 0.0
    },
    "rerank-multilingual-v3.0": {
        "display_name": "Rerank Multilingual v3.0",
        "model_vendor": "cohere",
        "input_cost_per_query": 0.002,
        "input_cost_per_token": 0.0,
        "litellm_provider": "cohere",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_query_tokens": 2048,
        "max_tokens": 4096,
        "mode": "rerank",
        "output_cost_per_token": 0.0
    },
    "rerank-v3.5": {
        "display_name": "Rerank v3.5",
        "model_vendor": "cohere",
        "input_cost_per_query": 0.002,
        "input_cost_per_token": 0.0,
        "litellm_provider": "cohere",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_query_tokens": 2048,
        "max_tokens": 4096,
        "mode": "rerank",
        "output_cost_per_token": 0.0
    },
    "nvidia_nim/nvidia/nv-rerankqa-mistral-4b-v3": {
        "display_name": "NV RerankQA Mistral 4B v3",
        "model_vendor": "nvidia",
        "input_cost_per_query": 0.0,
        "input_cost_per_token": 0.0,
        "litellm_provider": "nvidia_nim",
        "mode": "rerank",
        "output_cost_per_token": 0.0
    },
    "nvidia_nim/nvidia/llama-3_2-nv-rerankqa-1b-v2": {
        "display_name": "Llama 3.2 NV RerankQA 1B v2",
        "model_vendor": "nvidia",
        "input_cost_per_query": 0.0,
        "input_cost_per_token": 0.0,
        "litellm_provider": "nvidia_nim",
        "mode": "rerank",
        "output_cost_per_token": 0.0
    },
    "nvidia_nim/ranking/nvidia/llama-3.2-nv-rerankqa-1b-v2": {
        "display_name": "Llama 3.2 Nv Rerankqa 1B V2",
        "model_vendor": "meta",
        "model_version": "3.2",
        "input_cost_per_query": 0.0,
        "input_cost_per_token": 0.0,
        "litellm_provider": "nvidia_nim",
        "mode": "rerank",
        "output_cost_per_token": 0.0
    },
    "sagemaker/meta-textgeneration-llama-2-13b": {
        "display_name": "Llama 2 13B",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "sagemaker",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "completion",
        "output_cost_per_token": 0.0
    },
    "sagemaker/meta-textgeneration-llama-2-13b-f": {
        "display_name": "Llama 2 13B F",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "sagemaker",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 0.0
    },
    "sagemaker/meta-textgeneration-llama-2-70b": {
        "display_name": "Llama 2 70B",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "sagemaker",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "completion",
        "output_cost_per_token": 0.0
    },
    "sagemaker/meta-textgeneration-llama-2-70b-b-f": {
        "display_name": "Llama 2 70B B F",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "sagemaker",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 0.0
    },
    "sagemaker/meta-textgeneration-llama-2-7b": {
        "display_name": "Llama 2 7B",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "sagemaker",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "completion",
        "output_cost_per_token": 0.0
    },
    "sagemaker/meta-textgeneration-llama-2-7b-f": {
        "display_name": "Llama 2 7B F",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "sagemaker",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 0.0
    },
    "sambanova/DeepSeek-R1": {
        "display_name": "DeepSeek R1",
        "model_vendor": "deepseek",
        "input_cost_per_token": 5e-06,
        "litellm_provider": "sambanova",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 7e-06,
        "source": "https://cloud.sambanova.ai/plans/pricing"
    },
    "sambanova/DeepSeek-R1-Distill-Llama-70B": {
        "display_name": "DeepSeek R1 Distill Llama 70B",
        "model_vendor": "deepseek",
        "input_cost_per_token": 7e-07,
        "litellm_provider": "sambanova",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1.4e-06,
        "source": "https://cloud.sambanova.ai/plans/pricing"
    },
    "sambanova/DeepSeek-V3-0324": {
        "display_name": "DeepSeek V3 0324",
        "model_vendor": "deepseek",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "sambanova",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 4.5e-06,
        "source": "https://cloud.sambanova.ai/plans/pricing",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "sambanova/Llama-4-Maverick-17B-128E-Instruct": {
        "display_name": "Llama 4 Maverick 17B 128E Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 6.3e-07,
        "litellm_provider": "sambanova",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "metadata": {
            "notes": "For vision models, images are converted to 6432 input tokens and are billed at that amount"
        },
        "mode": "chat",
        "output_cost_per_token": 1.8e-06,
        "source": "https://cloud.sambanova.ai/plans/pricing",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "sambanova/Llama-4-Scout-17B-16E-Instruct": {
        "display_name": "Llama 4 Scout 17B 16E Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "sambanova",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "metadata": {
            "notes": "For vision models, images are converted to 6432 input tokens and are billed at that amount"
        },
        "mode": "chat",
        "output_cost_per_token": 7e-07,
        "source": "https://cloud.sambanova.ai/plans/pricing",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "sambanova/Meta-Llama-3.1-405B-Instruct": {
        "display_name": "Meta Llama 3.1 405B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 5e-06,
        "litellm_provider": "sambanova",
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "source": "https://cloud.sambanova.ai/plans/pricing",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "sambanova/Meta-Llama-3.1-8B-Instruct": {
        "display_name": "Meta Llama 3.1 8B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "sambanova",
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "source": "https://cloud.sambanova.ai/plans/pricing",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "sambanova/Meta-Llama-3.2-1B-Instruct": {
        "display_name": "Meta Llama 3.2 1B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 4e-08,
        "litellm_provider": "sambanova",
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 8e-08,
        "source": "https://cloud.sambanova.ai/plans/pricing"
    },
    "sambanova/Meta-Llama-3.2-3B-Instruct": {
        "display_name": "Meta Llama 3.2 3B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 8e-08,
        "litellm_provider": "sambanova",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.6e-07,
        "source": "https://cloud.sambanova.ai/plans/pricing"
    },
    "sambanova/Meta-Llama-3.3-70B-Instruct": {
        "display_name": "Meta Llama 3.3 70B Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "sambanova",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1.2e-06,
        "source": "https://cloud.sambanova.ai/plans/pricing",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "sambanova/Meta-Llama-Guard-3-8B": {
        "display_name": "Meta Llama Guard 3 8B",
        "model_vendor": "meta",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "sambanova",
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "source": "https://cloud.sambanova.ai/plans/pricing"
    },
    "sambanova/QwQ-32B": {
        "display_name": "QwQ 32B",
        "model_vendor": "alibaba",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "sambanova",
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-06,
        "source": "https://cloud.sambanova.ai/plans/pricing"
    },
    "sambanova/Qwen2-Audio-7B-Instruct": {
        "display_name": "Qwen2 Audio 7B Instruct",
        "model_vendor": "alibaba",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "sambanova",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 0.0001,
        "source": "https://cloud.sambanova.ai/plans/pricing",
        "supports_audio_input": true
    },
    "sambanova/Qwen3-32B": {
        "display_name": "Qwen3 32B",
        "model_vendor": "alibaba",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "sambanova",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 8e-07,
        "source": "https://cloud.sambanova.ai/plans/pricing",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "sambanova/DeepSeek-V3.1": {
        "display_name": "DeepSeek V3.1",
        "model_vendor": "deepseek",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 4.5e-06,
        "litellm_provider": "sambanova",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_reasoning": true,
        "source": "https://cloud.sambanova.ai/plans/pricing"
    },
    "sambanova/gpt-oss-120b": {
        "display_name": "GPT-OSS 120B",
        "model_vendor": "openai",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 4.5e-06,
        "litellm_provider": "sambanova",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_reasoning": true,
        "source": "https://cloud.sambanova.ai/plans/pricing"
    },
    "snowflake/claude-3-5-sonnet": {
        "display_name": "Claude 3.5 Sonnet",
        "model_vendor": "anthropic",
        "litellm_provider": "snowflake",
        "max_input_tokens": 18000,
        "max_output_tokens": 8192,
        "max_tokens": 18000,
        "mode": "chat",
        "supports_computer_use": true
    },
    "snowflake/deepseek-r1": {
        "display_name": "DeepSeek R1",
        "model_vendor": "deepseek",
        "litellm_provider": "snowflake",
        "max_input_tokens": 32768,
        "max_output_tokens": 8192,
        "max_tokens": 32768,
        "mode": "chat",
        "supports_reasoning": true
    },
    "snowflake/gemma-7b": {
        "display_name": "Gemma 7B",
        "model_vendor": "google",
        "litellm_provider": "snowflake",
        "max_input_tokens": 8000,
        "max_output_tokens": 8192,
        "max_tokens": 8000,
        "mode": "chat"
    },
    "snowflake/jamba-1.5-large": {
        "display_name": "Jamba 1.5 Large",
        "model_vendor": "ai21",
        "litellm_provider": "snowflake",
        "max_input_tokens": 256000,
        "max_output_tokens": 8192,
        "max_tokens": 256000,
        "mode": "chat"
    },
    "snowflake/jamba-1.5-mini": {
        "display_name": "Jamba 1.5 Mini",
        "model_vendor": "ai21",
        "litellm_provider": "snowflake",
        "max_input_tokens": 256000,
        "max_output_tokens": 8192,
        "max_tokens": 256000,
        "mode": "chat"
    },
    "snowflake/jamba-instruct": {
        "display_name": "Jamba Instruct",
        "model_vendor": "ai21",
        "litellm_provider": "snowflake",
        "max_input_tokens": 256000,
        "max_output_tokens": 8192,
        "max_tokens": 256000,
        "mode": "chat"
    },
    "snowflake/llama2-70b-chat": {
        "display_name": "Llama 2 70B Chat",
        "model_vendor": "meta",
        "litellm_provider": "snowflake",
        "max_input_tokens": 4096,
        "max_output_tokens": 8192,
        "max_tokens": 4096,
        "mode": "chat"
    },
    "snowflake/llama3-70b": {
        "display_name": "Llama 3 70B",
        "model_vendor": "meta",
        "litellm_provider": "snowflake",
        "max_input_tokens": 8000,
        "max_output_tokens": 8192,
        "max_tokens": 8000,
        "mode": "chat"
    },
    "snowflake/llama3-8b": {
        "display_name": "Llama 3 8B",
        "model_vendor": "meta",
        "litellm_provider": "snowflake",
        "max_input_tokens": 8000,
        "max_output_tokens": 8192,
        "max_tokens": 8000,
        "mode": "chat"
    },
    "snowflake/llama3.1-405b": {
        "display_name": "Llama 3.1 405B",
        "model_vendor": "meta",
        "litellm_provider": "snowflake",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 128000,
        "mode": "chat"
    },
    "snowflake/llama3.1-70b": {
        "display_name": "Llama 3.1 70B",
        "model_vendor": "meta",
        "litellm_provider": "snowflake",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 128000,
        "mode": "chat"
    },
    "snowflake/llama3.1-8b": {
        "display_name": "Llama 3.1 8B",
        "model_vendor": "meta",
        "litellm_provider": "snowflake",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 128000,
        "mode": "chat"
    },
    "snowflake/llama3.2-1b": {
        "display_name": "Llama 3.2 1B",
        "model_vendor": "meta",
        "litellm_provider": "snowflake",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 128000,
        "mode": "chat"
    },
    "snowflake/llama3.2-3b": {
        "display_name": "Llama 3.2 3B",
        "model_vendor": "meta",
        "litellm_provider": "snowflake",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 128000,
        "mode": "chat"
    },
    "snowflake/llama3.3-70b": {
        "display_name": "Llama 3.3 70B",
        "model_vendor": "meta",
        "litellm_provider": "snowflake",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 128000,
        "mode": "chat"
    },
    "snowflake/mistral-7b": {
        "display_name": "Mistral 7B",
        "model_vendor": "mistralai",
        "litellm_provider": "snowflake",
        "max_input_tokens": 32000,
        "max_output_tokens": 8192,
        "max_tokens": 32000,
        "mode": "chat"
    },
    "snowflake/mistral-large": {
        "display_name": "Mistral Large",
        "model_vendor": "mistralai",
        "litellm_provider": "snowflake",
        "max_input_tokens": 32000,
        "max_output_tokens": 8192,
        "max_tokens": 32000,
        "mode": "chat"
    },
    "snowflake/mistral-large2": {
        "display_name": "Mistral Large 2",
        "model_vendor": "mistralai",
        "litellm_provider": "snowflake",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 128000,
        "mode": "chat"
    },
    "snowflake/mixtral-8x7b": {
        "display_name": "Mixtral 8x7B",
        "model_vendor": "mistralai",
        "litellm_provider": "snowflake",
        "max_input_tokens": 32000,
        "max_output_tokens": 8192,
        "max_tokens": 32000,
        "mode": "chat"
    },
    "snowflake/reka-core": {
        "display_name": "Reka Core",
        "model_vendor": "reka",
        "litellm_provider": "snowflake",
        "max_input_tokens": 32000,
        "max_output_tokens": 8192,
        "max_tokens": 32000,
        "mode": "chat"
    },
    "snowflake/reka-flash": {
        "display_name": "Reka Flash",
        "model_vendor": "reka",
        "litellm_provider": "snowflake",
        "max_input_tokens": 100000,
        "max_output_tokens": 8192,
        "max_tokens": 100000,
        "mode": "chat"
    },
    "snowflake/snowflake-arctic": {
        "display_name": "Snowflake Arctic",
        "model_vendor": "snowflake",
        "litellm_provider": "snowflake",
        "max_input_tokens": 4096,
        "max_output_tokens": 8192,
        "max_tokens": 4096,
        "mode": "chat"
    },
    "snowflake/snowflake-llama-3.1-405b": {
        "display_name": "Snowflake Llama 3.1 405B",
        "model_vendor": "meta",
        "litellm_provider": "snowflake",
        "max_input_tokens": 8000,
        "max_output_tokens": 8192,
        "max_tokens": 8000,
        "mode": "chat"
    },
    "snowflake/snowflake-llama-3.3-70b": {
        "display_name": "Snowflake Llama 3.3 70B",
        "model_vendor": "meta",
        "litellm_provider": "snowflake",
        "max_input_tokens": 8000,
        "max_output_tokens": 8192,
        "max_tokens": 8000,
        "mode": "chat"
    },
    "stability/sd3": {
        "display_name": "SD3",
        "model_vendor": "stability",
        "litellm_provider": "stability",
        "mode": "image_generation",
        "output_cost_per_image": 0.065,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "stability/sd3-large": {
        "display_name": "SD3 Large",
        "model_vendor": "stability",
        "litellm_provider": "stability",
        "mode": "image_generation",
        "output_cost_per_image": 0.065,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "stability/sd3-large-turbo": {
        "display_name": "SD3 Large Turbo",
        "model_vendor": "stability",
        "litellm_provider": "stability",
        "mode": "image_generation",
        "output_cost_per_image": 0.04,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "stability/sd3-medium": {
        "display_name": "SD3 Medium",
        "model_vendor": "stability",
        "litellm_provider": "stability",
        "mode": "image_generation",
        "output_cost_per_image": 0.035,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "stability/sd3.5-large": {
        "display_name": "Sd3.5 Large",
        "model_vendor": "stability",
        "litellm_provider": "stability",
        "mode": "image_generation",
        "output_cost_per_image": 0.065,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "stability/sd3.5-large-turbo": {
        "display_name": "Sd3.5 Large Turbo",
        "model_vendor": "stability",
        "litellm_provider": "stability",
        "mode": "image_generation",
        "output_cost_per_image": 0.04,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "stability/sd3.5-medium": {
        "display_name": "Sd3.5 Medium",
        "model_vendor": "stability",
        "litellm_provider": "stability",
        "mode": "image_generation",
        "output_cost_per_image": 0.035,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "stability/stable-image-ultra": {
        "display_name": "Stable Image Ultra",
        "model_vendor": "stability",
        "litellm_provider": "stability",
        "mode": "image_generation",
        "output_cost_per_image": 0.08,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "stability/stable-image-core": {
        "display_name": "Stable Image Core",
        "model_vendor": "stability",
        "litellm_provider": "stability",
        "mode": "image_generation",
        "output_cost_per_image": 0.03,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "stability.sd3-5-large-v1:0": {
        "display_name": "Stable Diffusion 3.5 Large v1",
        "model_vendor": "stability_ai",
        "litellm_provider": "bedrock",
        "max_input_tokens": 77,
        "max_tokens": 77,
        "mode": "image_generation",
        "output_cost_per_image": 0.08
    },
    "stability.sd3-large-v1:0": {
        "display_name": "Stable Diffusion 3 Large v1",
        "model_vendor": "stability_ai",
        "litellm_provider": "bedrock",
        "max_input_tokens": 77,
        "max_tokens": 77,
        "mode": "image_generation",
        "output_cost_per_image": 0.08
    },
    "stability.stable-image-core-v1:0": {
        "display_name": "Stable Image Core v1.0",
        "model_vendor": "stability_ai",
        "litellm_provider": "bedrock",
        "max_input_tokens": 77,
        "max_tokens": 77,
        "mode": "image_generation",
        "output_cost_per_image": 0.04
    },
    "stability.stable-image-core-v1:1": {
        "display_name": "Stable Image Core v1.1",
        "model_vendor": "stability_ai",
        "model_version": "1.1",
        "litellm_provider": "bedrock",
        "max_input_tokens": 77,
        "max_tokens": 77,
        "mode": "image_generation",
        "output_cost_per_image": 0.04
    },
    "stability.stable-image-ultra-v1:0": {
        "display_name": "Stable Image Ultra v1.0",
        "model_vendor": "stability_ai",
        "litellm_provider": "bedrock",
        "max_input_tokens": 77,
        "max_tokens": 77,
        "mode": "image_generation",
        "output_cost_per_image": 0.14
    },
    "stability.stable-image-ultra-v1:1": {
        "display_name": "Stable Image Ultra v1.1",
        "model_vendor": "stability_ai",
        "model_version": "1.1",
        "litellm_provider": "bedrock",
        "max_input_tokens": 77,
        "max_tokens": 77,
        "mode": "image_generation",
        "output_cost_per_image": 0.14
    },
    "standard/1024-x-1024/dall-e-3": {
        "display_name": "DALL-E 3 Standard 1024x1024",
        "model_vendor": "openai",
        "input_cost_per_pixel": 3.81469e-08,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0
    },
    "standard/1024-x-1792/dall-e-3": {
        "display_name": "DALL-E 3 Standard 1024x1792",
        "model_vendor": "openai",
        "input_cost_per_pixel": 4.359e-08,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0
    },
    "standard/1792-x-1024/dall-e-3": {
        "display_name": "DALL-E 3 Standard 1792x1024",
        "model_vendor": "openai",
        "input_cost_per_pixel": 4.359e-08,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0
    },
    "tavily/search": {
        "display_name": "Tavily Search",
        "model_vendor": "tavily",
        "input_cost_per_query": 0.008,
        "litellm_provider": "tavily",
        "mode": "search"
    },
    "tavily/search-advanced": {
        "display_name": "Tavily Search Advanced",
        "model_vendor": "tavily",
        "input_cost_per_query": 0.016,
        "litellm_provider": "tavily",
        "mode": "search"
    },
    "text-bison": {
        "display_name": "Text Bison",
        "model_vendor": "google",
        "input_cost_per_character": 2.5e-07,
        "litellm_provider": "vertex_ai-text-models",
        "max_input_tokens": 8192,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "mode": "completion",
        "output_cost_per_character": 5e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "text-bison32k": {
        "display_name": "Text Bison 32K",
        "model_vendor": "google",
        "input_cost_per_character": 2.5e-07,
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-text-models",
        "max_input_tokens": 8192,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "completion",
        "output_cost_per_character": 5e-07,
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "text-bison32k@002": {
        "display_name": "Text Bison 32K @002",
        "model_vendor": "google",
        "input_cost_per_character": 2.5e-07,
        "input_cost_per_token": 1.25e-07,
        "litellm_provider": "vertex_ai-text-models",
        "max_input_tokens": 8192,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "completion",
        "output_cost_per_character": 5e-07,
        "output_cost_per_token": 1.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "text-bison@001": {
        "display_name": "Text Bison @001",
        "model_vendor": "google",
        "input_cost_per_character": 2.5e-07,
        "litellm_provider": "vertex_ai-text-models",
        "max_input_tokens": 8192,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "completion",
        "output_cost_per_character": 5e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "text-bison@002": {
        "display_name": "Text Bison @002",
        "model_vendor": "google",
        "input_cost_per_character": 2.5e-07,
        "litellm_provider": "vertex_ai-text-models",
        "max_input_tokens": 8192,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "completion",
        "output_cost_per_character": 5e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "text-completion-codestral/codestral-2405": {
        "display_name": "Codestral 2405",
        "model_vendor": "mistralai",
        "model_version": "2405",
        "input_cost_per_token": 0.0,
        "litellm_provider": "text-completion-codestral",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "completion",
        "output_cost_per_token": 0.0,
        "source": "https://docs.mistral.ai/capabilities/code_generation/"
    },
    "text-completion-codestral/codestral-latest": {
        "display_name": "Codestral Latest",
        "model_vendor": "mistralai",
        "input_cost_per_token": 0.0,
        "litellm_provider": "text-completion-codestral",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "completion",
        "output_cost_per_token": 0.0,
        "source": "https://docs.mistral.ai/capabilities/code_generation/"
    },
    "text-embedding-004": {
        "display_name": "Text Embedding 004",
        "model_vendor": "google",
        "input_cost_per_character": 2.5e-08,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vertex_ai-embedding-models",
        "max_input_tokens": 2048,
        "max_tokens": 2048,
        "mode": "embedding",
        "output_cost_per_token": 0,
        "output_vector_size": 768,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models"
    },
    "text-embedding-005": {
        "display_name": "Text Embedding 005",
        "model_vendor": "google",
        "input_cost_per_character": 2.5e-08,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vertex_ai-embedding-models",
        "max_input_tokens": 2048,
        "max_tokens": 2048,
        "mode": "embedding",
        "output_cost_per_token": 0,
        "output_vector_size": 768,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models"
    },
    "text-embedding-3-large": {
        "display_name": "Text Embedding 3 Large",
        "model_vendor": "openai",
        "input_cost_per_token": 1.3e-07,
        "input_cost_per_token_batches": 6.5e-08,
        "litellm_provider": "openai",
        "max_input_tokens": 8191,
        "max_tokens": 8191,
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "output_cost_per_token_batches": 0.0,
        "output_vector_size": 3072
    },
    "text-embedding-3-small": {
        "display_name": "Text Embedding 3 Small",
        "model_vendor": "openai",
        "input_cost_per_token": 2e-08,
        "input_cost_per_token_batches": 1e-08,
        "litellm_provider": "openai",
        "max_input_tokens": 8191,
        "max_tokens": 8191,
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "output_cost_per_token_batches": 0.0,
        "output_vector_size": 1536
    },
    "text-embedding-ada-002": {
        "display_name": "Text Embedding Ada 002",
        "model_vendor": "openai",
        "model_version": "002",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 8191,
        "max_tokens": 8191,
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "output_vector_size": 1536
    },
    "text-embedding-ada-002-v2": {
        "display_name": "Text Embedding Ada 002 v2",
        "model_vendor": "openai",
        "model_version": "002-v2",
        "input_cost_per_token": 1e-07,
        "input_cost_per_token_batches": 5e-08,
        "litellm_provider": "openai",
        "max_input_tokens": 8191,
        "max_tokens": 8191,
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "output_cost_per_token_batches": 0.0
    },
    "text-embedding-large-exp-03-07": {
        "display_name": "Text Embedding Large Exp 03-07",
        "model_vendor": "google",
        "input_cost_per_character": 2.5e-08,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vertex_ai-embedding-models",
        "max_input_tokens": 8192,
        "max_tokens": 8192,
        "mode": "embedding",
        "output_cost_per_token": 0,
        "output_vector_size": 3072,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models"
    },
    "text-embedding-preview-0409": {
        "display_name": "Text Embedding Preview 0409",
        "model_vendor": "google",
        "input_cost_per_token": 6.25e-09,
        "input_cost_per_token_batch_requests": 5e-09,
        "litellm_provider": "vertex_ai-embedding-models",
        "max_input_tokens": 3072,
        "max_tokens": 3072,
        "mode": "embedding",
        "output_cost_per_token": 0,
        "output_vector_size": 768,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "text-moderation-007": {
        "display_name": "Text Moderation 007",
        "model_vendor": "openai",
        "model_version": "007",
        "input_cost_per_token": 0.0,
        "litellm_provider": "openai",
        "max_input_tokens": 32768,
        "max_output_tokens": 0,
        "max_tokens": 32768,
        "mode": "moderation",
        "output_cost_per_token": 0.0
    },
    "text-moderation-latest": {
        "display_name": "Text Moderation Latest",
        "model_vendor": "openai",
        "input_cost_per_token": 0.0,
        "litellm_provider": "openai",
        "max_input_tokens": 32768,
        "max_output_tokens": 0,
        "max_tokens": 32768,
        "mode": "moderation",
        "output_cost_per_token": 0.0
    },
    "text-moderation-stable": {
        "display_name": "Text Moderation Stable",
        "model_vendor": "openai",
        "input_cost_per_token": 0.0,
        "litellm_provider": "openai",
        "max_input_tokens": 32768,
        "max_output_tokens": 0,
        "max_tokens": 32768,
        "mode": "moderation",
        "output_cost_per_token": 0.0
    },
    "text-multilingual-embedding-002": {
        "display_name": "Text Multilingual Embedding 002",
        "model_vendor": "google",
        "model_version": "002",
        "input_cost_per_character": 2.5e-08,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vertex_ai-embedding-models",
        "max_input_tokens": 2048,
        "max_tokens": 2048,
        "mode": "embedding",
        "output_cost_per_token": 0,
        "output_vector_size": 768,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models"
    },
    "text-multilingual-embedding-preview-0409": {
        "display_name": "Text Multilingual Embedding Preview 0409",
        "model_vendor": "google",
        "input_cost_per_token": 6.25e-09,
        "litellm_provider": "vertex_ai-embedding-models",
        "max_input_tokens": 3072,
        "max_tokens": 3072,
        "mode": "embedding",
        "output_cost_per_token": 0,
        "output_vector_size": 768,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "text-unicorn": {
        "display_name": "Text Unicorn",
        "model_vendor": "google",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "vertex_ai-text-models",
        "max_input_tokens": 8192,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "completion",
        "output_cost_per_token": 2.8e-05,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "text-unicorn@001": {
        "display_name": "Text Unicorn 001",
        "model_vendor": "google",
        "model_version": "001",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "vertex_ai-text-models",
        "max_input_tokens": 8192,
        "max_output_tokens": 1024,
        "max_tokens": 1024,
        "mode": "completion",
        "output_cost_per_token": 2.8e-05,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "textembedding-gecko": {
        "display_name": "Text Embedding Gecko",
        "model_vendor": "google",
        "input_cost_per_character": 2.5e-08,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vertex_ai-embedding-models",
        "max_input_tokens": 3072,
        "max_tokens": 3072,
        "mode": "embedding",
        "output_cost_per_token": 0,
        "output_vector_size": 768,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "textembedding-gecko-multilingual": {
        "display_name": "Text Embedding Gecko Multilingual",
        "model_vendor": "google",
        "input_cost_per_character": 2.5e-08,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vertex_ai-embedding-models",
        "max_input_tokens": 3072,
        "max_tokens": 3072,
        "mode": "embedding",
        "output_cost_per_token": 0,
        "output_vector_size": 768,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "textembedding-gecko-multilingual@001": {
        "display_name": "Text Embedding Gecko Multilingual 001",
        "model_vendor": "google",
        "model_version": "001",
        "input_cost_per_character": 2.5e-08,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vertex_ai-embedding-models",
        "max_input_tokens": 3072,
        "max_tokens": 3072,
        "mode": "embedding",
        "output_cost_per_token": 0,
        "output_vector_size": 768,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "textembedding-gecko@001": {
        "display_name": "Text Embedding Gecko 001",
        "model_vendor": "google",
        "model_version": "001",
        "input_cost_per_character": 2.5e-08,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vertex_ai-embedding-models",
        "max_input_tokens": 3072,
        "max_tokens": 3072,
        "mode": "embedding",
        "output_cost_per_token": 0,
        "output_vector_size": 768,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "textembedding-gecko@003": {
        "display_name": "Text Embedding Gecko 003",
        "model_vendor": "google",
        "model_version": "003",
        "input_cost_per_character": 2.5e-08,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vertex_ai-embedding-models",
        "max_input_tokens": 3072,
        "max_tokens": 3072,
        "mode": "embedding",
        "output_cost_per_token": 0,
        "output_vector_size": 768,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "together-ai-21.1b-41b": {
        "display_name": "Together AI 21.1B-41B",
        "model_vendor": "together_ai",
        "input_cost_per_token": 8e-07,
        "litellm_provider": "together_ai",
        "mode": "chat",
        "output_cost_per_token": 8e-07
    },
    "together-ai-4.1b-8b": {
        "display_name": "Together AI 4.1B-8B",
        "model_vendor": "together_ai",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "together_ai",
        "mode": "chat",
        "output_cost_per_token": 2e-07
    },
    "together-ai-41.1b-80b": {
        "display_name": "Together AI 41.1B-80B",
        "model_vendor": "together_ai",
        "input_cost_per_token": 9e-07,
        "litellm_provider": "together_ai",
        "mode": "chat",
        "output_cost_per_token": 9e-07
    },
    "together-ai-8.1b-21b": {
        "display_name": "Together AI 8.1B-21B",
        "model_vendor": "together_ai",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "together_ai",
        "max_tokens": 1000,
        "mode": "chat",
        "output_cost_per_token": 3e-07
    },
    "together-ai-81.1b-110b": {
        "display_name": "Together AI 81.1B-110B",
        "model_vendor": "together_ai",
        "input_cost_per_token": 1.8e-06,
        "litellm_provider": "together_ai",
        "mode": "chat",
        "output_cost_per_token": 1.8e-06
    },
    "together-ai-embedding-151m-to-350m": {
        "display_name": "Together AI Embedding 151M-350M",
        "model_vendor": "together_ai",
        "input_cost_per_token": 1.6e-08,
        "litellm_provider": "together_ai",
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "together-ai-embedding-up-to-150m": {
        "display_name": "Together AI Embedding Up to 150M",
        "model_vendor": "together_ai",
        "input_cost_per_token": 8e-09,
        "litellm_provider": "together_ai",
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "together_ai/baai/bge-base-en-v1.5": {
        "display_name": "BGE Base EN v1.5",
        "model_vendor": "baai",
        "input_cost_per_token": 8e-09,
        "litellm_provider": "together_ai",
        "max_input_tokens": 512,
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "output_vector_size": 768
    },
    "together_ai/BAAI/bge-base-en-v1.5": {
        "display_name": "BGE Base EN v1.5",
        "model_vendor": "baai",
        "input_cost_per_token": 8e-09,
        "litellm_provider": "together_ai",
        "max_input_tokens": 512,
        "mode": "embedding",
        "output_cost_per_token": 0.0,
        "output_vector_size": 768
    },
    "together-ai-up-to-4b": {
        "display_name": "Together AI Up to 4B",
        "model_vendor": "together_ai",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "together_ai",
        "mode": "chat",
        "output_cost_per_token": 1e-07
    },
    "together_ai/Qwen/Qwen2.5-72B-Instruct-Turbo": {
        "display_name": "Qwen 2.5 72B Instruct Turbo",
        "model_vendor": "alibaba",
        "litellm_provider": "together_ai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "together_ai/Qwen/Qwen2.5-7B-Instruct-Turbo": {
        "display_name": "Qwen 2.5 7B Instruct Turbo",
        "model_vendor": "alibaba",
        "litellm_provider": "together_ai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "together_ai/Qwen/Qwen3-235B-A22B-Instruct-2507-tput": {
        "display_name": "Qwen 3 235B A22B Instruct 2507",
        "model_vendor": "alibaba",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "together_ai",
        "max_input_tokens": 262000,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "source": "https://www.together.ai/models/qwen3-235b-a22b-instruct-2507-fp8",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "together_ai/Qwen/Qwen3-235B-A22B-Thinking-2507": {
        "display_name": "Qwen 3 235B A22B Thinking 2507",
        "model_vendor": "alibaba",
        "input_cost_per_token": 6.5e-07,
        "litellm_provider": "together_ai",
        "max_input_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 3e-06,
        "source": "https://www.together.ai/models/qwen3-235b-a22b-thinking-2507",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "together_ai/Qwen/Qwen3-235B-A22B-fp8-tput": {
        "display_name": "Qwen 3 235B A22B FP8",
        "model_vendor": "alibaba",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "together_ai",
        "max_input_tokens": 40000,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "source": "https://www.together.ai/models/qwen3-235b-a22b-fp8-tput",
        "supports_function_calling": false,
        "supports_parallel_function_calling": false,
        "supports_tool_choice": false
    },
    "together_ai/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8": {
        "display_name": "Qwen 3 Coder 480B A35B Instruct FP8",
        "model_vendor": "alibaba",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "together_ai",
        "max_input_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "source": "https://www.together.ai/models/qwen3-coder-480b-a35b-instruct",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "together_ai/deepseek-ai/DeepSeek-R1": {
        "display_name": "DeepSeek R1",
        "model_vendor": "deepseek",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "together_ai",
        "max_input_tokens": 128000,
        "max_output_tokens": 20480,
        "max_tokens": 20480,
        "mode": "chat",
        "output_cost_per_token": 7e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "together_ai/deepseek-ai/DeepSeek-R1-0528-tput": {
        "display_name": "DeepSeek R1 0528",
        "model_vendor": "deepseek",
        "model_version": "0528",
        "input_cost_per_token": 5.5e-07,
        "litellm_provider": "together_ai",
        "max_input_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 2.19e-06,
        "source": "https://www.together.ai/models/deepseek-r1-0528-throughput",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "together_ai/deepseek-ai/DeepSeek-V3": {
        "display_name": "DeepSeek V3",
        "model_vendor": "deepseek",
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "together_ai",
        "max_input_tokens": 65536,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.25e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "together_ai/deepseek-ai/DeepSeek-V3.1": {
        "display_name": "DeepSeek V3.1",
        "model_vendor": "deepseek",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "together_ai",
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.7e-06,
        "source": "https://www.together.ai/models/deepseek-v3-1",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "together_ai/meta-llama/Llama-3.2-3B-Instruct-Turbo": {
        "display_name": "Llama 3.2 3B Instruct Turbo",
        "model_vendor": "meta",
        "litellm_provider": "together_ai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo": {
        "display_name": "Llama 3.3 70B Instruct Turbo",
        "model_vendor": "meta",
        "input_cost_per_token": 8.8e-07,
        "litellm_provider": "together_ai",
        "mode": "chat",
        "output_cost_per_token": 8.8e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free": {
        "display_name": "Llama 3.3 70B Instruct Turbo Free",
        "model_vendor": "meta",
        "input_cost_per_token": 0,
        "litellm_provider": "together_ai",
        "mode": "chat",
        "output_cost_per_token": 0,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "together_ai/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
        "display_name": "Llama 4 Maverick 17B 128E Instruct FP8",
        "model_vendor": "meta",
        "input_cost_per_token": 2.7e-07,
        "litellm_provider": "together_ai",
        "mode": "chat",
        "output_cost_per_token": 8.5e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "together_ai/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
        "display_name": "Llama 4 Scout 17B 16E Instruct",
        "model_vendor": "meta",
        "input_cost_per_token": 1.8e-07,
        "litellm_provider": "together_ai",
        "mode": "chat",
        "output_cost_per_token": 5.9e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": {
        "display_name": "Meta Llama 3.1 405B Instruct Turbo",
        "model_vendor": "meta",
        "input_cost_per_token": 3.5e-06,
        "litellm_provider": "together_ai",
        "mode": "chat",
        "output_cost_per_token": 3.5e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
        "display_name": "Meta Llama 3.1 70B Instruct Turbo",
        "model_vendor": "meta",
        "input_cost_per_token": 8.8e-07,
        "litellm_provider": "together_ai",
        "mode": "chat",
        "output_cost_per_token": 8.8e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
        "display_name": "Meta Llama 3.1 8B Instruct Turbo",
        "model_vendor": "meta",
        "input_cost_per_token": 1.8e-07,
        "litellm_provider": "together_ai",
        "mode": "chat",
        "output_cost_per_token": 1.8e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "together_ai/mistralai/Mistral-7B-Instruct-v0.1": {
        "display_name": "Mistral 7B Instruct v0.1",
        "model_vendor": "mistralai",
        "litellm_provider": "together_ai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "together_ai/mistralai/Mistral-Small-24B-Instruct-2501": {
        "display_name": "Mistral Small 24B Instruct 2501",
        "model_vendor": "mistralai",
        "model_version": "2501",
        "litellm_provider": "together_ai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1": {
        "display_name": "Mixtral 8x7B Instruct v0.1",
        "model_vendor": "mistralai",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "together_ai",
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "together_ai/moonshotai/Kimi-K2-Instruct": {
        "display_name": "Kimi K2 Instruct",
        "model_vendor": "moonshot",
        "model_version": "k2",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "together_ai",
        "mode": "chat",
        "output_cost_per_token": 3e-06,
        "source": "https://www.together.ai/models/kimi-k2-instruct",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "together_ai/openai/gpt-oss-120b": {
        "display_name": "GPT-OSS 120B",
        "model_vendor": "openai",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "together_ai",
        "max_input_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "source": "https://www.together.ai/models/gpt-oss-120b",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "together_ai/openai/gpt-oss-20b": {
        "display_name": "GPT-OSS 20B",
        "model_vendor": "openai",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "together_ai",
        "max_input_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "source": "https://www.together.ai/models/gpt-oss-20b",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "together_ai/togethercomputer/CodeLlama-34b-Instruct": {
        "display_name": "CodeLlama 34B Instruct",
        "model_vendor": "meta",
        "litellm_provider": "together_ai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "together_ai/zai-org/GLM-4.5-Air-FP8": {
        "display_name": "GLM 4.5 Air FP8",
        "model_vendor": "zhipu",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "together_ai",
        "max_input_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.1e-06,
        "source": "https://www.together.ai/models/glm-4-5-air",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "together_ai/zai-org/GLM-4.6": {
        "display_name": "GLM 4.6",
        "model_vendor": "zhipu",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "together_ai",
        "max_input_tokens": 200000,
        "max_output_tokens": 200000,
        "max_tokens": 200000,
        "mode": "chat",
        "output_cost_per_token": 2.2e-06,
        "source": "https://www.together.ai/models/glm-4-6",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "together_ai/moonshotai/Kimi-K2-Instruct-0905": {
        "display_name": "Kimi K2 Instruct 0905",
        "model_vendor": "moonshot",
        "model_version": "k2-0905",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "together_ai",
        "max_input_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 3e-06,
        "source": "https://www.together.ai/models/kimi-k2-0905",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "together_ai/Qwen/Qwen3-Next-80B-A3B-Instruct": {
        "display_name": "Qwen 3 Next 80B A3B Instruct",
        "model_vendor": "alibaba",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "together_ai",
        "max_input_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "source": "https://www.together.ai/models/qwen3-next-80b-a3b-instruct",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "together_ai/Qwen/Qwen3-Next-80B-A3B-Thinking": {
        "display_name": "Qwen 3 Next 80B A3B Thinking",
        "model_vendor": "alibaba",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "together_ai",
        "max_input_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "source": "https://www.together.ai/models/qwen3-next-80b-a3b-thinking",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "tts-1": {
        "display_name": "TTS 1",
        "model_vendor": "openai",
        "input_cost_per_character": 1.5e-05,
        "litellm_provider": "openai",
        "mode": "audio_speech",
        "supported_endpoints": [
            "/v1/audio/speech"
        ]
    },
    "tts-1-hd": {
        "display_name": "TTS 1 HD",
        "model_vendor": "openai",
        "model_version": "1-hd",
        "input_cost_per_character": 3e-05,
        "litellm_provider": "openai",
        "mode": "audio_speech",
        "supported_endpoints": [
            "/v1/audio/speech"
        ]
    },
    "us.amazon.nova-lite-v1:0": {
        "display_name": "Amazon Nova Lite v1 US",
        "model_vendor": "amazon",
        "input_cost_per_token": 6e-08,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 300000,
        "max_output_tokens": 10000,
        "max_tokens": 10000,
        "mode": "chat",
        "output_cost_per_token": 2.4e-07,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "us.amazon.nova-micro-v1:0": {
        "display_name": "Amazon Nova Micro v1 US",
        "model_vendor": "amazon",
        "input_cost_per_token": 3.5e-08,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 10000,
        "max_tokens": 10000,
        "mode": "chat",
        "output_cost_per_token": 1.4e-07,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true
    },
    "us.amazon.nova-premier-v1:0": {
        "display_name": "Amazon Nova Premier v1 US",
        "model_vendor": "amazon",
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 1000000,
        "max_output_tokens": 10000,
        "max_tokens": 10000,
        "mode": "chat",
        "output_cost_per_token": 1.25e-05,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": false,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "us.amazon.nova-pro-v1:0": {
        "display_name": "Amazon Nova Pro v1 US",
        "model_vendor": "amazon",
        "input_cost_per_token": 8e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 300000,
        "max_output_tokens": 10000,
        "max_tokens": 10000,
        "mode": "chat",
        "output_cost_per_token": 3.2e-06,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_vision": true
    },
    "us.anthropic.claude-3-5-haiku-20241022-v1:0": {
        "display_name": "Claude 3.5 Haiku",
        "model_vendor": "anthropic",
        "model_version": "20241022",
        "cache_creation_input_token_cost": 1e-06,
        "cache_read_input_token_cost": 8e-08,
        "input_cost_per_token": 8e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 4e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "us.anthropic.claude-haiku-4-5-20251001-v1:0": {
        "display_name": "Claude Haiku 4.5",
        "model_vendor": "anthropic",
        "model_version": "20251001",
        "cache_creation_input_token_cost": 1.375e-06,
        "cache_read_input_token_cost": 1.1e-07,
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 5.5e-06,
        "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 346
    },
    "us.anthropic.claude-3-5-sonnet-20240620-v1:0": {
        "display_name": "Claude 3.5 Sonnet",
        "model_vendor": "anthropic",
        "model_version": "20240620",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "us.anthropic.claude-3-5-sonnet-20241022-v2:0": {
        "display_name": "Claude 3.5 Sonnet v2",
        "model_vendor": "anthropic",
        "model_version": "20241022",
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_token": 3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "us.anthropic.claude-3-7-sonnet-20250219-v1:0": {
        "display_name": "Claude 3.7 Sonnet",
        "model_vendor": "anthropic",
        "model_version": "20250219",
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_token": 3e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "us.anthropic.claude-3-haiku-20240307-v1:0": {
        "display_name": "Claude 3 Haiku",
        "model_vendor": "anthropic",
        "model_version": "20240307",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.25e-06,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "us.anthropic.claude-3-opus-20240229-v1:0": {
        "display_name": "Claude 3 Opus",
        "model_vendor": "anthropic",
        "model_version": "20240229",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "us.anthropic.claude-3-sonnet-20240229-v1:0": {
        "display_name": "Claude 3 Sonnet",
        "model_vendor": "anthropic",
        "model_version": "20240229",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "us.anthropic.claude-opus-4-1-20250805-v1:0": {
        "display_name": "Claude Opus 4.1",
        "model_vendor": "anthropic",
        "model_version": "20250805",
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "us.anthropic.claude-sonnet-4-5-20250929-v1:0": {
        "display_name": "Claude Sonnet 4.5",
        "model_vendor": "anthropic",
        "model_version": "20250929",
        "cache_creation_input_token_cost": 4.125e-06,
        "cache_read_input_token_cost": 3.3e-07,
        "input_cost_per_token": 3.3e-06,
        "input_cost_per_token_above_200k_tokens": 6.6e-06,
        "output_cost_per_token_above_200k_tokens": 2.475e-05,
        "cache_creation_input_token_cost_above_200k_tokens": 8.25e-06,
        "cache_read_input_token_cost_above_200k_tokens": 6.6e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 1.65e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 346
    },
    "au.anthropic.claude-haiku-4-5-20251001-v1:0": {
        "display_name": "Claude Haiku 4.5",
        "model_vendor": "anthropic",
        "model_version": "20251001",
        "cache_creation_input_token_cost": 1.375e-06,
        "cache_read_input_token_cost": 1.1e-07,
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 5.5e-06,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 346
    },
    "us.anthropic.claude-opus-4-20250514-v1:0": {
        "display_name": "Claude Opus 4",
        "model_vendor": "anthropic",
        "model_version": "20250514",
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "us.anthropic.claude-opus-4-5-20251101-v1:0": {
        "display_name": "Claude Opus 4.5",
        "model_vendor": "anthropic",
        "model_version": "20251101",
        "cache_creation_input_token_cost": 6.25e-06,
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 2.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "global.anthropic.claude-opus-4-5-20251101-v1:0": {
        "display_name": "Claude Opus 4.5",
        "model_vendor": "anthropic",
        "model_version": "20251101",
        "cache_creation_input_token_cost": 6.25e-06,
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 2.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "eu.anthropic.claude-opus-4-5-20251101-v1:0": {
        "display_name": "Anthropic.claude Opus 4 5 20251101 V1:0",
        "model_vendor": "anthropic",
        "model_version": "0",
        "cache_creation_input_token_cost": 6.25e-06,
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 2.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "us.anthropic.claude-sonnet-4-20250514-v1:0": {
        "display_name": "Claude Sonnet 4",
        "model_vendor": "anthropic",
        "model_version": "20250514",
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "us.deepseek.r1-v1:0": {
        "display_name": "DeepSeek R1 v1 US",
        "model_vendor": "deepseek",
        "input_cost_per_token": 1.35e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 5.4e-06,
        "supports_function_calling": false,
        "supports_reasoning": true,
        "supports_tool_choice": false
    },
    "us.meta.llama3-1-405b-instruct-v1:0": {
        "display_name": "Llama 3.1 405B Instruct v1 US",
        "model_vendor": "meta",
        "input_cost_per_token": 5.32e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.6e-05,
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "us.meta.llama3-1-70b-instruct-v1:0": {
        "display_name": "Llama 3.1 70B Instruct v1 US",
        "model_vendor": "meta",
        "input_cost_per_token": 9.9e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 9.9e-07,
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "us.meta.llama3-1-8b-instruct-v1:0": {
        "display_name": "Llama 3.1 8B Instruct v1 US",
        "model_vendor": "meta",
        "input_cost_per_token": 2.2e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 2.2e-07,
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "us.meta.llama3-2-11b-instruct-v1:0": {
        "display_name": "Llama 3.2 11B Instruct v1 US",
        "model_vendor": "meta",
        "input_cost_per_token": 3.5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 3.5e-07,
        "supports_function_calling": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "us.meta.llama3-2-1b-instruct-v1:0": {
        "display_name": "Llama 3.2 1B Instruct v1 US",
        "model_vendor": "meta",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-07,
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "us.meta.llama3-2-3b-instruct-v1:0": {
        "display_name": "Llama 3.2 3B Instruct v1 US",
        "model_vendor": "meta",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-07,
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "us.meta.llama3-2-90b-instruct-v1:0": {
        "display_name": "Llama 3.2 90B Instruct v1 US",
        "model_vendor": "meta",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "bedrock",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "supports_function_calling": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "us.meta.llama3-3-70b-instruct-v1:0": {
        "display_name": "Llama 3.3 70B Instruct v1 US",
        "model_vendor": "meta",
        "input_cost_per_token": 7.2e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 7.2e-07,
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "us.meta.llama4-maverick-17b-instruct-v1:0": {
        "display_name": "Llama 4 Maverick 17B Instruct v1 US",
        "model_vendor": "meta",
        "input_cost_per_token": 2.4e-07,
        "input_cost_per_token_batches": 1.2e-07,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 9.7e-07,
        "output_cost_per_token_batches": 4.85e-07,
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "code"
        ],
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "us.meta.llama4-scout-17b-instruct-v1:0": {
        "display_name": "Llama 4 Scout 17B Instruct v1 US",
        "model_vendor": "meta",
        "input_cost_per_token": 1.7e-07,
        "input_cost_per_token_batches": 8.5e-08,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6.6e-07,
        "output_cost_per_token_batches": 3.3e-07,
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "code"
        ],
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "us.mistral.pixtral-large-2502-v1:0": {
        "display_name": "Pixtral Large 2502 v1 US",
        "model_vendor": "mistralai",
        "model_version": "2502",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "bedrock_converse",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "v0/v0-1.0-md": {
        "display_name": "V0 1.0 Medium",
        "model_vendor": "vercel",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "v0",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "v0/v0-1.5-lg": {
        "display_name": "V0 1.5 Large",
        "model_vendor": "vercel",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "v0",
        "max_input_tokens": 512000,
        "max_output_tokens": 512000,
        "max_tokens": 512000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "v0/v0-1.5-md": {
        "display_name": "V0 1.5 Medium",
        "model_vendor": "vercel",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "v0",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "vercel_ai_gateway/alibaba/qwen-3-14b": {
        "display_name": "Qwen 3 14B",
        "model_vendor": "alibaba",
        "input_cost_per_token": 8e-08,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 40960,
        "max_output_tokens": 16384,
        "max_tokens": 40960,
        "mode": "chat",
        "output_cost_per_token": 2.4e-07
    },
    "vercel_ai_gateway/alibaba/qwen-3-235b": {
        "display_name": "Qwen 3 235B",
        "model_vendor": "alibaba",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 40960,
        "max_output_tokens": 16384,
        "max_tokens": 40960,
        "mode": "chat",
        "output_cost_per_token": 6e-07
    },
    "vercel_ai_gateway/alibaba/qwen-3-30b": {
        "display_name": "Qwen 3 30B",
        "model_vendor": "alibaba",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 40960,
        "max_output_tokens": 16384,
        "max_tokens": 40960,
        "mode": "chat",
        "output_cost_per_token": 3e-07
    },
    "vercel_ai_gateway/alibaba/qwen-3-32b": {
        "display_name": "Qwen 3 32B",
        "model_vendor": "alibaba",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 40960,
        "max_output_tokens": 16384,
        "max_tokens": 40960,
        "mode": "chat",
        "output_cost_per_token": 3e-07
    },
    "vercel_ai_gateway/alibaba/qwen3-coder": {
        "display_name": "Qwen 3 Coder",
        "model_vendor": "alibaba",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 262144,
        "max_output_tokens": 66536,
        "max_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 1.6e-06
    },
    "vercel_ai_gateway/amazon/nova-lite": {
        "display_name": "Amazon Nova Lite",
        "model_vendor": "amazon",
        "input_cost_per_token": 6e-08,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 300000,
        "max_output_tokens": 8192,
        "max_tokens": 300000,
        "mode": "chat",
        "output_cost_per_token": 2.4e-07
    },
    "vercel_ai_gateway/amazon/nova-micro": {
        "display_name": "Amazon Nova Micro",
        "model_vendor": "amazon",
        "input_cost_per_token": 3.5e-08,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.4e-07
    },
    "vercel_ai_gateway/amazon/nova-pro": {
        "display_name": "Amazon Nova Pro",
        "model_vendor": "amazon",
        "input_cost_per_token": 8e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 300000,
        "max_output_tokens": 8192,
        "max_tokens": 300000,
        "mode": "chat",
        "output_cost_per_token": 3.2e-06
    },
    "vercel_ai_gateway/amazon/titan-embed-text-v2": {
        "display_name": "Amazon Titan Embed Text v2",
        "model_vendor": "amazon",
        "input_cost_per_token": 2e-08,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 0,
        "max_output_tokens": 0,
        "max_tokens": 0,
        "mode": "chat",
        "output_cost_per_token": 0.0
    },
    "vercel_ai_gateway/anthropic/claude-3-haiku": {
        "display_name": "Claude 3 Haiku",
        "model_vendor": "anthropic",
        "cache_creation_input_token_cost": 3e-07,
        "cache_read_input_token_cost": 3e-08,
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 200000,
        "mode": "chat",
        "output_cost_per_token": 1.25e-06
    },
    "vercel_ai_gateway/anthropic/claude-3-opus": {
        "display_name": "Claude 3 Opus",
        "model_vendor": "anthropic",
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 200000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05
    },
    "vercel_ai_gateway/anthropic/claude-3.5-haiku": {
        "display_name": "Claude 3.5 Haiku",
        "model_vendor": "anthropic",
        "cache_creation_input_token_cost": 1e-06,
        "cache_read_input_token_cost": 8e-08,
        "input_cost_per_token": 8e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 200000,
        "mode": "chat",
        "output_cost_per_token": 4e-06
    },
    "vercel_ai_gateway/anthropic/claude-3.5-sonnet": {
        "display_name": "Claude 3.5 Sonnet",
        "model_vendor": "anthropic",
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_token": 3e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 200000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05
    },
    "vercel_ai_gateway/anthropic/claude-3.7-sonnet": {
        "display_name": "Claude 3.7 Sonnet",
        "model_vendor": "anthropic",
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_token": 3e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 200000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05
    },
    "vercel_ai_gateway/anthropic/claude-4-opus": {
        "display_name": "Claude Opus 4",
        "model_vendor": "anthropic",
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 200000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05
    },
    "vercel_ai_gateway/anthropic/claude-4-sonnet": {
        "display_name": "Claude Sonnet 4",
        "model_vendor": "anthropic",
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_token": 3e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 200000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05
    },
    "vercel_ai_gateway/cohere/command-a": {
        "display_name": "Command A",
        "model_vendor": "cohere",
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 256000,
        "max_output_tokens": 8000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 1e-05
    },
    "vercel_ai_gateway/cohere/command-r": {
        "display_name": "Command R",
        "model_vendor": "cohere",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 6e-07
    },
    "vercel_ai_gateway/cohere/command-r-plus": {
        "display_name": "Command R Plus",
        "model_vendor": "cohere",
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-05
    },
    "vercel_ai_gateway/cohere/embed-v4.0": {
        "display_name": "Embed v4.0",
        "model_vendor": "cohere",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 0,
        "max_output_tokens": 0,
        "max_tokens": 0,
        "mode": "chat",
        "output_cost_per_token": 0.0
    },
    "vercel_ai_gateway/deepseek/deepseek-r1": {
        "display_name": "DeepSeek R1",
        "model_vendor": "deepseek",
        "input_cost_per_token": 5.5e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 2.19e-06
    },
    "vercel_ai_gateway/deepseek/deepseek-r1-distill-llama-70b": {
        "display_name": "DeepSeek R1 Distill Llama 70B",
        "model_vendor": "deepseek",
        "input_cost_per_token": 7.5e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 9.9e-07
    },
    "vercel_ai_gateway/deepseek/deepseek-v3": {
        "display_name": "DeepSeek V3",
        "model_vendor": "deepseek",
        "input_cost_per_token": 9e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 9e-07
    },
    "vercel_ai_gateway/google/gemini-2.0-flash": {
        "display_name": "Gemini 2.0 Flash",
        "model_vendor": "google",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_tokens": 1048576,
        "mode": "chat",
        "output_cost_per_token": 6e-07
    },
    "vercel_ai_gateway/google/gemini-2.0-flash-lite": {
        "display_name": "Gemini 2.0 Flash Lite",
        "model_vendor": "google",
        "input_cost_per_token": 7.5e-08,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_tokens": 1048576,
        "mode": "chat",
        "output_cost_per_token": 3e-07
    },
    "vercel_ai_gateway/google/gemini-2.5-flash": {
        "display_name": "Gemini 2.5 Flash",
        "model_vendor": "google",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 1000000,
        "max_output_tokens": 65536,
        "max_tokens": 1000000,
        "mode": "chat",
        "output_cost_per_token": 2.5e-06
    },
    "vercel_ai_gateway/google/gemini-2.5-pro": {
        "display_name": "Gemini 2.5 Pro",
        "model_vendor": "google",
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 1048576,
        "max_output_tokens": 65536,
        "max_tokens": 1048576,
        "mode": "chat",
        "output_cost_per_token": 1e-05
    },
    "vercel_ai_gateway/google/gemini-embedding-001": {
        "display_name": "Gemini Embedding 001",
        "model_vendor": "google",
        "model_version": "001",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 0,
        "max_output_tokens": 0,
        "max_tokens": 0,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "vercel_ai_gateway/google/gemma-2-9b": {
        "display_name": "Gemma 2 9B",
        "model_vendor": "google",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2e-07
    },
    "vercel_ai_gateway/google/text-embedding-005": {
        "display_name": "Text Embedding 005",
        "model_vendor": "google",
        "model_version": "005",
        "input_cost_per_token": 2.5e-08,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 0,
        "max_output_tokens": 0,
        "max_tokens": 0,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "vercel_ai_gateway/google/text-multilingual-embedding-002": {
        "display_name": "Text Multilingual Embedding 002",
        "model_vendor": "google",
        "model_version": "002",
        "input_cost_per_token": 2.5e-08,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 0,
        "max_output_tokens": 0,
        "max_tokens": 0,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "vercel_ai_gateway/inception/mercury-coder-small": {
        "display_name": "Mercury Coder Small",
        "model_vendor": "inception",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 32000,
        "max_output_tokens": 16384,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 1e-06
    },
    "vercel_ai_gateway/meta/llama-3-70b": {
        "display_name": "Llama 3 70B",
        "model_vendor": "meta",
        "input_cost_per_token": 5.9e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 7.9e-07
    },
    "vercel_ai_gateway/meta/llama-3-8b": {
        "display_name": "Llama 3 8B",
        "model_vendor": "meta",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 8e-08
    },
    "vercel_ai_gateway/meta/llama-3.1-70b": {
        "display_name": "Llama 3.1 70B",
        "model_vendor": "meta",
        "input_cost_per_token": 7.2e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 7.2e-07
    },
    "vercel_ai_gateway/meta/llama-3.1-8b": {
        "display_name": "Llama 3.1 8B",
        "model_vendor": "meta",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 131000,
        "max_output_tokens": 131072,
        "max_tokens": 131000,
        "mode": "chat",
        "output_cost_per_token": 8e-08
    },
    "vercel_ai_gateway/meta/llama-3.2-11b": {
        "display_name": "Llama 3.2 11B",
        "model_vendor": "meta",
        "input_cost_per_token": 1.6e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.6e-07
    },
    "vercel_ai_gateway/meta/llama-3.2-1b": {
        "display_name": "Llama 3.2 1B",
        "model_vendor": "meta",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-07
    },
    "vercel_ai_gateway/meta/llama-3.2-3b": {
        "display_name": "Llama 3.2 3B",
        "model_vendor": "meta",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-07
    },
    "vercel_ai_gateway/meta/llama-3.2-90b": {
        "display_name": "Llama 3.2 90B",
        "model_vendor": "meta",
        "input_cost_per_token": 7.2e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 7.2e-07
    },
    "vercel_ai_gateway/meta/llama-3.3-70b": {
        "display_name": "Llama 3.3 70B",
        "model_vendor": "meta",
        "input_cost_per_token": 7.2e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 7.2e-07
    },
    "vercel_ai_gateway/meta/llama-4-maverick": {
        "display_name": "Llama 4 Maverick",
        "model_vendor": "meta",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 131072,
        "max_output_tokens": 8192,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 6e-07
    },
    "vercel_ai_gateway/meta/llama-4-scout": {
        "display_name": "Llama 4 Scout",
        "model_vendor": "meta",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 131072,
        "max_output_tokens": 8192,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 3e-07
    },
    "vercel_ai_gateway/mistral/codestral": {
        "display_name": "Codestral",
        "model_vendor": "mistralai",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 256000,
        "max_output_tokens": 4000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 9e-07
    },
    "vercel_ai_gateway/mistral/codestral-embed": {
        "display_name": "Codestral Embed",
        "model_vendor": "mistralai",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 0,
        "max_output_tokens": 0,
        "max_tokens": 0,
        "mode": "chat",
        "output_cost_per_token": 0.0
    },
    "vercel_ai_gateway/mistral/devstral-small": {
        "display_name": "Devstral Small",
        "model_vendor": "mistralai",
        "input_cost_per_token": 7e-08,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 2.8e-07
    },
    "vercel_ai_gateway/mistral/magistral-medium": {
        "display_name": "Magistral Medium",
        "model_vendor": "mistralai",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 64000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 5e-06
    },
    "vercel_ai_gateway/mistral/magistral-small": {
        "display_name": "Magistral Small",
        "model_vendor": "mistralai",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 64000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06
    },
    "vercel_ai_gateway/mistral/ministral-3b": {
        "display_name": "Ministral 3B",
        "model_vendor": "mistralai",
        "input_cost_per_token": 4e-08,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 4000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 4e-08
    },
    "vercel_ai_gateway/mistral/ministral-8b": {
        "display_name": "Ministral 8B",
        "model_vendor": "mistralai",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 4000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-07
    },
    "vercel_ai_gateway/mistral/mistral-embed": {
        "display_name": "Mistral Embed",
        "model_vendor": "mistralai",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 0,
        "max_output_tokens": 0,
        "max_tokens": 0,
        "mode": "chat",
        "output_cost_per_token": 0.0
    },
    "vercel_ai_gateway/mistral/mistral-large": {
        "display_name": "Mistral Large",
        "model_vendor": "mistralai",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 32000,
        "max_output_tokens": 4000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 6e-06
    },
    "vercel_ai_gateway/mistral/mistral-saba-24b": {
        "display_name": "Mistral Saba 24B",
        "model_vendor": "mistralai",
        "input_cost_per_token": 7.9e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 7.9e-07
    },
    "vercel_ai_gateway/mistral/mistral-small": {
        "display_name": "Mistral Small",
        "model_vendor": "mistralai",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 32000,
        "max_output_tokens": 4000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 3e-07
    },
    "vercel_ai_gateway/mistral/mixtral-8x22b-instruct": {
        "display_name": "Mixtral 8x22B Instruct",
        "model_vendor": "mistralai",
        "input_cost_per_token": 1.2e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 65536,
        "max_output_tokens": 2048,
        "max_tokens": 65536,
        "mode": "chat",
        "output_cost_per_token": 1.2e-06
    },
    "vercel_ai_gateway/mistral/pixtral-12b": {
        "display_name": "Pixtral 12B",
        "model_vendor": "mistralai",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 4000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-07
    },
    "vercel_ai_gateway/mistral/pixtral-large": {
        "display_name": "Pixtral Large",
        "model_vendor": "mistralai",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 4000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 6e-06
    },
    "vercel_ai_gateway/moonshotai/kimi-k2": {
        "display_name": "Kimi K2",
        "model_vendor": "moonshot",
        "model_version": "k2",
        "input_cost_per_token": 5.5e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 131072,
        "max_output_tokens": 16384,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 2.2e-06
    },
    "vercel_ai_gateway/morph/morph-v3-fast": {
        "display_name": "Morph v3 Fast",
        "model_vendor": "morph",
        "input_cost_per_token": 8e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 32768,
        "max_output_tokens": 16384,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 1.2e-06
    },
    "vercel_ai_gateway/morph/morph-v3-large": {
        "display_name": "Morph v3 Large",
        "model_vendor": "morph",
        "input_cost_per_token": 9e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 32768,
        "max_output_tokens": 16384,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 1.9e-06
    },
    "vercel_ai_gateway/openai/gpt-3.5-turbo": {
        "display_name": "GPT-3.5 Turbo",
        "model_vendor": "openai",
        "input_cost_per_token": 5e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "max_tokens": 16385,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06
    },
    "vercel_ai_gateway/openai/gpt-3.5-turbo-instruct": {
        "display_name": "GPT-3.5 Turbo Instruct",
        "model_vendor": "openai",
        "input_cost_per_token": 1.5e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2e-06
    },
    "vercel_ai_gateway/openai/gpt-4-turbo": {
        "display_name": "GPT-4 Turbo",
        "model_vendor": "openai",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 3e-05
    },
    "vercel_ai_gateway/openai/gpt-4.1": {
        "display_name": "GPT-4.1",
        "model_vendor": "openai",
        "cache_creation_input_token_cost": 0.0,
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 2e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 1047576,
        "mode": "chat",
        "output_cost_per_token": 8e-06
    },
    "vercel_ai_gateway/openai/gpt-4.1-mini": {
        "display_name": "GPT-4.1 Mini",
        "model_vendor": "openai",
        "cache_creation_input_token_cost": 0.0,
        "cache_read_input_token_cost": 1e-07,
        "input_cost_per_token": 4e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 1047576,
        "mode": "chat",
        "output_cost_per_token": 1.6e-06
    },
    "vercel_ai_gateway/openai/gpt-4.1-nano": {
        "display_name": "GPT-4.1 Nano",
        "model_vendor": "openai",
        "cache_creation_input_token_cost": 0.0,
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 1047576,
        "mode": "chat",
        "output_cost_per_token": 4e-07
    },
    "vercel_ai_gateway/openai/gpt-4o": {
        "display_name": "GPT-4o",
        "model_vendor": "openai",
        "model_version": "4o",
        "cache_creation_input_token_cost": 0.0,
        "cache_read_input_token_cost": 1.25e-06,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-05
    },
    "vercel_ai_gateway/openai/gpt-4o-mini": {
        "display_name": "GPT-4o Mini",
        "model_vendor": "openai",
        "model_version": "4o",
        "cache_creation_input_token_cost": 0.0,
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 6e-07
    },
    "vercel_ai_gateway/openai/o1": {
        "display_name": "o1",
        "model_vendor": "openai",
        "cache_creation_input_token_cost": 0.0,
        "cache_read_input_token_cost": 7.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 200000,
        "mode": "chat",
        "output_cost_per_token": 6e-05
    },
    "vercel_ai_gateway/openai/o3": {
        "display_name": "o3",
        "model_vendor": "openai",
        "cache_creation_input_token_cost": 0.0,
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 2e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 200000,
        "mode": "chat",
        "output_cost_per_token": 8e-06
    },
    "vercel_ai_gateway/openai/o3-mini": {
        "display_name": "o3 Mini",
        "model_vendor": "openai",
        "cache_creation_input_token_cost": 0.0,
        "cache_read_input_token_cost": 5.5e-07,
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 200000,
        "mode": "chat",
        "output_cost_per_token": 4.4e-06
    },
    "vercel_ai_gateway/openai/o4-mini": {
        "display_name": "o4 Mini",
        "model_vendor": "openai",
        "cache_creation_input_token_cost": 0.0,
        "cache_read_input_token_cost": 2.75e-07,
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 200000,
        "mode": "chat",
        "output_cost_per_token": 4.4e-06
    },
    "vercel_ai_gateway/openai/text-embedding-3-large": {
        "display_name": "Text Embedding 3 Large",
        "model_vendor": "openai",
        "input_cost_per_token": 1.3e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 0,
        "max_output_tokens": 0,
        "max_tokens": 0,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "vercel_ai_gateway/openai/text-embedding-3-small": {
        "display_name": "Text Embedding 3 Small",
        "model_vendor": "openai",
        "input_cost_per_token": 2e-08,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 0,
        "max_output_tokens": 0,
        "max_tokens": 0,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "vercel_ai_gateway/openai/text-embedding-ada-002": {
        "display_name": "Text Embedding Ada 002",
        "model_vendor": "openai",
        "model_version": "002",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 0,
        "max_output_tokens": 0,
        "max_tokens": 0,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "vercel_ai_gateway/perplexity/sonar": {
        "display_name": "Sonar",
        "model_vendor": "perplexity",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 127000,
        "max_output_tokens": 8000,
        "max_tokens": 127000,
        "mode": "chat",
        "output_cost_per_token": 1e-06
    },
    "vercel_ai_gateway/perplexity/sonar-pro": {
        "display_name": "Sonar Pro",
        "model_vendor": "perplexity",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 200000,
        "max_output_tokens": 8000,
        "max_tokens": 200000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05
    },
    "vercel_ai_gateway/perplexity/sonar-reasoning": {
        "display_name": "Sonar Reasoning",
        "model_vendor": "perplexity",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 127000,
        "max_output_tokens": 8000,
        "max_tokens": 127000,
        "mode": "chat",
        "output_cost_per_token": 5e-06
    },
    "vercel_ai_gateway/perplexity/sonar-reasoning-pro": {
        "display_name": "Sonar Reasoning Pro",
        "model_vendor": "perplexity",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 127000,
        "max_output_tokens": 8000,
        "max_tokens": 127000,
        "mode": "chat",
        "output_cost_per_token": 8e-06
    },
    "vercel_ai_gateway/vercel/v0-1.0-md": {
        "display_name": "V0 1.0 MD",
        "model_vendor": "vercel",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 32000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05
    },
    "vercel_ai_gateway/vercel/v0-1.5-md": {
        "display_name": "V0 1.5 MD",
        "model_vendor": "vercel",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05
    },
    "vercel_ai_gateway/xai/grok-2": {
        "display_name": "Grok 2",
        "model_vendor": "xai",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 131072,
        "max_output_tokens": 4000,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1e-05
    },
    "vercel_ai_gateway/xai/grok-2-vision": {
        "display_name": "Grok 2 Vision",
        "model_vendor": "xai",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 1e-05
    },
    "vercel_ai_gateway/xai/grok-3": {
        "display_name": "Grok 3",
        "model_vendor": "xai",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05
    },
    "vercel_ai_gateway/xai/grok-3-fast": {
        "display_name": "Grok 3 Fast",
        "model_vendor": "xai",
        "input_cost_per_token": 5e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 2.5e-05
    },
    "vercel_ai_gateway/xai/grok-3-mini": {
        "display_name": "Grok 3 Mini",
        "model_vendor": "xai",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 5e-07
    },
    "vercel_ai_gateway/xai/grok-3-mini-fast": {
        "display_name": "Grok 3 Mini Fast",
        "model_vendor": "xai",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 4e-06
    },
    "vercel_ai_gateway/xai/grok-4": {
        "display_name": "Grok 4",
        "model_vendor": "xai",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05
    },
    "vercel_ai_gateway/zai/glm-4.5": {
        "display_name": "GLM 4.5",
        "model_vendor": "zhipu",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 2.2e-06
    },
    "vercel_ai_gateway/zai/glm-4.5-air": {
        "display_name": "GLM 4.5 Air",
        "model_vendor": "zhipu",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "vercel_ai_gateway",
        "max_input_tokens": 128000,
        "max_output_tokens": 96000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.1e-06
    },
    "vercel_ai_gateway/zai/glm-4.6": {
        "display_name": "GLM 4.6",
        "model_vendor": "zhipu",
        "litellm_provider": "vercel_ai_gateway",
        "cache_read_input_token_cost": 1.1e-07,
        "input_cost_per_token": 4.5e-07,
        "max_input_tokens": 200000,
        "max_output_tokens": 200000,
        "max_tokens": 200000,
        "mode": "chat",
        "output_cost_per_token": 1.8e-06,
        "source": "https://vercel.com/ai-gateway/models/glm-4.6",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/chirp": {
        "display_name": "Chirp",
        "model_vendor": "google",
        "input_cost_per_character": 3e-05,
        "litellm_provider": "vertex_ai",
        "mode": "audio_speech",
        "source": "https://cloud.google.com/text-to-speech/pricing",
        "supported_endpoints": [
            "/v1/audio/speech"
        ]
    },
    "vertex_ai/claude-3-5-haiku": {
        "display_name": "Claude 3.5 Haiku",
        "model_vendor": "anthropic",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_tool_choice": true
    },
    "vertex_ai/claude-3-5-haiku@20241022": {
        "display_name": "Claude 3.5 Haiku",
        "model_vendor": "anthropic",
        "model_version": "20241022",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_tool_choice": true
    },
    "vertex_ai/claude-haiku-4-5@20251001": {
        "display_name": "Claude Haiku 4.5",
        "model_vendor": "anthropic",
        "model_version": "20251001",
        "cache_creation_input_token_cost": 1.25e-06,
        "cache_read_input_token_cost": 1e-07,
        "input_cost_per_token": 1e-06,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/haiku-4-5",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "vertex_ai/claude-3-5-sonnet": {
        "display_name": "Claude 3.5 Sonnet",
        "model_vendor": "anthropic",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "vertex_ai/claude-3-5-sonnet-v2": {
        "display_name": "Claude 3.5 Sonnet v2",
        "model_vendor": "anthropic",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "vertex_ai/claude-3-5-sonnet-v2@20241022": {
        "display_name": "Claude 3.5 Sonnet v2",
        "model_vendor": "anthropic",
        "model_version": "20241022",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "vertex_ai/claude-3-5-sonnet@20240620": {
        "display_name": "Claude 3.5 Sonnet",
        "model_vendor": "anthropic",
        "model_version": "20240620",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "vertex_ai/claude-3-7-sonnet@20250219": {
        "display_name": "Claude 3.7 Sonnet",
        "model_vendor": "anthropic",
        "model_version": "20250219",
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "deprecation_date": "2025-06-01",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "vertex_ai/claude-3-haiku": {
        "display_name": "Claude 3 Haiku",
        "model_vendor": "anthropic",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.25e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "vertex_ai/claude-3-haiku@20240307": {
        "display_name": "Claude 3 Haiku",
        "model_vendor": "anthropic",
        "model_version": "20240307",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.25e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "vertex_ai/claude-3-opus": {
        "display_name": "Claude 3 Opus",
        "model_vendor": "anthropic",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "vertex_ai/claude-3-opus@20240229": {
        "display_name": "Claude 3 Opus",
        "model_vendor": "anthropic",
        "model_version": "20240229",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "vertex_ai/claude-3-sonnet": {
        "display_name": "Claude 3 Sonnet",
        "model_vendor": "anthropic",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "vertex_ai/claude-3-sonnet@20240229": {
        "display_name": "Claude 3 Sonnet",
        "model_vendor": "anthropic",
        "model_version": "20240229",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "vertex_ai/claude-opus-4": {
        "display_name": "Claude Opus 4",
        "model_vendor": "anthropic",
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "vertex_ai/claude-opus-4-1": {
        "display_name": "Claude Opus 4.1",
        "model_vendor": "anthropic",
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "input_cost_per_token": 1.5e-05,
        "input_cost_per_token_batches": 7.5e-06,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "output_cost_per_token_batches": 3.75e-05,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "vertex_ai/claude-opus-4-1@20250805": {
        "display_name": "Claude Opus 4.1",
        "model_vendor": "anthropic",
        "model_version": "20250805",
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "input_cost_per_token": 1.5e-05,
        "input_cost_per_token_batches": 7.5e-06,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "output_cost_per_token_batches": 3.75e-05,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "vertex_ai/claude-opus-4-5": {
        "display_name": "Claude Opus 4.5",
        "model_vendor": "anthropic",
        "cache_creation_input_token_cost": 6.25e-06,
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 2.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "vertex_ai/claude-opus-4-5@20251101": {
        "display_name": "Claude Opus 4.5",
        "model_vendor": "anthropic",
        "model_version": "20251101",
        "cache_creation_input_token_cost": 6.25e-06,
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 2.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "vertex_ai/claude-sonnet-4-5": {
        "display_name": "Claude Sonnet 4.5",
        "model_vendor": "anthropic",
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "input_cost_per_token_batches": 1.5e-06,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "output_cost_per_token_batches": 7.5e-06,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "vertex_ai/claude-sonnet-4-5@20250929": {
        "display_name": "Claude Sonnet 4.5",
        "model_vendor": "anthropic",
        "model_version": "20250929",
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "input_cost_per_token_batches": 1.5e-06,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "output_cost_per_token_batches": 7.5e-06,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "vertex_ai/claude-opus-4@20250514": {
        "display_name": "Claude Opus 4",
        "model_vendor": "anthropic",
        "model_version": "20250514",
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "vertex_ai/claude-sonnet-4": {
        "display_name": "Claude Sonnet 4",
        "model_vendor": "anthropic",
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "vertex_ai/claude-sonnet-4@20250514": {
        "display_name": "Claude Sonnet 4",
        "model_vendor": "anthropic",
        "model_version": "20250514",
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "litellm_provider": "vertex_ai-anthropic_models",
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "vertex_ai/mistralai/codestral-2@001": {
        "display_name": "Codestral 2",
        "model_vendor": "mistralai",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vertex_ai-mistral_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 9e-07,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/codestral-2": {
        "display_name": "Codestral 2",
        "model_vendor": "mistralai",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vertex_ai-mistral_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 9e-07,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/codestral-2@001": {
        "display_name": "Codestral 2 @001",
        "model_vendor": "mistralai",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vertex_ai-mistral_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 9e-07,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/mistralai/codestral-2": {
        "display_name": "Codestral 2",
        "model_vendor": "mistralai",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vertex_ai-mistral_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 9e-07,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/codestral-2501": {
        "display_name": "Codestral 2501",
        "model_vendor": "mistralai",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "vertex_ai-mistral_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/codestral@2405": {
        "display_name": "Codestral 2405",
        "model_vendor": "mistralai",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "vertex_ai-mistral_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/codestral@latest": {
        "display_name": "Codestral Latest",
        "model_vendor": "mistralai",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "vertex_ai-mistral_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/deepseek-ai/deepseek-v3.1-maas": {
        "display_name": "DeepSeek V3.1 MaaS",
        "model_vendor": "deepseek",
        "input_cost_per_token": 1.35e-06,
        "litellm_provider": "vertex_ai-deepseek_models",
        "max_input_tokens": 163840,
        "max_output_tokens": 32768,
        "max_tokens": 163840,
        "mode": "chat",
        "output_cost_per_token": 5.4e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
        "supported_regions": [
            "us-west2"
        ],
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "vertex_ai/deepseek-ai/deepseek-v3.2-maas": {
        "display_name": "Deepseek AI Deepseek V3.2 Maas",
        "model_vendor": "deepseek",
        "model_version": "3.2",
        "input_cost_per_token": 5.6e-07,
        "input_cost_per_token_batches": 2.8e-07,
        "litellm_provider": "vertex_ai-deepseek_models",
        "max_input_tokens": 163840,
        "max_output_tokens": 32768,
        "max_tokens": 163840,
        "mode": "chat",
        "output_cost_per_token": 1.68e-06,
        "output_cost_per_token_batches": 8.4e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
        "supported_regions": [
            "us-west2"
        ],
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "vertex_ai/deepseek-ai/deepseek-r1-0528-maas": {
        "display_name": "DeepSeek R1 0528 MaaS",
        "model_vendor": "deepseek",
        "input_cost_per_token": 1.35e-06,
        "litellm_provider": "vertex_ai-deepseek_models",
        "max_input_tokens": 65336,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 5.4e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "vertex_ai/gemini-2.5-flash-image": {
        "display_name": "Gemini 2.5 Flash Image",
        "model_vendor": "google",
        "cache_read_input_token_cost": 3e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "max_pdf_size_mb": 30,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "image_generation",
        "output_cost_per_image": 0.039,
        "output_cost_per_reasoning_token": 2.5e-06,
        "output_cost_per_token": 2.5e-06,
        "rpm": 100000,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/image-generation#edit-an-image",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": false,
        "tpm": 8000000
    },
    "vertex_ai/gemini-3-pro-image-preview": {
        "display_name": "Gemini 3 Pro Image Preview",
        "model_vendor": "google",
        "input_cost_per_image": 0.0011,
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_batches": 1e-06,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 65536,
        "max_output_tokens": 32768,
        "max_tokens": 65536,
        "mode": "image_generation",
        "output_cost_per_image": 0.134,
        "output_cost_per_image_token": 0.00012,
        "output_cost_per_token": 1.2e-05,
        "output_cost_per_token_batches": 6e-06,
        "source": "https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/3-pro-image"
    },
    "vertex_ai/imagegeneration@006": {
        "display_name": "Image Generation 006",
        "model_vendor": "google",
        "litellm_provider": "vertex_ai-image-models",
        "mode": "image_generation",
        "output_cost_per_image": 0.02,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "vertex_ai/imagen-3.0-fast-generate-001": {
        "display_name": "Imagen 3.0 Fast Generate 001",
        "model_vendor": "google",
        "litellm_provider": "vertex_ai-image-models",
        "mode": "image_generation",
        "output_cost_per_image": 0.02,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "vertex_ai/imagen-3.0-generate-001": {
        "display_name": "Imagen 3.0 Generate 001",
        "model_vendor": "google",
        "litellm_provider": "vertex_ai-image-models",
        "mode": "image_generation",
        "output_cost_per_image": 0.04,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "vertex_ai/imagen-3.0-generate-002": {
        "display_name": "Imagen 3.0 Generate 002",
        "model_vendor": "google",
        "litellm_provider": "vertex_ai-image-models",
        "mode": "image_generation",
        "output_cost_per_image": 0.04,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "vertex_ai/imagen-3.0-capability-001": {
        "display_name": "Imagen 3.0 Capability 001",
        "model_vendor": "google",
        "litellm_provider": "vertex_ai-image-models",
        "mode": "image_generation",
        "output_cost_per_image": 0.04,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/image/edit-insert-objects"
    },
    "vertex_ai/imagen-4.0-fast-generate-001": {
        "display_name": "Imagen 4.0 Fast Generate 001",
        "model_vendor": "google",
        "litellm_provider": "vertex_ai-image-models",
        "mode": "image_generation",
        "output_cost_per_image": 0.02,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "vertex_ai/imagen-4.0-generate-001": {
        "display_name": "Imagen 4.0 Generate 001",
        "model_vendor": "google",
        "litellm_provider": "vertex_ai-image-models",
        "mode": "image_generation",
        "output_cost_per_image": 0.04,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "vertex_ai/imagen-4.0-ultra-generate-001": {
        "display_name": "Imagen 4.0 Ultra Generate 001",
        "model_vendor": "google",
        "litellm_provider": "vertex_ai-image-models",
        "mode": "image_generation",
        "output_cost_per_image": 0.06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "vertex_ai/jamba-1.5": {
        "display_name": "Jamba 1.5",
        "model_vendor": "ai21",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "vertex_ai-ai21_models",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "supports_tool_choice": true
    },
    "vertex_ai/jamba-1.5-large": {
        "display_name": "Jamba 1.5 Large",
        "model_vendor": "ai21",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "vertex_ai-ai21_models",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "supports_tool_choice": true
    },
    "vertex_ai/jamba-1.5-large@001": {
        "display_name": "Jamba 1.5 Large @001",
        "model_vendor": "ai21",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "vertex_ai-ai21_models",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "supports_tool_choice": true
    },
    "vertex_ai/jamba-1.5-mini": {
        "display_name": "Jamba 1.5 Mini",
        "model_vendor": "ai21",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "vertex_ai-ai21_models",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "supports_tool_choice": true
    },
    "vertex_ai/jamba-1.5-mini@001": {
        "display_name": "Jamba 1.5 Mini @001",
        "model_vendor": "ai21",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "vertex_ai-ai21_models",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "supports_tool_choice": true
    },
    "vertex_ai/meta/llama-3.1-405b-instruct-maas": {
        "display_name": "Llama 3.1 405B Instruct MaaS",
        "model_vendor": "meta",
        "input_cost_per_token": 5e-06,
        "litellm_provider": "vertex_ai-llama_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.6e-05,
        "source": "https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas",
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "vertex_ai/meta/llama-3.1-70b-instruct-maas": {
        "display_name": "Llama 3.1 70B Instruct MaaS",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "vertex_ai-llama_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "source": "https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas",
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "vertex_ai/meta/llama-3.1-8b-instruct-maas": {
        "display_name": "Llama 3.1 8B Instruct MaaS",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "vertex_ai-llama_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "max_tokens": 128000,
        "metadata": {
            "notes": "VertexAI states that The Llama 3.1 API service for llama-3.1-70b-instruct-maas and llama-3.1-8b-instruct-maas are in public preview and at no cost."
        },
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "source": "https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas",
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "vertex_ai/meta/llama-3.2-90b-vision-instruct-maas": {
        "display_name": "Llama 3.2 90B Vision Instruct MaaS",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "vertex_ai-llama_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "max_tokens": 128000,
        "metadata": {
            "notes": "VertexAI states that The Llama 3.2 API service is at no cost during public preview, and will be priced as per dollar-per-1M-tokens at GA."
        },
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "source": "https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas",
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "vertex_ai/meta/llama-4-maverick-17b-128e-instruct-maas": {
        "display_name": "Llama 4 Maverick 17B 128E Instruct MaaS",
        "model_vendor": "meta",
        "input_cost_per_token": 3.5e-07,
        "litellm_provider": "vertex_ai-llama_models",
        "max_input_tokens": 1000000,
        "max_output_tokens": 1000000,
        "max_tokens": 1000000,
        "mode": "chat",
        "output_cost_per_token": 1.15e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "code"
        ],
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/meta/llama-4-maverick-17b-16e-instruct-maas": {
        "display_name": "Llama 4 Maverick 17B 16E Instruct MaaS",
        "model_vendor": "meta",
        "input_cost_per_token": 3.5e-07,
        "litellm_provider": "vertex_ai-llama_models",
        "max_input_tokens": 1000000,
        "max_output_tokens": 1000000,
        "max_tokens": 1000000,
        "mode": "chat",
        "output_cost_per_token": 1.15e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "code"
        ],
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/meta/llama-4-scout-17b-128e-instruct-maas": {
        "display_name": "Llama 4 Scout 17B 128E Instruct MaaS",
        "model_vendor": "meta",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "vertex_ai-llama_models",
        "max_input_tokens": 10000000,
        "max_output_tokens": 10000000,
        "max_tokens": 10000000,
        "mode": "chat",
        "output_cost_per_token": 7e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "code"
        ],
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/meta/llama-4-scout-17b-16e-instruct-maas": {
        "display_name": "Llama 4 Scout 17B 16E Instruct MaaS",
        "model_vendor": "meta",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "vertex_ai-llama_models",
        "max_input_tokens": 10000000,
        "max_output_tokens": 10000000,
        "max_tokens": 10000000,
        "mode": "chat",
        "output_cost_per_token": 7e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "code"
        ],
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/meta/llama3-405b-instruct-maas": {
        "display_name": "Llama 3 405B Instruct MaaS",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "vertex_ai-llama_models",
        "max_input_tokens": 32000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
        "supports_tool_choice": true
    },
    "vertex_ai/meta/llama3-70b-instruct-maas": {
        "display_name": "Llama 3 70B Instruct MaaS",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "vertex_ai-llama_models",
        "max_input_tokens": 32000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
        "supports_tool_choice": true
    },
    "vertex_ai/meta/llama3-8b-instruct-maas": {
        "display_name": "Llama 3 8B Instruct MaaS",
        "model_vendor": "meta",
        "input_cost_per_token": 0.0,
        "litellm_provider": "vertex_ai-llama_models",
        "max_input_tokens": 32000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 0.0,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
        "supports_tool_choice": true
    },
    "vertex_ai/minimaxai/minimax-m2-maas": {
        "display_name": "MiniMax M2 MaaS",
        "model_vendor": "minimax",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vertex_ai-minimax_models",
        "max_input_tokens": 196608,
        "max_output_tokens": 196608,
        "max_tokens": 196608,
        "mode": "chat",
        "output_cost_per_token": 1.2e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/moonshotai/kimi-k2-thinking-maas": {
        "display_name": "Kimi K2 Thinking MaaS",
        "model_vendor": "moonshot",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "vertex_ai-moonshot_models",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 2.5e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "vertex_ai/mistral-medium-3": {
        "display_name": "Mistral Medium 3",
        "model_vendor": "mistralai",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "vertex_ai-mistral_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/mistral-medium-3@001": {
        "display_name": "Mistral Medium 3 @001",
        "model_vendor": "mistralai",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "vertex_ai-mistral_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/mistralai/mistral-medium-3": {
        "display_name": "Mistral Medium 3",
        "model_vendor": "mistralai",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "vertex_ai-mistral_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/mistralai/mistral-medium-3@001": {
        "display_name": "Mistral Medium 3 @001",
        "model_vendor": "mistralai",
        "input_cost_per_token": 4e-07,
        "litellm_provider": "vertex_ai-mistral_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/mistral-large-2411": {
        "display_name": "Mistral Large 2411",
        "model_vendor": "mistralai",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "vertex_ai-mistral_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/mistral-large@2407": {
        "display_name": "Mistral Large 2407",
        "model_vendor": "mistralai",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "vertex_ai-mistral_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/mistral-large@2411-001": {
        "display_name": "Mistral Large 2411-001",
        "model_vendor": "mistralai",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "vertex_ai-mistral_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/mistral-large@latest": {
        "display_name": "Mistral Large Latest",
        "model_vendor": "mistralai",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "vertex_ai-mistral_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/mistral-nemo@2407": {
        "display_name": "Mistral Nemo 2407",
        "model_vendor": "mistralai",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "vertex_ai-mistral_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 3e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/mistral-nemo@latest": {
        "display_name": "Mistral Nemo Latest",
        "model_vendor": "mistralai",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "vertex_ai-mistral_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-07,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/mistral-small-2503": {
        "display_name": "Mistral Small 2503",
        "model_vendor": "mistralai",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "vertex_ai-mistral_models",
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 3e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "vertex_ai/mistral-small-2503@001": {
        "display_name": "Mistral Small 2503 @001",
        "model_vendor": "mistralai",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "vertex_ai-mistral_models",
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "max_tokens": 8191,
        "mode": "chat",
        "output_cost_per_token": 3e-06,
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/mistral-ocr-2505": {
        "display_name": "Mistral OCR 2505",
        "model_vendor": "mistralai",
        "litellm_provider": "vertex_ai",
        "mode": "ocr",
        "ocr_cost_per_page": 0.0005,
        "supported_endpoints": [
            "/v1/ocr"
        ],
        "source": "https://cloud.google.com/generative-ai-app-builder/pricing"
    },
    "vertex_ai/openai/gpt-oss-120b-maas": {
        "display_name": "GPT-OSS 120B MaaS",
        "model_vendor": "openai",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "vertex_ai-openai_models",
        "max_input_tokens": 131072,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "source": "https://console.cloud.google.com/vertex-ai/publishers/openai/model-garden/gpt-oss-120b-maas",
        "supports_reasoning": true
    },
    "vertex_ai/openai/gpt-oss-20b-maas": {
        "display_name": "GPT-OSS 20B MaaS",
        "model_vendor": "openai",
        "input_cost_per_token": 7.5e-08,
        "litellm_provider": "vertex_ai-openai_models",
        "max_input_tokens": 131072,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "source": "https://console.cloud.google.com/vertex-ai/publishers/openai/model-garden/gpt-oss-120b-maas",
        "supports_reasoning": true
    },
    "vertex_ai/qwen/qwen3-235b-a22b-instruct-2507-maas": {
        "display_name": "Qwen 3 235B A22B Instruct 2507 MaaS",
        "model_vendor": "alibaba",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "vertex_ai-qwen_models",
        "max_input_tokens": 262144,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/qwen/qwen3-coder-480b-a35b-instruct-maas": {
        "display_name": "Qwen 3 Coder 480B A35B Instruct MaaS",
        "model_vendor": "alibaba",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "vertex_ai-qwen_models",
        "max_input_tokens": 262144,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 4e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/qwen/qwen3-next-80b-a3b-instruct-maas": {
        "display_name": "Qwen 3 Next 80B A3B Instruct MaaS",
        "model_vendor": "alibaba",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "vertex_ai-qwen_models",
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "max_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 1.2e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/qwen/qwen3-next-80b-a3b-thinking-maas": {
        "display_name": "Qwen 3 Next 80B A3B Thinking MaaS",
        "model_vendor": "alibaba",
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "vertex_ai-qwen_models",
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "max_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 1.2e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/veo-2.0-generate-001": {
        "display_name": "Veo 2.0 Generate 001",
        "model_vendor": "google",
        "litellm_provider": "vertex_ai-video-models",
        "max_input_tokens": 1024,
        "max_tokens": 1024,
        "mode": "video_generation",
        "output_cost_per_second": 0.35,
        "source": "https://ai.google.dev/gemini-api/docs/video",
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "video"
        ]
    },
    "vertex_ai/veo-3.0-fast-generate-preview": {
        "display_name": "Veo 3.0 Fast Generate Preview",
        "model_vendor": "google",
        "litellm_provider": "vertex_ai-video-models",
        "max_input_tokens": 1024,
        "max_tokens": 1024,
        "mode": "video_generation",
        "output_cost_per_second": 0.15,
        "source": "https://ai.google.dev/gemini-api/docs/video",
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "video"
        ]
    },
    "vertex_ai/veo-3.0-generate-preview": {
        "display_name": "Veo 3.0 Generate Preview",
        "model_vendor": "google",
        "litellm_provider": "vertex_ai-video-models",
        "max_input_tokens": 1024,
        "max_tokens": 1024,
        "mode": "video_generation",
        "output_cost_per_second": 0.4,
        "source": "https://ai.google.dev/gemini-api/docs/video",
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "video"
        ]
    },
    "vertex_ai/veo-3.0-fast-generate-001": {
        "display_name": "Veo 3.0 Fast Generate 001",
        "model_vendor": "google",
        "litellm_provider": "vertex_ai-video-models",
        "max_input_tokens": 1024,
        "max_tokens": 1024,
        "mode": "video_generation",
        "output_cost_per_second": 0.15,
        "source": "https://ai.google.dev/gemini-api/docs/video",
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "video"
        ]
    },
    "vertex_ai/veo-3.0-generate-001": {
        "display_name": "Veo 3.0 Generate 001",
        "model_vendor": "google",
        "litellm_provider": "vertex_ai-video-models",
        "max_input_tokens": 1024,
        "max_tokens": 1024,
        "mode": "video_generation",
        "output_cost_per_second": 0.4,
        "source": "https://ai.google.dev/gemini-api/docs/video",
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "video"
        ]
    },
    "vertex_ai/veo-3.1-generate-preview": {
        "display_name": "Veo 3.1 Generate Preview",
        "model_vendor": "google",
        "litellm_provider": "vertex_ai-video-models",
        "max_input_tokens": 1024,
        "max_tokens": 1024,
        "mode": "video_generation",
        "output_cost_per_second": 0.4,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/veo",
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "video"
        ]
    },
    "vertex_ai/veo-3.1-fast-generate-preview": {
        "display_name": "Veo 3.1 Fast Generate Preview",
        "model_vendor": "google",
        "litellm_provider": "vertex_ai-video-models",
        "max_input_tokens": 1024,
        "max_tokens": 1024,
        "mode": "video_generation",
        "output_cost_per_second": 0.15,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/veo",
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "video"
        ]
    },
    "voyage/rerank-2": {
        "display_name": "Rerank 2",
        "model_vendor": "voyage",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "voyage",
        "max_input_tokens": 16000,
        "max_output_tokens": 16000,
        "max_query_tokens": 16000,
        "max_tokens": 16000,
        "mode": "rerank",
        "output_cost_per_token": 0.0
    },
    "voyage/rerank-2-lite": {
        "display_name": "Rerank 2 Lite",
        "model_vendor": "voyage",
        "input_cost_per_token": 2e-08,
        "litellm_provider": "voyage",
        "max_input_tokens": 8000,
        "max_output_tokens": 8000,
        "max_query_tokens": 8000,
        "max_tokens": 8000,
        "mode": "rerank",
        "output_cost_per_token": 0.0
    },
    "voyage/rerank-2.5": {
        "display_name": "Rerank 2.5",
        "model_vendor": "voyage",
        "model_version": "2.5",
        "input_cost_per_token": 5e-08,
        "litellm_provider": "voyage",
        "max_input_tokens": 32000,
        "max_output_tokens": 32000,
        "max_query_tokens": 32000,
        "max_tokens": 32000,
        "mode": "rerank",
        "output_cost_per_token": 0.0
    },
    "voyage/rerank-2.5-lite": {
        "display_name": "Rerank 2.5 Lite",
        "model_vendor": "voyage",
        "model_version": "2.5",
        "input_cost_per_token": 2e-08,
        "litellm_provider": "voyage",
        "max_input_tokens": 32000,
        "max_output_tokens": 32000,
        "max_query_tokens": 32000,
        "max_tokens": 32000,
        "mode": "rerank",
        "output_cost_per_token": 0.0
    },
    "voyage/voyage-2": {
        "display_name": "Voyage 2",
        "model_vendor": "voyage",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "voyage",
        "max_input_tokens": 4000,
        "max_tokens": 4000,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "voyage/voyage-3": {
        "display_name": "Voyage 3",
        "model_vendor": "voyage",
        "input_cost_per_token": 6e-08,
        "litellm_provider": "voyage",
        "max_input_tokens": 32000,
        "max_tokens": 32000,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "voyage/voyage-3-large": {
        "display_name": "Voyage 3 Large",
        "model_vendor": "voyage",
        "input_cost_per_token": 1.8e-07,
        "litellm_provider": "voyage",
        "max_input_tokens": 32000,
        "max_tokens": 32000,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "voyage/voyage-3-lite": {
        "display_name": "Voyage 3 Lite",
        "model_vendor": "voyage",
        "input_cost_per_token": 2e-08,
        "litellm_provider": "voyage",
        "max_input_tokens": 32000,
        "max_tokens": 32000,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "voyage/voyage-3.5": {
        "display_name": "Voyage 3.5",
        "model_vendor": "voyage",
        "input_cost_per_token": 6e-08,
        "litellm_provider": "voyage",
        "max_input_tokens": 32000,
        "max_tokens": 32000,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "voyage/voyage-3.5-lite": {
        "display_name": "Voyage 3.5 Lite",
        "model_vendor": "voyage",
        "input_cost_per_token": 2e-08,
        "litellm_provider": "voyage",
        "max_input_tokens": 32000,
        "max_tokens": 32000,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "voyage/voyage-code-2": {
        "display_name": "Voyage Code 2",
        "model_vendor": "voyage",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "voyage",
        "max_input_tokens": 16000,
        "max_tokens": 16000,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "voyage/voyage-code-3": {
        "display_name": "Voyage Code 3",
        "model_vendor": "voyage",
        "input_cost_per_token": 1.8e-07,
        "litellm_provider": "voyage",
        "max_input_tokens": 32000,
        "max_tokens": 32000,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "voyage/voyage-context-3": {
        "display_name": "Voyage Context 3",
        "model_vendor": "voyage",
        "input_cost_per_token": 1.8e-07,
        "litellm_provider": "voyage",
        "max_input_tokens": 120000,
        "max_tokens": 120000,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "voyage/voyage-finance-2": {
        "display_name": "Voyage Finance 2",
        "model_vendor": "voyage",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "voyage",
        "max_input_tokens": 32000,
        "max_tokens": 32000,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "voyage/voyage-large-2": {
        "display_name": "Voyage Large 2",
        "model_vendor": "voyage",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "voyage",
        "max_input_tokens": 16000,
        "max_tokens": 16000,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "voyage/voyage-law-2": {
        "display_name": "Voyage Law 2",
        "model_vendor": "voyage",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "voyage",
        "max_input_tokens": 16000,
        "max_tokens": 16000,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "voyage/voyage-lite-01": {
        "display_name": "Voyage Lite 01",
        "model_vendor": "voyage",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "voyage",
        "max_input_tokens": 4096,
        "max_tokens": 4096,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "voyage/voyage-lite-02-instruct": {
        "display_name": "Voyage Lite 02 Instruct",
        "model_vendor": "voyage",
        "input_cost_per_token": 1e-07,
        "litellm_provider": "voyage",
        "max_input_tokens": 4000,
        "max_tokens": 4000,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "voyage/voyage-multimodal-3": {
        "display_name": "Voyage Multimodal 3",
        "model_vendor": "voyage",
        "input_cost_per_token": 1.2e-07,
        "litellm_provider": "voyage",
        "max_input_tokens": 32000,
        "max_tokens": 32000,
        "mode": "embedding",
        "output_cost_per_token": 0.0
    },
    "wandb/openai/gpt-oss-120b": {
        "display_name": "GPT-OSS 120B",
        "model_vendor": "openai",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 0.015,
        "output_cost_per_token": 0.06,
        "litellm_provider": "wandb",
        "mode": "chat"
    },
    "wandb/openai/gpt-oss-20b": {
        "display_name": "GPT-OSS 20B",
        "model_vendor": "openai",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 0.005,
        "output_cost_per_token": 0.02,
        "litellm_provider": "wandb",
        "mode": "chat"
    },
    "wandb/zai-org/GLM-4.5": {
        "display_name": "GLM 4.5",
        "model_vendor": "zhipu",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 0.055,
        "output_cost_per_token": 0.2,
        "litellm_provider": "wandb",
        "mode": "chat"
    },
    "wandb/Qwen/Qwen3-235B-A22B-Instruct-2507": {
        "display_name": "Qwen 3 235B A22B Instruct 2507",
        "model_vendor": "alibaba",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 0.01,
        "output_cost_per_token": 0.01,
        "litellm_provider": "wandb",
        "mode": "chat"
    },
    "wandb/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
        "display_name": "Qwen 3 Coder 480B A35B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 0.1,
        "output_cost_per_token": 0.15,
        "litellm_provider": "wandb",
        "mode": "chat"
    },
    "wandb/Qwen/Qwen3-235B-A22B-Thinking-2507": {
        "display_name": "Qwen 3 235B A22B Thinking 2507",
        "model_vendor": "alibaba",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 0.01,
        "output_cost_per_token": 0.01,
        "litellm_provider": "wandb",
        "mode": "chat"
    },
    "wandb/moonshotai/Kimi-K2-Instruct": {
        "display_name": "Kimi K2 Instruct",
        "model_vendor": "moonshot",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.5e-06,
        "litellm_provider": "wandb",
        "mode": "chat"
    },
    "wandb/meta-llama/Llama-3.1-8B-Instruct": {
        "display_name": "Llama 3.1 8B Instruct",
        "model_vendor": "meta",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 0.022,
        "output_cost_per_token": 0.022,
        "litellm_provider": "wandb",
        "mode": "chat"
    },
    "wandb/deepseek-ai/DeepSeek-V3.1": {
        "display_name": "DeepSeek V3.1",
        "model_vendor": "deepseek",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 0.055,
        "output_cost_per_token": 0.165,
        "litellm_provider": "wandb",
        "mode": "chat"
    },
    "wandb/deepseek-ai/DeepSeek-R1-0528": {
        "display_name": "DeepSeek R1 0528",
        "model_vendor": "deepseek",
        "max_tokens": 161000,
        "max_input_tokens": 161000,
        "max_output_tokens": 161000,
        "input_cost_per_token": 0.135,
        "output_cost_per_token": 0.54,
        "litellm_provider": "wandb",
        "mode": "chat"
    },
    "wandb/deepseek-ai/DeepSeek-V3-0324": {
        "display_name": "DeepSeek V3 0324",
        "model_vendor": "deepseek",
        "max_tokens": 161000,
        "max_input_tokens": 161000,
        "max_output_tokens": 161000,
        "input_cost_per_token": 0.114,
        "output_cost_per_token": 0.275,
        "litellm_provider": "wandb",
        "mode": "chat"
    },
    "wandb/meta-llama/Llama-3.3-70B-Instruct": {
        "display_name": "Llama 3.3 70B Instruct",
        "model_vendor": "meta",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 0.071,
        "output_cost_per_token": 0.071,
        "litellm_provider": "wandb",
        "mode": "chat"
    },
    "wandb/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
        "display_name": "Llama 4 Scout 17B 16E Instruct",
        "model_vendor": "meta",
        "max_tokens": 64000,
        "max_input_tokens": 64000,
        "max_output_tokens": 64000,
        "input_cost_per_token": 0.017,
        "output_cost_per_token": 0.066,
        "litellm_provider": "wandb",
        "mode": "chat"
    },
    "wandb/microsoft/Phi-4-mini-instruct": {
        "display_name": "Phi 4 Mini Instruct",
        "model_vendor": "microsoft",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 0.008,
        "output_cost_per_token": 0.035,
        "litellm_provider": "wandb",
        "mode": "chat"
    },
    "watsonx/ibm/granite-3-8b-instruct": {
        "display_name": "Granite 3 8B Instruct",
        "model_vendor": "ibm",
        "input_cost_per_token": 2e-07,
        "litellm_provider": "watsonx",
        "max_input_tokens": 8192,
        "max_output_tokens": 1024,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 2e-07,
        "supports_audio_input": false,
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "watsonx/mistralai/mistral-large": {
        "display_name": "Mistral Large",
        "model_vendor": "mistralai",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "watsonx",
        "max_input_tokens": 131072,
        "max_output_tokens": 16384,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supports_audio_input": false,
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "watsonx/bigscience/mt0-xxl-13b": {
        "display_name": "MT0 XXL 13B",
        "model_vendor": "bigscience",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.0005,
        "output_cost_per_token": 0.002,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": false,
        "supports_parallel_function_calling": false,
        "supports_vision": false
    },
    "watsonx/core42/jais-13b-chat": {
        "display_name": "JAIS 13B Chat",
        "model_vendor": "core42",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.0005,
        "output_cost_per_token": 0.002,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": false,
        "supports_parallel_function_calling": false,
        "supports_vision": false
    },
    "watsonx/google/flan-t5-xl-3b": {
        "display_name": "Flan T5 XL 3B",
        "model_vendor": "google",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 6e-07,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": false,
        "supports_parallel_function_calling": false,
        "supports_vision": false
    },
    "watsonx/ibm/granite-13b-chat-v2": {
        "display_name": "Granite 13B Chat V2",
        "model_vendor": "ibm",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 6e-07,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": false,
        "supports_parallel_function_calling": false,
        "supports_vision": false
    },
    "watsonx/ibm/granite-13b-instruct-v2": {
        "display_name": "Granite 13B Instruct V2",
        "model_vendor": "ibm",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 6e-07,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": false,
        "supports_parallel_function_calling": false,
        "supports_vision": false
    },
    "watsonx/ibm/granite-3-3-8b-instruct": {
        "display_name": "Granite 3.3 8B Instruct",
        "model_vendor": "ibm",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false
    },
    "watsonx/ibm/granite-4-h-small": {
        "display_name": "Granite 4 H Small",
        "model_vendor": "ibm",
        "max_tokens": 20480,
        "max_input_tokens": 20480,
        "max_output_tokens": 20480,
        "input_cost_per_token": 6e-08,
        "output_cost_per_token": 2.5e-07,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false
    },
    "watsonx/ibm/granite-guardian-3-2-2b": {
        "display_name": "Granite Guardian 3.2 2B",
        "model_vendor": "ibm",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": false,
        "supports_parallel_function_calling": false,
        "supports_vision": false
    },
    "watsonx/ibm/granite-guardian-3-3-8b": {
        "display_name": "Granite Guardian 3.3 8B",
        "model_vendor": "ibm",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": false,
        "supports_parallel_function_calling": false,
        "supports_vision": false
    },
    "watsonx/ibm/granite-ttm-1024-96-r2": {
        "display_name": "Granite TTM 1024 96 R2",
        "model_vendor": "ibm",
        "max_tokens": 512,
        "max_input_tokens": 512,
        "max_output_tokens": 512,
        "input_cost_per_token": 3.8e-07,
        "output_cost_per_token": 3.8e-07,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": false,
        "supports_parallel_function_calling": false,
        "supports_vision": false
    },
    "watsonx/ibm/granite-ttm-1536-96-r2": {
        "display_name": "Granite TTM 1536 96 R2",
        "model_vendor": "ibm",
        "max_tokens": 512,
        "max_input_tokens": 512,
        "max_output_tokens": 512,
        "input_cost_per_token": 3.8e-07,
        "output_cost_per_token": 3.8e-07,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": false,
        "supports_parallel_function_calling": false,
        "supports_vision": false
    },
    "watsonx/ibm/granite-ttm-512-96-r2": {
        "display_name": "Granite TTM 512 96 R2",
        "model_vendor": "ibm",
        "max_tokens": 512,
        "max_input_tokens": 512,
        "max_output_tokens": 512,
        "input_cost_per_token": 3.8e-07,
        "output_cost_per_token": 3.8e-07,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": false,
        "supports_parallel_function_calling": false,
        "supports_vision": false
    },
    "watsonx/ibm/granite-vision-3-2-2b": {
        "display_name": "Granite Vision 3.2 2B",
        "model_vendor": "ibm",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": false,
        "supports_parallel_function_calling": false,
        "supports_vision": true
    },
    "watsonx/meta-llama/llama-3-2-11b-vision-instruct": {
        "display_name": "Llama 3.2 11B Vision Instruct",
        "model_vendor": "meta",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 3.5e-07,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true
    },
    "watsonx/meta-llama/llama-3-2-1b-instruct": {
        "display_name": "Llama 3.2 1B Instruct",
        "model_vendor": "meta",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false
    },
    "watsonx/meta-llama/llama-3-2-3b-instruct": {
        "display_name": "Llama 3.2 3B Instruct",
        "model_vendor": "meta",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-07,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false
    },
    "watsonx/meta-llama/llama-3-2-90b-vision-instruct": {
        "display_name": "Llama 3.2 90B Vision Instruct",
        "model_vendor": "meta",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 2e-06,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true
    },
    "watsonx/meta-llama/llama-3-3-70b-instruct": {
        "display_name": "Llama 3.3 70B Instruct",
        "model_vendor": "meta",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 7.1e-07,
        "output_cost_per_token": 7.1e-07,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false
    },
    "watsonx/meta-llama/llama-4-maverick-17b": {
        "display_name": "Llama 4 Maverick 17B",
        "model_vendor": "meta",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 1.4e-06,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false
    },
    "watsonx/meta-llama/llama-guard-3-11b-vision": {
        "display_name": "Llama Guard 3 11B Vision",
        "model_vendor": "meta",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 3.5e-07,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": false,
        "supports_parallel_function_calling": false,
        "supports_vision": true
    },
    "watsonx/mistralai/mistral-medium-2505": {
        "display_name": "Mistral Medium 2505",
        "model_vendor": "mistralai",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1e-05,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false
    },
    "watsonx/mistralai/mistral-small-2503": {
        "display_name": "Mistral Small 2503",
        "model_vendor": "mistralai",
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 3e-07,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false
    },
    "watsonx/mistralai/mistral-small-3-1-24b-instruct-2503": {
        "display_name": "Mistral Small 3.1 24B Instruct 2503",
        "model_vendor": "mistralai",
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 3e-07,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false
    },
    "watsonx/mistralai/pixtral-12b-2409": {
        "display_name": "Pixtral 12B 2409",
        "model_vendor": "mistralai",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 3.5e-07,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": false,
        "supports_parallel_function_calling": false,
        "supports_vision": true
    },
    "watsonx/openai/gpt-oss-120b": {
        "display_name": "GPT-OSS 120B",
        "model_vendor": "openai",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": false,
        "supports_parallel_function_calling": false,
        "supports_vision": false
    },
    "watsonx/sdaia/allam-1-13b-instruct": {
        "display_name": "ALLaM 1 13B Instruct",
        "model_vendor": "sdaia",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 1.8e-06,
        "output_cost_per_token": 1.8e-06,
        "litellm_provider": "watsonx",
        "mode": "chat",
        "supports_function_calling": false,
        "supports_parallel_function_calling": false,
        "supports_vision": false
    },
    "watsonx/whisper-large-v3-turbo": {
        "display_name": "Whisper Large v3 Turbo",
        "model_vendor": "openai",
        "input_cost_per_second": 0.0001,
        "output_cost_per_second": 0.0001,
        "litellm_provider": "watsonx",
        "mode": "audio_transcription",
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "whisper-1": {
        "display_name": "Whisper 1",
        "model_vendor": "openai",
        "input_cost_per_second": 0.0001,
        "litellm_provider": "openai",
        "mode": "audio_transcription",
        "output_cost_per_second": 0.0001,
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "xai/grok-2": {
        "display_name": "Grok 2",
        "model_vendor": "xai",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "xai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "xai/grok-2-1212": {
        "display_name": "Grok 2 1212",
        "model_vendor": "xai",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "xai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "xai/grok-2-latest": {
        "display_name": "Grok 2 Latest",
        "model_vendor": "xai",
        "input_cost_per_token": 2e-06,
        "litellm_provider": "xai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "xai/grok-2-vision": {
        "display_name": "Grok 2 Vision",
        "model_vendor": "xai",
        "input_cost_per_image": 2e-06,
        "input_cost_per_token": 2e-06,
        "litellm_provider": "xai",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "xai/grok-2-vision-1212": {
        "display_name": "Grok 2 Vision 1212",
        "model_vendor": "xai",
        "input_cost_per_image": 2e-06,
        "input_cost_per_token": 2e-06,
        "litellm_provider": "xai",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "xai/grok-2-vision-latest": {
        "display_name": "Grok 2 Vision Latest",
        "model_vendor": "xai",
        "input_cost_per_image": 2e-06,
        "input_cost_per_token": 2e-06,
        "litellm_provider": "xai",
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "xai/grok-3": {
        "display_name": "Grok 3",
        "model_vendor": "xai",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "xai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "source": "https://x.ai/api#pricing",
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "xai/grok-3-beta": {
        "display_name": "Grok 3 Beta",
        "model_vendor": "xai",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "xai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "source": "https://x.ai/api#pricing",
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "xai/grok-3-fast-beta": {
        "display_name": "Grok 3 Fast Beta",
        "model_vendor": "xai",
        "input_cost_per_token": 5e-06,
        "litellm_provider": "xai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 2.5e-05,
        "source": "https://x.ai/api#pricing",
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "xai/grok-3-fast-latest": {
        "display_name": "Grok 3 Fast Latest",
        "model_vendor": "xai",
        "input_cost_per_token": 5e-06,
        "litellm_provider": "xai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 2.5e-05,
        "source": "https://x.ai/api#pricing",
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "xai/grok-3-latest": {
        "display_name": "Grok 3 Latest",
        "model_vendor": "xai",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "xai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "source": "https://x.ai/api#pricing",
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "xai/grok-3-mini": {
        "display_name": "Grok 3 Mini",
        "model_vendor": "xai",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "xai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 5e-07,
        "source": "https://x.ai/api#pricing",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": false,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "xai/grok-3-mini-beta": {
        "display_name": "Grok 3 Mini Beta",
        "model_vendor": "xai",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "xai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 5e-07,
        "source": "https://x.ai/api#pricing",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": false,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "xai/grok-3-mini-fast": {
        "display_name": "Grok 3 Mini Fast",
        "model_vendor": "xai",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "xai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 4e-06,
        "source": "https://x.ai/api#pricing",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": false,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "xai/grok-3-mini-fast-beta": {
        "display_name": "Grok 3 Mini Fast Beta",
        "model_vendor": "xai",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "xai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 4e-06,
        "source": "https://x.ai/api#pricing",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": false,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "xai/grok-3-mini-fast-latest": {
        "display_name": "Grok 3 Mini Fast Latest",
        "model_vendor": "xai",
        "input_cost_per_token": 6e-07,
        "litellm_provider": "xai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 4e-06,
        "source": "https://x.ai/api#pricing",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": false,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "xai/grok-3-mini-latest": {
        "display_name": "Grok 3 Mini Latest",
        "model_vendor": "xai",
        "input_cost_per_token": 3e-07,
        "litellm_provider": "xai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 5e-07,
        "source": "https://x.ai/api#pricing",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": false,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "xai/grok-4": {
        "display_name": "Grok 4",
        "model_vendor": "xai",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "xai",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "source": "https://docs.x.ai/docs/models",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "xai/grok-4-fast-reasoning": {
        "display_name": "Grok 4 Fast Reasoning",
        "model_vendor": "xai",
        "litellm_provider": "xai",
        "max_input_tokens": 2000000.0,
        "max_output_tokens": 2000000.0,
        "max_tokens": 2000000.0,
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "input_cost_per_token_above_128k_tokens": 4e-07,
        "output_cost_per_token": 5e-07,
        "output_cost_per_token_above_128k_tokens": 1e-06,
        "cache_read_input_token_cost": 5e-08,
        "source": "https://docs.x.ai/docs/models",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "xai/grok-4-fast-non-reasoning": {
        "display_name": "Grok 4 Fast Non-Reasoning",
        "model_vendor": "xai",
        "litellm_provider": "xai",
        "max_input_tokens": 2000000.0,
        "max_output_tokens": 2000000.0,
        "cache_read_input_token_cost": 5e-08,
        "max_tokens": 2000000.0,
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "input_cost_per_token_above_128k_tokens": 4e-07,
        "output_cost_per_token": 5e-07,
        "output_cost_per_token_above_128k_tokens": 1e-06,
        "source": "https://docs.x.ai/docs/models",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "xai/grok-4-0709": {
        "display_name": "Grok 4 0709",
        "model_vendor": "xai",
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_128k_tokens": 6e-06,
        "litellm_provider": "xai",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "output_cost_per_token_above_128k_tokens": 3e-05,
        "source": "https://docs.x.ai/docs/models",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "xai/grok-4-latest": {
        "display_name": "Grok 4 Latest",
        "model_vendor": "xai",
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_128k_tokens": 6e-06,
        "litellm_provider": "xai",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "output_cost_per_token_above_128k_tokens": 3e-05,
        "source": "https://docs.x.ai/docs/models",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "xai/grok-4-1-fast": {
        "display_name": "Grok 4.1 Fast",
        "model_vendor": "xai",
        "cache_read_input_token_cost": 5e-08,
        "input_cost_per_token": 2e-07,
        "input_cost_per_token_above_128k_tokens": 4e-07,
        "litellm_provider": "xai",
        "max_input_tokens": 2000000.0,
        "max_output_tokens": 2000000.0,
        "max_tokens": 2000000.0,
        "mode": "chat",
        "output_cost_per_token": 5e-07,
        "output_cost_per_token_above_128k_tokens": 1e-06,
        "source": "https://docs.x.ai/docs/models/grok-4-1-fast-reasoning",
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "xai/grok-4-1-fast-reasoning": {
        "display_name": "Grok 4.1 Fast Reasoning",
        "model_vendor": "xai",
        "cache_read_input_token_cost": 5e-08,
        "input_cost_per_token": 2e-07,
        "input_cost_per_token_above_128k_tokens": 4e-07,
        "litellm_provider": "xai",
        "max_input_tokens": 2000000.0,
        "max_output_tokens": 2000000.0,
        "max_tokens": 2000000.0,
        "mode": "chat",
        "output_cost_per_token": 5e-07,
        "output_cost_per_token_above_128k_tokens": 1e-06,
        "source": "https://docs.x.ai/docs/models/grok-4-1-fast-reasoning",
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "xai/grok-4-1-fast-reasoning-latest": {
        "display_name": "Grok 4.1 Fast Reasoning Latest",
        "model_vendor": "xai",
        "cache_read_input_token_cost": 5e-08,
        "input_cost_per_token": 2e-07,
        "input_cost_per_token_above_128k_tokens": 4e-07,
        "litellm_provider": "xai",
        "max_input_tokens": 2000000.0,
        "max_output_tokens": 2000000.0,
        "max_tokens": 2000000.0,
        "mode": "chat",
        "output_cost_per_token": 5e-07,
        "output_cost_per_token_above_128k_tokens": 1e-06,
        "source": "https://docs.x.ai/docs/models/grok-4-1-fast-reasoning",
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "xai/grok-4-1-fast-non-reasoning": {
        "display_name": "Grok 4.1 Fast Non-Reasoning",
        "model_vendor": "xai",
        "cache_read_input_token_cost": 5e-08,
        "input_cost_per_token": 2e-07,
        "input_cost_per_token_above_128k_tokens": 4e-07,
        "litellm_provider": "xai",
        "max_input_tokens": 2000000.0,
        "max_output_tokens": 2000000.0,
        "max_tokens": 2000000.0,
        "mode": "chat",
        "output_cost_per_token": 5e-07,
        "output_cost_per_token_above_128k_tokens": 1e-06,
        "source": "https://docs.x.ai/docs/models/grok-4-1-fast-non-reasoning",
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "xai/grok-4-1-fast-non-reasoning-latest": {
        "display_name": "Grok 4.1 Fast Non-Reasoning Latest",
        "model_vendor": "xai",
        "cache_read_input_token_cost": 5e-08,
        "input_cost_per_token": 2e-07,
        "input_cost_per_token_above_128k_tokens": 4e-07,
        "litellm_provider": "xai",
        "max_input_tokens": 2000000.0,
        "max_output_tokens": 2000000.0,
        "max_tokens": 2000000.0,
        "mode": "chat",
        "output_cost_per_token": 5e-07,
        "output_cost_per_token_above_128k_tokens": 1e-06,
        "source": "https://docs.x.ai/docs/models/grok-4-1-fast-non-reasoning",
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "xai/grok-beta": {
        "display_name": "Grok Beta",
        "model_vendor": "xai",
        "input_cost_per_token": 5e-06,
        "litellm_provider": "xai",
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "max_tokens": 131072,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "xai/grok-code-fast": {
        "display_name": "Grok Code Fast",
        "model_vendor": "xai",
        "cache_read_input_token_cost": 2e-08,
        "input_cost_per_token": 2e-07,
        "litellm_provider": "xai",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "source": "https://docs.x.ai/docs/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "xai/grok-code-fast-1": {
        "display_name": "Grok Code Fast 1",
        "model_vendor": "xai",
        "cache_read_input_token_cost": 2e-08,
        "input_cost_per_token": 2e-07,
        "litellm_provider": "xai",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "source": "https://docs.x.ai/docs/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "xai/grok-code-fast-1-0825": {
        "display_name": "Grok Code Fast 1 0825",
        "model_vendor": "xai",
        "cache_read_input_token_cost": 2e-08,
        "input_cost_per_token": 2e-07,
        "litellm_provider": "xai",
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "max_tokens": 256000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "source": "https://docs.x.ai/docs/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "xai/grok-vision-beta": {
        "display_name": "Grok Vision Beta",
        "model_vendor": "xai",
        "input_cost_per_image": 5e-06,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "xai",
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "zai/glm-4.6": {
        "display_name": "GLM-4.6",
        "model_vendor": "zhipu",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.2e-06,
        "litellm_provider": "zai",
        "max_input_tokens": 200000,
        "max_output_tokens": 128000,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "source": "https://docs.z.ai/guides/overview/pricing"
    },
    "zai/glm-4.5": {
        "display_name": "GLM-4.5",
        "model_vendor": "zhipu",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.2e-06,
        "litellm_provider": "zai",
        "max_input_tokens": 128000,
        "max_output_tokens": 32000,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "source": "https://docs.z.ai/guides/overview/pricing"
    },
    "zai/glm-4.5v": {
        "display_name": "GLM-4.5V",
        "model_vendor": "zhipu",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 1.8e-06,
        "litellm_provider": "zai",
        "max_input_tokens": 128000,
        "max_output_tokens": 32000,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "source": "https://docs.z.ai/guides/overview/pricing"
    },
    "zai/glm-4.5-x": {
        "display_name": "GLM-4.5X",
        "model_vendor": "zhipu",
        "input_cost_per_token": 2.2e-06,
        "output_cost_per_token": 8.9e-06,
        "litellm_provider": "zai",
        "max_input_tokens": 128000,
        "max_output_tokens": 32000,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "source": "https://docs.z.ai/guides/overview/pricing"
    },
    "zai/glm-4.5-air": {
        "display_name": "GLM-4.5 Air",
        "model_vendor": "zhipu",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 1.1e-06,
        "litellm_provider": "zai",
        "max_input_tokens": 128000,
        "max_output_tokens": 32000,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "source": "https://docs.z.ai/guides/overview/pricing"
    },
    "zai/glm-4.5-airx": {
        "display_name": "GLM-4.5 AirX",
        "model_vendor": "zhipu",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 4.5e-06,
        "litellm_provider": "zai",
        "max_input_tokens": 128000,
        "max_output_tokens": 32000,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "source": "https://docs.z.ai/guides/overview/pricing"
    },
    "zai/glm-4-32b-0414-128k": {
        "display_name": "GLM-4 32B",
        "model_vendor": "zhipu",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "zai",
        "max_input_tokens": 128000,
        "max_output_tokens": 32000,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "source": "https://docs.z.ai/guides/overview/pricing"
    },
    "zai/glm-4.5-flash": {
        "display_name": "GLM-4.5 Flash",
        "model_vendor": "zhipu",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "litellm_provider": "zai",
        "max_input_tokens": 128000,
        "max_output_tokens": 32000,
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "source": "https://docs.z.ai/guides/overview/pricing"
    },
    "vertex_ai/search_api": {
        "display_name": "Search API",
        "model_vendor": "google",
        "input_cost_per_query": 0.0015,
        "litellm_provider": "vertex_ai",
        "mode": "vector_store"
    },
    "openai/container": {
        "display_name": "Container",
        "model_vendor": "openai",
        "code_interpreter_cost_per_session": 0.03,
        "litellm_provider": "openai",
        "mode": "chat"
    },
    "openai/sora-2": {
        "display_name": "Sora 2",
        "model_vendor": "openai",
        "litellm_provider": "openai",
        "mode": "video_generation",
        "output_cost_per_video_per_second": 0.1,
        "source": "https://platform.openai.com/docs/api-reference/videos",
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "video"
        ],
        "supported_resolutions": [
            "720x1280",
            "1280x720"
        ]
    },
    "openai/sora-2-pro": {
        "display_name": "Sora 2 Pro",
        "model_vendor": "openai",
        "litellm_provider": "openai",
        "mode": "video_generation",
        "output_cost_per_video_per_second": 0.3,
        "source": "https://platform.openai.com/docs/api-reference/videos",
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "video"
        ],
        "supported_resolutions": [
            "720x1280",
            "1280x720"
        ]
    },
    "azure/sora-2": {
        "display_name": "Sora 2",
        "model_vendor": "openai",
        "litellm_provider": "azure",
        "mode": "video_generation",
        "output_cost_per_video_per_second": 0.1,
        "source": "https://azure.microsoft.com/en-us/products/ai-services/video-generation",
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "video"
        ],
        "supported_resolutions": [
            "720x1280",
            "1280x720"
        ]
    },
    "azure/sora-2-pro": {
        "display_name": "Sora 2 Pro",
        "model_vendor": "openai",
        "litellm_provider": "azure",
        "mode": "video_generation",
        "output_cost_per_video_per_second": 0.3,
        "source": "https://azure.microsoft.com/en-us/products/ai-services/video-generation",
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "video"
        ],
        "supported_resolutions": [
            "720x1280",
            "1280x720"
        ]
    },
    "azure/sora-2-pro-high-res": {
        "display_name": "Sora 2 Pro High Res",
        "model_vendor": "openai",
        "litellm_provider": "azure",
        "mode": "video_generation",
        "output_cost_per_video_per_second": 0.5,
        "source": "https://azure.microsoft.com/en-us/products/ai-services/video-generation",
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "video"
        ],
        "supported_resolutions": [
            "1024x1792",
            "1792x1024"
        ]
    },
    "runwayml/gen4_turbo": {
        "display_name": "Gen4 Turbo",
        "model_vendor": "runwayml",
        "litellm_provider": "runwayml",
        "mode": "video_generation",
        "output_cost_per_video_per_second": 0.05,
        "source": "https://docs.dev.runwayml.com/guides/pricing/",
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "video"
        ],
        "supported_resolutions": [
            "1280x720",
            "720x1280"
        ],
        "metadata": {
            "comment": "5 credits per second @ $0.01 per credit = $0.05 per second"
        }
    },
    "runwayml/gen4_aleph": {
        "display_name": "Gen4 Aleph",
        "model_vendor": "runwayml",
        "litellm_provider": "runwayml",
        "mode": "video_generation",
        "output_cost_per_video_per_second": 0.15,
        "source": "https://docs.dev.runwayml.com/guides/pricing/",
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "video"
        ],
        "supported_resolutions": [
            "1280x720",
            "720x1280"
        ],
        "metadata": {
            "comment": "15 credits per second @ $0.01 per credit = $0.15 per second"
        }
    },
    "runwayml/gen3a_turbo": {
        "display_name": "Gen3a Turbo",
        "model_vendor": "runwayml",
        "model_version": "3a",
        "litellm_provider": "runwayml",
        "mode": "video_generation",
        "output_cost_per_video_per_second": 0.05,
        "source": "https://docs.dev.runwayml.com/guides/pricing/",
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "video"
        ],
        "supported_resolutions": [
            "1280x720",
            "720x1280"
        ],
        "metadata": {
            "comment": "5 credits per second @ $0.01 per credit = $0.05 per second"
        }
    },
    "runwayml/gen4_image": {
        "display_name": "Gen4 Image",
        "model_vendor": "runwayml",
        "litellm_provider": "runwayml",
        "mode": "image_generation",
        "input_cost_per_image": 0.05,
        "output_cost_per_image": 0.05,
        "source": "https://docs.dev.runwayml.com/guides/pricing/",
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "image"
        ],
        "supported_resolutions": [
            "1280x720",
            "1920x1080"
        ],
        "metadata": {
            "comment": "5 credits per 720p image or 8 credits per 1080p image @ $0.01 per credit. Using 5 credits ($0.05) as base cost"
        }
    },
    "runwayml/gen4_image_turbo": {
        "display_name": "Gen4 Image Turbo",
        "model_vendor": "runwayml",
        "litellm_provider": "runwayml",
        "mode": "image_generation",
        "input_cost_per_image": 0.02,
        "output_cost_per_image": 0.02,
        "source": "https://docs.dev.runwayml.com/guides/pricing/",
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "image"
        ],
        "supported_resolutions": [
            "1280x720",
            "1920x1080"
        ],
        "metadata": {
            "comment": "2 credits per image (any resolution) @ $0.01 per credit = $0.02 per image"
        }
    },
    "runwayml/eleven_multilingual_v2": {
        "display_name": "Eleven Multilingual v2",
        "model_vendor": "elevenlabs",
        "litellm_provider": "runwayml",
        "mode": "audio_speech",
        "input_cost_per_character": 3e-07,
        "source": "https://docs.dev.runwayml.com/guides/pricing/",
        "metadata": {
            "comment": "Estimated cost based on standard TTS pricing. RunwayML uses ElevenLabs models."
        }
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-coder-480b-a35b-instruct": {
        "display_name": "Qwen3 Coder 480B A35b Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 4.5e-07,
        "output_cost_per_token": 1.8e-06,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/flux-kontext-pro": {
        "display_name": "Flux Kontext Pro",
        "model_vendor": "black_forest_labs",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 4e-08,
        "litellm_provider": "fireworks_ai",
        "mode": "image_generation"
    },
    "fireworks_ai/accounts/fireworks/models/SSD-1B": {
        "display_name": "SSD 1B",
        "model_vendor": "fireworks",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.3e-10,
        "output_cost_per_token": 1.3e-10,
        "litellm_provider": "fireworks_ai",
        "mode": "image_generation"
    },
    "fireworks_ai/accounts/fireworks/models/chronos-hermes-13b-v2": {
        "display_name": "Chronos Hermes 13B V2",
        "model_vendor": "nousresearch",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-13b": {
        "display_name": "Code Llama 13B",
        "model_vendor": "meta",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-13b-instruct": {
        "display_name": "Code Llama 13B Instruct",
        "model_vendor": "meta",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-13b-python": {
        "display_name": "Code Llama 13B Python",
        "model_vendor": "meta",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-34b": {
        "display_name": "Code Llama 34B",
        "model_vendor": "meta",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-34b-instruct": {
        "display_name": "Code Llama 34B Instruct",
        "model_vendor": "meta",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-34b-python": {
        "display_name": "Code Llama 34B Python",
        "model_vendor": "meta",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-70b": {
        "display_name": "Code Llama 70B",
        "model_vendor": "meta",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-70b-instruct": {
        "display_name": "Code Llama 70B Instruct",
        "model_vendor": "meta",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-70b-python": {
        "display_name": "Code Llama 70B Python",
        "model_vendor": "meta",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-7b": {
        "display_name": "Code Llama 7B",
        "model_vendor": "meta",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-7b-instruct": {
        "display_name": "Code Llama 7B Instruct",
        "model_vendor": "meta",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-7b-python": {
        "display_name": "Code Llama 7B Python",
        "model_vendor": "meta",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/code-qwen-1p5-7b": {
        "display_name": "Code Qwen 1p5 7B",
        "model_vendor": "alibaba",
        "max_tokens": 65536,
        "max_input_tokens": 65536,
        "max_output_tokens": 65536,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/codegemma-2b": {
        "display_name": "Codegemma 2B",
        "model_vendor": "google",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/codegemma-7b": {
        "display_name": "Codegemma 7B",
        "model_vendor": "google",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/cogito-671b-v2-p1": {
        "display_name": "Cogito 671B V2 P1",
        "model_vendor": "cogito",
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-3b": {
        "display_name": "Cogito V1 Preview Llama 3B",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-70b": {
        "display_name": "Cogito V1 Preview Llama 70B",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-8b": {
        "display_name": "Cogito V1 Preview Llama 8B",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-qwen-14b": {
        "display_name": "Cogito V1 Preview Qwen 14B",
        "model_vendor": "alibaba",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-qwen-32b": {
        "display_name": "Cogito V1 Preview Qwen 32B",
        "model_vendor": "alibaba",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/flux-kontext-max": {
        "display_name": "Flux Kontext Max",
        "model_vendor": "black_forest_labs",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 8e-08,
        "output_cost_per_token": 8e-08,
        "litellm_provider": "fireworks_ai",
        "mode": "image_generation"
    },
    "fireworks_ai/accounts/fireworks/models/dbrx-instruct": {
        "display_name": "Dbrx Instruct",
        "model_vendor": "databricks",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-1b-base": {
        "display_name": "Deepseek Coder 1B Base",
        "model_vendor": "deepseek",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-33b-instruct": {
        "display_name": "Deepseek Coder 33B Instruct",
        "model_vendor": "deepseek",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-7b-base": {
        "display_name": "Deepseek Coder 7B Base",
        "model_vendor": "deepseek",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-7b-base-v1p5": {
        "display_name": "Deepseek Coder 7B Base V1p5",
        "model_vendor": "deepseek",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-7b-instruct-v1p5": {
        "display_name": "Deepseek Coder 7B Instruct V1p5",
        "model_vendor": "deepseek",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-lite-base": {
        "display_name": "Deepseek Coder V2 Lite Base",
        "model_vendor": "deepseek",
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-lite-instruct": {
        "display_name": "Deepseek Coder V2 Lite Instruct",
        "model_vendor": "deepseek",
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-prover-v2": {
        "display_name": "Deepseek Prover V2",
        "model_vendor": "deepseek",
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-0528-distill-qwen3-8b": {
        "display_name": "Deepseek R1 0528 Distill Qwen3 8B",
        "model_vendor": "deepseek",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-llama-70b": {
        "display_name": "Deepseek R1 Distill Llama 70B",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-llama-8b": {
        "display_name": "Deepseek R1 Distill Llama 8B",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-14b": {
        "display_name": "Deepseek R1 Distill Qwen 14B",
        "model_vendor": "deepseek",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-1p5b": {
        "display_name": "Deepseek R1 Distill Qwen 1p5b",
        "model_vendor": "deepseek",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-32b": {
        "display_name": "Deepseek R1 Distill Qwen 32B",
        "model_vendor": "deepseek",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-7b": {
        "display_name": "Deepseek R1 Distill Qwen 7B",
        "model_vendor": "deepseek",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v2-lite-chat": {
        "display_name": "Deepseek V2 Lite Chat",
        "model_vendor": "deepseek",
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v2p5": {
        "display_name": "Deepseek V2p5",
        "model_vendor": "deepseek",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/devstral-small-2505": {
        "display_name": "Devstral Small 2505",
        "model_vendor": "mistral",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/dobby-mini-unhinged-plus-llama-3-1-8b": {
        "display_name": "Dobby Mini Unhinged Plus Llama 3 1 8B",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/dobby-unhinged-llama-3-3-70b-new": {
        "display_name": "Dobby Unhinged Llama 3 3 70B New",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/dolphin-2-9-2-qwen2-72b": {
        "display_name": "Dolphin 2 9 2 Qwen2 72B",
        "model_vendor": "alibaba",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/dolphin-2p6-mixtral-8x7b": {
        "display_name": "Dolphin 2p6 Mixtral 8x7b",
        "model_vendor": "mistral",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/ernie-4p5-21b-a3b-pt": {
        "display_name": "Ernie 4p5 21B A3b Pt",
        "model_vendor": "baidu",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/ernie-4p5-300b-a47b-pt": {
        "display_name": "Ernie 4p5 300B A47b Pt",
        "model_vendor": "baidu",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/fare-20b": {
        "display_name": "Fare 20B",
        "model_vendor": "fireworks",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/firefunction-v1": {
        "display_name": "Firefunction V1",
        "model_vendor": "fireworks",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/firellava-13b": {
        "display_name": "Firellava 13B",
        "model_vendor": "fireworks",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/firesearch-ocr-v6": {
        "display_name": "Firesearch OCR V6",
        "model_vendor": "fireworks",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/fireworks-asr-large": {
        "display_name": "Fireworks ASR Large",
        "model_vendor": "fireworks",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "fireworks_ai",
        "mode": "audio_transcription"
    },
    "fireworks_ai/accounts/fireworks/models/fireworks-asr-v2": {
        "display_name": "Fireworks ASR V2",
        "model_vendor": "fireworks",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "fireworks_ai",
        "mode": "audio_transcription"
    },
    "fireworks_ai/accounts/fireworks/models/flux-1-dev": {
        "display_name": "Flux 1 Dev",
        "model_vendor": "black_forest_labs",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/flux-1-dev-controlnet-union": {
        "display_name": "Flux 1 Dev Controlnet Union",
        "model_vendor": "black_forest_labs",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-09,
        "output_cost_per_token": 1e-09,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/flux-1-dev-fp8": {
        "display_name": "Flux 1 Dev FP8",
        "model_vendor": "black_forest_labs",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 5e-10,
        "output_cost_per_token": 5e-10,
        "litellm_provider": "fireworks_ai",
        "mode": "image_generation"
    },
    "fireworks_ai/accounts/fireworks/models/flux-1-schnell": {
        "display_name": "Flux 1 Schnell",
        "model_vendor": "black_forest_labs",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/flux-1-schnell-fp8": {
        "display_name": "Flux 1 Schnell FP8",
        "model_vendor": "black_forest_labs",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3.5e-10,
        "output_cost_per_token": 3.5e-10,
        "litellm_provider": "fireworks_ai",
        "mode": "image_generation"
    },
    "fireworks_ai/accounts/fireworks/models/gemma-2b-it": {
        "display_name": "Gemma 2B It",
        "model_vendor": "google",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/gemma-3-27b-it": {
        "display_name": "Gemma 3 27B It",
        "model_vendor": "google",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/gemma-7b": {
        "display_name": "Gemma 7B",
        "model_vendor": "google",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/gemma-7b-it": {
        "display_name": "Gemma 7B It",
        "model_vendor": "google",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/gemma2-9b-it": {
        "display_name": "Gemma2 9B It",
        "model_vendor": "google",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/glm-4p5v": {
        "display_name": "Glm 4p5v",
        "model_vendor": "zhipu",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "supports_reasoning": true
    },
    "fireworks_ai/accounts/fireworks/models/gpt-oss-safeguard-120b": {
        "display_name": "GPT Oss Safeguard 120B",
        "model_vendor": "openai",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/gpt-oss-safeguard-20b": {
        "display_name": "GPT Oss Safeguard 20B",
        "model_vendor": "openai",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/hermes-2-pro-mistral-7b": {
        "display_name": "Hermes 2 Pro Mistral 7B",
        "model_vendor": "mistral",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/internvl3-38b": {
        "display_name": "Internvl3 38B",
        "model_vendor": "opengvlab",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/internvl3-78b": {
        "display_name": "Internvl3 78B",
        "model_vendor": "opengvlab",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/internvl3-8b": {
        "display_name": "Internvl3 8B",
        "model_vendor": "opengvlab",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/japanese-stable-diffusion-xl": {
        "display_name": "Japanese Stable Diffusion XL",
        "model_vendor": "stability",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.3e-10,
        "output_cost_per_token": 1.3e-10,
        "litellm_provider": "fireworks_ai",
        "mode": "image_generation"
    },
    "fireworks_ai/accounts/fireworks/models/kat-coder": {
        "display_name": "Kat Coder",
        "model_vendor": "fireworks",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/kat-dev-32b": {
        "display_name": "Kat Dev 32B",
        "model_vendor": "fireworks",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/kat-dev-72b-exp": {
        "display_name": "Kat Dev 72B Exp",
        "model_vendor": "fireworks",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llama-guard-2-8b": {
        "display_name": "Llama Guard 2 8B",
        "model_vendor": "meta",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llama-guard-3-1b": {
        "display_name": "Llama Guard 3 1B",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llama-guard-3-8b": {
        "display_name": "Llama Guard 3 8B",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-13b": {
        "display_name": "Llama V2 13B",
        "model_vendor": "meta",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-13b-chat": {
        "display_name": "Llama V2 13B Chat",
        "model_vendor": "meta",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-70b": {
        "display_name": "Llama V2 70B",
        "model_vendor": "meta",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-70b-chat": {
        "display_name": "Llama V2 70B Chat",
        "model_vendor": "meta",
        "max_tokens": 2048,
        "max_input_tokens": 2048,
        "max_output_tokens": 2048,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-7b": {
        "display_name": "Llama V2 7B",
        "model_vendor": "meta",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-7b-chat": {
        "display_name": "Llama V2 7B Chat",
        "model_vendor": "meta",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3-70b-instruct": {
        "display_name": "Llama V3 70B Instruct",
        "model_vendor": "meta",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3-70b-instruct-hf": {
        "display_name": "Llama V3 70B Instruct Hf",
        "model_vendor": "meta",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3-8b": {
        "display_name": "Llama V3 8B",
        "model_vendor": "meta",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3-8b-instruct-hf": {
        "display_name": "Llama V3 8B Instruct Hf",
        "model_vendor": "meta",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct-long": {
        "display_name": "Llama V3p1 405B Instruct Long",
        "model_vendor": "meta",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct": {
        "display_name": "Llama V3p1 70B Instruct",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct-1b": {
        "display_name": "Llama V3p1 70B Instruct 1B",
        "model_vendor": "meta",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-nemotron-70b-instruct": {
        "display_name": "Llama V3p1 Nemotron 70B Instruct",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b": {
        "display_name": "Llama V3p2 1B",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-3b": {
        "display_name": "Llama V3p2 3B",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p3-70b-instruct": {
        "display_name": "Llama V3p3 70B Instruct",
        "model_vendor": "meta",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llamaguard-7b": {
        "display_name": "Llamaguard 7B",
        "model_vendor": "meta",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/llava-yi-34b": {
        "display_name": "Llava Yi 34B",
        "model_vendor": "zero_one_ai",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/minimax-m1-80k": {
        "display_name": "Minimax M1 80K",
        "model_vendor": "minimax",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/minimax-m2": {
        "display_name": "Minimax M2",
        "model_vendor": "minimax",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 1.2e-06,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/ministral-3-14b-instruct-2512": {
        "display_name": "Ministral 3 14B Instruct 2512",
        "model_vendor": "mistral",
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/ministral-3-3b-instruct-2512": {
        "display_name": "Ministral 3 3B Instruct 2512",
        "model_vendor": "mistral",
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/ministral-3-8b-instruct-2512": {
        "display_name": "Ministral 3 8B Instruct 2512",
        "model_vendor": "mistral",
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-7b": {
        "display_name": "Mistral 7B",
        "model_vendor": "mistral",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-7b-instruct-4k": {
        "display_name": "Mistral 7B Instruct 4K",
        "model_vendor": "mistral",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-7b-instruct-v0p2": {
        "display_name": "Mistral 7B Instruct V0p2",
        "model_vendor": "mistral",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-7b-instruct-v3": {
        "display_name": "Mistral 7B Instruct V3",
        "model_vendor": "mistral",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-7b-v0p2": {
        "display_name": "Mistral 7B V0p2",
        "model_vendor": "mistral",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-large-3-fp8": {
        "display_name": "Mistral Large 3 FP8",
        "model_vendor": "mistral",
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-nemo-base-2407": {
        "display_name": "Mistral Nemo Base 2407",
        "model_vendor": "mistral",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-nemo-instruct-2407": {
        "display_name": "Mistral Nemo Instruct 2407",
        "model_vendor": "mistral",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/mistral-small-24b-instruct-2501": {
        "display_name": "Mistral Small 24B Instruct 2501",
        "model_vendor": "mistral",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x22b": {
        "display_name": "Mixtral 8x22b",
        "model_vendor": "mistral",
        "max_tokens": 65536,
        "max_input_tokens": 65536,
        "max_output_tokens": 65536,
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct": {
        "display_name": "Mixtral 8x22b Instruct",
        "model_vendor": "mistral",
        "max_tokens": 65536,
        "max_input_tokens": 65536,
        "max_output_tokens": 65536,
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x7b": {
        "display_name": "Mixtral 8x7b",
        "model_vendor": "mistral",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x7b-instruct": {
        "display_name": "Mixtral 8x7b Instruct",
        "model_vendor": "mistral",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x7b-instruct-hf": {
        "display_name": "Mixtral 8x7b Instruct Hf",
        "model_vendor": "mistral",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/mythomax-l2-13b": {
        "display_name": "Mythomax L2 13B",
        "model_vendor": "fireworks",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/nemotron-nano-v2-12b-vl": {
        "display_name": "Nemotron Nano V2 12B VL",
        "model_vendor": "nvidia",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/nous-capybara-7b-v1p9": {
        "display_name": "Nous Capybara 7B V1p9",
        "model_vendor": "nousresearch",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/nous-hermes-2-mixtral-8x7b-dpo": {
        "display_name": "Nous Hermes 2 Mixtral 8x7b DPO",
        "model_vendor": "mistral",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/nous-hermes-2-yi-34b": {
        "display_name": "Nous Hermes 2 Yi 34B",
        "model_vendor": "zero_one_ai",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/nous-hermes-llama2-13b": {
        "display_name": "Nous Hermes Llama2 13B",
        "model_vendor": "meta",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/nous-hermes-llama2-70b": {
        "display_name": "Nous Hermes Llama2 70B",
        "model_vendor": "meta",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/nous-hermes-llama2-7b": {
        "display_name": "Nous Hermes Llama2 7B",
        "model_vendor": "meta",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/nvidia-nemotron-nano-12b-v2": {
        "display_name": "Nvidia Nemotron Nano 12B V2",
        "model_vendor": "nvidia",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/nvidia-nemotron-nano-9b-v2": {
        "display_name": "Nvidia Nemotron Nano 9B V2",
        "model_vendor": "nvidia",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/openchat-3p5-0106-7b": {
        "display_name": "Openchat 3p5 0106 7B",
        "model_vendor": "fireworks",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/openhermes-2-mistral-7b": {
        "display_name": "Openhermes 2 Mistral 7B",
        "model_vendor": "mistral",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/openhermes-2p5-mistral-7b": {
        "display_name": "Openhermes 2p5 Mistral 7B",
        "model_vendor": "mistral",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/openorca-7b": {
        "display_name": "Openorca 7B",
        "model_vendor": "fireworks",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/phi-2-3b": {
        "display_name": "Phi 2 3B",
        "model_vendor": "microsoft",
        "max_tokens": 2048,
        "max_input_tokens": 2048,
        "max_output_tokens": 2048,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/phi-3-mini-128k-instruct": {
        "display_name": "Phi 3 Mini 128K Instruct",
        "model_vendor": "microsoft",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/phi-3-vision-128k-instruct": {
        "display_name": "Phi 3 Vision 128K Instruct",
        "model_vendor": "microsoft",
        "max_tokens": 32064,
        "max_input_tokens": 32064,
        "max_output_tokens": 32064,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/phind-code-llama-34b-python-v1": {
        "display_name": "Phind Code Llama 34B Python V1",
        "model_vendor": "meta",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/phind-code-llama-34b-v1": {
        "display_name": "Phind Code Llama 34B V1",
        "model_vendor": "meta",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/phind-code-llama-34b-v2": {
        "display_name": "Phind Code Llama 34B V2",
        "model_vendor": "meta",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/playground-v2-1024px-aesthetic": {
        "display_name": "Playground V2 1024px Aesthetic",
        "model_vendor": "fireworks",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.3e-10,
        "output_cost_per_token": 1.3e-10,
        "litellm_provider": "fireworks_ai",
        "mode": "image_generation"
    },
    "fireworks_ai/accounts/fireworks/models/playground-v2-5-1024px-aesthetic": {
        "display_name": "Playground V2 5 1024px Aesthetic",
        "model_vendor": "fireworks",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.3e-10,
        "output_cost_per_token": 1.3e-10,
        "litellm_provider": "fireworks_ai",
        "mode": "image_generation"
    },
    "fireworks_ai/accounts/fireworks/models/pythia-12b": {
        "display_name": "Pythia 12B",
        "model_vendor": "fireworks",
        "max_tokens": 2048,
        "max_input_tokens": 2048,
        "max_output_tokens": 2048,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen-qwq-32b-preview": {
        "display_name": "Qwen Qwq 32B Preview",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen-v2p5-14b-instruct": {
        "display_name": "Qwen V2p5 14B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen-v2p5-7b": {
        "display_name": "Qwen V2p5 7B",
        "model_vendor": "alibaba",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen1p5-72b-chat": {
        "display_name": "Qwen1p5 72B Chat",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-7b-instruct": {
        "display_name": "Qwen2 7B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-vl-2b-instruct": {
        "display_name": "Qwen2 VL 2B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-vl-72b-instruct": {
        "display_name": "Qwen2 VL 72B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-vl-7b-instruct": {
        "display_name": "Qwen2 VL 7B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-0p5b-instruct": {
        "display_name": "Qwen2p5 0p5b Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-14b": {
        "display_name": "Qwen2p5 14B",
        "model_vendor": "alibaba",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-1p5b-instruct": {
        "display_name": "Qwen2p5 1p5b Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-32b": {
        "display_name": "Qwen2p5 32B",
        "model_vendor": "alibaba",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-32b-instruct": {
        "display_name": "Qwen2p5 32B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-72b": {
        "display_name": "Qwen2p5 72B",
        "model_vendor": "alibaba",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-72b-instruct": {
        "display_name": "Qwen2p5 72B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-7b-instruct": {
        "display_name": "Qwen2p5 7B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-0p5b": {
        "display_name": "Qwen2p5 Coder 0p5b",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-0p5b-instruct": {
        "display_name": "Qwen2p5 Coder 0p5b Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-14b": {
        "display_name": "Qwen2p5 Coder 14B",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-14b-instruct": {
        "display_name": "Qwen2p5 Coder 14B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-1p5b": {
        "display_name": "Qwen2p5 Coder 1p5b",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-1p5b-instruct": {
        "display_name": "Qwen2p5 Coder 1p5b Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b": {
        "display_name": "Qwen2p5 Coder 32B",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct-128k": {
        "display_name": "Qwen2p5 Coder 32B Instruct 128K",
        "model_vendor": "alibaba",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct-32k-rope": {
        "display_name": "Qwen2p5 Coder 32B Instruct 32K Rope",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct-64k": {
        "display_name": "Qwen2p5 Coder 32B Instruct 64K",
        "model_vendor": "alibaba",
        "max_tokens": 65536,
        "max_input_tokens": 65536,
        "max_output_tokens": 65536,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-3b": {
        "display_name": "Qwen2p5 Coder 3B",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-3b-instruct": {
        "display_name": "Qwen2p5 Coder 3B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-7b": {
        "display_name": "Qwen2p5 Coder 7B",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-7b-instruct": {
        "display_name": "Qwen2p5 Coder 7B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-math-72b-instruct": {
        "display_name": "Qwen2p5 Math 72B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-32b-instruct": {
        "display_name": "Qwen2p5 VL 32B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-3b-instruct": {
        "display_name": "Qwen2p5 VL 3B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-72b-instruct": {
        "display_name": "Qwen2p5 VL 72B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-7b-instruct": {
        "display_name": "Qwen2p5 VL 7B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-0p6b": {
        "display_name": "Qwen3 0p6b",
        "model_vendor": "alibaba",
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-14b": {
        "display_name": "Qwen3 14B",
        "model_vendor": "alibaba",
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-1p7b": {
        "display_name": "Qwen3 1p7b",
        "model_vendor": "alibaba",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-1p7b-fp8-draft": {
        "display_name": "Qwen3 1p7b FP8 Draft",
        "model_vendor": "alibaba",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-1p7b-fp8-draft-131072": {
        "display_name": "Qwen3 1p7b FP8 Draft 131072",
        "model_vendor": "alibaba",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-1p7b-fp8-draft-40960": {
        "display_name": "Qwen3 1p7b FP8 Draft 40960",
        "model_vendor": "alibaba",
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b": {
        "display_name": "Qwen3 235B A22b",
        "model_vendor": "alibaba",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2.2e-07,
        "output_cost_per_token": 8.8e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b-instruct-2507": {
        "display_name": "Qwen3 235B A22b Instruct 2507",
        "model_vendor": "alibaba",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 2.2e-07,
        "output_cost_per_token": 8.8e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b-thinking-2507": {
        "display_name": "Qwen3 235B A22b Thinking 2507",
        "model_vendor": "alibaba",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 2.2e-07,
        "output_cost_per_token": 8.8e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b": {
        "display_name": "Qwen3 30B A3b",
        "model_vendor": "alibaba",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b-instruct-2507": {
        "display_name": "Qwen3 30B A3b Instruct 2507",
        "model_vendor": "alibaba",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b-thinking-2507": {
        "display_name": "Qwen3 30B A3b Thinking 2507",
        "model_vendor": "alibaba",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-32b": {
        "display_name": "Qwen3 32B",
        "model_vendor": "alibaba",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-4b": {
        "display_name": "Qwen3 4B",
        "model_vendor": "alibaba",
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-4b-instruct-2507": {
        "display_name": "Qwen3 4B Instruct 2507",
        "model_vendor": "alibaba",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-8b": {
        "display_name": "Qwen3 8B",
        "model_vendor": "alibaba",
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-coder-30b-a3b-instruct": {
        "display_name": "Qwen3 Coder 30B A3b Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-coder-480b-instruct-bf16": {
        "display_name": "Qwen3 Coder 480B Instruct BF16",
        "model_vendor": "alibaba",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-embedding-0p6b": {
        "display_name": "Qwen3 Embedding 0p6b",
        "model_vendor": "alibaba",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "fireworks_ai",
        "mode": "embedding"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-embedding-4b": {
        "display_name": "Qwen3 Embedding 4B",
        "model_vendor": "alibaba",
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "fireworks_ai",
        "mode": "embedding"
    },
    "fireworks_ai/accounts/fireworks/models/": {
        "display_name": "",
        "model_vendor": "fireworks",
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "litellm_provider": "fireworks_ai",
        "mode": "embedding"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-next-80b-a3b-instruct": {
        "display_name": "Qwen3 Next 80B A3b Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-next-80b-a3b-thinking": {
        "display_name": "Qwen3 Next 80B A3b Thinking",
        "model_vendor": "alibaba",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-reranker-0p6b": {
        "display_name": "Qwen3 Reranker 0p6b",
        "model_vendor": "alibaba",
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "fireworks_ai",
        "mode": "rerank"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-reranker-4b": {
        "display_name": "Qwen3 Reranker 4B",
        "model_vendor": "alibaba",
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "fireworks_ai",
        "mode": "rerank"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-reranker-8b": {
        "display_name": "Qwen3 Reranker 8B",
        "model_vendor": "alibaba",
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "fireworks_ai",
        "mode": "rerank"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-235b-a22b-instruct": {
        "display_name": "Qwen3 VL 235B A22b Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 2.2e-07,
        "output_cost_per_token": 8.8e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-235b-a22b-thinking": {
        "display_name": "Qwen3 VL 235B A22b Thinking",
        "model_vendor": "alibaba",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 2.2e-07,
        "output_cost_per_token": 8.8e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-30b-a3b-instruct": {
        "display_name": "Qwen3 VL 30B A3b Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-30b-a3b-thinking": {
        "display_name": "Qwen3 VL 30B A3b Thinking",
        "model_vendor": "alibaba",
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-32b-instruct": {
        "display_name": "Qwen3 VL 32B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-8b-instruct": {
        "display_name": "Qwen3 VL 8B Instruct",
        "model_vendor": "alibaba",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/qwq-32b": {
        "display_name": "Qwq 32B",
        "model_vendor": "alibaba",
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/rolm-ocr": {
        "display_name": "Rolm OCR",
        "model_vendor": "fireworks",
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/snorkel-mistral-7b-pairrm-dpo": {
        "display_name": "Snorkel Mistral 7B Pairrm DPO",
        "model_vendor": "mistral",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/stable-diffusion-xl-1024-v1-0": {
        "display_name": "Stable Diffusion XL 1024 V1 0",
        "model_vendor": "stability",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.3e-10,
        "output_cost_per_token": 1.3e-10,
        "litellm_provider": "fireworks_ai",
        "mode": "image_generation"
    },
    "fireworks_ai/accounts/fireworks/models/stablecode-3b": {
        "display_name": "Stablecode 3B",
        "model_vendor": "fireworks",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/starcoder-16b": {
        "display_name": "Starcoder 16B",
        "model_vendor": "bigcode",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/starcoder-7b": {
        "display_name": "Starcoder 7B",
        "model_vendor": "bigcode",
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/starcoder2-15b": {
        "display_name": "Starcoder2 15B",
        "model_vendor": "bigcode",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/starcoder2-3b": {
        "display_name": "Starcoder2 3B",
        "model_vendor": "bigcode",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/starcoder2-7b": {
        "display_name": "Starcoder2 7B",
        "model_vendor": "bigcode",
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/toppy-m-7b": {
        "display_name": "Toppy M 7B",
        "model_vendor": "fireworks",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/whisper-v3": {
        "display_name": "Whisper V3",
        "model_vendor": "openai",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "fireworks_ai",
        "mode": "audio_transcription"
    },
    "fireworks_ai/accounts/fireworks/models/whisper-v3-turbo": {
        "display_name": "Whisper V3 Turbo",
        "model_vendor": "openai",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "fireworks_ai",
        "mode": "audio_transcription"
    },
    "fireworks_ai/accounts/fireworks/models/yi-34b": {
        "display_name": "Yi 34B",
        "model_vendor": "zero_one_ai",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/yi-34b-200k-capybara": {
        "display_name": "Yi 34B 200K Capybara",
        "model_vendor": "zero_one_ai",
        "max_tokens": 200000,
        "max_input_tokens": 200000,
        "max_output_tokens": 200000,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/yi-34b-chat": {
        "display_name": "Yi 34B Chat",
        "model_vendor": "zero_one_ai",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/yi-6b": {
        "display_name": "Yi 6B",
        "model_vendor": "zero_one_ai",
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/zephyr-7b-beta": {
        "display_name": "Zephyr 7B Beta",
        "model_vendor": "fireworks",
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat"
    }
}
