{
    "gpt-4": {
        "max_tokens": 8192,
        "input_cost_per_token": 0.00003,
        "output_cost_per_token": 0.00006,
        "litellm_provider": "openai",
        "mode": "chat"
    },
    "gpt-4-0314": {
        "max_tokens": 8192,
        "input_cost_per_token": 0.00003,
        "output_cost_per_token": 0.00006,
        "litellm_provider": "openai",
        "mode": "chat"
    },
    "gpt-4-0613": {
        "max_tokens": 8192,
        "input_cost_per_token": 0.00003,
        "output_cost_per_token": 0.00006,
        "litellm_provider": "openai",
        "mode": "chat"
    },
    "gpt-4-32k": {
        "max_tokens": 32768,
        "input_cost_per_token": 0.00006,
        "output_cost_per_token": 0.00012,
        "litellm_provider": "openai",
        "mode": "chat"
    },
    "gpt-4-32k-0314": {
        "max_tokens": 32768,
        "input_cost_per_token": 0.00006,
        "output_cost_per_token": 0.00012,
        "litellm_provider": "openai",
        "mode": "chat"
    },
    "gpt-4-32k-0613": {
        "max_tokens": 32768,
        "input_cost_per_token": 0.00006,
        "output_cost_per_token": 0.00012,
        "litellm_provider": "openai",
        "mode": "chat"
    },
    "gpt-3.5-turbo": {
        "max_tokens": 4097,
        "input_cost_per_token": 0.0000015,
        "output_cost_per_token": 0.000002,
        "litellm_provider": "openai",
        "mode": "chat"
    },
    "gpt-3.5-turbo-0301": {
        "max_tokens": 4097,
        "input_cost_per_token": 0.0000015,
        "output_cost_per_token": 0.000002,
        "litellm_provider": "openai",
        "mode": "chat"
    },
    "gpt-3.5-turbo-0613": {
        "max_tokens": 4097,
        "input_cost_per_token": 0.0000015,
        "output_cost_per_token": 0.000002,
        "litellm_provider": "openai",
        "mode": "chat"
    },
    "gpt-3.5-turbo-16k": {
        "max_tokens": 16385,
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000004,
        "litellm_provider": "openai",
        "mode": "chat"
    },
    "gpt-3.5-turbo-16k-0613": {
        "max_tokens": 16385,
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000004,
        "litellm_provider": "openai",
        "mode": "chat"
    },
    "text-davinci-003": {
        "max_tokens": 4097,
        "input_cost_per_token": 0.000002,
        "output_cost_per_token": 0.000002,
        "litellm_provider": "text-completion-openai",
        "mode": "completion"
    },
    "text-curie-001": {
        "max_tokens": 2049,
        "input_cost_per_token": 0.000002,
        "output_cost_per_token": 0.000002,
        "litellm_provider": "text-completion-openai",
        "mode": "completion"
    },
    "text-babbage-001": {
        "max_tokens": 2049,
        "input_cost_per_token": 0.0000004,
        "output_cost_per_token": 0.0000004,
        "litellm_provider": "text-completion-openai",
        "mode": "completion"
    },
    "text-ada-001": {
        "max_tokens": 2049,
        "input_cost_per_token": 0.0000004,
        "output_cost_per_token": 0.0000004,
        "litellm_provider": "text-completion-openai",
        "mode": "completion"
    },
    "babbage-002": {
        "max_tokens": 16384,
        "input_cost_per_token": 0.0000004,
        "output_cost_per_token": 0.0000004,
        "litellm_provider": "text-completion-openai",
        "mode": "completion"
    },
    "davinci-002": {
        "max_tokens": 16384,
        "input_cost_per_token": 0.000002,
        "output_cost_per_token": 0.000002,
        "litellm_provider": "text-completion-openai",
        "mode": "completion"
    },    
    "gpt-3.5-turbo-instruct": {
        "max_tokens": 8192,
        "input_cost_per_token": 0.0000015,
        "output_cost_per_token": 0.000002,
        "litellm_provider": "text-completion-openai",
        "mode": "completion"
    },
    "claude-instant-1": {
        "max_tokens": 100000,
        "input_cost_per_token": 0.00000163,
        "output_cost_per_token": 0.00000551,
        "litellm_provider": "anthropic",
        "mode": "chat"
    },
    "claude-instant-1.2": {
        "max_tokens": 100000,
        "input_cost_per_token": 0.00000163,
        "output_cost_per_token": 0.00000551,
        "litellm_provider": "anthropic",
        "mode": "chat"
    },
    "claude-2": {
        "max_tokens": 100000,
        "input_cost_per_token": 0.00001102,
        "output_cost_per_token": 0.00003268,
        "litellm_provider": "anthropic",
        "mode": "chat"
    },
    "text-bison": {
        "max_tokens": 8192,
        "input_cost_per_token": 0.000000125,
        "output_cost_per_token": 0.000000125,
        "litellm_provider": "vertex_ai-text-models",
        "mode": "completion"
    },
    "text-bison@001": {
        "max_tokens": 8192,
        "input_cost_per_token": 0.000000125,
        "output_cost_per_token": 0.000000125,
        "litellm_provider": "vertex_ai-text-models",
        "mode": "completion"
    },
    "chat-bison": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.000000125,
        "output_cost_per_token": 0.000000125,
        "litellm_provider": "vertex_ai-chat-models",
        "mode": "chat"
    },
    "chat-bison@001": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.000000125,
        "output_cost_per_token": 0.000000125,
        "litellm_provider": "vertex_ai-chat-models",
        "mode": "chat"
    },
    "chat-bison-32k": {
        "max_tokens": 32000,
        "input_cost_per_token": 0.000000125,
        "output_cost_per_token": 0.000000125,
        "litellm_provider": "vertex_ai-chat-models",
        "mode": "chat"
    },
    "code-bison": {
        "max_tokens": 6144,
        "input_cost_per_token": 0.000000125,
        "output_cost_per_token": 0.000000125,
        "litellm_provider": "vertex_ai-code-text-models",
        "mode": "chat"
    },
    "code-bison@001": {
        "max_tokens": 6144,
        "input_cost_per_token": 0.000000125,
        "output_cost_per_token": 0.000000125,
        "litellm_provider": "vertex_ai-code-text-models",
        "mode": "completion"
    },
    "code-gecko@001": {
        "max_tokens": 2048,
        "input_cost_per_token": 0.000000125,
        "output_cost_per_token": 0.000000125,
        "litellm_provider": "vertex_ai-chat-models",
        "mode": "completion"
    },
    "code-gecko@latest": {
        "max_tokens": 2048,
        "input_cost_per_token": 0.000000125,
        "output_cost_per_token": 0.000000125,
        "litellm_provider": "vertex_ai-chat-models",
        "mode": "completion"
    },
    "codechat-bison": {
        "max_tokens": 6144,
        "input_cost_per_token": 0.000000125,
        "output_cost_per_token": 0.000000125,
        "litellm_provider": "vertex_ai-code-chat-models",
        "mode": "chat"
    },
    "codechat-bison@001": {
        "max_tokens": 6144,
        "input_cost_per_token": 0.000000125,
        "output_cost_per_token": 0.000000125,
        "litellm_provider": "vertex_ai-code-chat-models",
        "mode": "chat"
    },
    "codechat-bison-32k": {
        "max_tokens": 32000,
        "input_cost_per_token": 0.000000125,
        "output_cost_per_token": 0.000000125,
        "litellm_provider": "vertex_ai-chat-models",
        "mode": "chat"
    },
    "command-nightly": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.000015,
        "output_cost_per_token": 0.000015,
        "litellm_provider": "cohere",
        "mode": "completion"
    },
     "command": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.000015,
        "output_cost_per_token": 0.000015,
        "litellm_provider": "cohere",
        "mode": "completion"
    },
     "command-light": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.000015,
        "output_cost_per_token": 0.000015,
        "litellm_provider": "cohere",
        "mode": "completion"
    },
     "command-medium-beta": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.000015,
        "output_cost_per_token": 0.000015,
        "litellm_provider": "cohere",
        "mode": "completion"
    },
     "command-xlarge-beta": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.000015,
        "output_cost_per_token": 0.000015,
        "litellm_provider": "cohere",
        "mode": "completion"
    },
    "replicate/llama-2-70b-chat:2c1608e18606fad2812020dc541930f2d0495ce32eee50074220b87300bc16e1": {
        "max_tokens": 4096,
        "litellm_provider": "replicate",
        "mode": "chat"
    },
    "openrouter/openai/gpt-3.5-turbo": {
        "max_tokens": 4095,
        "input_cost_per_token": 0.0000015,
        "output_cost_per_token": 0.000002,
        "litellm_provider": "openrouter",
        "mode": "chat"
    },
    "openrouter/openai/gpt-3.5-turbo-16k": {
        "max_tokens": 16383,
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000004,
        "litellm_provider": "openrouter",
        "mode": "chat"
    },
    "openrouter/openai/gpt-4": {
        "max_tokens": 8192,
        "input_cost_per_token": 0.00003,
        "output_cost_per_token": 0.00006,
        "litellm_provider": "openrouter",
        "mode": "chat"
    },
    "openrouter/anthropic/claude-instant-v1": {
        "max_tokens": 100000,
        "input_cost_per_token": 0.00000163,
        "output_cost_per_token": 0.00000551,
        "litellm_provider": "openrouter",
        "mode": "chat"
    },
    "openrouter/anthropic/claude-2": {
        "max_tokens": 100000,
        "input_cost_per_token": 0.00001102,
        "output_cost_per_token": 0.00003268,
        "litellm_provider": "openrouter",
        "mode": "chat"
    },
    "openrouter/google/palm-2-chat-bison": {
        "max_tokens": 8000,
        "input_cost_per_token": 0.0000005,
        "output_cost_per_token": 0.0000005,
        "litellm_provider": "openrouter",
        "mode": "chat"
    },
    "openrouter/google/palm-2-codechat-bison": {
        "max_tokens": 8000,
        "input_cost_per_token": 0.0000005,
        "output_cost_per_token": 0.0000005,
        "litellm_provider": "openrouter",
        "mode": "chat"
    },
    "openrouter/meta-llama/llama-2-13b-chat": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.0000002,
        "output_cost_per_token": 0.0000002,
        "litellm_provider": "openrouter",
        "mode": "chat"
    },
    "openrouter/meta-llama/llama-2-70b-chat": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.0000015,
        "output_cost_per_token": 0.0000015,
        "litellm_provider": "openrouter",
        "mode": "chat"
    },
    "openrouter/meta-llama/codellama-34b-instruct": {
        "max_tokens": 8096,
        "input_cost_per_token": 0.0000005,
        "output_cost_per_token": 0.0000005,
        "litellm_provider": "openrouter",
        "mode": "chat"
    },
    "openrouter/nousresearch/nous-hermes-llama2-13b": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.0000002,
        "output_cost_per_token": 0.0000002,
        "litellm_provider": "openrouter",
        "mode": "chat"
    },
    "openrouter/mancer/weaver": {
        "max_tokens": 8000,
        "input_cost_per_token": 0.000005625,
        "output_cost_per_token": 0.000005625,
        "litellm_provider": "openrouter",
        "mode": "chat"
    },
    "openrouter/gryphe/mythomax-l2-13b": {
        "max_tokens": 8192,
        "input_cost_per_token": 0.000001875,
        "output_cost_per_token": 0.000001875,
        "litellm_provider": "openrouter",
        "mode": "chat"
    },
    "openrouter/jondurbin/airoboros-l2-70b-2.1": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.000013875,
        "output_cost_per_token": 0.000013875,
        "litellm_provider": "openrouter",
        "mode": "chat"
    },
    "openrouter/undi95/remm-slerp-l2-13b": {
        "max_tokens": 6144,
        "input_cost_per_token": 0.000001875,
        "output_cost_per_token": 0.000001875,
        "litellm_provider": "openrouter",
        "mode": "chat"
    },
    "openrouter/pygmalionai/mythalion-13b": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.000001875,
        "output_cost_per_token": 0.000001875,
        "litellm_provider": "openrouter",
        "mode": "chat"
    },
    "openrouter/mistralai/mistral-7b-instruct": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "openrouter",
        "mode": "chat"
    },
    "j2-ultra": {
        "max_tokens": 8192,
        "input_cost_per_token": 0.000015,
        "output_cost_per_token": 0.000015,
        "litellm_provider": "ai21",
        "mode": "completion"
    },
    "j2-mid": {
        "max_tokens": 8192,
        "input_cost_per_token": 0.00001,
        "output_cost_per_token": 0.00001,
        "litellm_provider": "ai21",
        "mode": "completion"
    },
    "j2-light": {
        "max_tokens": 8192,
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000003,
        "litellm_provider": "ai21",
        "mode": "completion"
    },
    "dolphin": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.00002,
        "output_cost_per_token": 0.00002,
        "litellm_provider": "nlp_cloud",
        "mode": "completion"
    },
    "chatdolphin": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.00002,
        "output_cost_per_token": 0.00002,
        "litellm_provider": "nlp_cloud",
        "mode": "chat"
    },
    "luminous-base": {
        "max_tokens": 2048, 
        "input_cost_per_token": 0.00003,
        "output_cost_per_token": 0.000033,
        "litellm_provider": "aleph_alpha",
        "mode": "completion"
    },
    "luminous-base-control": {
        "max_tokens": 2048, 
        "input_cost_per_token": 0.0000375,
        "output_cost_per_token": 0.00004125,
        "litellm_provider": "aleph_alpha",
        "mode": "chat"
    },
    "luminous-extended": {
        "max_tokens": 2048, 
        "input_cost_per_token": 0.000045,
        "output_cost_per_token": 0.0000495,
        "litellm_provider": "aleph_alpha",
        "mode": "completion"
    },
    "luminous-extended-control": {
        "max_tokens": 2048, 
        "input_cost_per_token": 0.00005625,
        "output_cost_per_token": 0.000061875,
        "litellm_provider": "aleph_alpha",
        "mode": "chat"
    },
    "luminous-supreme": {
        "max_tokens": 2048, 
        "input_cost_per_token": 0.000175,
        "output_cost_per_token": 0.0001925,
        "litellm_provider": "aleph_alpha",
        "mode": "completion"
    },
    "luminous-supreme-control": {
        "max_tokens": 2048, 
        "input_cost_per_token": 0.00021875,
        "output_cost_per_token": 0.000240625,
        "litellm_provider": "aleph_alpha",
        "mode": "chat"
    },
    "ai21.j2-mid-v1": {
        "max_tokens": 8191, 
        "input_cost_per_token": 0.0000125,
        "output_cost_per_token": 0.0000125,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "ai21.j2-ultra-v1": {
        "max_tokens": 8191, 
        "input_cost_per_token": 0.0000188,
        "output_cost_per_token": 0.0000188,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "amazon.titan-text-lite-v1": {
        "max_tokens": 8000, 
        "input_cost_per_token": 0.0000003,
        "output_cost_per_token": 0.0000004,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "amazon.titan-text-express-v1": {
        "max_tokens": 8000, 
        "input_cost_per_token": 0.0000013,
        "output_cost_per_token": 0.0000017,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "anthropic.claude-v1": {
        "max_tokens": 100000, 
        "input_cost_per_token": 0.00001102,
        "output_cost_per_token": 0.00003268,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "anthropic.claude-v2": {
        "max_tokens": 100000, 
        "input_cost_per_token": 0.00001102,
        "output_cost_per_token": 0.00003268,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "anthropic.claude-instant-v1": {
        "max_tokens": 100000, 
        "input_cost_per_token": 0.00000163,
        "output_cost_per_token": 0.00000551,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "cohere.command-text-v14": {
        "max_tokens": 4096, 
        "input_cost_per_token": 0.0000015,
        "output_cost_per_token": 0.0000020,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "meta.llama2-13b-chat-v1": {
        "max_tokens": 4096, 
        "input_cost_per_token": 0.00000075,
        "output_cost_per_token": 0.000001,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "together-ai-up-to-3b": {
        "input_cost_per_token": 0.0000001,
        "output_cost_per_token": 0.0000001
    },
    "together-ai-3.1b-7b": {
        "input_cost_per_token": 0.0000002,
        "output_cost_per_token": 0.0000002
    },
    "together-ai-7.1b-20b": {
        "max_tokens": 1000,
        "input_cost_per_token": 0.0000004,
        "output_cost_per_token": 0.0000004
    },
    "together-ai-20.1b-40b": {
        "input_cost_per_token": 0.000001,
        "output_cost_per_token": 0.000001
    },
    "together-ai-40.1b-70b": {
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000003
    },
    "ollama/llama2": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "mode": "completion"
    },
    "ollama/llama2:13b": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "mode": "completion"
    },
    "ollama/llama2:70b": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "mode": "completion"
    },
    "ollama/llama2-uncensored": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "ollama",
        "mode": "completion"
    },
    "deepinfra/meta-llama/Llama-2-70b-chat-hf": {
        "max_tokens": 6144,
        "input_cost_per_token": 0.000001875,
        "output_cost_per_token": 0.000001875,
        "litellm_provider": "deepinfra",
        "mode": "chat"
    },
    "deepinfra/codellama/CodeLlama-34b-Instruct-hf": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.0000006,
        "output_cost_per_token": 0.0000006,
        "litellm_provider": "deepinfra",
        "mode": "chat"
      },
      "deepinfra/meta-llama/Llama-2-13b-chat-hf": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.00000035,
        "output_cost_per_token": 0.00000035,
        "litellm_provider": "deepinfra",
        "mode": "chat"
      },
      "deepinfra/meta-llama/Llama-2-7b-chat-hf": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.0000002,
        "output_cost_per_token": 0.0000002,
        "litellm_provider": "deepinfra",
        "mode": "chat"
      },
      "deepinfra/mistralai/Mistral-7B-Instruct-v0.1": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.0000002,
        "output_cost_per_token": 0.0000002,
        "litellm_provider": "deepinfra",
        "mode": "chat"
      },
      "deepinfra/jondurbin/airoboros-l2-70b-gpt4-1.4.1": {
        "max_tokens": 4096,
        "input_cost_per_token": 0.0000007,
        "output_cost_per_token": 0.00000095,
        "litellm_provider": "deepinfra",
        "mode": "chat"
      }
}
