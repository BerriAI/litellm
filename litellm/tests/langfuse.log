`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
Creating trace id='22019f81-81fc-4b65-8ab3-e141f6625ac9' timestamp=datetime.datetime(2024, 7, 7, 0, 49, 49, 2109, tzinfo=datetime.timezone.utc) name='litellm-acompletion' user_id='langfuse_latency_test_user' input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': "It's simple to use and easy to get started", 'role': 'assistant'} session_id=None release=None version=None metadata=None tags=[] public=None
Creating generation trace_id='22019f81-81fc-4b65-8ab3-e141f6625ac9' name='litellm-acompletion' start_time=datetime.datetime(2024, 7, 6, 17, 49, 48, 998308) metadata={'litellm_response_cost': None, 'cache_hit': False} input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': "It's simple to use and easy to get started", 'role': 'assistant'} level=<ObservationLevel.DEFAULT: 'DEFAULT'> status_message=None parent_observation_id=None version=None id='time-17-49-48-998308_chatcmpl-4fc2302c-b7e4-4703-b716-cd01a3d0b322' end_time=datetime.datetime(2024, 7, 6, 17, 49, 49, 719) completion_start_time=datetime.datetime(2024, 7, 6, 17, 49, 49, 719) model='chatgpt-v-2' model_parameters={'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'} usage=Usage(input=10, output=20, total=None, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None) prompt_name=None prompt_version=None...
item size 459
item size 887
Creating trace id='4e3773e6-037a-43e5-825d-b712babc0daf' timestamp=datetime.datetime(2024, 7, 7, 0, 49, 49, 3537, tzinfo=datetime.timezone.utc) name='litellm-acompletion' user_id='langfuse_latency_test_user' input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': "It's simple to use and easy to get started", 'role': 'assistant'} session_id=None release=None version=None metadata=None tags=[] public=None
Creating trace id='bf11b810-c475-4a96-b0ec-a581321a44af' timestamp=datetime.datetime(2024, 7, 7, 0, 49, 49, 3618, tzinfo=datetime.timezone.utc) name='litellm-acompletion' user_id='langfuse_latency_test_user' input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': "It's simple to use and easy to get started", 'role': 'assistant'} session_id=None release=None version=None metadata=None tags=[] public=None
Creating generation trace_id='bf11b810-c475-4a96-b0ec-a581321a44af' name='litellm-acompletion' start_time=datetime.datetime(2024, 7, 6, 17, 49, 48, 998866) metadata={'litellm_response_cost': None, 'cache_hit': False} input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': "It's simple to use and easy to get started", 'role': 'assistant'} level=<ObservationLevel.DEFAULT: 'DEFAULT'> status_message=None parent_observation_id=None version=None id='time-17-49-48-998866_chatcmpl-71dc0d36-7dfa-48af-ba45-613c2a31a6ae' end_time=datetime.datetime(2024, 7, 6, 17, 49, 49, 1253) completion_start_time=datetime.datetime(2024, 7, 6, 17, 49, 49, 1253) model='chatgpt-v-2' model_parameters={'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'} usage=Usage(input=10, output=20, total=None, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None) prompt_name=None prompt_version=None...
item size 459
Creating generation trace_id='4e3773e6-037a-43e5-825d-b712babc0daf' name='litellm-acompletion' start_time=datetime.datetime(2024, 7, 6, 17, 49, 48, 999544) metadata={'litellm_response_cost': None, 'cache_hit': False} input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': "It's simple to use and easy to get started", 'role': 'assistant'} level=<ObservationLevel.DEFAULT: 'DEFAULT'> status_message=None parent_observation_id=None version=None id='time-17-49-48-999544_chatcmpl-d61b3ab9-3b9d-4913-afa5-e84420c90ac5' end_time=datetime.datetime(2024, 7, 6, 17, 49, 49, 1850) completion_start_time=datetime.datetime(2024, 7, 6, 17, 49, 49, 1850) model='chatgpt-v-2' model_parameters={'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'} usage=Usage(input=10, output=20, total=None, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None) prompt_name=None prompt_version=None...
item size 459
item size 887
item size 887
Creating trace id='4a8fa429-f08d-4f6b-b3ca-9a404d7c61fa' timestamp=datetime.datetime(2024, 7, 7, 0, 49, 49, 5826, tzinfo=datetime.timezone.utc) name='litellm-acompletion' user_id='langfuse_latency_test_user' input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': "It's simple to use and easy to get started", 'role': 'assistant'} session_id=None release=None version=None metadata=None tags=[] public=None
Creating generation trace_id='4a8fa429-f08d-4f6b-b3ca-9a404d7c61fa' name='litellm-acompletion' start_time=datetime.datetime(2024, 7, 6, 17, 49, 48, 999955) metadata={'litellm_response_cost': None, 'cache_hit': False} input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': "It's simple to use and easy to get started", 'role': 'assistant'} level=<ObservationLevel.DEFAULT: 'DEFAULT'> status_message=None parent_observation_id=None version=None id='time-17-49-48-999955_chatcmpl-f1c470f6-2f80-4d4a-89a4-4a013bae4085' end_time=datetime.datetime(2024, 7, 6, 17, 49, 49, 5114) completion_start_time=datetime.datetime(2024, 7, 6, 17, 49, 49, 5114) model='chatgpt-v-2' model_parameters={'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'} usage=Usage(input=10, output=20, total=None, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None) prompt_name=None prompt_version=None...
item size 459
item size 887
Creating trace id='8da0e9ce-8b13-4b4d-9f0d-daa3d5e0afc0' timestamp=datetime.datetime(2024, 7, 7, 0, 49, 49, 6797, tzinfo=datetime.timezone.utc) name='litellm-acompletion' user_id='langfuse_latency_test_user' input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': "It's simple to use and easy to get started", 'role': 'assistant'} session_id=None release=None version=None metadata=None tags=[] public=None
Creating generation trace_id='8da0e9ce-8b13-4b4d-9f0d-daa3d5e0afc0' name='litellm-acompletion' start_time=datetime.datetime(2024, 7, 6, 17, 49, 49, 372) metadata={'litellm_response_cost': None, 'cache_hit': False} input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': "It's simple to use and easy to get started", 'role': 'assistant'} level=<ObservationLevel.DEFAULT: 'DEFAULT'> status_message=None parent_observation_id=None version=None id='time-17-49-49-000372_chatcmpl-f2672341-93c9-4fec-bccb-665a1df53ce5' end_time=datetime.datetime(2024, 7, 6, 17, 49, 49, 5904) completion_start_time=datetime.datetime(2024, 7, 6, 17, 49, 49, 5904) model='chatgpt-v-2' model_parameters={'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'} usage=Usage(input=10, output=20, total=None, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None) prompt_name=None prompt_version=None...
item size 459
item size 887
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
~0 items in the Langfuse queue
uploading batch of 10 items
uploading data: {'batch': [{'id': '8709b135-ff1a-454b-8e77-9c16c2ae590b', 'type': 'trace-create', 'body': {'id': '22019f81-81fc-4b65-8ab3-e141f6625ac9', 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 49, 2109, tzinfo=datetime.timezone.utc), 'name': 'litellm-acompletion', 'userId': 'langfuse_latency_test_user', 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': "It's simple to use and easy to get started", 'role': 'assistant'}, 'tags': []}, 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 49, 2578, tzinfo=datetime.timezone.utc)}, {'id': 'ffc73bd8-2f00-496e-8566-eaa4b67b1f2b', 'type': 'generation-create', 'body': {'traceId': '22019f81-81fc-4b65-8ab3-e141f6625ac9', 'name': 'litellm-acompletion', 'startTime': datetime.datetime(2024, 7, 6, 17, 49, 48, 998308), 'metadata': {'litellm_response_cost': None, 'cache_hit': False}, 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': "It's simple to use and easy to get started", 'role': 'assistant'}, 'level': <ObservationLevel.DEFAULT: 'DEFAULT'>, 'id': 'time-17-49-48-998308_chatcmpl-4fc2302c-b7e4-4703-b716-cd01a3d0b322', 'endTime': datetime.datetime(2024, 7, 6, 17, 49, 49, 719), 'completionStartTime': datetime.datetime(2024, 7, 6, 17, 49, 49, 719), 'model': 'chatgpt-v-2', 'modelParameters': {'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'}, 'usage': {'input': 10, 'output': 20, 'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>}}, 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 49, 2939, tzinfo=datetime.timezone.utc)}, {'id': '446c9edc-59e2-4805-946b-acdc25feb203', 'type': 'trace-create', 'body': {'id': 'bf11b810-c475-4a96-b0ec-a581321a44af', 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 49, 3618, tzinfo=datetime.timezone.utc), 'name': 'litellm-acompletion', 'userId': 'langfuse_latency_test_user', 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': "It's simple to use and easy to get started", 'role': 'assistant'}, 'tags': []}, 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 49, 3813, tzinfo=datetime.timezone.utc)}, {'id': '52a24782-ba7a-4bdf-9ae5-c79a5f4a8683', 'type': 'trace-create', 'body': {'id': '4e3773e6-037a-43e5-825d-b712babc0daf', 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 49, 3537, tzinfo=datetime.timezone.utc), 'name': 'litellm-acompletion', 'userId': 'langfuse_latency_test_user', 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': "It's simple to use and easy to get started", 'role': 'assistant'}, 'tags': []}, 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 49, 4113, tzinfo=datetime.timezone.utc)}, {'id': 'cce474cc-8881-4b76-8e33-64fcfb3333a5', 'type': 'generation-create', 'body': {'traceId': 'bf11b810-c475-4a96-b0ec-a581321a44af', 'name': 'litellm-acompletion', 'startTime': datetime.datetime(2024, 7, 6, 17, 49, 48, 998866), 'metadata': {'litellm_response_cost': None, 'cache_hit': False}, 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': "It's simple to use and easy to get started", 'role': 'assistant'}, 'level': <ObservationLevel.DEFAULT: 'DEFAULT'>, 'id': 'time-17-49-48-998866_chatcmpl-71dc0d36-7dfa-48af-ba45-613c2a31a6ae', 'endTime': datetime.datetime(2024, 7, 6, 17, 49, 49, 1253), 'completionStartTime': datetime.datetime(2024, 7, 6, 17, 49, 49, 1253), 'model': 'chatgpt-v-2', 'modelParameters': {'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'}, 'usage': {'input': 10, 'output': 20, 'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>}}, 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 49, 4357, tzinfo=datetime.timezone.utc)}, {'id': 'b688cd33-a978-459b-9bee-330c1ea3dc07', 'type': 'generation-create', 'body': {'traceId': '4e3773e6-037a-43e5-825d-b712babc0daf', 'name': 'litellm-acompletion', 'startTime': datetime.datetime(2024, 7, 6, 17, 49, 48, 999544), 'metadata': {'litellm_response_cost': None, 'cache_hit': False}, 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': "It's simple to use and easy to get started", 'role': 'assistant'}, 'level': <ObservationLevel.DEFAULT: 'DEFAULT'>, 'id': 'time-17-49-48-999544_chatcmpl-d61b3ab9-3b9d-4913-afa5-e84420c90ac5', 'endTime': datetime.datetime(2024, 7, 6, 17, 49, 49, 1850), 'completionStartTime': datetime.datetime(2024, 7, 6, 17, 49, 49, 1850), 'model': 'chatgpt-v-2', 'modelParameters': {'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'}, 'usage': {'input': 10, 'output': 20, 'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>}}, 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 49, 4708, tzinfo=datetime.timezone.utc)}, {'id': '9142c397-6a65-43a4-b4e2-4f24df372f46', 'type': 'trace-create', 'body': {'id': '4a8fa429-f08d-4f6b-b3ca-9a404d7c61fa', 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 49, 5826, tzinfo=datetime.timezone.utc), 'name': 'litellm-acompletion', 'userId': 'langfuse_latency_test_user', 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': "It's simple to use and easy to get started", 'role': 'assistant'}, 'tags': []}, 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 49, 6019, tzinfo=datetime.timezone.utc)}, {'id': '58990902-d78f-4e3c-ab93-806502bc273d', 'type': 'generation-create', 'body': {'traceId': '4a8fa429-f08d-4f6b-b3ca-9a404d7c61fa', 'name': 'litellm-acompletion', 'startTime': datetime.datetime(2024, 7, 6, 17, 49, 48, 999955), 'metadata': {'litellm_response_cost': None, 'cache_hit': False}, 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': "It's simple to use and easy to get started", 'role': 'assistant'}, 'level': <ObservationLevel.DEFAULT: 'DEFAULT'>, 'id': 'time-17-49-48-999955_chatcmpl-f1c470f6-2f80-4d4a-89a4-4a013bae4085', 'endTime': datetime.datetime(2024, 7, 6, 17, 49, 49, 5114), 'completionStartTime': datetime.datetime(2024, 7, 6, 17, 49, 49, 5114), 'model': 'chatgpt-v-2', 'modelParameters': {'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'}, 'usage': {'input': 10, 'output': 20, 'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>}}, 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 49, 6245, tzinfo=datetime.timezone.utc)}, {'id': 'f7dccb63-fb83-4523-81dd-dc218e482a0e', 'type': 'trace-create', 'body': {'id': '8da0e9ce-8b13-4b4d-9f0d-daa3d5e0afc0', 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 49, 6797, tzinfo=datetime.timezone.utc), 'name': 'litellm-acompletion', 'userId': 'langfuse_latency_test_user', 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': "It's simple to use and easy to get started", 'role': 'assistant'}, 'tags': []}, 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 49, 6918, tzinfo=datetime.timezone.utc)}, {'id': '89095577-def6-40c2-93f5-c073d3772dd8', 'type': 'generation-create', 'body': {'traceId': '8da0e9ce-8b13-4b4d-9f0d-daa3d5e0afc0', 'name': 'litellm-acompletion', 'startTime': datetime.datetime(2024, 7, 6, 17, 49, 49, 372), 'metadata': {'litellm_response_cost': None, 'cache_hit': False}, 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': "It's simple to use and easy to get started", 'role': 'assistant'}, 'level': <ObservationLevel.DEFAULT: 'DEFAULT'>, 'id': 'time-17-49-49-000372_chatcmpl-f2672341-93c9-4fec-bccb-665a1df53ce5', 'endTime': datetime.datetime(2024, 7, 6, 17, 49, 49, 5904), 'completionStartTime': datetime.datetime(2024, 7, 6, 17, 49, 49, 5904), 'model': 'chatgpt-v-2', 'modelParameters': {'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'}, 'usage': {'input': 10, 'output': 20, 'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>}}, 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 49, 7234, tzinfo=datetime.timezone.utc)}], 'metadata': {'batch_size': 10, 'sdk_integration': 'default', 'sdk_name': 'python', 'sdk_version': '2.32.0', 'public_key': 'pk-lf-b3db7e8e-c2f6-4fc7-825c-a541a8fbe003'}}
making request: {"batch": [{"id": "8709b135-ff1a-454b-8e77-9c16c2ae590b", "type": "trace-create", "body": {"id": "22019f81-81fc-4b65-8ab3-e141f6625ac9", "timestamp": "2024-07-07T00:49:49.002109Z", "name": "litellm-acompletion", "userId": "langfuse_latency_test_user", "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "It's simple to use and easy to get started", "role": "assistant"}, "tags": []}, "timestamp": "2024-07-07T00:49:49.002578Z"}, {"id": "ffc73bd8-2f00-496e-8566-eaa4b67b1f2b", "type": "generation-create", "body": {"traceId": "22019f81-81fc-4b65-8ab3-e141f6625ac9", "name": "litellm-acompletion", "startTime": "2024-07-06T17:49:48.998308-07:00", "metadata": {"litellm_response_cost": null, "cache_hit": false}, "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "It's simple to use and easy to get started", "role": "assistant"}, "level": "DEFAULT", "id": "time-17-49-48-998308_chatcmpl-4fc2302c-b7e4-4703-b716-cd01a3d0b322", "endTime": "2024-07-06T17:49:49.000719-07:00", "completionStartTime": "2024-07-06T17:49:49.000719-07:00", "model": "chatgpt-v-2", "modelParameters": {"temperature": "0.7", "max_tokens": 5, "user": "langfuse_latency_test_user", "extra_body": "{}"}, "usage": {"input": 10, "output": 20, "unit": "TOKENS"}}, "timestamp": "2024-07-07T00:49:49.002939Z"}, {"id": "446c9edc-59e2-4805-946b-acdc25feb203", "type": "trace-create", "body": {"id": "bf11b810-c475-4a96-b0ec-a581321a44af", "timestamp": "2024-07-07T00:49:49.003618Z", "name": "litellm-acompletion", "userId": "langfuse_latency_test_user", "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "It's simple to use and easy to get started", "role": "assistant"}, "tags": []}, "timestamp": "2024-07-07T00:49:49.003813Z"}, {"id": "52a24782-ba7a-4bdf-9ae5-c79a5f4a8683", "type": "trace-create", "body": {"id": "4e3773e6-037a-43e5-825d-b712babc0daf", "timestamp": "2024-07-07T00:49:49.003537Z", "name": "litellm-acompletion", "userId": "langfuse_latency_test_user", "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "It's simple to use and easy to get started", "role": "assistant"}, "tags": []}, "timestamp": "2024-07-07T00:49:49.004113Z"}, {"id": "cce474cc-8881-4b76-8e33-64fcfb3333a5", "type": "generation-create", "body": {"traceId": "bf11b810-c475-4a96-b0ec-a581321a44af", "name": "litellm-acompletion", "startTime": "2024-07-06T17:49:48.998866-07:00", "metadata": {"litellm_response_cost": null, "cache_hit": false}, "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "It's simple to use and easy to get started", "role": "assistant"}, "level": "DEFAULT", "id": "time-17-49-48-998866_chatcmpl-71dc0d36-7dfa-48af-ba45-613c2a31a6ae", "endTime": "2024-07-06T17:49:49.001253-07:00", "completionStartTime": "2024-07-06T17:49:49.001253-07:00", "model": "chatgpt-v-2", "modelParameters": {"temperature": "0.7", "max_tokens": 5, "user": "langfuse_latency_test_user", "extra_body": "{}"}, "usage": {"input": 10, "output": 20, "unit": "TOKENS"}}, "timestamp": "2024-07-07T00:49:49.004357Z"}, {"id": "b688cd33-a978-459b-9bee-330c1ea3dc07", "type": "generation-create", "body": {"traceId": "4e3773e6-037a-43e5-825d-b712babc0daf", "name": "litellm-acompletion", "startTime": "2024-07-06T17:49:48.999544-07:00", "metadata": {"litellm_response_cost": null, "cache_hit": false}, "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "It's simple to use and easy to get started", "role": "assistant"}, "level": "DEFAULT", "id": "time-17-49-48-999544_chatcmpl-d61b3ab9-3b9d-4913-afa5-e84420c90ac5", "endTime": "2024-07-06T17:49:49.001850-07:00", "completionStartTime": "2024-07-06T17:49:49.001850-07:00", "model": "chatgpt-v-2", "modelParameters": {"temperature": "0.7", "max_tokens": 5, "user": "langfuse_latency_test_user", "extra_body": "{}"}, "usage": {"input": 10, "output": 20, "unit": "TOKENS"}}, "timestamp": "2024-07-07T00:49:49.004708Z"}, {"id": "9142c397-6a65-43a4-b4e2-4f24df372f46", "type": "trace-create", "body": {"id": "4a8fa429-f08d-4f6b-b3ca-9a404d7c61fa", "timestamp": "2024-07-07T00:49:49.005826Z", "name": "litellm-acompletion", "userId": "langfuse_latency_test_user", "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "It's simple to use and easy to get started", "role": "assistant"}, "tags": []}, "timestamp": "2024-07-07T00:49:49.006019Z"}, {"id": "58990902-d78f-4e3c-ab93-806502bc273d", "type": "generation-create", "body": {"traceId": "4a8fa429-f08d-4f6b-b3ca-9a404d7c61fa", "name": "litellm-acompletion", "startTime": "2024-07-06T17:49:48.999955-07:00", "metadata": {"litellm_response_cost": null, "cache_hit": false}, "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "It's simple to use and easy to get started", "role": "assistant"}, "level": "DEFAULT", "id": "time-17-49-48-999955_chatcmpl-f1c470f6-2f80-4d4a-89a4-4a013bae4085", "endTime": "2024-07-06T17:49:49.005114-07:00", "completionStartTime": "2024-07-06T17:49:49.005114-07:00", "model": "chatgpt-v-2", "modelParameters": {"temperature": "0.7", "max_tokens": 5, "user": "langfuse_latency_test_user", "extra_body": "{}"}, "usage": {"input": 10, "output": 20, "unit": "TOKENS"}}, "timestamp": "2024-07-07T00:49:49.006245Z"}, {"id": "f7dccb63-fb83-4523-81dd-dc218e482a0e", "type": "trace-create", "body": {"id": "8da0e9ce-8b13-4b4d-9f0d-daa3d5e0afc0", "timestamp": "2024-07-07T00:49:49.006797Z", "name": "litellm-acompletion", "userId": "langfuse_latency_test_user", "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "It's simple to use and easy to get started", "role": "assistant"}, "tags": []}, "timestamp": "2024-07-07T00:49:49.006918Z"}, {"id": "89095577-def6-40c2-93f5-c073d3772dd8", "type": "generation-create", "body": {"traceId": "8da0e9ce-8b13-4b4d-9f0d-daa3d5e0afc0", "name": "litellm-acompletion", "startTime": "2024-07-06T17:49:49.000372-07:00", "metadata": {"litellm_response_cost": null, "cache_hit": false}, "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "It's simple to use and easy to get started", "role": "assistant"}, "level": "DEFAULT", "id": "time-17-49-49-000372_chatcmpl-f2672341-93c9-4fec-bccb-665a1df53ce5", "endTime": "2024-07-06T17:49:49.005904-07:00", "completionStartTime": "2024-07-06T17:49:49.005904-07:00", "model": "chatgpt-v-2", "modelParameters": {"temperature": "0.7", "max_tokens": 5, "user": "langfuse_latency_test_user", "extra_body": "{}"}, "usage": {"input": 10, "output": 20, "unit": "TOKENS"}}, "timestamp": "2024-07-07T00:49:49.007234Z"}], "metadata": {"batch_size": 10, "sdk_integration": "default", "sdk_name": "python", "sdk_version": "2.32.0", "public_key": "pk-lf-b3db7e8e-c2f6-4fc7-825c-a541a8fbe003"}} to https://us.cloud.langfuse.com/api/public/ingestion
received response: {"errors":[],"successes":[{"id":"8709b135-ff1a-454b-8e77-9c16c2ae590b","status":201},{"id":"ffc73bd8-2f00-496e-8566-eaa4b67b1f2b","status":201},{"id":"446c9edc-59e2-4805-946b-acdc25feb203","status":201},{"id":"52a24782-ba7a-4bdf-9ae5-c79a5f4a8683","status":201},{"id":"cce474cc-8881-4b76-8e33-64fcfb3333a5","status":201},{"id":"b688cd33-a978-459b-9bee-330c1ea3dc07","status":201},{"id":"9142c397-6a65-43a4-b4e2-4f24df372f46","status":201},{"id":"58990902-d78f-4e3c-ab93-806502bc273d","status":201},{"id":"f7dccb63-fb83-4523-81dd-dc218e482a0e","status":201},{"id":"89095577-def6-40c2-93f5-c073d3772dd8","status":201}]}
successfully uploaded batch of 10 items
consumer is running...
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
Creating trace id='litellm-test-86452fed-4136-4b1e-8083-803b21511bcc' timestamp=datetime.datetime(2024, 7, 7, 0, 49, 50, 228138, tzinfo=datetime.timezone.utc) name='litellm-acompletion' user_id='langfuse_latency_test_user' input={'messages': [{'role': 'user', 'content': 'redacted-by-litellm'}]} output={'content': 'redacted-by-litellm', 'role': 'assistant'} session_id=None release=None version=None metadata=None tags=[] public=None
Creating generation trace_id='litellm-test-86452fed-4136-4b1e-8083-803b21511bcc' name='litellm-acompletion' start_time=datetime.datetime(2024, 7, 6, 17, 49, 50, 227128) metadata={'litellm_response_cost': 5.4999999999999995e-05, 'cache_hit': False} input={'messages': [{'role': 'user', 'content': 'redacted-by-litellm'}]} output={'content': 'redacted-by-litellm', 'role': 'assistant'} level=<ObservationLevel.DEFAULT: 'DEFAULT'> status_message=None parent_observation_id=None version=None id='time-17-49-50-227128_chatcmpl-14db8e8d-39a5-4b84-a761-572f1ee2c1dd' end_time=datetime.datetime(2024, 7, 6, 17, 49, 50, 227686) completion_start_time=datetime.datetime(2024, 7, 6, 17, 49, 50, 227686) model='gpt-3.5-turbo' model_parameters={'temperature': '0.7', 'stream': False, 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'} usage=Usage(input=10, output=20, total=None, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=5.4999999999999995e-05) prompt_name=None prompt_version=None...
flushing queue
item size 454
successfully flushed about 0 items.
item size 956
~0 items in the Langfuse queue
uploading batch of 2 items
uploading data: {'batch': [{'id': '1d38c06a-12d5-4488-b3d4-5f39621c85ed', 'type': 'trace-create', 'body': {'id': 'litellm-test-86452fed-4136-4b1e-8083-803b21511bcc', 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 50, 228138, tzinfo=datetime.timezone.utc), 'name': 'litellm-acompletion', 'userId': 'langfuse_latency_test_user', 'input': {'messages': [{'role': 'user', 'content': 'redacted-by-litellm'}]}, 'output': {'content': 'redacted-by-litellm', 'role': 'assistant'}, 'tags': []}, 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 50, 228332, tzinfo=datetime.timezone.utc)}, {'id': 'ec542e6b-eee8-471b-bf44-8d89e06ac3f5', 'type': 'generation-create', 'body': {'traceId': 'litellm-test-86452fed-4136-4b1e-8083-803b21511bcc', 'name': 'litellm-acompletion', 'startTime': datetime.datetime(2024, 7, 6, 17, 49, 50, 227128), 'metadata': {'litellm_response_cost': 5.4999999999999995e-05, 'cache_hit': False}, 'input': {'messages': [{'role': 'user', 'content': 'redacted-by-litellm'}]}, 'output': {'content': 'redacted-by-litellm', 'role': 'assistant'}, 'level': <ObservationLevel.DEFAULT: 'DEFAULT'>, 'id': 'time-17-49-50-227128_chatcmpl-14db8e8d-39a5-4b84-a761-572f1ee2c1dd', 'endTime': datetime.datetime(2024, 7, 6, 17, 49, 50, 227686), 'completionStartTime': datetime.datetime(2024, 7, 6, 17, 49, 50, 227686), 'model': 'gpt-3.5-turbo', 'modelParameters': {'temperature': '0.7', 'stream': False, 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'}, 'usage': {'input': 10, 'output': 20, 'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>, 'totalCost': 5.4999999999999995e-05}}, 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 50, 228609, tzinfo=datetime.timezone.utc)}], 'metadata': {'batch_size': 2, 'sdk_integration': 'default', 'sdk_name': 'python', 'sdk_version': '2.32.0', 'public_key': 'pk-lf-b3db7e8e-c2f6-4fc7-825c-a541a8fbe003'}}
making request: {"batch": [{"id": "1d38c06a-12d5-4488-b3d4-5f39621c85ed", "type": "trace-create", "body": {"id": "litellm-test-86452fed-4136-4b1e-8083-803b21511bcc", "timestamp": "2024-07-07T00:49:50.228138Z", "name": "litellm-acompletion", "userId": "langfuse_latency_test_user", "input": {"messages": [{"role": "user", "content": "redacted-by-litellm"}]}, "output": {"content": "redacted-by-litellm", "role": "assistant"}, "tags": []}, "timestamp": "2024-07-07T00:49:50.228332Z"}, {"id": "ec542e6b-eee8-471b-bf44-8d89e06ac3f5", "type": "generation-create", "body": {"traceId": "litellm-test-86452fed-4136-4b1e-8083-803b21511bcc", "name": "litellm-acompletion", "startTime": "2024-07-06T17:49:50.227128-07:00", "metadata": {"litellm_response_cost": 5.4999999999999995e-05, "cache_hit": false}, "input": {"messages": [{"role": "user", "content": "redacted-by-litellm"}]}, "output": {"content": "redacted-by-litellm", "role": "assistant"}, "level": "DEFAULT", "id": "time-17-49-50-227128_chatcmpl-14db8e8d-39a5-4b84-a761-572f1ee2c1dd", "endTime": "2024-07-06T17:49:50.227686-07:00", "completionStartTime": "2024-07-06T17:49:50.227686-07:00", "model": "gpt-3.5-turbo", "modelParameters": {"temperature": "0.7", "stream": false, "max_tokens": 5, "user": "langfuse_latency_test_user", "extra_body": "{}"}, "usage": {"input": 10, "output": 20, "unit": "TOKENS", "totalCost": 5.4999999999999995e-05}}, "timestamp": "2024-07-07T00:49:50.228609Z"}], "metadata": {"batch_size": 2, "sdk_integration": "default", "sdk_name": "python", "sdk_version": "2.32.0", "public_key": "pk-lf-b3db7e8e-c2f6-4fc7-825c-a541a8fbe003"}} to https://us.cloud.langfuse.com/api/public/ingestion
received response: {"errors":[],"successes":[{"id":"1d38c06a-12d5-4488-b3d4-5f39621c85ed","status":201},{"id":"ec542e6b-eee8-471b-bf44-8d89e06ac3f5","status":201}]}
successfully uploaded batch of 2 items
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
Getting observations... None, None, None, None, litellm-test-86452fed-4136-4b1e-8083-803b21511bcc, None, GENERATION
~0 items in the Langfuse queue
consumer is running...
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
flushing queue
successfully flushed about 0 items.
~0 items in the Langfuse queue
~0 items in the Langfuse queue
Creating trace id='litellm-test-8d866db0-0114-48a2-9f24-12a82a7b3db6' timestamp=datetime.datetime(2024, 7, 7, 0, 49, 52, 866371, tzinfo=datetime.timezone.utc) name='litellm-acompletion' user_id='langfuse_latency_test_user' input={'messages': [{'role': 'user', 'content': 'redacted-by-litellm'}]} output={'content': 'redacted-by-litellm', 'role': 'assistant'} session_id=None release=None version=None metadata=None tags=[] public=None
Creating generation trace_id='litellm-test-8d866db0-0114-48a2-9f24-12a82a7b3db6' name='litellm-acompletion' start_time=datetime.datetime(2024, 7, 6, 17, 49, 52, 561285) metadata={'litellm_response_cost': 4.1e-05, 'cache_hit': False} input={'messages': [{'role': 'user', 'content': 'redacted-by-litellm'}]} output={'content': 'redacted-by-litellm', 'role': 'assistant'} level=<ObservationLevel.DEFAULT: 'DEFAULT'> status_message=None parent_observation_id=None version=None id='time-17-49-52-561285_chatcmpl-8079666e-d514-45b8-829f-887b4ae98ec0' end_time=datetime.datetime(2024, 7, 6, 17, 49, 52, 572272) completion_start_time=datetime.datetime(2024, 7, 6, 17, 49, 52, 564390) model='gpt-3.5-turbo' model_parameters={'temperature': '0.7', 'stream': True, 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'} usage=Usage(input=14, output=10, total=None, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=4.1e-05) prompt_name=None prompt_version=None...
item size 454
item size 925
~0 items in the Langfuse queue
~0 items in the Langfuse queue
uploading batch of 2 items
uploading data: {'batch': [{'id': '892fa3ad-9191-4f19-b050-0badbf773160', 'type': 'trace-create', 'body': {'id': 'litellm-test-8d866db0-0114-48a2-9f24-12a82a7b3db6', 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 52, 866371, tzinfo=datetime.timezone.utc), 'name': 'litellm-acompletion', 'userId': 'langfuse_latency_test_user', 'input': {'messages': [{'role': 'user', 'content': 'redacted-by-litellm'}]}, 'output': {'content': 'redacted-by-litellm', 'role': 'assistant'}, 'tags': []}, 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 52, 866977, tzinfo=datetime.timezone.utc)}, {'id': '6abdba0f-7dba-438d-99ac-1c1a9d481d14', 'type': 'generation-create', 'body': {'traceId': 'litellm-test-8d866db0-0114-48a2-9f24-12a82a7b3db6', 'name': 'litellm-acompletion', 'startTime': datetime.datetime(2024, 7, 6, 17, 49, 52, 561285), 'metadata': {'litellm_response_cost': 4.1e-05, 'cache_hit': False}, 'input': {'messages': [{'role': 'user', 'content': 'redacted-by-litellm'}]}, 'output': {'content': 'redacted-by-litellm', 'role': 'assistant'}, 'level': <ObservationLevel.DEFAULT: 'DEFAULT'>, 'id': 'time-17-49-52-561285_chatcmpl-8079666e-d514-45b8-829f-887b4ae98ec0', 'endTime': datetime.datetime(2024, 7, 6, 17, 49, 52, 572272), 'completionStartTime': datetime.datetime(2024, 7, 6, 17, 49, 52, 564390), 'model': 'gpt-3.5-turbo', 'modelParameters': {'temperature': '0.7', 'stream': True, 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'}, 'usage': {'input': 14, 'output': 10, 'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>, 'totalCost': 4.1e-05}}, 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 52, 867926, tzinfo=datetime.timezone.utc)}], 'metadata': {'batch_size': 2, 'sdk_integration': 'default', 'sdk_name': 'python', 'sdk_version': '2.32.0', 'public_key': 'pk-lf-b3db7e8e-c2f6-4fc7-825c-a541a8fbe003'}}
making request: {"batch": [{"id": "892fa3ad-9191-4f19-b050-0badbf773160", "type": "trace-create", "body": {"id": "litellm-test-8d866db0-0114-48a2-9f24-12a82a7b3db6", "timestamp": "2024-07-07T00:49:52.866371Z", "name": "litellm-acompletion", "userId": "langfuse_latency_test_user", "input": {"messages": [{"role": "user", "content": "redacted-by-litellm"}]}, "output": {"content": "redacted-by-litellm", "role": "assistant"}, "tags": []}, "timestamp": "2024-07-07T00:49:52.866977Z"}, {"id": "6abdba0f-7dba-438d-99ac-1c1a9d481d14", "type": "generation-create", "body": {"traceId": "litellm-test-8d866db0-0114-48a2-9f24-12a82a7b3db6", "name": "litellm-acompletion", "startTime": "2024-07-06T17:49:52.561285-07:00", "metadata": {"litellm_response_cost": 4.1e-05, "cache_hit": false}, "input": {"messages": [{"role": "user", "content": "redacted-by-litellm"}]}, "output": {"content": "redacted-by-litellm", "role": "assistant"}, "level": "DEFAULT", "id": "time-17-49-52-561285_chatcmpl-8079666e-d514-45b8-829f-887b4ae98ec0", "endTime": "2024-07-06T17:49:52.572272-07:00", "completionStartTime": "2024-07-06T17:49:52.564390-07:00", "model": "gpt-3.5-turbo", "modelParameters": {"temperature": "0.7", "stream": true, "max_tokens": 5, "user": "langfuse_latency_test_user", "extra_body": "{}"}, "usage": {"input": 14, "output": 10, "unit": "TOKENS", "totalCost": 4.1e-05}}, "timestamp": "2024-07-07T00:49:52.867926Z"}], "metadata": {"batch_size": 2, "sdk_integration": "default", "sdk_name": "python", "sdk_version": "2.32.0", "public_key": "pk-lf-b3db7e8e-c2f6-4fc7-825c-a541a8fbe003"}} to https://us.cloud.langfuse.com/api/public/ingestion
~0 items in the Langfuse queue
received response: {"errors":[],"successes":[{"id":"892fa3ad-9191-4f19-b050-0badbf773160","status":201},{"id":"6abdba0f-7dba-438d-99ac-1c1a9d481d14","status":201}]}
successfully uploaded batch of 2 items
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
Getting observations... None, None, None, None, litellm-test-8d866db0-0114-48a2-9f24-12a82a7b3db6, None, GENERATION
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
consumer is running...
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
flushing queue
successfully flushed about 0 items.
Creating trace id='litellm-test-dbb12cf8-f570-4742-91b9-16c6f23a7be4' timestamp=datetime.datetime(2024, 7, 7, 0, 49, 54, 946118, tzinfo=datetime.timezone.utc) name='litellm-acompletion' user_id='langfuse_latency_test_user' input='redacted-by-litellm' output='redacted-by-litellm' session_id=None release=None version=None metadata=None tags=[] public=None
Creating generation trace_id='litellm-test-dbb12cf8-f570-4742-91b9-16c6f23a7be4' name='litellm-acompletion' start_time=datetime.datetime(2024, 7, 6, 17, 49, 54, 944317) metadata={'litellm_response_cost': 5.4999999999999995e-05, 'cache_hit': False} input='redacted-by-litellm' output='redacted-by-litellm' level=<ObservationLevel.DEFAULT: 'DEFAULT'> status_message=None parent_observation_id=None version=None id='time-17-49-54-944317_chatcmpl-0ff349c9-b506-4d5e-a511-ca47ba2b55c2' end_time=datetime.datetime(2024, 7, 6, 17, 49, 54, 945181) completion_start_time=datetime.datetime(2024, 7, 6, 17, 49, 54, 945181) model='gpt-3.5-turbo' model_parameters={'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'} usage=Usage(input=10, output=20, total=None, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=5.4999999999999995e-05) prompt_name=None prompt_version=None...
item size 375
item size 860
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
uploading batch of 2 items
uploading data: {'batch': [{'id': '00f5d689-e397-4ad8-b084-998a49084b84', 'type': 'trace-create', 'body': {'id': 'litellm-test-dbb12cf8-f570-4742-91b9-16c6f23a7be4', 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 54, 946118, tzinfo=datetime.timezone.utc), 'name': 'litellm-acompletion', 'userId': 'langfuse_latency_test_user', 'input': 'redacted-by-litellm', 'output': 'redacted-by-litellm', 'tags': []}, 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 54, 946313, tzinfo=datetime.timezone.utc)}, {'id': 'c0dae082-ef3d-4884-8e9a-aede1cf07ff1', 'type': 'generation-create', 'body': {'traceId': 'litellm-test-dbb12cf8-f570-4742-91b9-16c6f23a7be4', 'name': 'litellm-acompletion', 'startTime': datetime.datetime(2024, 7, 6, 17, 49, 54, 944317), 'metadata': {'litellm_response_cost': 5.4999999999999995e-05, 'cache_hit': False}, 'input': 'redacted-by-litellm', 'output': 'redacted-by-litellm', 'level': <ObservationLevel.DEFAULT: 'DEFAULT'>, 'id': 'time-17-49-54-944317_chatcmpl-0ff349c9-b506-4d5e-a511-ca47ba2b55c2', 'endTime': datetime.datetime(2024, 7, 6, 17, 49, 54, 945181), 'completionStartTime': datetime.datetime(2024, 7, 6, 17, 49, 54, 945181), 'model': 'gpt-3.5-turbo', 'modelParameters': {'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'}, 'usage': {'input': 10, 'output': 20, 'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>, 'totalCost': 5.4999999999999995e-05}}, 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 54, 946682, tzinfo=datetime.timezone.utc)}], 'metadata': {'batch_size': 2, 'sdk_integration': 'default', 'sdk_name': 'python', 'sdk_version': '2.32.0', 'public_key': 'pk-lf-b3db7e8e-c2f6-4fc7-825c-a541a8fbe003'}}
making request: {"batch": [{"id": "00f5d689-e397-4ad8-b084-998a49084b84", "type": "trace-create", "body": {"id": "litellm-test-dbb12cf8-f570-4742-91b9-16c6f23a7be4", "timestamp": "2024-07-07T00:49:54.946118Z", "name": "litellm-acompletion", "userId": "langfuse_latency_test_user", "input": "redacted-by-litellm", "output": "redacted-by-litellm", "tags": []}, "timestamp": "2024-07-07T00:49:54.946313Z"}, {"id": "c0dae082-ef3d-4884-8e9a-aede1cf07ff1", "type": "generation-create", "body": {"traceId": "litellm-test-dbb12cf8-f570-4742-91b9-16c6f23a7be4", "name": "litellm-acompletion", "startTime": "2024-07-06T17:49:54.944317-07:00", "metadata": {"litellm_response_cost": 5.4999999999999995e-05, "cache_hit": false}, "input": "redacted-by-litellm", "output": "redacted-by-litellm", "level": "DEFAULT", "id": "time-17-49-54-944317_chatcmpl-0ff349c9-b506-4d5e-a511-ca47ba2b55c2", "endTime": "2024-07-06T17:49:54.945181-07:00", "completionStartTime": "2024-07-06T17:49:54.945181-07:00", "model": "gpt-3.5-turbo", "modelParameters": {"temperature": "0.7", "max_tokens": 5, "user": "langfuse_latency_test_user", "extra_body": "{}"}, "usage": {"input": 10, "output": 20, "unit": "TOKENS", "totalCost": 5.4999999999999995e-05}}, "timestamp": "2024-07-07T00:49:54.946682Z"}], "metadata": {"batch_size": 2, "sdk_integration": "default", "sdk_name": "python", "sdk_version": "2.32.0", "public_key": "pk-lf-b3db7e8e-c2f6-4fc7-825c-a541a8fbe003"}} to https://us.cloud.langfuse.com/api/public/ingestion
~0 items in the Langfuse queue
~0 items in the Langfuse queue
received response: {"errors":[],"successes":[{"id":"00f5d689-e397-4ad8-b084-998a49084b84","status":201},{"id":"c0dae082-ef3d-4884-8e9a-aede1cf07ff1","status":201}]}
successfully uploaded batch of 2 items
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
Getting trace litellm-test-dbb12cf8-f570-4742-91b9-16c6f23a7be4
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
Getting observations... None, None, None, None, litellm-test-dbb12cf8-f570-4742-91b9-16c6f23a7be4, None, GENERATION
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
Creating trace id='litellm-test-f2b16f5b-81b8-4716-b812-3ff8d4d7b6cb' timestamp=datetime.datetime(2024, 7, 7, 0, 49, 57, 252490, tzinfo=datetime.timezone.utc) name='litellm-acompletion' user_id='langfuse_latency_test_user' input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': 'This is a test response', 'role': 'assistant'} session_id=None release=None version=None metadata=None tags=[] public=None
Creating generation trace_id='litellm-test-f2b16f5b-81b8-4716-b812-3ff8d4d7b6cb' name='litellm-acompletion' start_time=datetime.datetime(2024, 7, 6, 17, 49, 57, 251265) metadata={'litellm_response_cost': 5.4999999999999995e-05, 'cache_hit': False} input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': 'This is a test response', 'role': 'assistant'} level=<ObservationLevel.DEFAULT: 'DEFAULT'> status_message=None parent_observation_id=None version=None id='time-17-49-57-251265_chatcmpl-963c5062-9c99-4bd7-9bd2-7ff039f129e5' end_time=datetime.datetime(2024, 7, 6, 17, 49, 57, 251932) completion_start_time=datetime.datetime(2024, 7, 6, 17, 49, 57, 251932) model='gpt-3.5-turbo' model_parameters={'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'} usage=Usage(input=10, output=20, total=None, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=5.4999999999999995e-05) prompt_name=None prompt_version=None...
item size 453
flushing queue
item size 938
successfully flushed about 0 items.
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
uploading batch of 2 items
uploading data: {'batch': [{'id': '6b7f45eb-d322-4614-9611-10b6325982da', 'type': 'trace-create', 'body': {'id': 'litellm-test-f2b16f5b-81b8-4716-b812-3ff8d4d7b6cb', 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 57, 252490, tzinfo=datetime.timezone.utc), 'name': 'litellm-acompletion', 'userId': 'langfuse_latency_test_user', 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': 'This is a test response', 'role': 'assistant'}, 'tags': []}, 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 57, 252967, tzinfo=datetime.timezone.utc)}, {'id': '7db8d145-bb3f-4e64-958b-0e73ea777d6d', 'type': 'generation-create', 'body': {'traceId': 'litellm-test-f2b16f5b-81b8-4716-b812-3ff8d4d7b6cb', 'name': 'litellm-acompletion', 'startTime': datetime.datetime(2024, 7, 6, 17, 49, 57, 251265), 'metadata': {'litellm_response_cost': 5.4999999999999995e-05, 'cache_hit': False}, 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': 'This is a test response', 'role': 'assistant'}, 'level': <ObservationLevel.DEFAULT: 'DEFAULT'>, 'id': 'time-17-49-57-251265_chatcmpl-963c5062-9c99-4bd7-9bd2-7ff039f129e5', 'endTime': datetime.datetime(2024, 7, 6, 17, 49, 57, 251932), 'completionStartTime': datetime.datetime(2024, 7, 6, 17, 49, 57, 251932), 'model': 'gpt-3.5-turbo', 'modelParameters': {'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'}, 'usage': {'input': 10, 'output': 20, 'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>, 'totalCost': 5.4999999999999995e-05}}, 'timestamp': datetime.datetime(2024, 7, 7, 0, 49, 57, 253374, tzinfo=datetime.timezone.utc)}], 'metadata': {'batch_size': 2, 'sdk_integration': 'default', 'sdk_name': 'python', 'sdk_version': '2.32.0', 'public_key': 'pk-lf-b3db7e8e-c2f6-4fc7-825c-a541a8fbe003'}}
making request: {"batch": [{"id": "6b7f45eb-d322-4614-9611-10b6325982da", "type": "trace-create", "body": {"id": "litellm-test-f2b16f5b-81b8-4716-b812-3ff8d4d7b6cb", "timestamp": "2024-07-07T00:49:57.252490Z", "name": "litellm-acompletion", "userId": "langfuse_latency_test_user", "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "This is a test response", "role": "assistant"}, "tags": []}, "timestamp": "2024-07-07T00:49:57.252967Z"}, {"id": "7db8d145-bb3f-4e64-958b-0e73ea777d6d", "type": "generation-create", "body": {"traceId": "litellm-test-f2b16f5b-81b8-4716-b812-3ff8d4d7b6cb", "name": "litellm-acompletion", "startTime": "2024-07-06T17:49:57.251265-07:00", "metadata": {"litellm_response_cost": 5.4999999999999995e-05, "cache_hit": false}, "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "This is a test response", "role": "assistant"}, "level": "DEFAULT", "id": "time-17-49-57-251265_chatcmpl-963c5062-9c99-4bd7-9bd2-7ff039f129e5", "endTime": "2024-07-06T17:49:57.251932-07:00", "completionStartTime": "2024-07-06T17:49:57.251932-07:00", "model": "gpt-3.5-turbo", "modelParameters": {"temperature": "0.7", "max_tokens": 5, "user": "langfuse_latency_test_user", "extra_body": "{}"}, "usage": {"input": 10, "output": 20, "unit": "TOKENS", "totalCost": 5.4999999999999995e-05}}, "timestamp": "2024-07-07T00:49:57.253374Z"}], "metadata": {"batch_size": 2, "sdk_integration": "default", "sdk_name": "python", "sdk_version": "2.32.0", "public_key": "pk-lf-b3db7e8e-c2f6-4fc7-825c-a541a8fbe003"}} to https://us.cloud.langfuse.com/api/public/ingestion
~0 items in the Langfuse queue
received response: {"errors":[],"successes":[{"id":"6b7f45eb-d322-4614-9611-10b6325982da","status":201},{"id":"7db8d145-bb3f-4e64-958b-0e73ea777d6d","status":201}]}
successfully uploaded batch of 2 items
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
Getting trace litellm-test-f2b16f5b-81b8-4716-b812-3ff8d4d7b6cb
~0 items in the Langfuse queue
~0 items in the Langfuse queue
Getting observations... None, None, None, None, litellm-test-f2b16f5b-81b8-4716-b812-3ff8d4d7b6cb, None, GENERATION
~0 items in the Langfuse queue
joining 1 consumer threads
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
consumer thread 0 joined
joining 1 consumer threads
~0 items in the Langfuse queue
consumer thread 0 joined
joining 1 consumer threads
~0 items in the Langfuse queue
consumer thread 0 joined
joining 1 consumer threads
~0 items in the Langfuse queue
consumer thread 0 joined
