`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
Creating trace id='52a58bac-492b-433e-9228-2759b73303a6' timestamp=datetime.datetime(2024, 6, 23, 6, 26, 45, 565911, tzinfo=datetime.timezone.utc) name='litellm-acompletion' user_id='langfuse_latency_test_user' input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': "It's simple to use and easy to get started", 'role': 'assistant'} session_id=None release=None version=None metadata=None tags=[] public=None
Creating trace id='28bc21fe-5955-4ec5-ba39-27325718af5a' timestamp=datetime.datetime(2024, 6, 23, 6, 26, 45, 566213, tzinfo=datetime.timezone.utc) name='litellm-acompletion' user_id='langfuse_latency_test_user' input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': "It's simple to use and easy to get started", 'role': 'assistant'} session_id=None release=None version=None metadata=None tags=[] public=None
Creating generation trace_id='52a58bac-492b-433e-9228-2759b73303a6' name='litellm-acompletion' start_time=datetime.datetime(2024, 6, 22, 23, 26, 45, 561383) metadata={'litellm_response_cost': None, 'cache_hit': False} input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': "It's simple to use and easy to get started", 'role': 'assistant'} level=<ObservationLevel.DEFAULT: 'DEFAULT'> status_message=None parent_observation_id=None version=None id='time-23-26-45-561383_chatcmpl-193fd5b6-87ce-4b8f-90bb-e2c2608f0f73' end_time=datetime.datetime(2024, 6, 22, 23, 26, 45, 564028) completion_start_time=datetime.datetime(2024, 6, 22, 23, 26, 45, 564028) model='chatgpt-v-2' model_parameters={'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'} usage=Usage(input=10, output=20, total=None, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None) prompt_name=None prompt_version=None...
Creating generation trace_id='28bc21fe-5955-4ec5-ba39-27325718af5a' name='litellm-acompletion' start_time=datetime.datetime(2024, 6, 22, 23, 26, 45, 562146) metadata={'litellm_response_cost': None, 'cache_hit': False} input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': "It's simple to use and easy to get started", 'role': 'assistant'} level=<ObservationLevel.DEFAULT: 'DEFAULT'> status_message=None parent_observation_id=None version=None id='time-23-26-45-562146_chatcmpl-2dc26df5-d4e4-46f5-868e-138aac85dd95' end_time=datetime.datetime(2024, 6, 22, 23, 26, 45, 564312) completion_start_time=datetime.datetime(2024, 6, 22, 23, 26, 45, 564312) model='chatgpt-v-2' model_parameters={'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'} usage=Usage(input=10, output=20, total=None, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None) prompt_name=None prompt_version=None...
item size 459
Creating trace id='f545a5c8-dfdf-4226-a30c-f24ff8d75144' timestamp=datetime.datetime(2024, 6, 23, 6, 26, 45, 567765, tzinfo=datetime.timezone.utc) name='litellm-acompletion' user_id='langfuse_latency_test_user' input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': "It's simple to use and easy to get started", 'role': 'assistant'} session_id=None release=None version=None metadata=None tags=[] public=None
item size 459
Creating trace id='c8d266ca-c370-439e-9d14-f011e5cfa254' timestamp=datetime.datetime(2024, 6, 23, 6, 26, 45, 568137, tzinfo=datetime.timezone.utc) name='litellm-acompletion' user_id='langfuse_latency_test_user' input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': "It's simple to use and easy to get started", 'role': 'assistant'} session_id=None release=None version=None metadata=None tags=[] public=None
Creating generation trace_id='f545a5c8-dfdf-4226-a30c-f24ff8d75144' name='litellm-acompletion' start_time=datetime.datetime(2024, 6, 22, 23, 26, 45, 562753) metadata={'litellm_response_cost': None, 'cache_hit': False} input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': "It's simple to use and easy to get started", 'role': 'assistant'} level=<ObservationLevel.DEFAULT: 'DEFAULT'> status_message=None parent_observation_id=None version=None id='time-23-26-45-562753_chatcmpl-33ae3e6d-d66a-4447-82d9-c8f5d5be43e5' end_time=datetime.datetime(2024, 6, 22, 23, 26, 45, 564869) completion_start_time=datetime.datetime(2024, 6, 22, 23, 26, 45, 564869) model='chatgpt-v-2' model_parameters={'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'} usage=Usage(input=10, output=20, total=None, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None) prompt_name=None prompt_version=None...
item size 887
Creating generation trace_id='c8d266ca-c370-439e-9d14-f011e5cfa254' name='litellm-acompletion' start_time=datetime.datetime(2024, 6, 22, 23, 26, 45, 563300) metadata={'litellm_response_cost': None, 'cache_hit': False} input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': "It's simple to use and easy to get started", 'role': 'assistant'} level=<ObservationLevel.DEFAULT: 'DEFAULT'> status_message=None parent_observation_id=None version=None id='time-23-26-45-563300_chatcmpl-56c11246-4c9c-43c0-bb4e-0be309907acd' end_time=datetime.datetime(2024, 6, 22, 23, 26, 45, 565142) completion_start_time=datetime.datetime(2024, 6, 22, 23, 26, 45, 565142) model='chatgpt-v-2' model_parameters={'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'} usage=Usage(input=10, output=20, total=None, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None) prompt_name=None prompt_version=None...
item size 887
item size 459
item size 459
item size 887
item size 887
Creating trace id='7c6fec55-def1-4838-8ea1-86960a1ccb19' timestamp=datetime.datetime(2024, 6, 23, 6, 26, 45, 570331, tzinfo=datetime.timezone.utc) name='litellm-acompletion' user_id='langfuse_latency_test_user' input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': "It's simple to use and easy to get started", 'role': 'assistant'} session_id=None release=None version=None metadata=None tags=[] public=None
Creating generation trace_id='7c6fec55-def1-4838-8ea1-86960a1ccb19' name='litellm-acompletion' start_time=datetime.datetime(2024, 6, 22, 23, 26, 45, 563792) metadata={'litellm_response_cost': None, 'cache_hit': False} input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': "It's simple to use and easy to get started", 'role': 'assistant'} level=<ObservationLevel.DEFAULT: 'DEFAULT'> status_message=None parent_observation_id=None version=None id='time-23-26-45-563792_chatcmpl-c159069a-bc65-43a0-bef5-e2d42688cead' end_time=datetime.datetime(2024, 6, 22, 23, 26, 45, 569384) completion_start_time=datetime.datetime(2024, 6, 22, 23, 26, 45, 569384) model='chatgpt-v-2' model_parameters={'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'} usage=Usage(input=10, output=20, total=None, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None) prompt_name=None prompt_version=None...
item size 459
item size 887
~0 items in the Langfuse queue
uploading batch of 10 items
uploading data: {'batch': [{'id': 'cd6c78ba-81aa-4106-bc92-48adbda0ef1b', 'type': 'trace-create', 'body': {'id': '52a58bac-492b-433e-9228-2759b73303a6', 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 45, 565911, tzinfo=datetime.timezone.utc), 'name': 'litellm-acompletion', 'userId': 'langfuse_latency_test_user', 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': "It's simple to use and easy to get started", 'role': 'assistant'}, 'tags': []}, 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 45, 566569, tzinfo=datetime.timezone.utc)}, {'id': '57b678c1-d620-4aad-8052-1722a498972e', 'type': 'trace-create', 'body': {'id': '28bc21fe-5955-4ec5-ba39-27325718af5a', 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 45, 566213, tzinfo=datetime.timezone.utc), 'name': 'litellm-acompletion', 'userId': 'langfuse_latency_test_user', 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': "It's simple to use and easy to get started", 'role': 'assistant'}, 'tags': []}, 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 45, 566947, tzinfo=datetime.timezone.utc)}, {'id': '831370be-b2bd-48d8-b32b-bfcaf103712b', 'type': 'generation-create', 'body': {'traceId': '52a58bac-492b-433e-9228-2759b73303a6', 'name': 'litellm-acompletion', 'startTime': datetime.datetime(2024, 6, 22, 23, 26, 45, 561383), 'metadata': {'litellm_response_cost': None, 'cache_hit': False}, 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': "It's simple to use and easy to get started", 'role': 'assistant'}, 'level': <ObservationLevel.DEFAULT: 'DEFAULT'>, 'id': 'time-23-26-45-561383_chatcmpl-193fd5b6-87ce-4b8f-90bb-e2c2608f0f73', 'endTime': datetime.datetime(2024, 6, 22, 23, 26, 45, 564028), 'completionStartTime': datetime.datetime(2024, 6, 22, 23, 26, 45, 564028), 'model': 'chatgpt-v-2', 'modelParameters': {'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'}, 'usage': {'input': 10, 'output': 20, 'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>}}, 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 45, 567294, tzinfo=datetime.timezone.utc)}, {'id': '571fe93d-34b4-405e-98b4-e47b538b884a', 'type': 'generation-create', 'body': {'traceId': '28bc21fe-5955-4ec5-ba39-27325718af5a', 'name': 'litellm-acompletion', 'startTime': datetime.datetime(2024, 6, 22, 23, 26, 45, 562146), 'metadata': {'litellm_response_cost': None, 'cache_hit': False}, 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': "It's simple to use and easy to get started", 'role': 'assistant'}, 'level': <ObservationLevel.DEFAULT: 'DEFAULT'>, 'id': 'time-23-26-45-562146_chatcmpl-2dc26df5-d4e4-46f5-868e-138aac85dd95', 'endTime': datetime.datetime(2024, 6, 22, 23, 26, 45, 564312), 'completionStartTime': datetime.datetime(2024, 6, 22, 23, 26, 45, 564312), 'model': 'chatgpt-v-2', 'modelParameters': {'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'}, 'usage': {'input': 10, 'output': 20, 'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>}}, 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 45, 567688, tzinfo=datetime.timezone.utc)}, {'id': '13ae52b9-7480-4b2e-977c-e85f422f9a16', 'type': 'trace-create', 'body': {'id': 'f545a5c8-dfdf-4226-a30c-f24ff8d75144', 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 45, 567765, tzinfo=datetime.timezone.utc), 'name': 'litellm-acompletion', 'userId': 'langfuse_latency_test_user', 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': "It's simple to use and easy to get started", 'role': 'assistant'}, 'tags': []}, 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 45, 568357, tzinfo=datetime.timezone.utc)}, {'id': '7498e67e-0b2b-451c-8533-a35de0aed092', 'type': 'trace-create', 'body': {'id': 'c8d266ca-c370-439e-9d14-f011e5cfa254', 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 45, 568137, tzinfo=datetime.timezone.utc), 'name': 'litellm-acompletion', 'userId': 'langfuse_latency_test_user', 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': "It's simple to use and easy to get started", 'role': 'assistant'}, 'tags': []}, 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 45, 568812, tzinfo=datetime.timezone.utc)}, {'id': '2656f364-b367-442a-a694-19dd159a0769', 'type': 'generation-create', 'body': {'traceId': 'f545a5c8-dfdf-4226-a30c-f24ff8d75144', 'name': 'litellm-acompletion', 'startTime': datetime.datetime(2024, 6, 22, 23, 26, 45, 562753), 'metadata': {'litellm_response_cost': None, 'cache_hit': False}, 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': "It's simple to use and easy to get started", 'role': 'assistant'}, 'level': <ObservationLevel.DEFAULT: 'DEFAULT'>, 'id': 'time-23-26-45-562753_chatcmpl-33ae3e6d-d66a-4447-82d9-c8f5d5be43e5', 'endTime': datetime.datetime(2024, 6, 22, 23, 26, 45, 564869), 'completionStartTime': datetime.datetime(2024, 6, 22, 23, 26, 45, 564869), 'model': 'chatgpt-v-2', 'modelParameters': {'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'}, 'usage': {'input': 10, 'output': 20, 'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>}}, 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 45, 569165, tzinfo=datetime.timezone.utc)}, {'id': '8c42f89e-be59-4226-812e-bc849d35ab59', 'type': 'generation-create', 'body': {'traceId': 'c8d266ca-c370-439e-9d14-f011e5cfa254', 'name': 'litellm-acompletion', 'startTime': datetime.datetime(2024, 6, 22, 23, 26, 45, 563300), 'metadata': {'litellm_response_cost': None, 'cache_hit': False}, 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': "It's simple to use and easy to get started", 'role': 'assistant'}, 'level': <ObservationLevel.DEFAULT: 'DEFAULT'>, 'id': 'time-23-26-45-563300_chatcmpl-56c11246-4c9c-43c0-bb4e-0be309907acd', 'endTime': datetime.datetime(2024, 6, 22, 23, 26, 45, 565142), 'completionStartTime': datetime.datetime(2024, 6, 22, 23, 26, 45, 565142), 'model': 'chatgpt-v-2', 'modelParameters': {'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'}, 'usage': {'input': 10, 'output': 20, 'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>}}, 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 45, 569494, tzinfo=datetime.timezone.utc)}, {'id': 'a926d1eb-68ed-484c-a9b9-3d82938a7d28', 'type': 'trace-create', 'body': {'id': '7c6fec55-def1-4838-8ea1-86960a1ccb19', 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 45, 570331, tzinfo=datetime.timezone.utc), 'name': 'litellm-acompletion', 'userId': 'langfuse_latency_test_user', 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': "It's simple to use and easy to get started", 'role': 'assistant'}, 'tags': []}, 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 45, 570495, tzinfo=datetime.timezone.utc)}, {'id': '97b5dee7-a3b2-4526-91cb-75dac909c78f', 'type': 'generation-create', 'body': {'traceId': '7c6fec55-def1-4838-8ea1-86960a1ccb19', 'name': 'litellm-acompletion', 'startTime': datetime.datetime(2024, 6, 22, 23, 26, 45, 563792), 'metadata': {'litellm_response_cost': None, 'cache_hit': False}, 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': "It's simple to use and easy to get started", 'role': 'assistant'}, 'level': <ObservationLevel.DEFAULT: 'DEFAULT'>, 'id': 'time-23-26-45-563792_chatcmpl-c159069a-bc65-43a0-bef5-e2d42688cead', 'endTime': datetime.datetime(2024, 6, 22, 23, 26, 45, 569384), 'completionStartTime': datetime.datetime(2024, 6, 22, 23, 26, 45, 569384), 'model': 'chatgpt-v-2', 'modelParameters': {'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'}, 'usage': {'input': 10, 'output': 20, 'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>}}, 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 45, 570858, tzinfo=datetime.timezone.utc)}], 'metadata': {'batch_size': 10, 'sdk_integration': 'default', 'sdk_name': 'python', 'sdk_version': '2.32.0', 'public_key': 'pk-lf-b3db7e8e-c2f6-4fc7-825c-a541a8fbe003'}}
making request: {"batch": [{"id": "cd6c78ba-81aa-4106-bc92-48adbda0ef1b", "type": "trace-create", "body": {"id": "52a58bac-492b-433e-9228-2759b73303a6", "timestamp": "2024-06-23T06:26:45.565911Z", "name": "litellm-acompletion", "userId": "langfuse_latency_test_user", "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "It's simple to use and easy to get started", "role": "assistant"}, "tags": []}, "timestamp": "2024-06-23T06:26:45.566569Z"}, {"id": "57b678c1-d620-4aad-8052-1722a498972e", "type": "trace-create", "body": {"id": "28bc21fe-5955-4ec5-ba39-27325718af5a", "timestamp": "2024-06-23T06:26:45.566213Z", "name": "litellm-acompletion", "userId": "langfuse_latency_test_user", "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "It's simple to use and easy to get started", "role": "assistant"}, "tags": []}, "timestamp": "2024-06-23T06:26:45.566947Z"}, {"id": "831370be-b2bd-48d8-b32b-bfcaf103712b", "type": "generation-create", "body": {"traceId": "52a58bac-492b-433e-9228-2759b73303a6", "name": "litellm-acompletion", "startTime": "2024-06-22T23:26:45.561383-07:00", "metadata": {"litellm_response_cost": null, "cache_hit": false}, "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "It's simple to use and easy to get started", "role": "assistant"}, "level": "DEFAULT", "id": "time-23-26-45-561383_chatcmpl-193fd5b6-87ce-4b8f-90bb-e2c2608f0f73", "endTime": "2024-06-22T23:26:45.564028-07:00", "completionStartTime": "2024-06-22T23:26:45.564028-07:00", "model": "chatgpt-v-2", "modelParameters": {"temperature": "0.7", "max_tokens": 5, "user": "langfuse_latency_test_user", "extra_body": "{}"}, "usage": {"input": 10, "output": 20, "unit": "TOKENS"}}, "timestamp": "2024-06-23T06:26:45.567294Z"}, {"id": "571fe93d-34b4-405e-98b4-e47b538b884a", "type": "generation-create", "body": {"traceId": "28bc21fe-5955-4ec5-ba39-27325718af5a", "name": "litellm-acompletion", "startTime": "2024-06-22T23:26:45.562146-07:00", "metadata": {"litellm_response_cost": null, "cache_hit": false}, "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "It's simple to use and easy to get started", "role": "assistant"}, "level": "DEFAULT", "id": "time-23-26-45-562146_chatcmpl-2dc26df5-d4e4-46f5-868e-138aac85dd95", "endTime": "2024-06-22T23:26:45.564312-07:00", "completionStartTime": "2024-06-22T23:26:45.564312-07:00", "model": "chatgpt-v-2", "modelParameters": {"temperature": "0.7", "max_tokens": 5, "user": "langfuse_latency_test_user", "extra_body": "{}"}, "usage": {"input": 10, "output": 20, "unit": "TOKENS"}}, "timestamp": "2024-06-23T06:26:45.567688Z"}, {"id": "13ae52b9-7480-4b2e-977c-e85f422f9a16", "type": "trace-create", "body": {"id": "f545a5c8-dfdf-4226-a30c-f24ff8d75144", "timestamp": "2024-06-23T06:26:45.567765Z", "name": "litellm-acompletion", "userId": "langfuse_latency_test_user", "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "It's simple to use and easy to get started", "role": "assistant"}, "tags": []}, "timestamp": "2024-06-23T06:26:45.568357Z"}, {"id": "7498e67e-0b2b-451c-8533-a35de0aed092", "type": "trace-create", "body": {"id": "c8d266ca-c370-439e-9d14-f011e5cfa254", "timestamp": "2024-06-23T06:26:45.568137Z", "name": "litellm-acompletion", "userId": "langfuse_latency_test_user", "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "It's simple to use and easy to get started", "role": "assistant"}, "tags": []}, "timestamp": "2024-06-23T06:26:45.568812Z"}, {"id": "2656f364-b367-442a-a694-19dd159a0769", "type": "generation-create", "body": {"traceId": "f545a5c8-dfdf-4226-a30c-f24ff8d75144", "name": "litellm-acompletion", "startTime": "2024-06-22T23:26:45.562753-07:00", "metadata": {"litellm_response_cost": null, "cache_hit": false}, "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "It's simple to use and easy to get started", "role": "assistant"}, "level": "DEFAULT", "id": "time-23-26-45-562753_chatcmpl-33ae3e6d-d66a-4447-82d9-c8f5d5be43e5", "endTime": "2024-06-22T23:26:45.564869-07:00", "completionStartTime": "2024-06-22T23:26:45.564869-07:00", "model": "chatgpt-v-2", "modelParameters": {"temperature": "0.7", "max_tokens": 5, "user": "langfuse_latency_test_user", "extra_body": "{}"}, "usage": {"input": 10, "output": 20, "unit": "TOKENS"}}, "timestamp": "2024-06-23T06:26:45.569165Z"}, {"id": "8c42f89e-be59-4226-812e-bc849d35ab59", "type": "generation-create", "body": {"traceId": "c8d266ca-c370-439e-9d14-f011e5cfa254", "name": "litellm-acompletion", "startTime": "2024-06-22T23:26:45.563300-07:00", "metadata": {"litellm_response_cost": null, "cache_hit": false}, "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "It's simple to use and easy to get started", "role": "assistant"}, "level": "DEFAULT", "id": "time-23-26-45-563300_chatcmpl-56c11246-4c9c-43c0-bb4e-0be309907acd", "endTime": "2024-06-22T23:26:45.565142-07:00", "completionStartTime": "2024-06-22T23:26:45.565142-07:00", "model": "chatgpt-v-2", "modelParameters": {"temperature": "0.7", "max_tokens": 5, "user": "langfuse_latency_test_user", "extra_body": "{}"}, "usage": {"input": 10, "output": 20, "unit": "TOKENS"}}, "timestamp": "2024-06-23T06:26:45.569494Z"}, {"id": "a926d1eb-68ed-484c-a9b9-3d82938a7d28", "type": "trace-create", "body": {"id": "7c6fec55-def1-4838-8ea1-86960a1ccb19", "timestamp": "2024-06-23T06:26:45.570331Z", "name": "litellm-acompletion", "userId": "langfuse_latency_test_user", "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "It's simple to use and easy to get started", "role": "assistant"}, "tags": []}, "timestamp": "2024-06-23T06:26:45.570495Z"}, {"id": "97b5dee7-a3b2-4526-91cb-75dac909c78f", "type": "generation-create", "body": {"traceId": "7c6fec55-def1-4838-8ea1-86960a1ccb19", "name": "litellm-acompletion", "startTime": "2024-06-22T23:26:45.563792-07:00", "metadata": {"litellm_response_cost": null, "cache_hit": false}, "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "It's simple to use and easy to get started", "role": "assistant"}, "level": "DEFAULT", "id": "time-23-26-45-563792_chatcmpl-c159069a-bc65-43a0-bef5-e2d42688cead", "endTime": "2024-06-22T23:26:45.569384-07:00", "completionStartTime": "2024-06-22T23:26:45.569384-07:00", "model": "chatgpt-v-2", "modelParameters": {"temperature": "0.7", "max_tokens": 5, "user": "langfuse_latency_test_user", "extra_body": "{}"}, "usage": {"input": 10, "output": 20, "unit": "TOKENS"}}, "timestamp": "2024-06-23T06:26:45.570858Z"}], "metadata": {"batch_size": 10, "sdk_integration": "default", "sdk_name": "python", "sdk_version": "2.32.0", "public_key": "pk-lf-b3db7e8e-c2f6-4fc7-825c-a541a8fbe003"}} to https://us.cloud.langfuse.com/api/public/ingestion
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
received response: {"errors":[],"successes":[{"id":"cd6c78ba-81aa-4106-bc92-48adbda0ef1b","status":201},{"id":"57b678c1-d620-4aad-8052-1722a498972e","status":201},{"id":"831370be-b2bd-48d8-b32b-bfcaf103712b","status":201},{"id":"571fe93d-34b4-405e-98b4-e47b538b884a","status":201},{"id":"13ae52b9-7480-4b2e-977c-e85f422f9a16","status":201},{"id":"7498e67e-0b2b-451c-8533-a35de0aed092","status":201},{"id":"2656f364-b367-442a-a694-19dd159a0769","status":201},{"id":"8c42f89e-be59-4226-812e-bc849d35ab59","status":201},{"id":"a926d1eb-68ed-484c-a9b9-3d82938a7d28","status":201},{"id":"97b5dee7-a3b2-4526-91cb-75dac909c78f","status":201}]}
successfully uploaded batch of 10 items
~0 items in the Langfuse queue
consumer is running...
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
Creating trace id='litellm-test-4d2a861a-39d1-451c-8187-c1bc8f5253bf' timestamp=datetime.datetime(2024, 6, 23, 6, 26, 47, 529980, tzinfo=datetime.timezone.utc) name='litellm-acompletion' user_id='langfuse_latency_test_user' input={'messages': [{'role': 'user', 'content': 'redacted-by-litellm'}]} output={'content': 'redacted-by-litellm', 'role': 'assistant'} session_id=None release=None version=None metadata=None tags=[] public=None
flushing queue
Creating generation trace_id='litellm-test-4d2a861a-39d1-451c-8187-c1bc8f5253bf' name='litellm-acompletion' start_time=datetime.datetime(2024, 6, 22, 23, 26, 47, 528930) metadata={'litellm_response_cost': 5.4999999999999995e-05, 'cache_hit': False} input={'messages': [{'role': 'user', 'content': 'redacted-by-litellm'}]} output={'content': 'redacted-by-litellm', 'role': 'assistant'} level=<ObservationLevel.DEFAULT: 'DEFAULT'> status_message=None parent_observation_id=None version=None id='time-23-26-47-528930_chatcmpl-811d9755-120c-4934-9efd-5ec08b8c41c6' end_time=datetime.datetime(2024, 6, 22, 23, 26, 47, 529521) completion_start_time=datetime.datetime(2024, 6, 22, 23, 26, 47, 529521) model='gpt-3.5-turbo' model_parameters={'temperature': '0.7', 'stream': False, 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'} usage=Usage(input=10, output=20, total=None, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=5.4999999999999995e-05) prompt_name=None prompt_version=None...
item size 454
successfully flushed about 0 items.
item size 956
~0 items in the Langfuse queue
uploading batch of 2 items
uploading data: {'batch': [{'id': '997346c5-9bb9-4789-9ba9-33893bc65ee3', 'type': 'trace-create', 'body': {'id': 'litellm-test-4d2a861a-39d1-451c-8187-c1bc8f5253bf', 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 47, 529980, tzinfo=datetime.timezone.utc), 'name': 'litellm-acompletion', 'userId': 'langfuse_latency_test_user', 'input': {'messages': [{'role': 'user', 'content': 'redacted-by-litellm'}]}, 'output': {'content': 'redacted-by-litellm', 'role': 'assistant'}, 'tags': []}, 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 47, 530178, tzinfo=datetime.timezone.utc)}, {'id': 'c1c856eb-0aad-4da1-b68c-b68295b847e1', 'type': 'generation-create', 'body': {'traceId': 'litellm-test-4d2a861a-39d1-451c-8187-c1bc8f5253bf', 'name': 'litellm-acompletion', 'startTime': datetime.datetime(2024, 6, 22, 23, 26, 47, 528930), 'metadata': {'litellm_response_cost': 5.4999999999999995e-05, 'cache_hit': False}, 'input': {'messages': [{'role': 'user', 'content': 'redacted-by-litellm'}]}, 'output': {'content': 'redacted-by-litellm', 'role': 'assistant'}, 'level': <ObservationLevel.DEFAULT: 'DEFAULT'>, 'id': 'time-23-26-47-528930_chatcmpl-811d9755-120c-4934-9efd-5ec08b8c41c6', 'endTime': datetime.datetime(2024, 6, 22, 23, 26, 47, 529521), 'completionStartTime': datetime.datetime(2024, 6, 22, 23, 26, 47, 529521), 'model': 'gpt-3.5-turbo', 'modelParameters': {'temperature': '0.7', 'stream': False, 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'}, 'usage': {'input': 10, 'output': 20, 'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>, 'totalCost': 5.4999999999999995e-05}}, 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 47, 530501, tzinfo=datetime.timezone.utc)}], 'metadata': {'batch_size': 2, 'sdk_integration': 'default', 'sdk_name': 'python', 'sdk_version': '2.32.0', 'public_key': 'pk-lf-b3db7e8e-c2f6-4fc7-825c-a541a8fbe003'}}
making request: {"batch": [{"id": "997346c5-9bb9-4789-9ba9-33893bc65ee3", "type": "trace-create", "body": {"id": "litellm-test-4d2a861a-39d1-451c-8187-c1bc8f5253bf", "timestamp": "2024-06-23T06:26:47.529980Z", "name": "litellm-acompletion", "userId": "langfuse_latency_test_user", "input": {"messages": [{"role": "user", "content": "redacted-by-litellm"}]}, "output": {"content": "redacted-by-litellm", "role": "assistant"}, "tags": []}, "timestamp": "2024-06-23T06:26:47.530178Z"}, {"id": "c1c856eb-0aad-4da1-b68c-b68295b847e1", "type": "generation-create", "body": {"traceId": "litellm-test-4d2a861a-39d1-451c-8187-c1bc8f5253bf", "name": "litellm-acompletion", "startTime": "2024-06-22T23:26:47.528930-07:00", "metadata": {"litellm_response_cost": 5.4999999999999995e-05, "cache_hit": false}, "input": {"messages": [{"role": "user", "content": "redacted-by-litellm"}]}, "output": {"content": "redacted-by-litellm", "role": "assistant"}, "level": "DEFAULT", "id": "time-23-26-47-528930_chatcmpl-811d9755-120c-4934-9efd-5ec08b8c41c6", "endTime": "2024-06-22T23:26:47.529521-07:00", "completionStartTime": "2024-06-22T23:26:47.529521-07:00", "model": "gpt-3.5-turbo", "modelParameters": {"temperature": "0.7", "stream": false, "max_tokens": 5, "user": "langfuse_latency_test_user", "extra_body": "{}"}, "usage": {"input": 10, "output": 20, "unit": "TOKENS", "totalCost": 5.4999999999999995e-05}}, "timestamp": "2024-06-23T06:26:47.530501Z"}], "metadata": {"batch_size": 2, "sdk_integration": "default", "sdk_name": "python", "sdk_version": "2.32.0", "public_key": "pk-lf-b3db7e8e-c2f6-4fc7-825c-a541a8fbe003"}} to https://us.cloud.langfuse.com/api/public/ingestion
received response: {"errors":[],"successes":[{"id":"997346c5-9bb9-4789-9ba9-33893bc65ee3","status":201},{"id":"c1c856eb-0aad-4da1-b68c-b68295b847e1","status":201}]}
successfully uploaded batch of 2 items
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
Getting observations... None, None, None, None, litellm-test-4d2a861a-39d1-451c-8187-c1bc8f5253bf, None, GENERATION
~0 items in the Langfuse queue
consumer is running...
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
flushing queue
successfully flushed about 0 items.
~0 items in the Langfuse queue
~0 items in the Langfuse queue
Creating trace id='litellm-test-a6ce08b7-2364-4efd-b030-7ee3a9ed6996' timestamp=datetime.datetime(2024, 6, 23, 6, 26, 50, 95341, tzinfo=datetime.timezone.utc) name='litellm-acompletion' user_id='langfuse_latency_test_user' input={'messages': [{'role': 'user', 'content': 'redacted-by-litellm'}]} output={'content': 'redacted-by-litellm', 'role': 'assistant'} session_id=None release=None version=None metadata=None tags=[] public=None
Creating generation trace_id='litellm-test-a6ce08b7-2364-4efd-b030-7ee3a9ed6996' name='litellm-acompletion' start_time=datetime.datetime(2024, 6, 22, 23, 26, 49, 844949) metadata={'litellm_response_cost': 4.1e-05, 'cache_hit': False} input={'messages': [{'role': 'user', 'content': 'redacted-by-litellm'}]} output={'content': 'redacted-by-litellm', 'role': 'assistant'} level=<ObservationLevel.DEFAULT: 'DEFAULT'> status_message=None parent_observation_id=None version=None id='time-23-26-49-844949_chatcmpl-61f43be5-fc8e-4d92-ad89-8080b51f60de' end_time=datetime.datetime(2024, 6, 22, 23, 26, 49, 855530) completion_start_time=datetime.datetime(2024, 6, 22, 23, 26, 49, 846913) model='gpt-3.5-turbo' model_parameters={'temperature': '0.7', 'stream': True, 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'} usage=Usage(input=14, output=10, total=None, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=4.1e-05) prompt_name=None prompt_version=None...
item size 454
item size 925
~0 items in the Langfuse queue
~0 items in the Langfuse queue
uploading batch of 2 items
uploading data: {'batch': [{'id': '9bde426a-b7e9-480f-adc2-e1530b572882', 'type': 'trace-create', 'body': {'id': 'litellm-test-a6ce08b7-2364-4efd-b030-7ee3a9ed6996', 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 50, 95341, tzinfo=datetime.timezone.utc), 'name': 'litellm-acompletion', 'userId': 'langfuse_latency_test_user', 'input': {'messages': [{'role': 'user', 'content': 'redacted-by-litellm'}]}, 'output': {'content': 'redacted-by-litellm', 'role': 'assistant'}, 'tags': []}, 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 50, 95711, tzinfo=datetime.timezone.utc)}, {'id': '77964887-be69-42b6-b903-8b01d37643ca', 'type': 'generation-create', 'body': {'traceId': 'litellm-test-a6ce08b7-2364-4efd-b030-7ee3a9ed6996', 'name': 'litellm-acompletion', 'startTime': datetime.datetime(2024, 6, 22, 23, 26, 49, 844949), 'metadata': {'litellm_response_cost': 4.1e-05, 'cache_hit': False}, 'input': {'messages': [{'role': 'user', 'content': 'redacted-by-litellm'}]}, 'output': {'content': 'redacted-by-litellm', 'role': 'assistant'}, 'level': <ObservationLevel.DEFAULT: 'DEFAULT'>, 'id': 'time-23-26-49-844949_chatcmpl-61f43be5-fc8e-4d92-ad89-8080b51f60de', 'endTime': datetime.datetime(2024, 6, 22, 23, 26, 49, 855530), 'completionStartTime': datetime.datetime(2024, 6, 22, 23, 26, 49, 846913), 'model': 'gpt-3.5-turbo', 'modelParameters': {'temperature': '0.7', 'stream': True, 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'}, 'usage': {'input': 14, 'output': 10, 'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>, 'totalCost': 4.1e-05}}, 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 50, 96374, tzinfo=datetime.timezone.utc)}], 'metadata': {'batch_size': 2, 'sdk_integration': 'default', 'sdk_name': 'python', 'sdk_version': '2.32.0', 'public_key': 'pk-lf-b3db7e8e-c2f6-4fc7-825c-a541a8fbe003'}}
making request: {"batch": [{"id": "9bde426a-b7e9-480f-adc2-e1530b572882", "type": "trace-create", "body": {"id": "litellm-test-a6ce08b7-2364-4efd-b030-7ee3a9ed6996", "timestamp": "2024-06-23T06:26:50.095341Z", "name": "litellm-acompletion", "userId": "langfuse_latency_test_user", "input": {"messages": [{"role": "user", "content": "redacted-by-litellm"}]}, "output": {"content": "redacted-by-litellm", "role": "assistant"}, "tags": []}, "timestamp": "2024-06-23T06:26:50.095711Z"}, {"id": "77964887-be69-42b6-b903-8b01d37643ca", "type": "generation-create", "body": {"traceId": "litellm-test-a6ce08b7-2364-4efd-b030-7ee3a9ed6996", "name": "litellm-acompletion", "startTime": "2024-06-22T23:26:49.844949-07:00", "metadata": {"litellm_response_cost": 4.1e-05, "cache_hit": false}, "input": {"messages": [{"role": "user", "content": "redacted-by-litellm"}]}, "output": {"content": "redacted-by-litellm", "role": "assistant"}, "level": "DEFAULT", "id": "time-23-26-49-844949_chatcmpl-61f43be5-fc8e-4d92-ad89-8080b51f60de", "endTime": "2024-06-22T23:26:49.855530-07:00", "completionStartTime": "2024-06-22T23:26:49.846913-07:00", "model": "gpt-3.5-turbo", "modelParameters": {"temperature": "0.7", "stream": true, "max_tokens": 5, "user": "langfuse_latency_test_user", "extra_body": "{}"}, "usage": {"input": 14, "output": 10, "unit": "TOKENS", "totalCost": 4.1e-05}}, "timestamp": "2024-06-23T06:26:50.096374Z"}], "metadata": {"batch_size": 2, "sdk_integration": "default", "sdk_name": "python", "sdk_version": "2.32.0", "public_key": "pk-lf-b3db7e8e-c2f6-4fc7-825c-a541a8fbe003"}} to https://us.cloud.langfuse.com/api/public/ingestion
~0 items in the Langfuse queue
received response: {"errors":[],"successes":[{"id":"9bde426a-b7e9-480f-adc2-e1530b572882","status":201},{"id":"77964887-be69-42b6-b903-8b01d37643ca","status":201}]}
successfully uploaded batch of 2 items
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
Getting observations... None, None, None, None, litellm-test-a6ce08b7-2364-4efd-b030-7ee3a9ed6996, None, GENERATION
~0 items in the Langfuse queue
consumer is running...
~0 items in the Langfuse queue
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
Creating trace id='litellm-test-b3e968bf-c9cb-4f4d-a834-b0cba57e4695' timestamp=datetime.datetime(2024, 6, 23, 6, 26, 52, 198564, tzinfo=datetime.timezone.utc) name='litellm-acompletion' user_id='langfuse_latency_test_user' input='redacted-by-litellm' output='redacted-by-litellm' session_id=None release=None version=None metadata=None tags=[] public=None
Creating generation trace_id='litellm-test-b3e968bf-c9cb-4f4d-a834-b0cba57e4695' name='litellm-acompletion' start_time=datetime.datetime(2024, 6, 22, 23, 26, 52, 197638) metadata={'litellm_response_cost': 5.4999999999999995e-05, 'cache_hit': False} input='redacted-by-litellm' output='redacted-by-litellm' level=<ObservationLevel.DEFAULT: 'DEFAULT'> status_message=None parent_observation_id=None version=None id='time-23-26-52-197638_chatcmpl-089072da-028d-4425-ae6d-76e71d21df0d' end_time=datetime.datetime(2024, 6, 22, 23, 26, 52, 198243) completion_start_time=datetime.datetime(2024, 6, 22, 23, 26, 52, 198243) model='gpt-3.5-turbo' model_parameters={'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'} usage=Usage(input=10, output=20, total=None, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=5.4999999999999995e-05) prompt_name=None prompt_version=None...
item size 375
item size 860
flushing queue
successfully flushed about 0 items.
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
uploading batch of 2 items
uploading data: {'batch': [{'id': 'a44cc9e3-8b12-4a3f-b8d5-f7a3949ac5c2', 'type': 'trace-create', 'body': {'id': 'litellm-test-b3e968bf-c9cb-4f4d-a834-b0cba57e4695', 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 52, 198564, tzinfo=datetime.timezone.utc), 'name': 'litellm-acompletion', 'userId': 'langfuse_latency_test_user', 'input': 'redacted-by-litellm', 'output': 'redacted-by-litellm', 'tags': []}, 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 52, 198832, tzinfo=datetime.timezone.utc)}, {'id': 'fceda986-a5a6-4e87-b7e6-bf208a2f7589', 'type': 'generation-create', 'body': {'traceId': 'litellm-test-b3e968bf-c9cb-4f4d-a834-b0cba57e4695', 'name': 'litellm-acompletion', 'startTime': datetime.datetime(2024, 6, 22, 23, 26, 52, 197638), 'metadata': {'litellm_response_cost': 5.4999999999999995e-05, 'cache_hit': False}, 'input': 'redacted-by-litellm', 'output': 'redacted-by-litellm', 'level': <ObservationLevel.DEFAULT: 'DEFAULT'>, 'id': 'time-23-26-52-197638_chatcmpl-089072da-028d-4425-ae6d-76e71d21df0d', 'endTime': datetime.datetime(2024, 6, 22, 23, 26, 52, 198243), 'completionStartTime': datetime.datetime(2024, 6, 22, 23, 26, 52, 198243), 'model': 'gpt-3.5-turbo', 'modelParameters': {'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'}, 'usage': {'input': 10, 'output': 20, 'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>, 'totalCost': 5.4999999999999995e-05}}, 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 52, 199379, tzinfo=datetime.timezone.utc)}], 'metadata': {'batch_size': 2, 'sdk_integration': 'default', 'sdk_name': 'python', 'sdk_version': '2.32.0', 'public_key': 'pk-lf-b3db7e8e-c2f6-4fc7-825c-a541a8fbe003'}}
making request: {"batch": [{"id": "a44cc9e3-8b12-4a3f-b8d5-f7a3949ac5c2", "type": "trace-create", "body": {"id": "litellm-test-b3e968bf-c9cb-4f4d-a834-b0cba57e4695", "timestamp": "2024-06-23T06:26:52.198564Z", "name": "litellm-acompletion", "userId": "langfuse_latency_test_user", "input": "redacted-by-litellm", "output": "redacted-by-litellm", "tags": []}, "timestamp": "2024-06-23T06:26:52.198832Z"}, {"id": "fceda986-a5a6-4e87-b7e6-bf208a2f7589", "type": "generation-create", "body": {"traceId": "litellm-test-b3e968bf-c9cb-4f4d-a834-b0cba57e4695", "name": "litellm-acompletion", "startTime": "2024-06-22T23:26:52.197638-07:00", "metadata": {"litellm_response_cost": 5.4999999999999995e-05, "cache_hit": false}, "input": "redacted-by-litellm", "output": "redacted-by-litellm", "level": "DEFAULT", "id": "time-23-26-52-197638_chatcmpl-089072da-028d-4425-ae6d-76e71d21df0d", "endTime": "2024-06-22T23:26:52.198243-07:00", "completionStartTime": "2024-06-22T23:26:52.198243-07:00", "model": "gpt-3.5-turbo", "modelParameters": {"temperature": "0.7", "max_tokens": 5, "user": "langfuse_latency_test_user", "extra_body": "{}"}, "usage": {"input": 10, "output": 20, "unit": "TOKENS", "totalCost": 5.4999999999999995e-05}}, "timestamp": "2024-06-23T06:26:52.199379Z"}], "metadata": {"batch_size": 2, "sdk_integration": "default", "sdk_name": "python", "sdk_version": "2.32.0", "public_key": "pk-lf-b3db7e8e-c2f6-4fc7-825c-a541a8fbe003"}} to https://us.cloud.langfuse.com/api/public/ingestion
~0 items in the Langfuse queue
received response: {"errors":[],"successes":[{"id":"a44cc9e3-8b12-4a3f-b8d5-f7a3949ac5c2","status":201},{"id":"fceda986-a5a6-4e87-b7e6-bf208a2f7589","status":201}]}
successfully uploaded batch of 2 items
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
Getting trace litellm-test-b3e968bf-c9cb-4f4d-a834-b0cba57e4695
~0 items in the Langfuse queue
~0 items in the Langfuse queue
Getting observations... None, None, None, None, litellm-test-b3e968bf-c9cb-4f4d-a834-b0cba57e4695, None, GENERATION
~0 items in the Langfuse queue
`litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
flushing queue
Creating trace id='litellm-test-2a7ed10d-b0aa-41c3-874e-adb2e128a9a6' timestamp=datetime.datetime(2024, 6, 23, 6, 26, 54, 545241, tzinfo=datetime.timezone.utc) name='litellm-acompletion' user_id='langfuse_latency_test_user' input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': 'This is a test response', 'role': 'assistant'} session_id=None release=None version=None metadata=None tags=[] public=None
successfully flushed about 0 items.
Creating generation trace_id='litellm-test-2a7ed10d-b0aa-41c3-874e-adb2e128a9a6' name='litellm-acompletion' start_time=datetime.datetime(2024, 6, 22, 23, 26, 54, 540644) metadata={'litellm_response_cost': 5.4999999999999995e-05, 'cache_hit': False} input={'messages': [{'role': 'user', 'content': 'This is a test'}]} output={'content': 'This is a test response', 'role': 'assistant'} level=<ObservationLevel.DEFAULT: 'DEFAULT'> status_message=None parent_observation_id=None version=None id='time-23-26-54-540644_chatcmpl-5c5777de-9eaf-4515-ad2c-b9a9cf2cfbe5' end_time=datetime.datetime(2024, 6, 22, 23, 26, 54, 543392) completion_start_time=datetime.datetime(2024, 6, 22, 23, 26, 54, 543392) model='gpt-3.5-turbo' model_parameters={'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'} usage=Usage(input=10, output=20, total=None, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=5.4999999999999995e-05) prompt_name=None prompt_version=None...
item size 453
item size 938
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
uploading batch of 2 items
uploading data: {'batch': [{'id': '696d738d-b46a-418f-be31-049e9add4bd8', 'type': 'trace-create', 'body': {'id': 'litellm-test-2a7ed10d-b0aa-41c3-874e-adb2e128a9a6', 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 54, 545241, tzinfo=datetime.timezone.utc), 'name': 'litellm-acompletion', 'userId': 'langfuse_latency_test_user', 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': 'This is a test response', 'role': 'assistant'}, 'tags': []}, 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 54, 545804, tzinfo=datetime.timezone.utc)}, {'id': 'caf378b4-ae86-4a74-a7ac-2f9a83ed9d67', 'type': 'generation-create', 'body': {'traceId': 'litellm-test-2a7ed10d-b0aa-41c3-874e-adb2e128a9a6', 'name': 'litellm-acompletion', 'startTime': datetime.datetime(2024, 6, 22, 23, 26, 54, 540644), 'metadata': {'litellm_response_cost': 5.4999999999999995e-05, 'cache_hit': False}, 'input': {'messages': [{'role': 'user', 'content': 'This is a test'}]}, 'output': {'content': 'This is a test response', 'role': 'assistant'}, 'level': <ObservationLevel.DEFAULT: 'DEFAULT'>, 'id': 'time-23-26-54-540644_chatcmpl-5c5777de-9eaf-4515-ad2c-b9a9cf2cfbe5', 'endTime': datetime.datetime(2024, 6, 22, 23, 26, 54, 543392), 'completionStartTime': datetime.datetime(2024, 6, 22, 23, 26, 54, 543392), 'model': 'gpt-3.5-turbo', 'modelParameters': {'temperature': '0.7', 'max_tokens': 5, 'user': 'langfuse_latency_test_user', 'extra_body': '{}'}, 'usage': {'input': 10, 'output': 20, 'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>, 'totalCost': 5.4999999999999995e-05}}, 'timestamp': datetime.datetime(2024, 6, 23, 6, 26, 54, 547005, tzinfo=datetime.timezone.utc)}], 'metadata': {'batch_size': 2, 'sdk_integration': 'default', 'sdk_name': 'python', 'sdk_version': '2.32.0', 'public_key': 'pk-lf-b3db7e8e-c2f6-4fc7-825c-a541a8fbe003'}}
making request: {"batch": [{"id": "696d738d-b46a-418f-be31-049e9add4bd8", "type": "trace-create", "body": {"id": "litellm-test-2a7ed10d-b0aa-41c3-874e-adb2e128a9a6", "timestamp": "2024-06-23T06:26:54.545241Z", "name": "litellm-acompletion", "userId": "langfuse_latency_test_user", "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "This is a test response", "role": "assistant"}, "tags": []}, "timestamp": "2024-06-23T06:26:54.545804Z"}, {"id": "caf378b4-ae86-4a74-a7ac-2f9a83ed9d67", "type": "generation-create", "body": {"traceId": "litellm-test-2a7ed10d-b0aa-41c3-874e-adb2e128a9a6", "name": "litellm-acompletion", "startTime": "2024-06-22T23:26:54.540644-07:00", "metadata": {"litellm_response_cost": 5.4999999999999995e-05, "cache_hit": false}, "input": {"messages": [{"role": "user", "content": "This is a test"}]}, "output": {"content": "This is a test response", "role": "assistant"}, "level": "DEFAULT", "id": "time-23-26-54-540644_chatcmpl-5c5777de-9eaf-4515-ad2c-b9a9cf2cfbe5", "endTime": "2024-06-22T23:26:54.543392-07:00", "completionStartTime": "2024-06-22T23:26:54.543392-07:00", "model": "gpt-3.5-turbo", "modelParameters": {"temperature": "0.7", "max_tokens": 5, "user": "langfuse_latency_test_user", "extra_body": "{}"}, "usage": {"input": 10, "output": 20, "unit": "TOKENS", "totalCost": 5.4999999999999995e-05}}, "timestamp": "2024-06-23T06:26:54.547005Z"}], "metadata": {"batch_size": 2, "sdk_integration": "default", "sdk_name": "python", "sdk_version": "2.32.0", "public_key": "pk-lf-b3db7e8e-c2f6-4fc7-825c-a541a8fbe003"}} to https://us.cloud.langfuse.com/api/public/ingestion
~0 items in the Langfuse queue
~0 items in the Langfuse queue
received response: {"errors":[],"successes":[{"id":"696d738d-b46a-418f-be31-049e9add4bd8","status":201},{"id":"caf378b4-ae86-4a74-a7ac-2f9a83ed9d67","status":201}]}
successfully uploaded batch of 2 items
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
Getting trace litellm-test-2a7ed10d-b0aa-41c3-874e-adb2e128a9a6
~0 items in the Langfuse queue
Getting observations... None, None, None, None, litellm-test-2a7ed10d-b0aa-41c3-874e-adb2e128a9a6, None, GENERATION
~0 items in the Langfuse queue
joining 1 consumer threads
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
~0 items in the Langfuse queue
consumer thread 0 joined
joining 1 consumer threads
~0 items in the Langfuse queue
~0 items in the Langfuse queue
consumer thread 0 joined
joining 1 consumer threads
~0 items in the Langfuse queue
consumer thread 0 joined
joining 1 consumer threads
~0 items in the Langfuse queue
consumer thread 0 joined
