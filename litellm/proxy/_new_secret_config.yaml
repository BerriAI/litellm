model_list:
- model_name: fake-openai-endpoint
  litellm_params:
    model: openai/my-fake-model
    api_key: my-fake-key
    api_base: https://exampleopenaiendpoint-production.up.railway.app/

litellm_settings:
  cache: true
  cache_params:
    type: redis

general_settings:
  master_key: sk-1234
  proxy_batch_write_at: 60 # ðŸ‘ˆ Frequency of batch writing logs to server (in seconds)
  enable_jwt_auth: True
  alerting: ["slack"]
  litellm_jwtauth:
    admin_jwt_scope: "litellm_proxy_admin"
    team_jwt_scope: "litellm_team" 
    public_key_ttl: 600