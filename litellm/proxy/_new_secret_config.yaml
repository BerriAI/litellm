general_settings:
  store_model_in_db: true
  database_connection_pool_limit: 20

model_list:
  - model_name: fake-openai-endpoint
    litellm_params:
      model: openai/my-fake-model
      api_key: my-fake-key
      api_base: https://exampleopenaiendpoint-production.up.railway.app/
litellm_settings:
  drop_params: True
  success_callback: ["prometheus"]
  failure_callback: ["prometheus"]
  service_callback: ["prometheus_system"]
  _langfuse_default_tags: ["user_api_key_alias", "user_api_key_user_id", "user_api_key_user_email", "user_api_key_team_alias", "semantic-similarity", "proxy_base_url"]

router_settings:
  routing_strategy: "latency-based-routing"
  routing_strategy_args: {"ttl": 86400} # Average the last 10 calls to compute avg latency per model
  allowed_fails: 1
  num_retries: 3
  retry_after: 5 # seconds to wait before retrying a failed request
  cooldown_time: 30 # seconds to cooldown a deployment after failure
