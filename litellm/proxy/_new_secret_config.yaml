model_list:
  # At least one model must exist for the proxy to start.
  - model_name: gpt-4o
    litellm_params:
      model: gpt-4o
      api_key: os.environ/OPENAI_API_KEY
      # timeout: 0.1                      # timeout in (seconds)
      # stream_timeout: 0.01              # timeout for stream requests (seconds)
  - model_name: anthropic.claude-3-5-sonnet-20241022-v2:0
    litellm_params:
      model: bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0
  - model_name: nova-lite
    litellm_params:
      model: bedrock/us.amazon.nova-lite-v1:0
  - model_name: llama3-2-11b-instruct-v1:0
    litellm_params:
      model: bedrock/us.meta.llama3-2-11b-instruct-v1:0
  - model_name: gpt-4o-bad
    litellm_params:
      model: gpt-4o
      api_key: bad
  - model_name: "bedrock/*"
    litellm_params:
      model: "bedrock/*"
  - model_name: "openai/*"
    litellm_params:
      model: "openai/*"
      api_key: os.environ/OPENAI_API_KEY
general_settings:
  store_model_in_db: true
  disable_prisma_schema_update: true
#   master_key: os.environ/LITELLM_MASTER_KEY
litellm_settings:
  fallbacks: [{"gpt-4o-bad": ["gpt-4o"]}] #, {"gpt-4o": ["nova-lite"]}]
  request_timeout: 600    # raise Timeout error if call takes longer than 600 seconds. Default value is 6000seconds if not set
  # set_verbose: false      # Switch off Debug Logging, ensure your logs do not have any debugging on
  # json_logs: true         # Get debug logs in json format
  ssl_verify: true
  callbacks: ["prometheus", "amberflo"]
  service_callback: ["prometheus_system"]
  turn_off_message_logging: true  # turn off messages in otel
  #callbacks: ["langfuse"]
  redact_user_api_key_info: true