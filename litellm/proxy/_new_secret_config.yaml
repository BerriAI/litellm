model_list:
  - model_name: azure-ai-mistral
    litellm_params:
      api_base: os.environ/AZURE_AI_MISTRAL_API_BASE
      api_key: os.environ/AZURE_AI_MISTRAL_API_KEY
      model: azure_ai/Mistral-large-nmefg
      input_cost_per_token: 0.00001
      output_cost_per_token: 0.000004
  - model_name: azure-ai-phi
    litellm_params:
      api_base: os.environ/AZURE_AI_PHI_API_BASE
      api_key: os.environ/AZURE_AI_PHI_API_KEY
      model: azure_ai/Phi-3-medium-128k-instruct-fpmvj
  - model_name: azure-ai-jamba-instruct
    litellm_params:
      api_base: "https://AI21-Jamba-Instruct-jpddv.eastus2.models.ai.azure.com"
      api_key: "WJkvJneEcBMhFqK8zZBaAVw9cl4Ec5Pb"
      model: azure_ai/jamba-instruct


general_settings:
  alerting_threshold: 10
  master_key: sk-1234
  pass_through_endpoints:
    - path: "/v1/test-messages"                                  # route you want to add to LiteLLM Proxy Server
      target: litellm.adapters.anthropic_adapter.anthropic_adapter          # URL this route should forward requests to
      headers:                                            # headers to forward to this URL
        litellm_user_api_key: "x-my-test-key"