model_list:
  - model_name: azure-embedding-model
    litellm_params:
      model: azure/azure-embedding-model
      api_key: os.environ/AZURE_API_KEY
      api_base: os.environ/AZURE_API_BASE
  - model_name: openai-text-completion
    litellm_params:
      model: openai/gpt-3.5-turbo
      api_key: os.environ/OPENAI_API_KEY
  - model_name: chatbot_actions
    litellm_params:
      model: langfuse/gpt-3.5-turbo
      api_key: os.environ/OPENAI_API_KEY
      tpm: 1000000
      prompt_id: "jokes"
  - model_name: openai-deepseek
    litellm_params:
      model: deepseek/deepseek-chat
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      access_groups: ["restricted-models"]
      custom_tokenizer: 
        identifier: deepseek-ai/DeepSeek-V3-Base
        revision: main
        auth_token: os.environ/HUGGINGFACE_API_KEY
  - model_name: watsonx/ibm/granite-13b-chat-v2 # tried to keep original name for backwards compatibility but I've also tried watsonx_text
    litellm_params: 
      model: watsonx_text/ibm/granite-13b-chat-v2
    model_info:
      input_cost_per_token: 0.0000006
      output_cost_per_token: 0.0000006
  

litellm_settings:
  success_callback: ["s3"]
  enable_preview_features: true
  s3_callback_params:
    s3_bucket_name: my-new-test-bucket-litellm   # AWS Bucket Name for S3
    s3_region_name: us-west-2              # AWS Region Name for S3
    s3_aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID  # us os.environ/<variable name> to pass environment variables. This is AWS Access Key ID for S3
    s3_aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY  # AWS Secret Access Key for S3
    s3_use_team_prefix: true

