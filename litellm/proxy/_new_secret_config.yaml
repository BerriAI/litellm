model_list:
- model_name: fake-openai-endpoint
  litellm_params:
    model: openai/my-fake-model
    api_key: my-fake-key
    api_base: https://openai-function-calling-workers.tasslexyz.workers.dev/
    stream_timeout: 0.001
    rpm: 10
- litellm_params:
      model: azure/chatgpt-v-2
      api_base: os.environ/AZURE_API_BASE
      api_key: os.environ/AZURE_API_KEY
      api_version: "2023-07-01-preview"
      stream_timeout: 0.001
  model_name: azure-gpt-3.5
- model_name: text-embedding-ada-002
  litellm_params:
    model: text-embedding-ada-002
    api_key: os.environ/OPENAI_API_KEY
- model_name: gpt-instruct
  litellm_params:
    model: gpt-3.5-turbo-instruct
    # api_key: my-fake-key
    # api_base: https://exampleopenaiendpoint-production.up.railway.app/

litellm_settings:
  success_callback: ["prometheus"]
  upperbound_key_generate_params: 
    max_budget: os.environ/LITELLM_UPPERBOUND_KEYS_MAX_BUDGET

router_settings:
  routing_strategy: usage-based-routing-v2 
  redis_host: os.environ/REDIS_HOST
  redis_password: os.environ/REDIS_PASSWORD
  redis_port: os.environ/REDIS_PORT
  enable_pre_call_checks: True

general_settings:
  master_key: sk-1234
  allow_user_auth: true
  alerting: ["slack"]
  # store_model_in_db: True // set via environment variable - os.environ["STORE_MODEL_IN_DB"] = "True"
  proxy_batch_write_at: 5 # ðŸ‘ˆ Frequency of batch writing logs to server (in seconds)
  enable_jwt_auth: True
  alerting: ["slack"]
  litellm_jwtauth:
    admin_jwt_scope: "litellm_proxy_admin"
    public_key_ttl: os.environ/LITELLM_PUBLIC_KEY_TTL
    user_id_jwt_field: "sub"
    org_id_jwt_field: "azp"