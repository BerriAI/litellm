model_list:
  - model_name: azure-embedding-model
    litellm_params:
      model: azure/azure-embedding-model
      api_key: os.environ/AZURE_API_KEY
      api_base: os.environ/AZURE_API_BASE
  - model_name: openai-text-completion
    litellm_params:
      model: openai/gpt-3.5-turbo
      api_key: os.environ/OPENAI_API_KEY
  - model_name: chatbot_actions
    litellm_params:
      model: langfuse/gpt-3.5-turbo
      api_key: os.environ/OPENAI_API_KEY
      tpm: 1000000
      prompt_id: "jokes"
  - model_name: openai-deepseek
    litellm_params:
      model: deepseek/deepseek-chat
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      access_groups: ["restricted-models"]
      custom_tokenizer: 
        identifier: deepseek-ai/DeepSeek-V3-Base
        revision: main
        auth_token: os.environ/HUGGINGFACE_API_KEY
  - model_name: watsonx/ibm/granite-13b-chat-v2 # tried to keep original name for backwards compatibility but I've also tried watsonx_text
    litellm_params: 
      model: watsonx_text/ibm/granite-13b-chat-v2
    model_info:
      input_cost_per_token: 0.0000006
      output_cost_per_token: 0.0000006

# litellm_settings:
#   key_generation_settings:
#     personal_key_generation: # maps to 'Default Team' on UI 
#       allowed_user_roles: ["proxy_admin"]

