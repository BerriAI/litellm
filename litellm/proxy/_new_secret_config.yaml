model_list:
  - model_name: claude-3-5-sonnet             # all requests where model not in your config go to this deployment
    litellm_params:
      model: "openai/*"
      mock_response: "litellm.RateLimitError"