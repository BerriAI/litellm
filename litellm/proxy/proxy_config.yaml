model_list:
  - model_name: db-openai-endpoint
    litellm_params:
      model: openai/fake
      api_key: fake-key
      api_base: https://exampleopenaiendpoint-production.up.railway.app/
      rpm: 100
  - model_name: openai/*
    litellm_params:
      model: openai/*



# Litellm settings
litellm_settings:
  callbacks: ["prometheus", "dynamic_rate_limiter_v3"]
  priority_reservation: {"dev": 0.1, "prod": 0.9}
  set_verbose: true  # Enable debug logging to see priority allocation

general_settings:
  store_prompts_in_spend_logs: true