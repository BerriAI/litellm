model_list:
- litellm_params:
    api_base: https://openai-function-calling-workers.tasslexyz.workers.dev/
    api_key: my-fake-key
    model: openai/my-fake-model
  model_name: fake-openai-endpoint
- litellm_params:
    api_base: https://openai-function-calling-workers.tasslexyz.workers.dev/
    api_key: my-fake-key-2
    model: openai/my-fake-model-2
  model_name: fake-openai-endpoint
- litellm_params:
    api_base: https://openai-function-calling-workers.tasslexyz.workers.dev/
    api_key: my-fake-key-3
    model: openai/my-fake-model-3
  model_name: fake-openai-endpoint
- model_name: gpt-4
  litellm_params:
    model: gpt-3.5-turbo
- litellm_params:
    model: together_ai/codellama/CodeLlama-13b-Instruct-hf
  model_name: CodeLlama-13b-Instruct

router_settings:
  redis_host: redis
  # redis_password: <your redis password>
  redis_port: 6379

litellm_settings:
  set_verbose: True
  # service_callback: ["prometheus_system"]
  # success_callback: ["prometheus"]
  # failure_callback: ["prometheus"]

general_settings:
  enable_jwt_auth: True
  disable_reset_budget: True
  proxy_batch_write_at: 60 # ðŸ‘ˆ Frequency of batch writing logs to server (in seconds)
  routing_strategy: simple-shuffle # Literal["simple-shuffle", "least-busy", "usage-based-routing","latency-based-routing"], default="simple-shuffle"