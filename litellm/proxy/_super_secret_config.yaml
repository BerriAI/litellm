environment_variables:
  SLACK_WEBHOOK_URL: SQD2/FQHvDuj6Q9/Umyqi+EKLNKKLRCXETX2ncO0xCIQp6EHCKiYD7jPW0+1QdrsQ+pnEzhsfVY2r21SiQV901n/9iyJ2tSnEyWViP7FKQVtTvwutsAqSqbiVHxLHbpjPCu03fhS/idjZrtK7dJLbLBB3RgudjNjHg==
general_settings:
  alerting:
  - slack
  alerting_threshold: 300
  database_connection_pool_limit: 100
  database_connection_timeout: 60
  health_check_interval: 300
  proxy_batch_write_at: 10
  ui_access_mode: all
litellm_settings:
  allowed_fails: 3
  failure_callback:
  - prometheus
  fallbacks:
  - gpt-3.5-turbo:
    - fake-openai-endpoint
    - gpt-4
  num_retries: 3
  service_callback:
  - prometheus_system
  success_callback:
  - prometheus
model_list:
- litellm_params:
    api_base: https://openai-function-calling-workers.tasslexyz.workers.dev/
    api_key: my-fake-key
    model: openai/my-fake-model
  model_name: fake-openai-endpoint
- litellm_params:
    model: gpt-3.5-turbo
  model_name: gpt-3.5-turbo
- model_name: llama-3
  litellm_params:
    model: replicate/meta/meta-llama-3-8b-instruct
router_settings:
  allowed_fails: 3
  context_window_fallbacks: null
  cooldown_time: 1
  fallbacks:
  - gpt-3.5-turbo:
    - fake-openai-endpoint
    - gpt-4
  - gpt-3.5-turbo-3:
    - fake-openai-endpoint
  num_retries: 3
  retry_after: 0
  routing_strategy: simple-shuffle
  routing_strategy_args: {}
  timeout: 6000
