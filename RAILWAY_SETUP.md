# üöÄ Deploy LiteLLM na Railway (1 Container + SQLite)

## Configura√ß√£o Super Simples

### 1Ô∏è‚É£ Vari√°veis de Ambiente na Railway

Adicione estas 3 vari√°veis no seu servi√ßo Railway:

```bash
LITELLM_MASTER_KEY=sk-1234567890
LITELLM_SALT_KEY=change-this-to-a-random-string-min-32-chars
DATABASE_URL=file:./local.db
```

**Importante:**
- `LITELLM_MASTER_KEY`: Use qualquer chave que comece com `sk-` (ser√° sua senha de API)
- `LITELLM_SALT_KEY`: Use uma string aleat√≥ria de pelo menos 32 caracteres
- `DATABASE_URL`: Deixe como `file:./local.db` para usar SQLite

### 2Ô∏è‚É£ Deploy

A Railway vai:
- Detectar o `Dockerfile` automaticamente
- Buildar a imagem
- Expor a porta 4000
- Iniciar o servidor

### 3Ô∏è‚É£ Testando

Ap√≥s o deploy, pegue a URL do seu app (ex: `https://seu-app.up.railway.app`) e teste:

**Health Check:**
```bash
curl https://seu-app.up.railway.app/health/liveliness
```

**Acessar Dashboard:**
```
https://seu-app.up.railway.app/ui
```

### 4Ô∏è‚É£ Adicionar modelos (Opcional)

Para testar com modelos reais, adicione mais vari√°veis de ambiente:

```bash
# Para usar OpenAI
OPENAI_API_KEY=sk-sua-chave-openai

# Para usar Anthropic
ANTHROPIC_API_KEY=sk-ant-sua-chave
```

Depois, adicione modelos pelo dashboard UI ou fa√ßa uma chamada direto:

```bash
curl https://seu-app.up.railway.app/chat/completions \
  -H "Authorization: Bearer sk-1234567890" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

## üéØ Resumo

1. Conecte o reposit√≥rio na Railway
2. Adicione as 3 vari√°veis de ambiente
3. Deploy autom√°tico
4. Acesse `/ui` para configurar

**Pronto!** üéâ
