#!/usr/bin/env python3
"""
Detailed demo showing streaming ID consistency fix with exact output format.

This shows the same streaming format you demonstrated, highlighting that
streaming chunks now have properly encoded resp_ IDs.
"""

import os
import sys
import base64
import json
from openai import OpenAI

def decode_response_id(response_id):
    """Decode a litellm response ID to show its contents"""
    if response_id.startswith("resp_"):
        encoded_part = response_id[5:]  # Remove "resp_" prefix
        try:
            decoded = base64.b64decode(encoded_part).decode('utf-8')
            return decoded
        except Exception as e:
            return f"Could not decode: {e}"
    return "Not an encoded response ID"

def main():
    print("ü§ñ Streaming ID Consistency Fix - Detailed Demo")
    print("=" * 60)
    
    # Set up client
    client = OpenAI(api_key="sk-1234", base_url="http://localhost:4000")
    
    print("\nüì§ Request:")
    request_example = {
        "model": "gemini-1.5-flash",
        "input": [
            {
                "role": "user",
                "content": "Hi",
                "type": "message"
            }
        ],
        "stream": True,
        "litellm_trace_id": "demo-trace-id"
    }
    print(json.dumps(request_example, indent=2))
    
    print(f"\nüì° Responses:")
    
    try:
        # Make streaming request
        stream = client.responses.create(
            model="gemini-1.5-flash",
            input="Hi",
            stream=True
        )
        
        encoded_ids = []
        
        for chunk in stream:
            if hasattr(chunk, 'item_id'):
                # Show the streaming chunk in the same format as your example
                chunk_data = {
                    "type": chunk.type,
                    "item_id": chunk.item_id,
                    "output_index": chunk.output_index,
                    "content_index": chunk.content_index,
                    "delta": chunk.delta
                }
                print(f'data: {json.dumps(chunk_data)}')
                
                # Track the encoded ID
                encoded_ids.append(chunk.item_id)
                
            elif hasattr(chunk, 'response'):
                # Show the final response
                response_data = {
                    "type": chunk.type,
                    "response": {
                        "id": chunk.response.id,
                        "created_at": chunk.response.created_at,
                        "model": chunk.response.model,
                        "status": chunk.response.status,
                        # Simplified for demo
                        "output": [{"type": "message", "content": "Response content"}]
                    }
                }
                print(f'data: {json.dumps(response_data)}')
                
        print(f'data: [DONE]')
        
        # Analysis
        print(f"\nüìä Analysis:")
        print(f"   - Total streaming chunks: {len(encoded_ids)}")
        
        if encoded_ids:
            print(f"   - Example encoded ID: {encoded_ids[0]}")
            print(f"   - Decoded content: {decode_response_id(encoded_ids[0])}")
            
            # Check if all IDs are properly encoded
            all_encoded = all(id.startswith("resp_") for id in encoded_ids)
            print(f"   - All IDs properly encoded: {'‚úÖ' if all_encoded else '‚ùå'}")
            
            # Show the key insight
            print(f"\nüîç Key Insight:")
            print(f"   Before your fix: item_id would be raw like 'chunk-123-from-gemini'")
            print(f"   After your fix:  item_id is encoded like 'resp_bGl0ZWxsbTpjdXN0b21fbGxtX3Byb3ZpZGVyOmdlbWluaS4uLic='")
            print(f"   This ensures consistency between streaming and non-streaming responses!")
        
        print(f"\nüéâ Your streaming ID consistency fix is working perfectly!")
        
    except Exception as e:
        print(f"‚ùå Demo failed: {e}")
        print(f"\nüîß To run this demo:")
        print(f"   1. Start proxy: GOOGLE_API_KEY=your_key python3 litellm/proxy/proxy_cli.py --config proxy_server_config.yaml --port 4000")
        print(f"   2. Run demo: python3 demo_streaming_detailed.py")

if __name__ == "__main__":
    main()